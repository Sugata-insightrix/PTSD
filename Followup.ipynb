{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1023c4a7-a378-4ac2-a88e-fecc9a59d765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: C:\\Windows\\System32\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "path = os.getcwd()\n",
    "print(\"Current directory:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d11789-0791-4756-b0f1-6142b2653f27",
   "metadata": {},
   "source": [
    "# DML:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6c90a93-4b16-4ed0-b2e7-985448b2fdb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed to: D:\\Work\\PTSD_Followup\\DML\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")  # optional\n",
    "\n",
    "# Option 1 (recommended)\n",
    "new_path = r\"D:\\Work\\PTSD_Followup\\DML\"\n",
    "\n",
    "os.chdir(new_path)  # Change working directory\n",
    "print(\"Changed to:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b2ef094-c824-4279-b898-719c211cc4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(r\"data_baseline.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d590acf7-a693-4000-8042-e96cddf95f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values summary:\n",
      "DIAGNOSIS_PSYCHOTIC_missing: 2484\n",
      "DIAGNOSIS_ANXIETY_OCD_missing: 2484\n",
      "Bipolar_and_Mood_disorder_missing: 2484\n",
      "DIAGNOSIS_EATING_DISORDER_missing: 2484\n",
      "total_rows: 6125\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Check missing values for each variable\n",
    "missing_summary = {\n",
    "    'DIAGNOSIS_PSYCHOTIC_missing': df['DIAGNOSIS_PSYCHOTIC'].isna().sum(),\n",
    "    'DIAGNOSIS_ANXIETY_OCD_missing': df['DIAGNOSIS_ANXIETY_OCD'].isna().sum(),\n",
    "    'Bipolar_and_Mood_disorder_missing': df['Bipolar_and_Mood_disorder'].isna().sum(),\n",
    "    'DIAGNOSIS_EATING_DISORDER_missing': df['DIAGNOSIS_EATING_DISORDER'].isna().sum(),\n",
    "    'total_rows': len(df)\n",
    "}\n",
    "\n",
    "print(\"Missing values summary:\")\n",
    "for key, value in missing_summary.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56024911-29cb-4f8b-993f-c1bd2223f19b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing data pattern:\n",
      "has_missing\n",
      "False    3641\n",
      "True     2484\n",
      "Name: count, dtype: int64\n",
      "Patients with missing data: 2484\n",
      "Patients with complete data: 3641\n"
     ]
    }
   ],
   "source": [
    "# Define the mental health variables\n",
    "mental_health_vars = ['DIAGNOSIS_PSYCHOTIC', 'DIAGNOSIS_ANXIETY_OCD', \n",
    "                      'Bipolar_and_Mood_disorder', 'DIAGNOSIS_EATING_DISORDER']\n",
    "\n",
    "# Check patients with missing data on any of the 4 variables\n",
    "df['has_missing'] = df[mental_health_vars].isna().any(axis=1)\n",
    "\n",
    "# Summary of missing pattern\n",
    "print(\"\\nMissing data pattern:\")\n",
    "print(df['has_missing'].value_counts())\n",
    "print(f\"Patients with missing data: {df['has_missing'].sum()}\")\n",
    "print(f\"Patients with complete data: {(~df['has_missing']).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35c8499f-923c-41f2-b652-3f73e7694412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset summary:\n",
      "Original dataset: 6125 observations\n",
      "Complete cases: 3641 observations\n",
      "Excluded (missing): 2484 observations\n"
     ]
    }
   ],
   "source": [
    "# Store original count before filtering\n",
    "original_count = len(df)\n",
    "\n",
    "# Filter to keep only complete cases (this modifies df)\n",
    "df = df.dropna(subset=mental_health_vars)\n",
    "\n",
    "# Get the count after filtering\n",
    "complete_count = len(df)\n",
    "\n",
    "# Calculate excluded count\n",
    "excluded_count = original_count - complete_count\n",
    "\n",
    "# Verify the counts\n",
    "print(f\"\\nDataset summary:\")\n",
    "print(f\"Original dataset: {original_count} observations\")\n",
    "print(f\"Complete cases: {complete_count} observations\")\n",
    "print(f\"Excluded (missing): {excluded_count} observations\")\n",
    "\n",
    "# Remove the temporary column (if it exists)\n",
    "if 'has_missing' in df.columns:\n",
    "    df = df.drop('has_missing', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7b06ffb-57fe-4c65-ab21-abcc8b612e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values in mental health variables:\n",
      "DIAGNOSIS_PSYCHOTIC: 0\n",
      "DIAGNOSIS_ANXIETY_OCD: 0\n",
      "Bipolar_and_Mood_disorder: 0\n",
      "DIAGNOSIS_EATING_DISORDER: 0\n"
     ]
    }
   ],
   "source": [
    "# Check the 4 variables you filtered on (should be 0 missing)\n",
    "mental_health_vars = ['DIAGNOSIS_PSYCHOTIC', 'DIAGNOSIS_ANXIETY_OCD', \n",
    "                      'Bipolar_and_Mood_disorder', 'DIAGNOSIS_EATING_DISORDER']\n",
    "\n",
    "print(f\"\\nMissing values in mental health variables:\")\n",
    "for var in mental_health_vars:\n",
    "    missing = df[var].isnull().sum()\n",
    "    print(f\"{var}: {missing}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7383c16b-bf42-43cd-9e4b-3db434a0a41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CAT_ columns: 23\n",
      "Number of SUBCAT_ columns: 42\n",
      "Number of SubSubCat_ columns: 243\n",
      "✅ Exported to 'category_column_sums.xlsx'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 1: Identify columns by prefix\n",
    "cat_cols = [col for col in df.columns if col.startswith('CAT_')]\n",
    "subcat_cols = [col for col in df.columns if col.startswith('SUBCAT_')]\n",
    "subsubcat_cols = [col for col in df.columns if col.startswith('SubSubCat_')]\n",
    "\n",
    "# Step 2: Print counts\n",
    "print(f\"Number of CAT_ columns: {len(cat_cols)}\")\n",
    "print(f\"Number of SUBCAT_ columns: {len(subcat_cols)}\")\n",
    "print(f\"Number of SubSubCat_ columns: {len(subsubcat_cols)}\")\n",
    "\n",
    "# Step 3: Column-wise sums\n",
    "cat_sums = df[cat_cols].sum().sort_values(ascending=False)\n",
    "subcat_sums = df[subcat_cols].sum().sort_values(ascending=False)\n",
    "subsubcat_sums = df[subsubcat_cols].sum().sort_values(ascending=False)\n",
    "\n",
    "# Step 4: Convert to DataFrames\n",
    "cat_df = cat_sums.reset_index()\n",
    "cat_df.columns = ['Column', 'Sum']\n",
    "\n",
    "subcat_df = subcat_sums.reset_index()\n",
    "subcat_df.columns = ['Column', 'Sum']\n",
    "\n",
    "subsubcat_df = subsubcat_sums.reset_index()\n",
    "subsubcat_df.columns = ['Column', 'Sum']\n",
    "\n",
    "# Step 5: Write to Excel\n",
    "with pd.ExcelWriter(\"category_column_sums.xlsx\") as writer:\n",
    "    cat_df.to_excel(writer, sheet_name=\"CAT_Sums\", index=False)\n",
    "    subcat_df.to_excel(writer, sheet_name=\"SUBCAT_Sums\", index=False)\n",
    "    subsubcat_df.to_excel(writer, sheet_name=\"SubSubCat_Sums\", index=False)\n",
    "\n",
    "print(\"✅ Exported to 'category_column_sums.xlsx'\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "860bb20c-6e42-4336-b4d7-cfbd5e31cd56",
   "metadata": {},
   "source": [
    "These below CAT, SUBCAT, and SubSubCat are do not have more than 30 treatment groups.\n",
    "Hence, we will not consider these onces.\n",
    "\n",
    "CAT_Anticonceptiva\n",
    "CAT_Immunomodulerende_middelen\n",
    "CAT_Migrainemiddelen\n",
    "CAT_Stemmingsstabilisatoren\n",
    "CAT_Salicylaat\n",
    "CAT_Alcoholverslaving\n",
    "CAT_Spierrelaxantia\n",
    "CAT_Parkinson\n",
    "\n",
    "\n",
    "SUBCAT_Anticonceptiva_klassiek\n",
    "SUBCAT_Anti_epileptica_GABA_analogon\n",
    "SUBCAT_Antipsychotica_Klassiek\n",
    "SUBCAT_calciumantagonisten\n",
    "SUBCAT_Paracetamol_overig_combinatie\n",
    "SUBCAT_stemm_Lithiumzouten\n",
    "SUBCAT_ACE_remmer\n",
    "SUBCAT_Paracetamol_salycilaat_combinatiepreparaat\n",
    "SUBCAT_Corticosteroiden\n",
    "SUBCAT_Anti_epileptica_Benzodiazepine\n",
    "SUBCAT_psychostimulans_overige\n",
    "SUBCAT_Anti_epileptica_overig\n",
    "SUBCAT_Immunomodulerend_Coxibs\n",
    "SUBCAT_Interleukine_remmers\n",
    "SUBCAT_Clonidine\n",
    "SUBCAT_TNF_alpha_blockers\n",
    "SUBCAT_Antihypertensiva_ARBs\n",
    "SUBCAT_Aminosalicylaten\n",
    "SUBCAT_Selectieve_immunosuppresiva\n",
    "SUBCAT_MAO_remmers\n",
    "SUBCAT_stemm_benzamide\n",
    "SUBCAT_Antihypertensiva_centraal_aangrijpend\n",
    "SUBCAT_DMARDs\n",
    "SUBCAT_calcineurineremmers\n",
    "SUBCAT_ADHD_klassiek\n",
    "SUBCAT_Combinatiepreparaten\n",
    "SUBCAT_Systemische_betablokkers\n",
    "\n",
    "\n",
    "\n",
    "SubSubCat_Nortriptyline\n",
    "SubSubCat_pil\n",
    "SubSubCat_Aripiprazol\n",
    "SubSubCat_Dexamfetamine\n",
    "SubSubCat_Pregabaline\n",
    "SubSubCat_Trazodon\n",
    "SubSubCat_Oxycodon\n",
    "SubSubCat_Diclofenac\n",
    "SubSubCat_Risperidon\n",
    "SubSubCat_Metoprolol\n",
    "SubSubCat_Naproxen\n",
    "SubSubCat_Antidepressiva_overige\n",
    "SubSubCat_Ibuprofen\n",
    "SubSubCat_Morfine\n",
    "SubSubCat_Desloratadine\n",
    "SubSubCat_Lithium\n",
    "SubSubCat_Paracetamol_ascorbinezuur\n",
    "SubSubCat_Duloxetine\n",
    "SubSubCat_Amlodipine\n",
    "SubSubCat_Fluvoxamine\n",
    "SubSubCat_Acrivastine\n",
    "SubSubCat_Propranolol\n",
    "SubSubCat_Haloperidol\n",
    "SubSubCat_Valproïnezuur\n",
    "SubSubCat_Lamotrigine\n",
    "SubSubCat_Pipamperon\n",
    "SubSubCat_Clomipramine\n",
    "SubSubCat_Lormetazepam\n",
    "SubSubCat_Midazolam\n",
    "SubSubCat_Clonazepam\n",
    "SubSubCat_Fexofenadine\n",
    "SubSubCat_Levocetirizine\n",
    "SubSubCat_Nicardipine\n",
    "SubSubCat_Acetylsalicylzuur_paracetamol_coffeïne\n",
    "SubSubCat_Pethidine\n",
    "SubSubCat_Fentanyl\n",
    "SubSubCat_Atomoxetine\n",
    "SubSubCat_Prazepam\n",
    "SubSubCat_Doxepine\n",
    "SubSubCat_Enalapril\n",
    "SubSubCat_Gabapentine\n",
    "SubSubCat_Loratadine\n",
    "SubSubCat_Bisoprolol\n",
    "SubSubCat_Nitrazepam\n",
    "SubSubCat_Cetirizine\n",
    "SubSubCat_Levetiracetam\n",
    "SubSubCat_clonidine\n",
    "SubSubCat_celecoxib\n",
    "SubSubCat_Etoricoxib\n",
    "SubSubCat_Buspiron\n",
    "SubSubCat_Lisinopril\n",
    "SubSubCat_Prednison\n",
    "SubSubCat_Ustekinumab\n",
    "SubSubCat_Meclozine\n",
    "SubSubCat_Perindopril\n",
    "SubSubCat_Maprotiline\n",
    "SubSubCat_Flurazepam\n",
    "SubSubCat_chloorprotixeen\n",
    "SubSubCat_Imipramine\n",
    "SubSubCat_Vedolizumab\n",
    "SubSubCat_Ebastine\n",
    "SubSubCat_Clorazepinezuur\n",
    "SubSubCat_Clozapine\n",
    "SubSubCat_Sertindol\n",
    "SubSubCat_Carbamazepine\n",
    "SubSubCat_Prednisolon\n",
    "SubSubCat_Antihypertensiva_ARBs\n",
    "SubSubCat_Rupatadine\n",
    "SubSubCat_Mesalazine\n",
    "SubSubCat_Nabumeton\n",
    "SubSubCat_Nebivolol\n",
    "SubSubCat_Vigabatrine\n",
    "SubSubCat_Eculizumab\n",
    "SubSubCat_Certolizumab_pegol\n",
    "SubSubCat_Adalimumab\n",
    "SubSubCat_Tocilizumab\n",
    "SubSubCat_safinamide\n",
    "SubSubCat_Hydrocortison\n",
    "SubSubCat_Ramipril\n",
    "SubSubCat_Methylprednisolon\n",
    "SubSubCat_Satralizumab\n",
    "SubSubCat_Sulpiride\n",
    "SubSubCat_Moclobemide\n",
    "SubSubCat_Clevidipine\n",
    "SubSubCat_Atenolol\n",
    "SubSubCat_Dupilumab\n",
    "SubSubCat_Clemastine\n",
    "SubSubCat_Brivaracetam\n",
    "SubSubCat_Lercanidipine\n",
    "SubSubCat_Etanercept\n",
    "SubSubCat_Meloxicam\n",
    "SubSubCat_Nifedipine\n",
    "SubSubCat_Fosinopril\n",
    "SubSubCat_Infliximab\n",
    "SubSubCat_Barnidipine\n",
    "SubSubCat_Tofacitinib\n",
    "SubSubCat_Mycofenolaatmofetil\n",
    "SubSubCat_Mycofenolzuur\n",
    "SubSubCat_Ravulizumab\n",
    "SubSubCat_Sirolimus\n",
    "SubSubCat_Thymocytenglobuline\n",
    "SubSubCat_Anakinra\n",
    "SubSubCat_Upadacitinib\n",
    "SubSubCat_Basiliximab\n",
    "SubSubCat_Bimekizumab\n",
    "SubSubCat_Leflunomide\n",
    "SubSubCat_Canakinumab\n",
    "SubSubCat_Guselkumab\n",
    "SubSubCat_Brodalumab\n",
    "SubSubCat_Apremilast\n",
    "SubSubCat_Filgotinib\n",
    "SubSubCat_Everolimus\n",
    "SubSubCat_Belimumab\n",
    "SubSubCat_Belatacept\n",
    "SubSubCat_Baricitinib\n",
    "SubSubCat_Abatacept\n",
    "SubSubCat_Golimumab\n",
    "SubSubCat_Olsalazine\n",
    "SubSubCat_Sulfasalazine\n",
    "SubSubCat_Thalidomide\n",
    "SubSubCat_Pomalidomide\n",
    "SubSubCat_Pirfenidon\n",
    "SubSubCat_Risankizumab\n",
    "SubSubCat_Lenalidomide\n",
    "SubSubCat_Ixekizumab\n",
    "SubSubCat_Aceclofenac\n",
    "SubSubCat_Sarilumab\n",
    "SubSubCat_Secukinumab\n",
    "SubSubCat_Methotrexaat\n",
    "SubSubCat_Corticosteroiden\n",
    "SubSubCat_hypnotica_Benzodiazepine\n",
    "SubSubCat_Paracetamol_propyfenazon_coffeïne\n",
    "SubSubCat_Paracetamol_coffeïne_ascorbinezuur\n",
    "SubSubCat_Paracetamol_coffeïne\n",
    "SubSubCat_Tiaprofeenzuur\n",
    "SubSubCat_Piroxicam\n",
    "SubSubCat_Metamizol\n",
    "SubSubCat_Indometacine\n",
    "SubSubCat_Flurbiprofen\n",
    "SubSubCat_Fenylbutazon\n",
    "SubSubCat_Dexketoprofen\n",
    "SubSubCat_Tapentadol\n",
    "SubSubCat_Sufentanil\n",
    "SubSubCat_Remifentanil\n",
    "SubSubCat_Piritramide\n",
    "SubSubCat_Nalbufine\n",
    "SubSubCat_Hydromorfon\n",
    "SubSubCat_Buprenorfine\n",
    "SubSubCat_Alfentanil\n",
    "SubSubCat_Tacrolimus\n",
    "SubSubCat_Pimecrolimus\n",
    "SubSubCat_Ciclosporine\n",
    "SubSubCat_Tralokinumab\n",
    "SubSubCat_Tildrakizumab\n",
    "SubSubCat_Siltuximab\n",
    "SubSubCat_Azathioprine\n",
    "SubSubCat_fluspirileen\n",
    "SubSubCat_Parecoxib\n",
    "SubSubCat_Bromazepam\n",
    "SubSubCat_Primidon\n",
    "SubSubCat_Perampanel\n",
    "SubSubCat_Oxcarbazepine\n",
    "SubSubCat_Lacosamide\n",
    "SubSubCat_Fenobarbital\n",
    "SubSubCat_Felbamaat\n",
    "SubSubCat_Ethosuximide\n",
    "SubSubCat_Chloralhydraat\n",
    "SubSubCat_Fenytoïne\n",
    "SubSubCat_Remimazolam\n",
    "SubSubCat_Flunitrazepam\n",
    "SubSubCat_Clobazam\n",
    "SubSubCat_Brotizolam\n",
    "SubSubCat_Hydroxyzine\n",
    "SubSubCat_Triamcinolonhexacetonide\n",
    "SubSubCat_Selegiline\n",
    "SubSubCat_Rasagiline\n",
    "SubSubCat_Dosulepine\n",
    "SubSubCat_Tiapride\n",
    "SubSubCat_Paliperidon\n",
    "SubSubCat_Lurasidon\n",
    "SubSubCat_Cariprazine\n",
    "SubSubCat_Brexpiprazol\n",
    "SubSubCat_Amisulpride\n",
    "SubSubCat_periciazine\n",
    "SubSubCat_pimozide\n",
    "SubSubCat_Broomperidol\n",
    "SubSubCat_Zuclopentixol\n",
    "SubSubCat_Rufinamide\n",
    "SubSubCat_Stiripentol\n",
    "SubSubCat_Zonisamide\n",
    "SubSubCat_Chloorcyclizine\n",
    "SubSubCat_Triamcinolonacetonide\n",
    "SubSubCat_Fludrocortison\n",
    "SubSubCat_Dexamethason\n",
    "SubSubCat_Cortison\n",
    "SubSubCat_Moxonidine\n",
    "SubSubCat_Methyldopa\n",
    "SubSubCat_Guanfacine\n",
    "SubSubCat_Clonidine\n",
    "SubSubCat_Nimodipine\n",
    "SubSubCat_Lacidipine\n",
    "SubSubCat_Felodipine\n",
    "SubSubCat_Zofenopril\n",
    "SubSubCat_Captopril\n",
    "SubSubCat_Benazepril\n",
    "SubSubCat_Sotalol\n",
    "SubSubCat_Landiolol\n",
    "SubSubCat_Labetalol\n",
    "SubSubCat_Esmolol\n",
    "SubSubCat_Celiprolol\n",
    "SubSubCat_Carvedilol\n",
    "SubSubCat_Acebutolol\n",
    "SubSubCat_Oxomemazine\n",
    "SubSubCat_Mizolastine\n",
    "SubSubCat_Ketotifen\n",
    "SubSubCat_Doxylamine\n",
    "SubSubCat_Dimetindeen\n",
    "SubSubCat_Cyclizine\n",
    "SubSubCat_ADHD\n",
    "SubSubCat_Tramadol\n",
    "SubSubCat_Loprazolam\n",
    "SubSubCat_Alprazolam\n",
    "SubSubCat_promethazine\n",
    "SubSubCat_Paroxetine\n",
    "SubSubCat_Zolpidem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cfb8f5-7ba0-4bde-96b6-42e631f07681",
   "metadata": {},
   "source": [
    "## CAT analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b9a3959-6c9a-436a-8be2-dac4f16454f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "# For visualization and future steps\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer  # Needed to enable the experimental feature\n",
    "from sklearn.impute import IterativeImputer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c4a4a00-1c01-4e2b-a5e6-6c123e0b6bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataset: (3641, 465)\n",
      "\n",
      "Sample columns: ['CIN5', 'StartDatum', 'BEH_MOD', 'BEHDAGEN_GEPLAND', 'AANTAL_PCL', 'TOESTWO', 'BEH_AFG', 'TK', 'MM_CAPS_IN', 'MM_CAPS_TK']\n",
      "\n",
      "Missing values:\n",
      " Ecriterium_TK    3641\n",
      "Eernst_TK        3641\n",
      "Daantal_FU       3641\n",
      "Dcriterium_FU    3641\n",
      "Cernst_FU        3641\n",
      "Caantal_FU       3641\n",
      "Ccriterium_FU    3641\n",
      "Bernst_FU        3641\n",
      "Baantal_FU       3641\n",
      "Bcriterium_FU    3641\n",
      "dtype: int64\n",
      "Shape after removing duplicates: (3641, 465)\n"
     ]
    }
   ],
   "source": [
    "# Check basic structure\n",
    "print(\"Shape of dataset:\", df.shape)\n",
    "print(\"\\nSample columns:\", df.columns.tolist()[:10])\n",
    "print(\"\\nMissing values:\\n\", df.isnull().sum().sort_values(ascending=False).head(10))\n",
    "\n",
    "# Remove duplicate rows\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Confirm shape after removing duplicates\n",
    "print(\"Shape after removing duplicates:\", df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd7bb726-0877-4969-81b3-998a6663feba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDV_SEXE  gender_label\n",
      "2.0       Female          2750\n",
      "1.0       Male             862\n",
      "3.0       Other             29\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pyreadstat\n",
    "\n",
    "# Load gender info\n",
    "gender_df, meta = pyreadstat.read_sav(\"SDV_IN_Gender_2019_2024.sav\")\n",
    "\n",
    "# Just extract SDV_SEXE column and append to df\n",
    "df[\"SDV_SEXE\"] = gender_df[\"SDV_SEXE\"].reset_index(drop=True)\n",
    "\n",
    "# Optional: map to labels\n",
    "gender_map = {1.0: \"Male\", 2.0: \"Female\", 3.0: \"Other\"}\n",
    "df[\"gender_label\"] = df[\"SDV_SEXE\"].map(gender_map)\n",
    "\n",
    "# Done! Check a sample\n",
    "print(df[[\"SDV_SEXE\", \"gender_label\"]].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8e32268-4eb2-4ab8-9323-586bd306dd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'gender' and 'SDV_SEXE' columns are in df\n",
    "\n",
    "# Gender dummy variables\n",
    "df['gender_1'] = (df['gender'] == 1).astype(int)\n",
    "df['gender_2'] = (df['gender'] == 2).astype(int)\n",
    "\n",
    "# SDV_SEXE dummy variables\n",
    "df['SDV_SEXE_1'] = (df['SDV_SEXE'] == 1).astype(int)\n",
    "df['SDV_SEXE_2'] = (df['SDV_SEXE'] == 2).astype(int)\n",
    "df['SDV_SEXE_3'] = (df['SDV_SEXE'] == 3).astype(int)\n",
    "\n",
    "# Create binary columns\n",
    "df['ethnicity_Dutch'] = np.where(df['ethnicity'] == 1, 1, 0)\n",
    "df['ethnicity_other'] = np.where(df['ethnicity'] != 1, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a30c922-0ef4-4623-9a37-b49ce14d1995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining columns: 458\n"
     ]
    }
   ],
   "source": [
    "# Columns manually identified for removal (example set from the R script)\n",
    "cols_to_drop = [\n",
    "    'gender', 'ethnicity', 'CIN5', 'SDV_SEXE', 'StartDatum', 'STARTDATUM', 'DROPOUT_EARLYCOMPLETER', 'TOEST_WO',\n",
    "    'depressie_IN', 'TERUGKOMER', 'VROEGK_ST', 'gender_label',\n",
    "    'depr_m_psychose_huid', 'depr_z_psychose_huid', 'depr_z_psychose_verl',\n",
    "    'depr_m_psychose_verl', 'CAPS5score_followup', 'CAPS5_DAT_IN'\n",
    "]\n",
    "\n",
    "df = df.drop(columns=[col for col in cols_to_drop if col in df.columns])\n",
    "print(\"Remaining columns:\", df.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2928476d-1477-4f94-aef1-2ba57cc90110",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if 'BEH_DAGEN' in df.columns:\n",
    "    df.rename(columns={'BEH_DAGEN': 'treatmentdurationdays'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44379251-fbb1-422d-af00-1695e5bf3d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean and standardize column names\n",
    "df.columns = (\n",
    "    df.columns\n",
    "    .str.replace(r\"\\.+\", \"_\", regex=True)\n",
    "    .str.replace(r\"[^a-zA-Z0-9_]\", \"\", regex=True)\n",
    "    .str.replace(\" \", \"_\")\n",
    "    .str.strip()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc51f23a-e5ac-4736-a4e1-815cffd05783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAPS5score_baseline: 0 missing\n",
      "CAPS5Score_TK: 0 missing\n"
     ]
    }
   ],
   "source": [
    "# Preview key outcome variables\n",
    "outcome_vars = ['CAPS5score_baseline', 'CAPS5Score_TK']\n",
    "for col in outcome_vars:\n",
    "    if col in df.columns:\n",
    "        print(f\"{col}: {df[col].isnull().sum()} missing\")\n",
    "\n",
    "# Calculate change score\n",
    "if 'CAPS5score_baseline' in df.columns and 'CAPS5Score_TK' in df.columns:\n",
    "    df['caps5_change_baseline'] = df['CAPS5Score_TK'] - df['CAPS5score_baseline'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16955012-06c6-42d3-b91d-e103338584f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define exceptions to keep\n",
    "protected_cols = [\n",
    "    \"DIAGNOSIS_ANXIETY_OCD\",\n",
    "    \"DIAGNOSIS_PSYCHOTIC\",\n",
    "    \"DIAGNOSIS_EATING_DISORDER\",\n",
    "    \"DIAGNOSIS_SUBSTANCE_DISORDER\", \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"EB_NON_TF_THERAPY\", \"OTHER_TREATM_APPROACH\", \"Bipolar_and_Mood_disorder\", 'SUBCAT_Selectieve_immunosuppresiva', 'treatmentdurationdays',\n",
    "'SUBCAT_Corticosteroiden',\n",
    "'SUBCAT_Immunomodulerend_Coxibs',\n",
    "'SUBCAT_Aminosalicylaten',\n",
    "'SUBCAT_calcineurineremmers',\n",
    "'SUBCAT_Anti_epileptica_Benzodiazepine',\n",
    "'SUBCAT_Paracetamol_overig_combinatie', 'SUBCAT_MAO_remmers', 'SUBCAT_psychostimulans_overige', 'SUBCAT_Interleukine_remmers'\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "# ----------------------------------------\n",
    "# 1. Drop columns with >95% missing values (except protected)\n",
    "thresh_missing = int(0.95 * len(df))\n",
    "missing_cols = [col for col in df.columns if df[col].isnull().sum() > (len(df) - thresh_missing)]\n",
    "missing_cols_to_drop = [col for col in missing_cols if col not in protected_cols]\n",
    "df = df.drop(columns=missing_cols_to_drop)\n",
    "\n",
    "# ----------------------------------------\n",
    "# 2. Drop near-zero variance columns (except protected)\n",
    "low_variance_cols = [col for col in df.columns if df[col].nunique(dropna=True) <= 1 and col not in protected_cols]\n",
    "df = df.drop(columns=low_variance_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fab9270e-9e84-4999-9cf9-6d3d6781c224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Step 1 Complete: Cleaned dataset saved.\n"
     ]
    }
   ],
   "source": [
    "df.to_csv(\"cleaned_data_baseline.csv\", index=False)\n",
    "print(\" Step 1 Complete: Cleaned dataset saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3195492-0a77-4727-9370-4b8616218575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target variables:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2af56f32-3a6c-48c6-90bc-baf17a47caee",
   "metadata": {},
   "source": [
    "CAPS5score_baseline:    PTSD severity before treatment\n",
    "CAPS5Score_TK:      \tPTSD severity after treatment (post test)\n",
    "Derived:                caps5_change_baseline\t(pre - post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f3559c4-6bf8-402a-8739-050a016c5cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install scikit-learn\n",
    "# !pip install fancyimpute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0cf58d99-d747-4ac5-b4b1-c481572459c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from fancyimpute import IterativeImputer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "291e0886-8be9-4f10-b65a-8c8d8771cf9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3641, 194)\n",
      "DIAGNOSIS_ANXIETY_OCD           float64\n",
      "DIAGNOSIS_SMOKING               float64\n",
      "DIAGNOSIS_EATING_DISORDER       float64\n",
      "DIAGNOSIS_STEMMING_BIPOL        float64\n",
      "DIAGNOSIS_SUBSTANCE_DISORDER    float64\n",
      "DIAGNOSIS_PSYCHOTIC             float64\n",
      "DIAGNOSIS_SUICIDALITY           float64\n",
      "DIAGNOSIS_SEXUAL_TRAUMA         float64\n",
      "DIAGNOSIS_CHILDHOOD_TRAUMA        int64\n",
      "DIAGNOSIS_CPTSD                 float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Load the cleaned dataset from Step 1\n",
    "df = pd.read_csv(\"cleaned_data_baseline.csv\")\n",
    "\n",
    "# Quick check\n",
    "print(df.shape)\n",
    "print(df.dtypes.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a7040b25-e2fc-4cff-a371-36f3cee7839b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate Numerical and Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5dd82f05-926b-4e42-a049-7d46e4e47dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical Columns: 194\n",
      "Categorical Columns: 0\n"
     ]
    }
   ],
   "source": [
    "# Identify numerical and categorical columns\n",
    "numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "print(f\"Numerical Columns: {len(numerical_cols)}\")\n",
    "print(f\"Categorical Columns: {len(categorical_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "390faf58-9c35-4b4a-aae8-0414079eadf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values summary:\n",
      "DIAGNOSIS_PSYCHOTIC_missing: 0\n",
      "DIAGNOSIS_ANXIETY_OCD_missing: 0\n",
      "Bipolar_and_Mood_disorder_missing: 0\n",
      "DIAGNOSIS_EATING_DISORDER_missing: 0\n",
      "total_rows: 3641\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Check missing values for each variable\n",
    "missing_summary = {\n",
    "    'DIAGNOSIS_PSYCHOTIC_missing': df['DIAGNOSIS_PSYCHOTIC'].isna().sum(),\n",
    "    'DIAGNOSIS_ANXIETY_OCD_missing': df['DIAGNOSIS_ANXIETY_OCD'].isna().sum(),\n",
    "    'Bipolar_and_Mood_disorder_missing': df['Bipolar_and_Mood_disorder'].isna().sum(),\n",
    "    'DIAGNOSIS_EATING_DISORDER_missing': df['DIAGNOSIS_EATING_DISORDER'].isna().sum(),\n",
    "    'total_rows': len(df)\n",
    "}\n",
    "\n",
    "print(\"Missing values summary:\")\n",
    "for key, value in missing_summary.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "385a9df4-734c-415d-b062-b081dbaa4ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing data pattern:\n",
      "has_missing\n",
      "False    3641\n",
      "Name: count, dtype: int64\n",
      "Patients with missing data: 0\n",
      "Patients with complete data: 3641\n"
     ]
    }
   ],
   "source": [
    "# Define the mental health variables\n",
    "mental_health_vars = ['DIAGNOSIS_PSYCHOTIC', 'DIAGNOSIS_ANXIETY_OCD', \n",
    "                      'Bipolar_and_Mood_disorder', 'DIAGNOSIS_EATING_DISORDER']\n",
    "\n",
    "# Check patients with missing data on any of the 4 variables\n",
    "df['has_missing'] = df[mental_health_vars].isna().any(axis=1)\n",
    "\n",
    "# Summary of missing pattern\n",
    "print(\"\\nMissing data pattern:\")\n",
    "print(df['has_missing'].value_counts())\n",
    "print(f\"Patients with missing data: {df['has_missing'].sum()}\")\n",
    "print(f\"Patients with complete data: {(~df['has_missing']).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d47a76d6-1775-4b55-8e71-33d91d2e143e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset summary:\n",
      "Original dataset: 3641 observations\n",
      "Complete cases: 3641 observations\n",
      "Excluded (missing): 0 observations\n"
     ]
    }
   ],
   "source": [
    "# Store original count before filtering\n",
    "original_count = len(df)\n",
    "\n",
    "# Filter to keep only complete cases (this modifies df)\n",
    "df = df.dropna(subset=mental_health_vars)\n",
    "\n",
    "# Get the count after filtering\n",
    "complete_count = len(df)\n",
    "\n",
    "# Calculate excluded count\n",
    "excluded_count = original_count - complete_count\n",
    "\n",
    "# Verify the counts\n",
    "print(f\"\\nDataset summary:\")\n",
    "print(f\"Original dataset: {original_count} observations\")\n",
    "print(f\"Complete cases: {complete_count} observations\")\n",
    "print(f\"Excluded (missing): {excluded_count} observations\")\n",
    "\n",
    "# Remove the temporary column (if it exists)\n",
    "if 'has_missing' in df.columns:\n",
    "    df = df.drop('has_missing', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "12d763e9-d4ac-4652-87f0-522d8025a981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values in mental health variables:\n",
      "DIAGNOSIS_PSYCHOTIC: 0\n",
      "DIAGNOSIS_ANXIETY_OCD: 0\n",
      "Bipolar_and_Mood_disorder: 0\n",
      "DIAGNOSIS_EATING_DISORDER: 0\n"
     ]
    }
   ],
   "source": [
    "# Check the 4 variables you filtered on (should be 0 missing)\n",
    "mental_health_vars = ['DIAGNOSIS_PSYCHOTIC', 'DIAGNOSIS_ANXIETY_OCD', \n",
    "                      'Bipolar_and_Mood_disorder', 'DIAGNOSIS_EATING_DISORDER']\n",
    "\n",
    "print(f\"\\nMissing values in mental health variables:\")\n",
    "for var in mental_health_vars:\n",
    "    missing = df[var].isnull().sum()\n",
    "    print(f\"{var}: {missing}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "77aec19c-15a1-4dd9-902f-f7ee0de6f6a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3641 entries, 0 to 3640\n",
      "Columns: 194 entries, DIAGNOSIS_ANXIETY_OCD to ethnicity_other\n",
      "dtypes: float64(11), int64(183)\n",
      "memory usage: 5.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e23db7c4-d773-4df1-9681-382a86a4d940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Step 2 Complete: Final prepared dataset saved as 'final_prepared_data.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Save the fully prepared data\n",
    "df.to_csv(\"final_prepared_data.csv\", index=False)\n",
    "print(\" Step 2 Complete: Final prepared dataset saved as 'final_prepared_data.csv'.\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "31c98559-4385-4a03-9883-006b35a54d72",
   "metadata": {},
   "source": [
    "Define Features, Treatment, and Outcome\n",
    "\n",
    "\n",
    " X = Covariates\n",
    "\n",
    " T = Treatment Variable (e.g., use of antidepressants CAT_Antidepressiva)\n",
    "\n",
    " Y = Target Outcome (caps5_change_baseline)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0db325e1-30db-48ea-bd24-177192b3429d",
   "metadata": {},
   "source": [
    "MICE IMputation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0cc519e7-8480-41c8-9a15-956044ac1b04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "STEP 1: MICE IMPUTATION\n",
      "==================================================\n",
      "\n",
      "=== Running MICE Imputation: Dataset 1 ===\n",
      " Completed imputation 1\n",
      "\n",
      "=== Running MICE Imputation: Dataset 2 ===\n",
      " Completed imputation 2\n",
      "\n",
      "=== Running MICE Imputation: Dataset 3 ===\n",
      " Completed imputation 3\n",
      "\n",
      "=== Running MICE Imputation: Dataset 4 ===\n",
      " Completed imputation 4\n",
      "\n",
      "=== Running MICE Imputation: Dataset 5 ===\n",
      " Completed imputation 5\n",
      "\n",
      "==================================================\n",
      "STEP 2: ROUNDING NUMERIC COLUMNS\n",
      "==================================================\n",
      " Imputation 1: Rounded 194 numeric columns to 0 decimal place(s).\n",
      " Imputation 2: Rounded 194 numeric columns to 0 decimal place(s).\n",
      " Imputation 3: Rounded 194 numeric columns to 0 decimal place(s).\n",
      " Imputation 4: Rounded 194 numeric columns to 0 decimal place(s).\n",
      " Imputation 5: Rounded 194 numeric columns to 0 decimal place(s).\n",
      "\n",
      "==================================================\n",
      "STEP 3: SAVING FINAL DATASETS\n",
      "==================================================\n",
      " Saved files for imputation 1:\n",
      "   → imputed_data/df_imputed_final_imp1.pkl\n",
      "   → imputed_data/df_imputed_final_imp1.csv\n",
      "   → imputed_data/df_imputed_final_imp1.xlsx\n",
      " Saved files for imputation 2:\n",
      "   → imputed_data/df_imputed_final_imp2.pkl\n",
      "   → imputed_data/df_imputed_final_imp2.csv\n",
      "   → imputed_data/df_imputed_final_imp2.xlsx\n",
      " Saved files for imputation 3:\n",
      "   → imputed_data/df_imputed_final_imp3.pkl\n",
      "   → imputed_data/df_imputed_final_imp3.csv\n",
      "   → imputed_data/df_imputed_final_imp3.xlsx\n",
      " Saved files for imputation 4:\n",
      "   → imputed_data/df_imputed_final_imp4.pkl\n",
      "   → imputed_data/df_imputed_final_imp4.csv\n",
      "   → imputed_data/df_imputed_final_imp4.xlsx\n",
      " Saved files for imputation 5:\n",
      "   → imputed_data/df_imputed_final_imp5.pkl\n",
      "   → imputed_data/df_imputed_final_imp5.csv\n",
      "   → imputed_data/df_imputed_final_imp5.xlsx\n",
      "\n",
      "==================================================\n",
      "STEP 4: VERIFYING DATASET DIFFERENCES\n",
      "==================================================\n",
      " Checking differences in 4 columns that had missing values...\n",
      " Column 'DIAGNOSIS_SMOKING': 34 different values between datasets 1 & 2\n",
      " Column 'DIAGNOSIS_SEXUAL_TRAUMA': 12 different values between datasets 1 & 2\n",
      " Column 'DIAGNOSIS_CPTSD': 20 different values between datasets 1 & 2\n",
      "\n",
      " SUCCESS: Datasets show proper variability!\n",
      "\n",
      "==================================================\n",
      " MICE IMPUTATION COMPLETE!\n",
      "==================================================\n",
      " Created 5 imputed datasets\n",
      " Applied rounding to all numeric columns\n",
      " Saved files in: imputed_data/\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "# ========== CONFIG ==========\n",
    "save_folder = \"imputed_data\"\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "n_imputations = 5\n",
    "\n",
    "# ========== LOAD ==========\n",
    "# Ensure df is already defined\n",
    "assert 'df' in globals(), \"Please load the original DataFrame as `df` before running this script.\"\n",
    "\n",
    "# ========== IDENTIFY NUMERIC COLUMNS ==========\n",
    "numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "\n",
    "# ========== STEP 1: MICE IMPUTATION ==========\n",
    "print(\"=\" * 50)\n",
    "print(\"STEP 1: MICE IMPUTATION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "imputed_dfs = []\n",
    "for i in range(1, n_imputations + 1):\n",
    "    print(f\"\\n=== Running MICE Imputation: Dataset {i} ===\")\n",
    "    #  NEW instance with different seed AND sample_posterior=True for randomness\n",
    "    mice_imputer = IterativeImputer(\n",
    "        max_iter=10, \n",
    "        random_state=42+i,  # Different base to avoid low numbers\n",
    "        sample_posterior=True,  #  KEY: This adds randomness!\n",
    "        n_nearest_features=None,\n",
    "        initial_strategy='mean'\n",
    "    )\n",
    "    # Fit-transform on numeric columns\n",
    "    imputed_array = mice_imputer.fit_transform(df[numeric_cols])\n",
    "    # Replace numeric columns in a copy of the original df\n",
    "    df_imputed = df.copy()\n",
    "    df_imputed[numeric_cols] = pd.DataFrame(imputed_array, columns=numeric_cols, index=df.index)\n",
    "    # Append to list\n",
    "    imputed_dfs.append(df_imputed)\n",
    "    print(f\" Completed imputation {i}\")\n",
    "\n",
    "# ========== STEP 2: ROUNDING ==========\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"STEP 2: ROUNDING NUMERIC COLUMNS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "def round_all_numeric_columns_all_imputations(imputed_dfs, decimals=0, verbose=True):\n",
    "    rounded_dfs = []\n",
    "    for i, df in enumerate(imputed_dfs):\n",
    "        df_copy = df.copy()\n",
    "        numeric_cols = df_copy.select_dtypes(include=[np.number]).columns\n",
    "        df_copy[numeric_cols] = df_copy[numeric_cols].round(decimals)\n",
    "        rounded_dfs.append(df_copy)\n",
    "        if verbose:\n",
    "            print(f\" Imputation {i+1}: Rounded {len(numeric_cols)} numeric columns to {decimals} decimal place(s).\")\n",
    "    return rounded_dfs\n",
    "\n",
    "# Apply rounding to all imputed datasets\n",
    "imputed_dfs = round_all_numeric_columns_all_imputations(imputed_dfs)\n",
    "\n",
    "# ========== STEP 3: SAVE FINAL DATASETS ==========\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"STEP 3: SAVING FINAL DATASETS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for i, df_imputed in enumerate(imputed_dfs, 1):\n",
    "    # Save outputs\n",
    "    pkl_path = f\"{save_folder}/df_imputed_final_imp{i}.pkl\"\n",
    "    csv_path = f\"{save_folder}/df_imputed_final_imp{i}.csv\"\n",
    "    excel_path = f\"{save_folder}/df_imputed_final_imp{i}.xlsx\"\n",
    "    \n",
    "    df_imputed.to_pickle(pkl_path)\n",
    "    df_imputed.to_csv(csv_path, index=False)\n",
    "    df_imputed.to_excel(excel_path, index=False)\n",
    "    \n",
    "    print(f\" Saved files for imputation {i}:\")\n",
    "    print(f\"   → {pkl_path}\")\n",
    "    print(f\"   → {csv_path}\")\n",
    "    print(f\"   → {excel_path}\")\n",
    "\n",
    "# ========== STEP 4: VERIFY DATASETS ARE DIFFERENT ==========\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"STEP 4: VERIFYING DATASET DIFFERENCES\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "def check_imputation_differences(imputed_dfs, verbose=True):\n",
    "    \"\"\"Check if imputed datasets are actually different from each other\"\"\"\n",
    "    if len(imputed_dfs) < 2:\n",
    "        print(\"  Only one dataset - cannot check differences\")\n",
    "        return\n",
    "    \n",
    "    # Get numeric columns that had missing values originally\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    missing_cols = [col for col in numeric_cols if df[col].isnull().any()]\n",
    "    \n",
    "    if not missing_cols:\n",
    "        print(\"  No missing values found in original data\")\n",
    "        return\n",
    "    \n",
    "    print(f\" Checking differences in {len(missing_cols)} columns that had missing values...\")\n",
    "    \n",
    "    differences_found = False\n",
    "    \n",
    "    for col in missing_cols[:3]:  # Check first 3 columns with missing values\n",
    "        # Compare first two datasets for this column\n",
    "        values_1 = imputed_dfs[0][col].values\n",
    "        values_2 = imputed_dfs[1][col].values\n",
    "        \n",
    "        if not np.array_equal(values_1, values_2):\n",
    "            differences_found = True\n",
    "            # Count how many values are different\n",
    "            diff_count = np.sum(values_1 != values_2)\n",
    "            print(f\" Column '{col}': {diff_count} different values between datasets 1 & 2\")\n",
    "        else:\n",
    "            print(f\" Column '{col}': IDENTICAL values between datasets 1 & 2\")\n",
    "    \n",
    "    if differences_found:\n",
    "        print(f\"\\n SUCCESS: Datasets show proper variability!\")\n",
    "    else:\n",
    "        print(f\"\\n  WARNING: Datasets appear identical - check random_state implementation\")\n",
    "    \n",
    "    return differences_found\n",
    "\n",
    "# Run the check\n",
    "check_imputation_differences(imputed_dfs)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\" MICE IMPUTATION COMPLETE!\")\n",
    "print(\"=\" * 50)\n",
    "print(f\" Created {n_imputations} imputed datasets\")\n",
    "print(f\" Applied rounding to all numeric columns\")\n",
    "print(f\" Saved files in: {save_folder}/\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8be134f2-0f23-4614-900c-f0e3d2b5bc3c",
   "metadata": {},
   "source": [
    "Imputation check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e4b4bd5c-a5ad-4fb8-9f74-620e4d2d14cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CHECKING IMPUTATION DIFFERENCES\n",
      "============================================================\n",
      "Dataset 1 vs Dataset 2: DIFFERENT ✅\n",
      "  'DIAGNOSIS_SMOKING': 34 different values\n",
      "  'DIAGNOSIS_SEXUAL_TRAUMA': 12 different values\n",
      "  'DIAGNOSIS_CPTSD': 20 different values\n",
      "  'treatmentdurationdays': 1129 different values\n",
      "  Total different values: 1195\n",
      "\n",
      "=== Checking all 5 datasets ===\n",
      "Dataset 1 vs Dataset 2: DIFFERENT ✅\n",
      "Dataset 1 vs Dataset 3: DIFFERENT ✅\n",
      "Dataset 1 vs Dataset 4: DIFFERENT ✅\n",
      "Dataset 1 vs Dataset 5: DIFFERENT ✅\n",
      "Dataset 2 vs Dataset 3: DIFFERENT ✅\n",
      "Dataset 2 vs Dataset 4: DIFFERENT ✅\n",
      "Dataset 2 vs Dataset 5: DIFFERENT ✅\n",
      "Dataset 3 vs Dataset 4: DIFFERENT ✅\n",
      "Dataset 3 vs Dataset 5: DIFFERENT ✅\n",
      "Dataset 4 vs Dataset 5: DIFFERENT ✅\n",
      "\n",
      "=== Checking differences in originally missing positions ===\n",
      "\n",
      "Column 'DIAGNOSIS_SMOKING' (64 missing values):\n",
      "  Dataset 1 vs 2: 34/64 different imputed values ✅\n",
      "  Dataset 2 vs 3: 35/64 different imputed values ✅\n",
      "  Dataset 3 vs 4: 33/64 different imputed values ✅\n",
      "  Dataset 4 vs 5: 35/64 different imputed values ✅\n",
      "\n",
      "Column 'DIAGNOSIS_SEXUAL_TRAUMA' (29 missing values):\n",
      "  Dataset 1 vs 2: 12/29 different imputed values ✅\n",
      "  Dataset 2 vs 3: 14/29 different imputed values ✅\n",
      "  Dataset 3 vs 4: 13/29 different imputed values ✅\n",
      "  Dataset 4 vs 5: 16/29 different imputed values ✅\n",
      "\n",
      "Column 'DIAGNOSIS_CPTSD' (51 missing values):\n",
      "  Dataset 1 vs 2: 20/51 different imputed values ✅\n",
      "  Dataset 2 vs 3: 24/51 different imputed values ✅\n",
      "  Dataset 3 vs 4: 30/51 different imputed values ✅\n",
      "  Dataset 4 vs 5: 23/51 different imputed values ✅\n",
      "\n",
      "Column 'treatmentdurationdays' (1412 missing values):\n",
      "  Dataset 1 vs 2: 1129/1412 different imputed values ✅\n",
      "  Dataset 2 vs 3: 1148/1412 different imputed values ✅\n",
      "  Dataset 3 vs 4: 1177/1412 different imputed values ✅\n",
      "  Dataset 4 vs 5: 1143/1412 different imputed values ✅\n",
      "\n",
      "🎉 SUCCESS: Found differences in imputed values!\n",
      "\n",
      "=== Sample imputed values (first 3 missing positions) ===\n",
      "\n",
      "Column 'DIAGNOSIS_SMOKING' at positions [5, 7, 57]:\n",
      "  Dataset 1: [-1.  0.  1.]\n",
      "  Dataset 2: [ 0. -1.  1.]\n",
      "  Dataset 3: [ 0. -0.  1.]\n",
      "  Dataset 4: [ 1. -1.  1.]\n",
      "  Dataset 5: [0. 0. 0.]\n",
      "\n",
      "Column 'DIAGNOSIS_SEXUAL_TRAUMA' at positions [29, 30, 31]:\n",
      "  Dataset 1: [1. 1. 1.]\n",
      "  Dataset 2: [1. 1. 1.]\n",
      "  Dataset 3: [1. 2. 0.]\n",
      "  Dataset 4: [0. 1. 0.]\n",
      "  Dataset 5: [0. 1. 1.]\n",
      "\n",
      "Column 'DIAGNOSIS_CPTSD' at positions [7, 57, 216]:\n",
      "  Dataset 1: [0. 1. 1.]\n",
      "  Dataset 2: [1. 1. 1.]\n",
      "  Dataset 3: [1. 1. 1.]\n",
      "  Dataset 4: [0. 1. 1.]\n",
      "  Dataset 5: [0. 1. 1.]\n",
      "\n",
      "Column 'treatmentdurationdays' at positions [0, 1, 6]:\n",
      "  Dataset 1: [3. 6. 2.]\n",
      "  Dataset 2: [3. 4. 5.]\n",
      "  Dataset 3: [3. 3. 3.]\n",
      "  Dataset 4: [3. 4. 4.]\n",
      "  Dataset 5: [5. 4. 1.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ========== METHOD 1: QUICK CHECK - Compare first 2 datasets ==========\n",
    "def quick_difference_check(imputed_dfs):\n",
    "    \"\"\"Quick check to see if first two datasets are different\"\"\"\n",
    "    if len(imputed_dfs) < 2:\n",
    "        print(\"Need at least 2 datasets to compare\")\n",
    "        return\n",
    "    \n",
    "    df1 = imputed_dfs[0]\n",
    "    df2 = imputed_dfs[1]\n",
    "    \n",
    "    # Check if dataframes are identical\n",
    "    are_identical = df1.equals(df2)\n",
    "    print(f\"Dataset 1 vs Dataset 2: {'IDENTICAL ❌' if are_identical else 'DIFFERENT ✅'}\")\n",
    "    \n",
    "    if not are_identical:\n",
    "        # Count different values\n",
    "        numeric_cols = df1.select_dtypes(include=[np.number]).columns\n",
    "        total_diff = 0\n",
    "        for col in numeric_cols:\n",
    "            diff_count = np.sum(df1[col] != df2[col])\n",
    "            if diff_count > 0:\n",
    "                total_diff += diff_count\n",
    "                print(f\"  '{col}': {diff_count} different values\")\n",
    "        print(f\"  Total different values: {total_diff}\")\n",
    "\n",
    "# ========== METHOD 2: DETAILED CHECK - All pairwise comparisons ==========\n",
    "def detailed_difference_check(imputed_dfs):\n",
    "    \"\"\"Check differences between all pairs of datasets\"\"\"\n",
    "    n_datasets = len(imputed_dfs)\n",
    "    print(f\"\\n=== Checking all {n_datasets} datasets ===\")\n",
    "    \n",
    "    numeric_cols = imputed_dfs[0].select_dtypes(include=[np.number]).columns\n",
    "    \n",
    "    for i in range(n_datasets):\n",
    "        for j in range(i+1, n_datasets):\n",
    "            are_identical = imputed_dfs[i].equals(imputed_dfs[j])\n",
    "            print(f\"Dataset {i+1} vs Dataset {j+1}: {'IDENTICAL ❌' if are_identical else 'DIFFERENT ✅'}\")\n",
    "\n",
    "# ========== METHOD 3: FOCUS ON ORIGINALLY MISSING VALUES ==========\n",
    "def check_missing_value_differences(original_df, imputed_dfs):\n",
    "    \"\"\"Check differences only in originally missing positions\"\"\"\n",
    "    print(f\"\\n=== Checking differences in originally missing positions ===\")\n",
    "    \n",
    "    numeric_cols = original_df.select_dtypes(include=[np.number]).columns\n",
    "    \n",
    "    differences_found = False\n",
    "    for col in numeric_cols:\n",
    "        if original_df[col].isnull().any():\n",
    "            missing_mask = original_df[col].isnull()\n",
    "            print(f\"\\nColumn '{col}' ({missing_mask.sum()} missing values):\")\n",
    "            \n",
    "            # Compare imputed values at missing positions\n",
    "            for i in range(len(imputed_dfs)-1):\n",
    "                imp1_values = imputed_dfs[i].loc[missing_mask, col]\n",
    "                imp2_values = imputed_dfs[i+1].loc[missing_mask, col]\n",
    "                \n",
    "                are_same = np.array_equal(imp1_values.values, imp2_values.values)\n",
    "                if not are_same:\n",
    "                    differences_found = True\n",
    "                    diff_count = np.sum(imp1_values.values != imp2_values.values)\n",
    "                    print(f\"  Dataset {i+1} vs {i+2}: {diff_count}/{len(imp1_values)} different imputed values ✅\")\n",
    "                else:\n",
    "                    print(f\"  Dataset {i+1} vs {i+2}: IDENTICAL imputed values ❌\")\n",
    "    \n",
    "    return differences_found\n",
    "\n",
    "# ========== METHOD 4: SAMPLE VALUES FROM EACH DATASET ==========\n",
    "def show_sample_imputed_values(original_df, imputed_dfs, n_samples=5):\n",
    "    \"\"\"Show sample imputed values from each dataset\"\"\"\n",
    "    print(f\"\\n=== Sample imputed values (first {n_samples} missing positions) ===\")\n",
    "    \n",
    "    numeric_cols = original_df.select_dtypes(include=[np.number]).columns\n",
    "    \n",
    "    for col in numeric_cols:\n",
    "        if original_df[col].isnull().any():\n",
    "            missing_positions = original_df[original_df[col].isnull()].index[:n_samples]\n",
    "            \n",
    "            print(f\"\\nColumn '{col}' at positions {list(missing_positions)}:\")\n",
    "            for i, df_imp in enumerate(imputed_dfs):\n",
    "                values = df_imp.loc[missing_positions, col].values\n",
    "                print(f\"  Dataset {i+1}: {values}\")\n",
    "\n",
    "# ========== RUN ALL CHECKS ==========\n",
    "print(\"=\" * 60)\n",
    "print(\"CHECKING IMPUTATION DIFFERENCES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Method 1: Quick check\n",
    "quick_difference_check(imputed_dfs)\n",
    "\n",
    "# Method 2: All pairwise comparisons  \n",
    "detailed_difference_check(imputed_dfs)\n",
    "\n",
    "# Method 3: Focus on originally missing values (assumes 'df' is your original dataframe)\n",
    "if 'df' in globals():\n",
    "    differences_found = check_missing_value_differences(df, imputed_dfs)\n",
    "    if differences_found:\n",
    "        print(f\"\\n🎉 SUCCESS: Found differences in imputed values!\")\n",
    "    else:\n",
    "        print(f\"\\n⚠️ WARNING: No differences found in imputed values!\")\n",
    "\n",
    "# Method 4: Show sample values\n",
    "if 'df' in globals():\n",
    "    show_sample_imputed_values(df, imputed_dfs, n_samples=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ab0b31cd-485d-43af-aa6b-2c74bfabed76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y for imputation 1 defined. Sample values:\n",
      "0   -41.0\n",
      "1   -15.0\n",
      "2   -46.0\n",
      "3   -41.0\n",
      "4   -20.0\n",
      "Name: caps5_change_baseline, dtype: float64\n",
      "Y for imputation 2 defined. Sample values:\n",
      "0   -41.0\n",
      "1   -15.0\n",
      "2   -46.0\n",
      "3   -41.0\n",
      "4   -20.0\n",
      "Name: caps5_change_baseline, dtype: float64\n",
      "Y for imputation 3 defined. Sample values:\n",
      "0   -41.0\n",
      "1   -15.0\n",
      "2   -46.0\n",
      "3   -41.0\n",
      "4   -20.0\n",
      "Name: caps5_change_baseline, dtype: float64\n",
      "Y for imputation 4 defined. Sample values:\n",
      "0   -41.0\n",
      "1   -15.0\n",
      "2   -46.0\n",
      "3   -41.0\n",
      "4   -20.0\n",
      "Name: caps5_change_baseline, dtype: float64\n",
      "Y for imputation 5 defined. Sample values:\n",
      "0   -41.0\n",
      "1   -15.0\n",
      "2   -46.0\n",
      "3   -41.0\n",
      "4   -20.0\n",
      "Name: caps5_change_baseline, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "imputed_folder = \"imputed_data\"\n",
    "n_imputations = 5\n",
    "\n",
    "# Lists to hold DataFrames and Y vectors\n",
    "imputed_dfs = []\n",
    "Y_list = []\n",
    "\n",
    "for i in range(1, n_imputations + 1):\n",
    "    file_path = f\"{imputed_folder}/df_imputed_final_imp{i}.pkl\"\n",
    "    \n",
    "    # Load imputed DataFrame\n",
    "    df_imp = pd.read_pickle(file_path)\n",
    "    imputed_dfs.append(df_imp)\n",
    "\n",
    "    # Define Y for this imputation\n",
    "    Y = df_imp[\"caps5_change_baseline\"]\n",
    "    Y_list.append(Y)\n",
    "\n",
    "    print(f\"Y for imputation {i} defined. Sample values:\")\n",
    "    print(Y.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2d30451e-4ae5-433b-94a0-946273af517f",
   "metadata": {},
   "outputs": [],
   "source": [
    "covariates_CAT_ADHD = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline', 'CAT_Anti_epileptica', 'CAT_Antidepressiva', 'CAT_Antipsychotica',\n",
    "    'CAT_Benzodiazepine', 'CAT_Opioden',\n",
    "    'CAT_Z_drugs', 'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD',\n",
    "    'DIAGNOSIS_SEXUAL_TRAUMA', 'DIAGNOSIS_SMOKING', 'DIAGNOSIS_SUICIDALITY',\n",
    "    'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"EB_NON_TF_THERAPY\", \"OTHER_TREATM_APPROACH\", \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "\n",
    "covariates_CAT_Aceetanilidederivaten = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline', 'CAT_Anti_epileptica', 'CAT_Antidepressiva', 'CAT_Antipsychotica',\n",
    "    'CAT_Benzodiazepine', 'CAT_Opioden', 'CAT_Z_drugs',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SMOKING', 'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"EB_NON_TF_THERAPY\", \"OTHER_TREATM_APPROACH\", \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "\n",
    "covariates_CAT_Z_drugs = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline', 'CAT_Anti_epileptica', 'CAT_Antidepressiva', 'CAT_Antipsychotica',\n",
    "    'CAT_Benzodiazepine', 'CAT_Opioden',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SMOKING', 'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"EB_NON_TF_THERAPY\", \"OTHER_TREATM_APPROACH\", \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "\n",
    "covariates_CAT_Opioden = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline', 'CAT_Anti_epileptica',\n",
    "    'CAT_Antidepressiva',\n",
    "    'CAT_Antipsychotica', 'CAT_Benzodiazepine', 'CAT_Z_drugs',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SMOKING', 'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"EB_NON_TF_THERAPY\", \"OTHER_TREATM_APPROACH\", \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "\n",
    "covariates_CAT_NSAIDs = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline', 'CAT_Anti_epileptica',\n",
    "    'CAT_Antidepressiva',\n",
    "    'CAT_Antipsychotica', 'CAT_Benzodiazepine', 'CAT_Opioden', 'CAT_Z_drugs',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SMOKING', 'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"EB_NON_TF_THERAPY\", \"OTHER_TREATM_APPROACH\", \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "covariates_CAT_Benzodiazepine = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline', 'CAT_Anti_epileptica',\n",
    "    'CAT_Antidepressiva',\n",
    "    'CAT_Antipsychotica', 'CAT_Opioden', 'CAT_Z_drugs',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SMOKING', 'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"EB_NON_TF_THERAPY\", \"OTHER_TREATM_APPROACH\", \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "\n",
    "covariates_CAT_Antihypertensiva = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline', 'CAT_Anti_epileptica',\n",
    "    'CAT_Antidepressiva', 'CAT_Antipsychotica',\n",
    "    'CAT_Benzodiazepine', 'CAT_Opioden', 'CAT_Z_drugs',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SMOKING', 'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"EB_NON_TF_THERAPY\", \"OTHER_TREATM_APPROACH\", \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "\n",
    "covariates_CAT_Antihistaminica = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline', 'CAT_Anti_epileptica',\n",
    "    'CAT_Antidepressiva', 'CAT_Antipsychotica',\n",
    "    'CAT_Benzodiazepine', 'CAT_Opioden', 'CAT_Z_drugs',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SMOKING', 'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"EB_NON_TF_THERAPY\", \"OTHER_TREATM_APPROACH\", \"Bipolar_and_Mood_disorder\"\n",
    "]\n",
    "\n",
    "\n",
    "covariates_CAT_Anti_epileptica = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline', 'CAT_Antidepressiva', 'CAT_Antipsychotica',\n",
    "    'CAT_Benzodiazepine', 'CAT_Opioden', 'CAT_Z_drugs',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SMOKING', 'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"EB_NON_TF_THERAPY\", \"OTHER_TREATM_APPROACH\", \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "\n",
    "covariates_CAT_Antidepressiva = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline', 'CAT_Anti_epileptica', 'CAT_Antipsychotica',\n",
    "    'CAT_Benzodiazepine', 'CAT_Opioden', 'CAT_Z_drugs',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SMOKING', 'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"EB_NON_TF_THERAPY\", \"OTHER_TREATM_APPROACH\", \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "\n",
    "covariates_CAT_Antipsychotica = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline', 'CAT_Anti_epileptica',\n",
    "    'CAT_Antidepressiva',\n",
    "    'CAT_Benzodiazepine', 'CAT_Opioden', 'CAT_Z_drugs',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SMOKING', 'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"EB_NON_TF_THERAPY\", \"OTHER_TREATM_APPROACH\", \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "covariates_CAT_ALL_PSYCHOTROPICS_EXCL_BENZO = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Benzodiazepine', 'CAT_Anticonceptiva',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SMOKING', 'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"EB_NON_TF_THERAPY\", \"OTHER_TREATM_APPROACH\", \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "covariates_CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Benzodiazepine', 'CAT_Z_drugs', 'CAT_Anticonceptiva',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SMOKING', 'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"EB_NON_TF_THERAPY\", \"OTHER_TREATM_APPROACH\", \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "\n",
    "covariates_CAT_ALL_PSYCHOTROPICS = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SMOKING', 'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"EB_NON_TF_THERAPY\", \"OTHER_TREATM_APPROACH\", \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "\n",
    "covariates_CAT_ALL = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA',\n",
    "    'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SMOKING', 'DIAGNOSIS_SUICIDALITY',\n",
    "    'age', 'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"EB_NON_TF_THERAPY\", \"OTHER_TREATM_APPROACH\", \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7887112f-e4d1-4beb-b93b-1d96a34cf5c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groups found: ['CAT_ADHD', 'CAT_Aceetanilidederivaten', 'CAT_Z_drugs', 'CAT_Opioden', 'CAT_NSAIDs', 'CAT_Benzodiazepine', 'CAT_Antihypertensiva', 'CAT_Antihistaminica', 'CAT_Anti_epileptica', 'CAT_Antidepressiva', 'CAT_Antipsychotica', 'CAT_ALL_PSYCHOTROPICS_EXCL_BENZO', 'CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS', 'CAT_ALL_PSYCHOTROPICS', 'CAT_ALL']\n",
      "['CAT_ADHD', 'CAT_Aceetanilidederivaten', 'CAT_Z_drugs', 'CAT_Opioden', 'CAT_NSAIDs', 'CAT_Benzodiazepine', 'CAT_Antihypertensiva', 'CAT_Antihistaminica', 'CAT_Anti_epileptica', 'CAT_Antidepressiva', 'CAT_Antipsychotica', 'CAT_ALL_PSYCHOTROPICS_EXCL_BENZO', 'CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS', 'CAT_ALL_PSYCHOTROPICS', 'CAT_ALL']\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# This finds all variables that start with covariates_CAT_ or covariates_cat_\n",
    "final_covariates_map = defaultdict(list)\n",
    "final_covariates_map.update({\n",
    "    var.replace(\"covariates_\", \"\"): val\n",
    "    for var, val in globals().items()\n",
    "    if var.lower().startswith(\"covariates_cat_\") and isinstance(val, list)\n",
    "})\n",
    "\n",
    "# Show detected group names\n",
    "print(\"Groups found:\", list(final_covariates_map.keys()))\n",
    "medication_groups = list(final_covariates_map.keys())\n",
    "print(medication_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ef0586b8-17ca-4e92-acc8-b137bd4e98a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Starting analysis for all CAT groups\n",
      "\n",
      " Processing CAT_Adhd...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: CAT_Adhd\n",
      "\n",
      " Processing CAT_Aceetanilidederivaten...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: CAT_Aceetanilidederivaten\n",
      "\n",
      " Processing CAT_Z_Drugs...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: CAT_Z_Drugs\n",
      "\n",
      " Processing CAT_Opioden...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: CAT_Opioden\n",
      "\n",
      " Processing CAT_Nsaids...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: CAT_Nsaids\n",
      "\n",
      " Processing CAT_Benzodiazepine...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: CAT_Benzodiazepine\n",
      "\n",
      " Processing CAT_Antihypertensiva...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: CAT_Antihypertensiva\n",
      "\n",
      " Processing CAT_Antihistaminica...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: CAT_Antihistaminica\n",
      "\n",
      " Processing CAT_Anti_Epileptica...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: CAT_Anti_Epileptica\n",
      "\n",
      " Processing CAT_Antidepressiva...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: CAT_Antidepressiva\n",
      "\n",
      " Processing CAT_Antipsychotica...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: CAT_Antipsychotica\n",
      "\n",
      " Processing CAT_All_Psychotropics_Excl_Benzo...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: CAT_All_Psychotropics_Excl_Benzo\n",
      "\n",
      " Processing CAT_All_Psychotropics_Excl_Sedatives_Hypnotics...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: CAT_All_Psychotropics_Excl_Sedatives_Hypnotics\n",
      "\n",
      " Processing CAT_All_Psychotropics...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: CAT_All_Psychotropics\n",
      "\n",
      " Processing CAT_All...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: CAT_All\n",
      "\n",
      " All CAT group analyses complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def run_all_CAT_group_models(imputed_dfs):\n",
    "    \"\"\"\n",
    "    Runs downstream analysis for each CAT medication group using imputed datasets.\n",
    "\n",
    "    Parameters:\n",
    "    - imputed_dfs: list of 5 imputed DataFrames (from df_imputed_final_imp1.pkl ... imp5.pkl)\n",
    "    \n",
    "    Notes:\n",
    "    - Covariate lists must be defined as global variables: covariates_cat_<group>\n",
    "    - Outputs are saved in: outputs/CAT_<GROUP>/\n",
    "    \"\"\"\n",
    "\n",
    "    print(\" Starting analysis for all CAT groups\")\n",
    "\n",
    "    for var_name in globals():\n",
    "        if var_name.lower().startswith(\"covariates_cat_\") and isinstance(globals()[var_name], list):\n",
    "            group_name = var_name.replace(\"covariates_\", \"\")\n",
    "            group_name = group_name.replace(\"_\", \" \").title().replace(\" \", \"_\")  # e.g., cat_z_drugs → Cat_Z_Drugs\n",
    "            group_name = group_name.replace(\"Cat_\", \"CAT_\")  # force prefix to uppercase\n",
    "\n",
    "            covariates = globals()[var_name]\n",
    "            output_dir = f\"outputs/{group_name}\"\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "            print(f\"\\n Processing {group_name}...\")\n",
    "\n",
    "            for k, df_imp in enumerate(imputed_dfs):\n",
    "                print(f\"  → Using imputation {k+1}\")\n",
    "\n",
    "                # Define X and Y\n",
    "                X = df_imp[covariates]\n",
    "                Y = df_imp[\"caps5_change_baseline\"]\n",
    "\n",
    "                # === Save X and Y as placeholder (replace with modeling later)\n",
    "                X.to_csv(f\"{output_dir}/X_imp{k+1}.csv\", index=False)\n",
    "                Y.to_frame(name=\"Y\").to_csv(f\"{output_dir}/Y_imp{k+1}.csv\", index=False)\n",
    "\n",
    "            print(f\" Done: {group_name}\")\n",
    "\n",
    "    print(\"\\n All CAT group analyses complete.\")\n",
    "\n",
    "# ========= STEP 4: Execute ========= #\n",
    "run_all_CAT_group_models(imputed_dfs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "964aaa15-0261-4194-b3ea-3d42c6e093d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " CAT_ADHD\n",
      "  Imp 1: Treated = 56, Control = 3585, Missing = 0\n",
      "  Imp 2: Treated = 56, Control = 3585, Missing = 0\n",
      "  Imp 3: Treated = 56, Control = 3585, Missing = 0\n",
      "  Imp 4: Treated = 56, Control = 3585, Missing = 0\n",
      "  Imp 5: Treated = 56, Control = 3585, Missing = 0\n",
      "\n",
      " CAT_Aceetanilidederivaten\n",
      "  Imp 1: Treated = 50, Control = 3591, Missing = 0\n",
      "  Imp 2: Treated = 50, Control = 3591, Missing = 0\n",
      "  Imp 3: Treated = 50, Control = 3591, Missing = 0\n",
      "  Imp 4: Treated = 50, Control = 3591, Missing = 0\n",
      "  Imp 5: Treated = 50, Control = 3591, Missing = 0\n",
      "\n",
      " CAT_Z_drugs\n",
      "  Imp 1: Treated = 57, Control = 3584, Missing = 0\n",
      "  Imp 2: Treated = 57, Control = 3584, Missing = 0\n",
      "  Imp 3: Treated = 57, Control = 3584, Missing = 0\n",
      "  Imp 4: Treated = 57, Control = 3584, Missing = 0\n",
      "  Imp 5: Treated = 57, Control = 3584, Missing = 0\n",
      "\n",
      " CAT_Opioden\n",
      "  Imp 1: Treated = 54, Control = 3587, Missing = 0\n",
      "  Imp 2: Treated = 54, Control = 3587, Missing = 0\n",
      "  Imp 3: Treated = 54, Control = 3587, Missing = 0\n",
      "  Imp 4: Treated = 54, Control = 3587, Missing = 0\n",
      "  Imp 5: Treated = 54, Control = 3587, Missing = 0\n",
      "\n",
      " CAT_NSAIDs\n",
      "  Imp 1: Treated = 37, Control = 3604, Missing = 0\n",
      "  Imp 2: Treated = 37, Control = 3604, Missing = 0\n",
      "  Imp 3: Treated = 37, Control = 3604, Missing = 0\n",
      "  Imp 4: Treated = 37, Control = 3604, Missing = 0\n",
      "  Imp 5: Treated = 37, Control = 3604, Missing = 0\n",
      "\n",
      " CAT_Benzodiazepine\n",
      "  Imp 1: Treated = 396, Control = 3245, Missing = 0\n",
      "  Imp 2: Treated = 396, Control = 3245, Missing = 0\n",
      "  Imp 3: Treated = 396, Control = 3245, Missing = 0\n",
      "  Imp 4: Treated = 396, Control = 3245, Missing = 0\n",
      "  Imp 5: Treated = 396, Control = 3245, Missing = 0\n",
      "\n",
      " CAT_Antihypertensiva\n",
      "  Imp 1: Treated = 45, Control = 3596, Missing = 0\n",
      "  Imp 2: Treated = 45, Control = 3596, Missing = 0\n",
      "  Imp 3: Treated = 45, Control = 3596, Missing = 0\n",
      "  Imp 4: Treated = 45, Control = 3596, Missing = 0\n",
      "  Imp 5: Treated = 45, Control = 3596, Missing = 0\n",
      "\n",
      " CAT_Antihistaminica\n",
      "  Imp 1: Treated = 56, Control = 3585, Missing = 0\n",
      "  Imp 2: Treated = 56, Control = 3585, Missing = 0\n",
      "  Imp 3: Treated = 56, Control = 3585, Missing = 0\n",
      "  Imp 4: Treated = 56, Control = 3585, Missing = 0\n",
      "  Imp 5: Treated = 56, Control = 3585, Missing = 0\n",
      "\n",
      " CAT_Anti_epileptica\n",
      "  Imp 1: Treated = 84, Control = 3557, Missing = 0\n",
      "  Imp 2: Treated = 84, Control = 3557, Missing = 0\n",
      "  Imp 3: Treated = 84, Control = 3557, Missing = 0\n",
      "  Imp 4: Treated = 84, Control = 3557, Missing = 0\n",
      "  Imp 5: Treated = 84, Control = 3557, Missing = 0\n",
      "\n",
      " CAT_Antidepressiva\n",
      "  Imp 1: Treated = 636, Control = 3005, Missing = 0\n",
      "  Imp 2: Treated = 636, Control = 3005, Missing = 0\n",
      "  Imp 3: Treated = 636, Control = 3005, Missing = 0\n",
      "  Imp 4: Treated = 636, Control = 3005, Missing = 0\n",
      "  Imp 5: Treated = 636, Control = 3005, Missing = 0\n",
      "\n",
      " CAT_Antipsychotica\n",
      "  Imp 1: Treated = 268, Control = 3373, Missing = 0\n",
      "  Imp 2: Treated = 268, Control = 3373, Missing = 0\n",
      "  Imp 3: Treated = 268, Control = 3373, Missing = 0\n",
      "  Imp 4: Treated = 268, Control = 3373, Missing = 0\n",
      "  Imp 5: Treated = 268, Control = 3373, Missing = 0\n",
      "\n",
      " CAT_ALL_PSYCHOTROPICS_EXCL_BENZO\n",
      "  Imp 1: Treated = 869, Control = 2772, Missing = 0\n",
      "  Imp 2: Treated = 869, Control = 2772, Missing = 0\n",
      "  Imp 3: Treated = 869, Control = 2772, Missing = 0\n",
      "  Imp 4: Treated = 869, Control = 2772, Missing = 0\n",
      "  Imp 5: Treated = 869, Control = 2772, Missing = 0\n",
      "\n",
      " CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS\n",
      "  Imp 1: Treated = 846, Control = 2795, Missing = 0\n",
      "  Imp 2: Treated = 846, Control = 2795, Missing = 0\n",
      "  Imp 3: Treated = 846, Control = 2795, Missing = 0\n",
      "  Imp 4: Treated = 846, Control = 2795, Missing = 0\n",
      "  Imp 5: Treated = 846, Control = 2795, Missing = 0\n",
      "\n",
      " CAT_ALL_PSYCHOTROPICS\n",
      "  Imp 1: Treated = 1031, Control = 2610, Missing = 0\n",
      "  Imp 2: Treated = 1031, Control = 2610, Missing = 0\n",
      "  Imp 3: Treated = 1031, Control = 2610, Missing = 0\n",
      "  Imp 4: Treated = 1031, Control = 2610, Missing = 0\n",
      "  Imp 5: Treated = 1031, Control = 2610, Missing = 0\n",
      "\n",
      " CAT_ALL\n",
      "  Imp 1: Treated = 1072, Control = 2569, Missing = 0\n",
      "  Imp 2: Treated = 1072, Control = 2569, Missing = 0\n",
      "  Imp 3: Treated = 1072, Control = 2569, Missing = 0\n",
      "  Imp 4: Treated = 1072, Control = 2569, Missing = 0\n",
      "  Imp 5: Treated = 1072, Control = 2569, Missing = 0\n"
     ]
    }
   ],
   "source": [
    "for treatment_var in medication_groups:\n",
    "    print(f\"\\n {treatment_var}\")\n",
    "    \n",
    "    for i, df in enumerate(imputed_dfs):\n",
    "        if treatment_var not in df.columns:\n",
    "            print(f\"  Imp {i+1}:  Not found in columns.\")\n",
    "            continue\n",
    "\n",
    "        treated = (df[treatment_var] == 1).sum()\n",
    "        control = (df[treatment_var] == 0).sum()\n",
    "        missing = df[treatment_var].isna().sum()\n",
    "\n",
    "        print(f\"  Imp {i+1}: Treated = {treated}, Control = {control}, Missing = {missing}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "556179f5-ba78-4e8d-ac27-5632bc5aaf4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Processing VIF for CAT_ADHD\n",
      " ✅ Saved: outputs\\CAT_ADHD/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for CAT_Aceetanilidederivaten\n",
      " ✅ Saved: outputs\\CAT_Aceetanilidederivaten/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for CAT_Z_drugs\n",
      " ✅ Saved: outputs\\CAT_Z_drugs/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for CAT_Opioden\n",
      " ✅ Saved: outputs\\CAT_Opioden/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for CAT_NSAIDs\n",
      " ✅ Saved: outputs\\CAT_NSAIDs/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for CAT_Benzodiazepine\n",
      " ✅ Saved: outputs\\CAT_Benzodiazepine/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for CAT_Antihypertensiva\n",
      " ✅ Saved: outputs\\CAT_Antihypertensiva/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for CAT_Antihistaminica\n",
      " ✅ Saved: outputs\\CAT_Antihistaminica/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for CAT_Anti_epileptica\n",
      " ✅ Saved: outputs\\CAT_Anti_epileptica/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for CAT_Antidepressiva\n",
      " ✅ Saved: outputs\\CAT_Antidepressiva/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for CAT_Antipsychotica\n",
      " ✅ Saved: outputs\\CAT_Antipsychotica/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for CAT_ALL_PSYCHOTROPICS_EXCL_BENZO\n",
      " ✅ Saved: outputs\\CAT_ALL_PSYCHOTROPICS_EXCL_BENZO/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS\n",
      " ✅ Saved: outputs\\CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for CAT_ALL_PSYCHOTROPICS\n",
      " ✅ Saved: outputs\\CAT_ALL_PSYCHOTROPICS/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for CAT_ALL\n",
      " ✅ Saved: outputs\\CAT_ALL/pooled_vif.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from collections import defaultdict\n",
    "\n",
    "# ✅ VIF computation function\n",
    "def compute_vif(X):\n",
    "    X = sm.add_constant(X, has_constant='add')\n",
    "    vif_df = pd.DataFrame()\n",
    "    vif_df[\"variable\"] = X.columns\n",
    "    vif_df[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "    return vif_df\n",
    "\n",
    "# ✅ Process each group\n",
    "for group in medication_groups:\n",
    "    print(f\"\\n🔍 Processing VIF for {group}\")\n",
    "\n",
    "    if group not in final_covariates_map:\n",
    "        print(f\" ⚠️ No covariates found for {group}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    covariates = final_covariates_map[group]\n",
    "    vif_list = []\n",
    "\n",
    "    for i, df_imp in enumerate(imputed_dfs):\n",
    "        try:\n",
    "            X = df_imp[covariates].copy()\n",
    "            vif_df = compute_vif(X)\n",
    "            vif_df[\"imputation\"] = i + 1\n",
    "            vif_list.append(vif_df)\n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ Failed on imputation {i+1} for {group}: {e}\")\n",
    "\n",
    "    if vif_list:\n",
    "        all_vif = pd.concat(vif_list)\n",
    "        pooled_vif = all_vif.groupby(\"variable\")[\"VIF\"].mean().reset_index()\n",
    "        pooled_vif = pooled_vif.sort_values(by=\"VIF\", ascending=False)\n",
    "\n",
    "        output_folder = os.path.join(\"outputs\", group)\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        pooled_vif.to_csv(os.path.join(output_folder, \"pooled_vif.csv\"), index=False)\n",
    "\n",
    "        print(f\" ✅ Saved: {output_folder}/pooled_vif.csv\")\n",
    "    else:\n",
    "        print(f\" ⚠️ Skipped {group}: No valid imputations.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5c8f0127-0657-483c-9469-c4d67267d7cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Running PS estimation for CAT_ADHD\n",
      "   Imp 1: AUC = 0.705, ROC saved.\n",
      "   Imp 2: AUC = 0.678, ROC saved.\n",
      "   Imp 3: AUC = 0.675, ROC saved.\n",
      "   Imp 4: AUC = 0.751, ROC saved.\n",
      "   Imp 5: AUC = 0.635, ROC saved.\n",
      " Composite PS + AUC saved for CAT_ADHD\n",
      " Running PS estimation for CAT_Aceetanilidederivaten\n",
      "   Imp 1: AUC = 0.725, ROC saved.\n",
      "   Imp 2: AUC = 0.774, ROC saved.\n",
      "   Imp 3: AUC = 0.726, ROC saved.\n",
      "   Imp 4: AUC = 0.786, ROC saved.\n",
      "   Imp 5: AUC = 0.759, ROC saved.\n",
      " Composite PS + AUC saved for CAT_Aceetanilidederivaten\n",
      " Running PS estimation for CAT_Z_drugs\n",
      "   Imp 1: AUC = 0.746, ROC saved.\n",
      "   Imp 2: AUC = 0.724, ROC saved.\n",
      "   Imp 3: AUC = 0.699, ROC saved.\n",
      "   Imp 4: AUC = 0.712, ROC saved.\n",
      "   Imp 5: AUC = 0.702, ROC saved.\n",
      " Composite PS + AUC saved for CAT_Z_drugs\n",
      " Running PS estimation for CAT_Opioden\n",
      "   Imp 1: AUC = 0.772, ROC saved.\n",
      "   Imp 2: AUC = 0.800, ROC saved.\n",
      "   Imp 3: AUC = 0.809, ROC saved.\n",
      "   Imp 4: AUC = 0.791, ROC saved.\n",
      "   Imp 5: AUC = 0.794, ROC saved.\n",
      " Composite PS + AUC saved for CAT_Opioden\n",
      " Running PS estimation for CAT_NSAIDs\n",
      "   Imp 1: AUC = 0.676, ROC saved.\n",
      "   Imp 2: AUC = 0.668, ROC saved.\n",
      "   Imp 3: AUC = 0.683, ROC saved.\n",
      "   Imp 4: AUC = 0.700, ROC saved.\n",
      "   Imp 5: AUC = 0.654, ROC saved.\n",
      " Composite PS + AUC saved for CAT_NSAIDs\n",
      " Running PS estimation for CAT_Benzodiazepine\n",
      "   Imp 1: AUC = 0.764, ROC saved.\n",
      "   Imp 2: AUC = 0.736, ROC saved.\n",
      "   Imp 3: AUC = 0.754, ROC saved.\n",
      "   Imp 4: AUC = 0.763, ROC saved.\n",
      "   Imp 5: AUC = 0.763, ROC saved.\n",
      " Composite PS + AUC saved for CAT_Benzodiazepine\n",
      " Running PS estimation for CAT_Antihypertensiva\n",
      "   Imp 1: AUC = 0.783, ROC saved.\n",
      "   Imp 2: AUC = 0.766, ROC saved.\n",
      "   Imp 3: AUC = 0.759, ROC saved.\n",
      "   Imp 4: AUC = 0.752, ROC saved.\n",
      "   Imp 5: AUC = 0.734, ROC saved.\n",
      " Composite PS + AUC saved for CAT_Antihypertensiva\n",
      " Running PS estimation for CAT_Antihistaminica\n",
      "   Imp 1: AUC = 0.798, ROC saved.\n",
      "   Imp 2: AUC = 0.793, ROC saved.\n",
      "   Imp 3: AUC = 0.789, ROC saved.\n",
      "   Imp 4: AUC = 0.771, ROC saved.\n",
      "   Imp 5: AUC = 0.761, ROC saved.\n",
      " Composite PS + AUC saved for CAT_Antihistaminica\n",
      " Running PS estimation for CAT_Anti_epileptica\n",
      "   Imp 1: AUC = 0.727, ROC saved.\n",
      "   Imp 2: AUC = 0.775, ROC saved.\n",
      "   Imp 3: AUC = 0.746, ROC saved.\n",
      "   Imp 4: AUC = 0.784, ROC saved.\n",
      "   Imp 5: AUC = 0.742, ROC saved.\n",
      " Composite PS + AUC saved for CAT_Anti_epileptica\n",
      " Running PS estimation for CAT_Antidepressiva\n",
      "   Imp 1: AUC = 0.788, ROC saved.\n",
      "   Imp 2: AUC = 0.771, ROC saved.\n",
      "   Imp 3: AUC = 0.780, ROC saved.\n",
      "   Imp 4: AUC = 0.779, ROC saved.\n",
      "   Imp 5: AUC = 0.793, ROC saved.\n",
      " Composite PS + AUC saved for CAT_Antidepressiva\n",
      " Running PS estimation for CAT_Antipsychotica\n",
      "   Imp 1: AUC = 0.801, ROC saved.\n",
      "   Imp 2: AUC = 0.805, ROC saved.\n",
      "   Imp 3: AUC = 0.821, ROC saved.\n",
      "   Imp 4: AUC = 0.803, ROC saved.\n",
      "   Imp 5: AUC = 0.821, ROC saved.\n",
      " Composite PS + AUC saved for CAT_Antipsychotica\n",
      " Running PS estimation for CAT_ALL_PSYCHOTROPICS_EXCL_BENZO\n",
      "   Imp 1: AUC = 0.772, ROC saved.\n",
      "   Imp 2: AUC = 0.776, ROC saved.\n",
      "   Imp 3: AUC = 0.771, ROC saved.\n",
      "   Imp 4: AUC = 0.768, ROC saved.\n",
      "   Imp 5: AUC = 0.771, ROC saved.\n",
      " Composite PS + AUC saved for CAT_ALL_PSYCHOTROPICS_EXCL_BENZO\n",
      " Running PS estimation for CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS\n",
      "   Imp 1: AUC = 0.783, ROC saved.\n",
      "   Imp 2: AUC = 0.779, ROC saved.\n",
      "   Imp 3: AUC = 0.781, ROC saved.\n",
      "   Imp 4: AUC = 0.769, ROC saved.\n",
      "   Imp 5: AUC = 0.780, ROC saved.\n",
      " Composite PS + AUC saved for CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS\n",
      " Running PS estimation for CAT_ALL_PSYCHOTROPICS\n",
      "   Imp 1: AUC = 0.773, ROC saved.\n",
      "   Imp 2: AUC = 0.770, ROC saved.\n",
      "   Imp 3: AUC = 0.772, ROC saved.\n",
      "   Imp 4: AUC = 0.759, ROC saved.\n",
      "   Imp 5: AUC = 0.775, ROC saved.\n",
      " Composite PS + AUC saved for CAT_ALL_PSYCHOTROPICS\n",
      " Running PS estimation for CAT_ALL\n",
      "   Imp 1: AUC = 0.779, ROC saved.\n",
      "   Imp 2: AUC = 0.785, ROC saved.\n",
      "   Imp 3: AUC = 0.779, ROC saved.\n",
      "   Imp 4: AUC = 0.775, ROC saved.\n",
      "   Imp 5: AUC = 0.786, ROC saved.\n",
      " Composite PS + AUC saved for CAT_ALL\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ---------- PS Estimation Function ----------\n",
    "def run_xgboost_ps_modeling(imputed_dfs, medication_groups, final_covariates_map):\n",
    "    for group in medication_groups:\n",
    "        print(f\" Running PS estimation for {group}\")\n",
    "\n",
    "        if group not in final_covariates_map:\n",
    "            print(f\" No covariates found for {group}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        output_folder = os.path.join(\"outputs\", group)\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "        covariates = final_covariates_map[group]\n",
    "        ps_matrix = pd.DataFrame()\n",
    "        auc_list = []\n",
    "\n",
    "        for i, df_imp in enumerate(imputed_dfs):\n",
    "            if group not in df_imp.columns:\n",
    "                print(f\" {group} not found in imputed dataset {i+1}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            X = df_imp[covariates].copy()\n",
    "            T = df_imp[group]\n",
    "\n",
    "            # Drop missing treatment rows\n",
    "            valid_idx = T.dropna().index\n",
    "            X = X.loc[valid_idx]\n",
    "            T = T.loc[valid_idx]\n",
    "\n",
    "            # Train-test split for ROC\n",
    "            X_train, X_test, T_train, T_test = train_test_split(\n",
    "                X, T, stratify=T, test_size=0.3, random_state=42\n",
    "            )\n",
    "\n",
    "            try:\n",
    "                model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "                model.fit(X_train, T_train)\n",
    "\n",
    "                ps_scores = model.predict_proba(X)[:, 1]\n",
    "                ps_matrix[f\"ps_imp{i+1}\"] = pd.Series(ps_scores, index=valid_idx)\n",
    "\n",
    "                # ROC & AUC\n",
    "                auc = roc_auc_score(T_test, model.predict_proba(X_test)[:, 1])\n",
    "                auc_list.append(auc)\n",
    "\n",
    "                fpr, tpr, _ = roc_curve(T_test, model.predict_proba(X_test)[:, 1])\n",
    "                plt.figure()\n",
    "                plt.plot(fpr, tpr, label=f\"AUC = {auc:.3f}\")\n",
    "                plt.plot([0, 1], [0, 1], 'k--')\n",
    "                plt.xlabel(\"False Positive Rate\")\n",
    "                plt.ylabel(\"True Positive Rate\")\n",
    "                plt.title(f\"ROC Curve - {group} (Imp {i+1})\")\n",
    "                plt.legend()\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(os.path.join(output_folder, f\"roc_curve_imp{i+1}.png\"))\n",
    "                plt.close()\n",
    "                print(f\"   Imp {i+1}: AUC = {auc:.3f}, ROC saved.\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"   Error in {group} (imp {i+1}): {e}\")\n",
    "\n",
    "        # Save AUCs and Composite PS\n",
    "        if not ps_matrix.empty:\n",
    "            # Fill NaN rows (from dropped subjects in some imputations) with mean\n",
    "            ps_matrix[\"composite_ps\"] = ps_matrix.mean(axis=1)\n",
    "            ps_matrix.to_excel(os.path.join(output_folder, \"propensity_scores.xlsx\"))\n",
    "\n",
    "            auc_df = pd.DataFrame({\n",
    "                \"imputation\": [f\"imp{i+1}\" for i in range(len(auc_list))],\n",
    "                \"AUC\": auc_list\n",
    "            })\n",
    "            auc_df.loc[len(auc_df.index)] = [\"mean\", np.mean(auc_list) if auc_list else np.nan]\n",
    "            auc_df.to_excel(os.path.join(output_folder, \"auc_scores.xlsx\"), index=False)\n",
    "\n",
    "            print(f\" Composite PS + AUC saved for {group}\")\n",
    "        else:\n",
    "            print(f\" No valid PS scores generated for {group}\")\n",
    "\n",
    "# ---------- Run ----------\n",
    "run_xgboost_ps_modeling(imputed_dfs, medication_groups, final_covariates_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6b7ac931-822f-4b4a-b79e-62211e9b032c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Computing feature importance for CAT_ADHD\n",
      " Saved feature importance plot and CSV for CAT_ADHD\n",
      "\n",
      " Computing feature importance for CAT_Aceetanilidederivaten\n",
      " Saved feature importance plot and CSV for CAT_Aceetanilidederivaten\n",
      "\n",
      " Computing feature importance for CAT_Z_drugs\n",
      " Saved feature importance plot and CSV for CAT_Z_drugs\n",
      "\n",
      " Computing feature importance for CAT_Opioden\n",
      " Saved feature importance plot and CSV for CAT_Opioden\n",
      "\n",
      " Computing feature importance for CAT_NSAIDs\n",
      " Saved feature importance plot and CSV for CAT_NSAIDs\n",
      "\n",
      " Computing feature importance for CAT_Benzodiazepine\n",
      " Saved feature importance plot and CSV for CAT_Benzodiazepine\n",
      "\n",
      " Computing feature importance for CAT_Antihypertensiva\n",
      " Saved feature importance plot and CSV for CAT_Antihypertensiva\n",
      "\n",
      " Computing feature importance for CAT_Antihistaminica\n",
      " Saved feature importance plot and CSV for CAT_Antihistaminica\n",
      "\n",
      " Computing feature importance for CAT_Anti_epileptica\n",
      " Saved feature importance plot and CSV for CAT_Anti_epileptica\n",
      "\n",
      " Computing feature importance for CAT_Antidepressiva\n",
      " Saved feature importance plot and CSV for CAT_Antidepressiva\n",
      "\n",
      " Computing feature importance for CAT_Antipsychotica\n",
      " Saved feature importance plot and CSV for CAT_Antipsychotica\n",
      "\n",
      " Computing feature importance for CAT_ALL_PSYCHOTROPICS_EXCL_BENZO\n",
      " Saved feature importance plot and CSV for CAT_ALL_PSYCHOTROPICS_EXCL_BENZO\n",
      "\n",
      " Computing feature importance for CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS\n",
      " Saved feature importance plot and CSV for CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS\n",
      "\n",
      " Computing feature importance for CAT_ALL_PSYCHOTROPICS\n",
      " Saved feature importance plot and CSV for CAT_ALL_PSYCHOTROPICS\n",
      "\n",
      " Computing feature importance for CAT_ALL\n",
      " Saved feature importance plot and CSV for CAT_ALL\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "def compute_feature_importance(imputed_dfs, medication_groups, final_covariates_map):\n",
    "    for group in medication_groups:\n",
    "        print(f\"\\n Computing feature importance for {group}\")\n",
    "\n",
    "        if group not in final_covariates_map:\n",
    "            print(f\" No covariates found for {group}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        covariates = final_covariates_map[group]\n",
    "        output_folder = os.path.join(\"outputs\", group)\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "        importance_df_list = []\n",
    "\n",
    "        for i, df_imp in enumerate(imputed_dfs):\n",
    "            if group not in df_imp.columns:\n",
    "                print(f\" {group} not in imputed dataset {i+1}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            X = df_imp[covariates].copy()\n",
    "            T = df_imp[group]\n",
    "\n",
    "            # Drop NaNs in treatment\n",
    "            valid_idx = T.dropna().index\n",
    "            X = X.loc[valid_idx]\n",
    "            T = T.loc[valid_idx]\n",
    "\n",
    "            try:\n",
    "                model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "                model.fit(X, T)\n",
    "\n",
    "                # Get feature importance\n",
    "                importances = model.get_booster().get_score(importance_type='gain')\n",
    "                df_feat = pd.DataFrame.from_dict(importances, orient='index', columns=[f\"imp{i+1}\"])\n",
    "                df_feat.index.name = 'feature'\n",
    "                importance_df_list.append(df_feat)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"   Error during modeling: {e}\")\n",
    "\n",
    "        if importance_df_list:\n",
    "            # Combine and average\n",
    "            all_feat = pd.concat(importance_df_list, axis=1).fillna(0)\n",
    "            all_feat[\"mean_importance\"] = all_feat.mean(axis=1)\n",
    "\n",
    "            # Filter top 30 non-zero\n",
    "            non_zero = all_feat[all_feat[\"mean_importance\"] > 0]\n",
    "            top30 = non_zero.sort_values(by=\"mean_importance\", ascending=False).head(30)\n",
    "\n",
    "            # Save to CSV\n",
    "            top30.to_csv(os.path.join(output_folder, \"feature_importance.csv\"))\n",
    "\n",
    "            # Plot\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            plt.barh(top30.index[::-1], top30[\"mean_importance\"][::-1])  # plot top → bottom\n",
    "            plt.xlabel(\"Mean Gain Importance\")\n",
    "            plt.title(f\"Top 30 Feature Importance - {group}\")\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(output_folder, \"feature_importance_top30.png\"))\n",
    "            plt.close()\n",
    "\n",
    "            print(f\" Saved feature importance plot and CSV for {group}\")\n",
    "        else:\n",
    "            print(f\" No valid models for {group}\")\n",
    "\n",
    "#  Run\n",
    "compute_feature_importance(imputed_dfs, medication_groups, final_covariates_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "151ba168-9ae5-400a-a2cd-0485a8a7c5a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Processing IPTW + trimming + clipping for CAT_ADHD\n",
      "✅ Saved IPTW weights for CAT_ADHD\n",
      "    ℹ️ Retained 108/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_ADHD/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 97/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_ADHD/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 107/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_ADHD/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 100/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_ADHD/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 104/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_ADHD/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for CAT_Aceetanilidederivaten\n",
      "✅ Saved IPTW weights for CAT_Aceetanilidederivaten\n",
      "    ℹ️ Retained 73/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Aceetanilidederivaten/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 71/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Aceetanilidederivaten/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 73/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Aceetanilidederivaten/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 72/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Aceetanilidederivaten/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 68/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Aceetanilidederivaten/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for CAT_Z_drugs\n",
      "✅ Saved IPTW weights for CAT_Z_drugs\n",
      "    ℹ️ Retained 103/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Z_drugs/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 101/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Z_drugs/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 103/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Z_drugs/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 104/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Z_drugs/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 104/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Z_drugs/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for CAT_Opioden\n",
      "✅ Saved IPTW weights for CAT_Opioden\n",
      "    ℹ️ Retained 92/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Opioden/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 94/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Opioden/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 91/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Opioden/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 97/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Opioden/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 94/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Opioden/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for CAT_NSAIDs\n",
      "✅ Saved IPTW weights for CAT_NSAIDs\n",
      "    ℹ️ Retained 65/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_NSAIDs/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 63/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_NSAIDs/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 66/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_NSAIDs/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 68/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_NSAIDs/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 62/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_NSAIDs/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for CAT_Benzodiazepine\n",
      "✅ Saved IPTW weights for CAT_Benzodiazepine\n",
      "    ℹ️ Retained 1037/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Benzodiazepine/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 1038/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Benzodiazepine/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 984/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Benzodiazepine/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 1105/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Benzodiazepine/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 1028/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Benzodiazepine/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for CAT_Antihypertensiva\n",
      "✅ Saved IPTW weights for CAT_Antihypertensiva\n",
      "    ℹ️ Retained 85/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Antihypertensiva/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 84/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Antihypertensiva/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 79/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Antihypertensiva/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 85/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Antihypertensiva/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 85/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Antihypertensiva/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for CAT_Antihistaminica\n",
      "✅ Saved IPTW weights for CAT_Antihistaminica\n",
      "    ℹ️ Retained 92/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Antihistaminica/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 86/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Antihistaminica/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 100/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Antihistaminica/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 89/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Antihistaminica/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 87/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Antihistaminica/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for CAT_Anti_epileptica\n",
      "✅ Saved IPTW weights for CAT_Anti_epileptica\n",
      "    ℹ️ Retained 130/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Anti_epileptica/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 135/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Anti_epileptica/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 142/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Anti_epileptica/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 150/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Anti_epileptica/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 143/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Anti_epileptica/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for CAT_Antidepressiva\n",
      "✅ Saved IPTW weights for CAT_Antidepressiva\n",
      "    ℹ️ Retained 1593/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Antidepressiva/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 1608/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Antidepressiva/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 1587/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Antidepressiva/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 1602/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Antidepressiva/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 1653/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Antidepressiva/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for CAT_Antipsychotica\n",
      "✅ Saved IPTW weights for CAT_Antipsychotica\n",
      "    ℹ️ Retained 591/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Antipsychotica/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 645/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Antipsychotica/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 626/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Antipsychotica/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 630/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Antipsychotica/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 612/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Antipsychotica/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for CAT_ALL_PSYCHOTROPICS_EXCL_BENZO\n",
      "✅ Saved IPTW weights for CAT_ALL_PSYCHOTROPICS_EXCL_BENZO\n",
      "    ℹ️ Retained 1951/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_ALL_PSYCHOTROPICS_EXCL_BENZO/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 1903/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_ALL_PSYCHOTROPICS_EXCL_BENZO/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 1959/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_ALL_PSYCHOTROPICS_EXCL_BENZO/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 1980/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_ALL_PSYCHOTROPICS_EXCL_BENZO/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 1923/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_ALL_PSYCHOTROPICS_EXCL_BENZO/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS\n",
      "✅ Saved IPTW weights for CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS\n",
      "    ℹ️ Retained 1928/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 1991/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 1918/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 1955/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 1845/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for CAT_ALL_PSYCHOTROPICS\n",
      "✅ Saved IPTW weights for CAT_ALL_PSYCHOTROPICS\n",
      "    ℹ️ Retained 2296/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_ALL_PSYCHOTROPICS/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 2249/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_ALL_PSYCHOTROPICS/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 2343/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_ALL_PSYCHOTROPICS/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 2296/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_ALL_PSYCHOTROPICS/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 2295/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_ALL_PSYCHOTROPICS/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for CAT_ALL\n",
      "✅ Saved IPTW weights for CAT_ALL\n",
      "    ℹ️ Retained 2303/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_ALL/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 2242/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_ALL/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 2279/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_ALL/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 2290/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_ALL/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 2354/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_ALL/trimmed_data_imp5.*\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_trimmed_clipped_iptw(ps_df, treatment, lower=0.05, upper=0.95, clip_max=10):\n",
    "    weights = []\n",
    "    keep_mask = (ps_df > lower) & (ps_df < upper)\n",
    "\n",
    "    for i in range(ps_df.shape[1]):\n",
    "        ps = ps_df.iloc[:, i].clip(lower=1e-6, upper=1 - 1e-6)  # avoid div by zero\n",
    "        mask = keep_mask.iloc[:, i]\n",
    "        w = pd.Series(np.nan, index=ps.index)\n",
    "\n",
    "        w[mask & (treatment == 1)] = 1 / ps[mask & (treatment == 1)]\n",
    "        w[mask & (treatment == 0)] = 1 / (1 - ps[mask & (treatment == 0)])\n",
    "        w = w.clip(upper=clip_max)\n",
    "        weights.append(w)\n",
    "\n",
    "    return pd.concat(weights, axis=1)\n",
    "\n",
    "\n",
    "def apply_rubins_rule_to_iptw(iptw_matrix):\n",
    "    \"\"\"\n",
    "    Given an IPTW matrix (n rows × M imputations), return Rubin’s rule pooled mean, SD, SE.\n",
    "    \"\"\"\n",
    "    M = iptw_matrix.shape[1]\n",
    "    q_bar = iptw_matrix.mean(axis=1)\n",
    "    u_bar = iptw_matrix.var(axis=1, ddof=1)\n",
    "    B = iptw_matrix.apply(lambda x: x.mean(), axis=1).var(ddof=1)\n",
    "    total_var = u_bar + (1 + 1/M) * B\n",
    "    total_se = np.sqrt(total_var)\n",
    "    return q_bar, u_bar.pow(0.5), total_se\n",
    "\n",
    "\n",
    "def run_trim_clip_save_all(imputed_dfs, medication_groups, final_covariates_map):\n",
    "    for group in medication_groups:\n",
    "        print(f\"\\n🔍 Processing IPTW + trimming + clipping for {group}\")\n",
    "        output_folder = os.path.join(\"outputs\", group)\n",
    "        ps_path = os.path.join(output_folder, \"propensity_scores.xlsx\")\n",
    "\n",
    "        if not os.path.exists(ps_path):\n",
    "            print(f\"⚠️ Missing PS file: {ps_path}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            ps_all = pd.read_excel(ps_path, index_col=0)\n",
    "            ps_cols = [col for col in ps_all.columns if col.startswith(\"ps_imp\")]\n",
    "            composite_index = ps_all.index\n",
    "\n",
    "            # Get treatment from one imputed dataset\n",
    "            T_full = None\n",
    "            for df in imputed_dfs:\n",
    "                if group in df.columns:\n",
    "                    T_full = df.loc[composite_index, group]\n",
    "                    break\n",
    "\n",
    "            if T_full is None:\n",
    "                print(f\"❌ Treatment column {group} not found in any imputed dataset.\")\n",
    "                continue\n",
    "\n",
    "            # Compute IPTW matrix (shape: n × M)\n",
    "            iptw_matrix = compute_trimmed_clipped_iptw(ps_all[ps_cols], T_full)\n",
    "            iptw_matrix.columns = [f\"iptw_imp{i+1}\" for i in range(iptw_matrix.shape[1])]\n",
    "\n",
    "            # Apply Rubin’s Rule for mean, SD, SE\n",
    "            iptw_matrix[\"iptw_mean\"], iptw_matrix[\"iptw_sd\"], iptw_matrix[\"iptw_se\"] = apply_rubins_rule_to_iptw(\n",
    "                iptw_matrix[[f\"iptw_imp{i+1}\" for i in range(iptw_matrix.shape[1])]]\n",
    "            )\n",
    "\n",
    "            # Save IPTW matrix separately\n",
    "            iptw_matrix.to_excel(os.path.join(output_folder, \"iptw_weights.xlsx\"))\n",
    "            print(f\"✅ Saved IPTW weights for {group}\")\n",
    "\n",
    "            # Save trimmed & clipped imputed datasets with IPTW\n",
    "            for i in range(5):\n",
    "                df = imputed_dfs[i].copy()\n",
    "                if group not in df.columns:\n",
    "                    continue\n",
    "\n",
    "                trimmed_idx = iptw_matrix.index.intersection(df.index)\n",
    "                needed_cols = final_covariates_map[group] + [group, \"caps5_change_baseline\"]\n",
    "\n",
    "                # Select only necessary columns\n",
    "                df_trimmed = df.loc[trimmed_idx, needed_cols].copy()\n",
    "                df_trimmed[\"iptw\"] = iptw_matrix[f\"iptw_imp{i+1}\"].loc[trimmed_idx]\n",
    "\n",
    "                # ✅ DROP rows with missing IPTW values\n",
    "                before = len(df_trimmed)\n",
    "                df_trimmed = df_trimmed.dropna(subset=[\"iptw\"])\n",
    "                after = len(df_trimmed)\n",
    "                print(f\"    ℹ️ Retained {after}/{before} rows after IPTW NaN drop.\")\n",
    "\n",
    "                # Save to .pkl\n",
    "                df_trimmed.to_pickle(os.path.join(output_folder, f\"trimmed_data_imp{i+1}.pkl\"))\n",
    "                print(f\"  💾 Saved trimmed dataset: {output_folder}/trimmed_data_imp{i+1}.*\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error in {group}: {e}\")\n",
    "\n",
    "\n",
    "run_trim_clip_save_all(imputed_dfs, medication_groups, final_covariates_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "40ee9f71-87cb-49de-93a7-6ec93070579f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Plotting PS overlap for CAT_ADHD\n",
      "✅ Saved unweighted and weighted PS plots for CAT_ADHD\n",
      "\n",
      "📊 Plotting PS overlap for CAT_Aceetanilidederivaten\n",
      "✅ Saved unweighted and weighted PS plots for CAT_Aceetanilidederivaten\n",
      "\n",
      "📊 Plotting PS overlap for CAT_Z_drugs\n",
      "✅ Saved unweighted and weighted PS plots for CAT_Z_drugs\n",
      "\n",
      "📊 Plotting PS overlap for CAT_Opioden\n",
      "✅ Saved unweighted and weighted PS plots for CAT_Opioden\n",
      "\n",
      "📊 Plotting PS overlap for CAT_NSAIDs\n",
      "✅ Saved unweighted and weighted PS plots for CAT_NSAIDs\n",
      "\n",
      "📊 Plotting PS overlap for CAT_Benzodiazepine\n",
      "✅ Saved unweighted and weighted PS plots for CAT_Benzodiazepine\n",
      "\n",
      "📊 Plotting PS overlap for CAT_Antihypertensiva\n",
      "✅ Saved unweighted and weighted PS plots for CAT_Antihypertensiva\n",
      "\n",
      "📊 Plotting PS overlap for CAT_Antihistaminica\n",
      "✅ Saved unweighted and weighted PS plots for CAT_Antihistaminica\n",
      "\n",
      "📊 Plotting PS overlap for CAT_Anti_epileptica\n",
      "✅ Saved unweighted and weighted PS plots for CAT_Anti_epileptica\n",
      "\n",
      "📊 Plotting PS overlap for CAT_Antidepressiva\n",
      "✅ Saved unweighted and weighted PS plots for CAT_Antidepressiva\n",
      "\n",
      "📊 Plotting PS overlap for CAT_Antipsychotica\n",
      "✅ Saved unweighted and weighted PS plots for CAT_Antipsychotica\n",
      "\n",
      "📊 Plotting PS overlap for CAT_ALL_PSYCHOTROPICS_EXCL_BENZO\n",
      "✅ Saved unweighted and weighted PS plots for CAT_ALL_PSYCHOTROPICS_EXCL_BENZO\n",
      "\n",
      "📊 Plotting PS overlap for CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS\n",
      "✅ Saved unweighted and weighted PS plots for CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS\n",
      "\n",
      "📊 Plotting PS overlap for CAT_ALL_PSYCHOTROPICS\n",
      "✅ Saved unweighted and weighted PS plots for CAT_ALL_PSYCHOTROPICS\n",
      "\n",
      "📊 Plotting PS overlap for CAT_ALL\n",
      "✅ Saved unweighted and weighted PS plots for CAT_ALL\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_ps_overlap_all_groups(medication_groups):\n",
    "    for group in medication_groups:\n",
    "        print(f\"\\n📊 Plotting PS overlap for {group}\")\n",
    "\n",
    "        folder = os.path.join(\"outputs\", group)\n",
    "        ps_file = os.path.join(folder, \"propensity_scores.xlsx\")\n",
    "        iptw_file = os.path.join(folder, \"iptw_weights.xlsx\")\n",
    "        trimmed_file = os.path.join(folder, \"trimmed_data_imp1.pkl\")\n",
    "\n",
    "        if not all(os.path.exists(f) for f in [ps_file, iptw_file, trimmed_file]):\n",
    "            print(f\"⚠️ Missing required files for {group}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            ps_df = pd.read_excel(ps_file, index_col=0)\n",
    "            iptw_df = pd.read_excel(iptw_file, index_col=0)\n",
    "            trimmed_df = pd.read_pickle(trimmed_file)\n",
    "\n",
    "            # Extract\n",
    "            ps = ps_df[\"composite_ps\"].reindex(trimmed_df.index)\n",
    "            w = iptw_df[\"iptw_mean\"].reindex(trimmed_df.index)\n",
    "            T = trimmed_df[group]\n",
    "\n",
    "            # Masks to remove NaNs\n",
    "            treated_mask = (T == 1) & ps.notna() & w.notna()\n",
    "            control_mask = (T == 0) & ps.notna() & w.notna()\n",
    "\n",
    "            treated = ps[treated_mask]\n",
    "            treated_w = w[treated_mask]\n",
    "\n",
    "            control = ps[control_mask]\n",
    "            control_w = w[control_mask]\n",
    "\n",
    "            # === Unweighted Plot ===\n",
    "            plt.figure(figsize=(8, 5))\n",
    "            plt.hist([treated, control], bins=25, label=[\"Treated\", \"Control\"], alpha=0.6)\n",
    "            plt.title(f\"Unweighted PS Overlap - {group}\")\n",
    "            plt.xlabel(\"Composite Propensity Score\")\n",
    "            plt.ylabel(\"Count\")\n",
    "            plt.legend()\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(folder, \"ps_overlap_unweighted.png\"))\n",
    "            plt.close()\n",
    "\n",
    "            # === Weighted Plot ===\n",
    "            plt.figure(figsize=(8, 5))\n",
    "            plt.hist([treated, control], bins=25, weights=[treated_w, control_w], label=[\"Treated\", \"Control\"], alpha=0.6)\n",
    "            plt.title(f\"Weighted PS Overlap - {group}\")\n",
    "            plt.xlabel(\"Composite Propensity Score\")\n",
    "            plt.ylabel(\"Weighted Count\")\n",
    "            plt.legend()\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(folder, \"ps_overlap_weighted.png\"))\n",
    "            plt.close()\n",
    "\n",
    "            print(f\"✅ Saved unweighted and weighted PS plots for {group}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error processing {group}: {e}\")\n",
    "\n",
    "# 🔁 Run\n",
    "plot_ps_overlap_all_groups(medication_groups)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "de65729a-8951-4439-a512-fdbd8bc123fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ✅ Saved: outputs\\CAT_ADHD\\four_panel_overlap_CAT_ADHD.png\n",
      " ✅ Saved: outputs\\CAT_Aceetanilidederivaten\\four_panel_overlap_CAT_Aceetanilidederivaten.png\n",
      " ✅ Saved: outputs\\CAT_Z_drugs\\four_panel_overlap_CAT_Z_drugs.png\n",
      " ✅ Saved: outputs\\CAT_Opioden\\four_panel_overlap_CAT_Opioden.png\n",
      " ✅ Saved: outputs\\CAT_NSAIDs\\four_panel_overlap_CAT_NSAIDs.png\n",
      " ✅ Saved: outputs\\CAT_Benzodiazepine\\four_panel_overlap_CAT_Benzodiazepine.png\n",
      " ✅ Saved: outputs\\CAT_Antihypertensiva\\four_panel_overlap_CAT_Antihypertensiva.png\n",
      " ✅ Saved: outputs\\CAT_Antihistaminica\\four_panel_overlap_CAT_Antihistaminica.png\n",
      " ✅ Saved: outputs\\CAT_Anti_epileptica\\four_panel_overlap_CAT_Anti_epileptica.png\n",
      " ✅ Saved: outputs\\CAT_Antidepressiva\\four_panel_overlap_CAT_Antidepressiva.png\n",
      " ✅ Saved: outputs\\CAT_Antipsychotica\\four_panel_overlap_CAT_Antipsychotica.png\n",
      " ✅ Saved: outputs\\CAT_ALL_PSYCHOTROPICS_EXCL_BENZO\\four_panel_overlap_CAT_ALL_PSYCHOTROPICS_EXCL_BENZO.png\n",
      " ✅ Saved: outputs\\CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS\\four_panel_overlap_CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS.png\n",
      " ✅ Saved: outputs\\CAT_ALL_PSYCHOTROPICS\\four_panel_overlap_CAT_ALL_PSYCHOTROPICS.png\n",
      " ✅ Saved: outputs\\CAT_ALL\\four_panel_overlap_CAT_ALL.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set up base output folder\n",
    "output_base = \"outputs\"\n",
    "ps_file = \"propensity_scores.xlsx\"\n",
    "iptw_file = \"iptw_weights.xlsx\"\n",
    "trimmed_data_file = \"trimmed_data_imp1.pkl\"\n",
    "\n",
    "# Collect all treatment group folders\n",
    "groups = [g for g in medication_groups if os.path.isdir(os.path.join(output_base, g))]\n",
    "\n",
    "# Generate 4-panel overlap plots\n",
    "for group in groups:\n",
    "    group_path = os.path.join(output_base, group)\n",
    "    try:\n",
    "        # Load trimmed treatment info\n",
    "        trimmed_df = pd.read_pickle(os.path.join(group_path, trimmed_data_file))\n",
    "        index = trimmed_df.index\n",
    "\n",
    "        # Fix: case-insensitive match for treatment variable\n",
    "        possible_cols = [col for col in trimmed_df.columns if col.upper() == group.upper()]\n",
    "        if not possible_cols:\n",
    "            print(f\" Treatment variable {group} not found in {group}, skipping.\")\n",
    "            continue\n",
    "        treatment_var = possible_cols[0]\n",
    "        T = trimmed_df[treatment_var]\n",
    "\n",
    "        # Load composite PS (aligned to trimmed_df index)\n",
    "        ps_df = pd.read_excel(os.path.join(group_path, ps_file), index_col=0)\n",
    "        if 'composite_ps' not in ps_df.columns:\n",
    "            print(f\" Composite column missing in {ps_file}, skipping {group}.\")\n",
    "            continue\n",
    "        ps = ps_df.loc[index, 'composite_ps']\n",
    "\n",
    "        # Load IPTW weights (aligned to trimmed_df index)\n",
    "        weights_df = pd.read_excel(os.path.join(group_path, iptw_file), index_col=0)\n",
    "        if 'iptw_mean' not in weights_df.columns:\n",
    "            print(f\" IPTW weight column missing in {iptw_file}, skipping {group}.\")\n",
    "            continue\n",
    "        weights = weights_df.loc[index, 'iptw_mean']\n",
    "\n",
    "        # Prepare 4 datasets\n",
    "        raw_treated = ps[T == 1]\n",
    "        raw_control = ps[T == 0]\n",
    "        weighted_treated = (ps[T == 1], weights[T == 1])\n",
    "        weighted_control = (ps[T == 0], weights[T == 0])\n",
    "\n",
    "        # Create plot\n",
    "        fig, axs = plt.subplots(2, 2, figsize=(12, 8))\n",
    "        fig.suptitle(f\"Propensity Score Distribution - {group}\", fontsize=14)\n",
    "\n",
    "        axs[0, 0].hist(raw_treated, bins=20, alpha=0.7, color='blue')\n",
    "        axs[0, 0].set_title(\"Raw Treated\")\n",
    "\n",
    "        axs[0, 1].hist(raw_control, bins=20, alpha=0.7, color='green')\n",
    "        axs[0, 1].set_title(\"Raw Control\")\n",
    "\n",
    "        axs[1, 0].hist(weighted_treated[0], bins=20, weights=weighted_treated[1], alpha=0.7, color='blue')\n",
    "        axs[1, 0].set_title(\"Weighted Treated\")\n",
    "\n",
    "        axs[1, 1].hist(weighted_control[0], bins=20, weights=weighted_control[1], alpha=0.7, color='green')\n",
    "        axs[1, 1].set_title(\"Weighted Control\")\n",
    "\n",
    "        for ax in axs.flat:\n",
    "            ax.set_xlim(0, 1)\n",
    "            ax.set_xlabel(\"Propensity Score\")\n",
    "            ax.set_ylabel(\"Count\")\n",
    "\n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "\n",
    "        # Save figure\n",
    "        plot_path = os.path.join(group_path, f\"four_panel_overlap_{group}.png\")\n",
    "        plt.savefig(plot_path)\n",
    "        plt.close()\n",
    "        print(f\" ✅ Saved: {plot_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\" ❌ Error in {group}: {e}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4cafc79c-dfbd-4e76-9d53-0351551e895b",
   "metadata": {},
   "source": [
    "# ATT calculation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a4f41948-593f-43dd-b58e-821d6545c844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weighted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d2314df2-9945-4767-82df-24455dedfe58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Running DML for CAT_ADHD\n",
      "✅ CAT_ADHD | Seed 1: ATT = 1.2397, SE = 6.8200, p = 0.85613\n",
      "✅ CAT_ADHD | Seed 2: ATT = 1.0542, SE = 4.5240, p = 0.81623\n",
      "✅ CAT_ADHD | Seed 3: ATT = 1.5099, SE = 4.1519, p = 0.71688\n",
      "✅ CAT_ADHD | Seed 4: ATT = 0.5644, SE = 4.3396, p = 0.89678\n",
      "✅ CAT_ADHD | Seed 5: ATT = 1.0534, SE = 4.3665, p = 0.80987\n",
      "✅ CAT_ADHD | Seed 6: ATT = 0.9717, SE = 5.1615, p = 0.85105\n",
      "✅ CAT_ADHD | Seed 7: ATT = 0.4021, SE = 4.4526, p = 0.92822\n",
      "✅ CAT_ADHD | Seed 8: ATT = 1.3008, SE = 5.2249, p = 0.80390\n",
      "✅ CAT_ADHD | Seed 9: ATT = 0.4596, SE = 5.6194, p = 0.93498\n",
      "✅ CAT_ADHD | Seed 10: ATT = 0.7922, SE = 4.1617, p = 0.84942\n",
      "📊 Diagnostic plots saved for CAT_ADHD\n",
      "🏆 Best result for CAT_ADHD → Seed 3 | SE = 4.1519\n",
      "\n",
      "🚀 Running DML for CAT_Aceetanilidederivaten\n",
      "✅ CAT_Aceetanilidederivaten | Seed 1: ATT = 1.2488, SE = 5.2711, p = 0.81322\n",
      "✅ CAT_Aceetanilidederivaten | Seed 2: ATT = 1.2627, SE = 4.9976, p = 0.80106\n",
      "✅ CAT_Aceetanilidederivaten | Seed 3: ATT = 1.0622, SE = 5.3644, p = 0.84344\n",
      "✅ CAT_Aceetanilidederivaten | Seed 4: ATT = 1.9898, SE = 5.6774, p = 0.72672\n",
      "✅ CAT_Aceetanilidederivaten | Seed 5: ATT = 1.3893, SE = 6.3578, p = 0.82747\n",
      "✅ CAT_Aceetanilidederivaten | Seed 6: ATT = 1.1894, SE = 5.6943, p = 0.83497\n",
      "✅ CAT_Aceetanilidederivaten | Seed 7: ATT = 1.0065, SE = 5.4010, p = 0.85256\n",
      "✅ CAT_Aceetanilidederivaten | Seed 8: ATT = 1.2191, SE = 5.4568, p = 0.82368\n",
      "✅ CAT_Aceetanilidederivaten | Seed 9: ATT = 0.7507, SE = 5.5238, p = 0.89217\n",
      "✅ CAT_Aceetanilidederivaten | Seed 10: ATT = 0.8017, SE = 6.2285, p = 0.89785\n",
      "📊 Diagnostic plots saved for CAT_Aceetanilidederivaten\n",
      "🏆 Best result for CAT_Aceetanilidederivaten → Seed 2 | SE = 4.9976\n",
      "\n",
      "🚀 Running DML for CAT_Z_drugs\n",
      "✅ CAT_Z_drugs | Seed 1: ATT = 4.3864, SE = 4.1416, p = 0.29213\n",
      "✅ CAT_Z_drugs | Seed 2: ATT = 4.4270, SE = 4.2567, p = 0.30086\n",
      "✅ CAT_Z_drugs | Seed 3: ATT = 4.3088, SE = 4.8799, p = 0.37939\n",
      "✅ CAT_Z_drugs | Seed 4: ATT = 3.8424, SE = 4.5543, p = 0.40088\n",
      "✅ CAT_Z_drugs | Seed 5: ATT = 4.2215, SE = 5.1842, p = 0.41742\n",
      "✅ CAT_Z_drugs | Seed 6: ATT = 4.0267, SE = 4.4930, p = 0.37232\n",
      "✅ CAT_Z_drugs | Seed 7: ATT = 3.8418, SE = 5.2509, p = 0.46612\n",
      "✅ CAT_Z_drugs | Seed 8: ATT = 4.4595, SE = 4.2071, p = 0.29172\n",
      "✅ CAT_Z_drugs | Seed 9: ATT = 4.3388, SE = 4.6932, p = 0.35748\n",
      "✅ CAT_Z_drugs | Seed 10: ATT = 4.0097, SE = 5.4015, p = 0.45964\n",
      "📊 Diagnostic plots saved for CAT_Z_drugs\n",
      "🏆 Best result for CAT_Z_drugs → Seed 1 | SE = 4.1416\n",
      "\n",
      "🚀 Running DML for CAT_Opioden\n",
      "✅ CAT_Opioden | Seed 1: ATT = 4.0693, SE = 4.8407, p = 0.40257\n",
      "✅ CAT_Opioden | Seed 2: ATT = 4.5005, SE = 5.3258, p = 0.40013\n",
      "✅ CAT_Opioden | Seed 3: ATT = 4.1958, SE = 4.3366, p = 0.33564\n",
      "✅ CAT_Opioden | Seed 4: ATT = 3.9487, SE = 4.7029, p = 0.40314\n",
      "✅ CAT_Opioden | Seed 5: ATT = 4.3587, SE = 4.6683, p = 0.35274\n",
      "✅ CAT_Opioden | Seed 6: ATT = 4.1139, SE = 4.5220, p = 0.36517\n",
      "✅ CAT_Opioden | Seed 7: ATT = 4.1148, SE = 4.2603, p = 0.33646\n",
      "✅ CAT_Opioden | Seed 8: ATT = 4.4443, SE = 4.8451, p = 0.36122\n",
      "✅ CAT_Opioden | Seed 9: ATT = 4.3168, SE = 4.2902, p = 0.31677\n",
      "✅ CAT_Opioden | Seed 10: ATT = 4.5252, SE = 5.3339, p = 0.39827\n",
      "📊 Diagnostic plots saved for CAT_Opioden\n",
      "🏆 Best result for CAT_Opioden → Seed 7 | SE = 4.2603\n",
      "\n",
      "🚀 Running DML for CAT_NSAIDs\n",
      "✅ CAT_NSAIDs | Seed 1: ATT = 4.4268, SE = 5.4180, p = 0.41586\n",
      "✅ CAT_NSAIDs | Seed 2: ATT = 4.2226, SE = 5.8859, p = 0.47481\n",
      "✅ CAT_NSAIDs | Seed 3: ATT = 4.1298, SE = 6.1718, p = 0.50496\n",
      "✅ CAT_NSAIDs | Seed 4: ATT = 3.7619, SE = 5.8035, p = 0.51835\n",
      "✅ CAT_NSAIDs | Seed 5: ATT = 5.0570, SE = 6.0422, p = 0.40464\n",
      "✅ CAT_NSAIDs | Seed 6: ATT = 4.4886, SE = 5.5095, p = 0.41719\n",
      "✅ CAT_NSAIDs | Seed 7: ATT = 4.3988, SE = 5.3397, p = 0.41204\n",
      "✅ CAT_NSAIDs | Seed 8: ATT = 4.0738, SE = 6.3203, p = 0.52071\n",
      "✅ CAT_NSAIDs | Seed 9: ATT = 4.5370, SE = 6.3793, p = 0.47863\n",
      "✅ CAT_NSAIDs | Seed 10: ATT = 4.2460, SE = 5.8957, p = 0.47311\n",
      "📊 Diagnostic plots saved for CAT_NSAIDs\n",
      "🏆 Best result for CAT_NSAIDs → Seed 7 | SE = 5.3397\n",
      "\n",
      "🚀 Running DML for CAT_Benzodiazepine\n",
      "✅ CAT_Benzodiazepine | Seed 1: ATT = -0.2558, SE = 0.9627, p = 0.79098\n",
      "✅ CAT_Benzodiazepine | Seed 2: ATT = -0.2672, SE = 0.9231, p = 0.77281\n",
      "✅ CAT_Benzodiazepine | Seed 3: ATT = -0.2483, SE = 0.8837, p = 0.77934\n",
      "✅ CAT_Benzodiazepine | Seed 4: ATT = -0.3068, SE = 0.9126, p = 0.73745\n",
      "✅ CAT_Benzodiazepine | Seed 5: ATT = -0.1797, SE = 0.8420, p = 0.83145\n",
      "✅ CAT_Benzodiazepine | Seed 6: ATT = -0.4079, SE = 1.0038, p = 0.68535\n",
      "✅ CAT_Benzodiazepine | Seed 7: ATT = -0.3509, SE = 0.9855, p = 0.72257\n",
      "✅ CAT_Benzodiazepine | Seed 8: ATT = -0.3092, SE = 0.9809, p = 0.75325\n",
      "✅ CAT_Benzodiazepine | Seed 9: ATT = -0.3217, SE = 0.9604, p = 0.73833\n",
      "✅ CAT_Benzodiazepine | Seed 10: ATT = -0.2992, SE = 1.0070, p = 0.76695\n",
      "📊 Diagnostic plots saved for CAT_Benzodiazepine\n",
      "🏆 Best result for CAT_Benzodiazepine → Seed 5 | SE = 0.8420\n",
      "\n",
      "🚀 Running DML for CAT_Antihypertensiva\n",
      "✅ CAT_Antihypertensiva | Seed 1: ATT = -1.3355, SE = 4.1276, p = 0.74696\n",
      "✅ CAT_Antihypertensiva | Seed 2: ATT = -1.4657, SE = 4.0243, p = 0.71647\n",
      "✅ CAT_Antihypertensiva | Seed 3: ATT = -1.7286, SE = 4.2162, p = 0.68270\n",
      "✅ CAT_Antihypertensiva | Seed 4: ATT = -1.4511, SE = 3.9191, p = 0.71197\n",
      "✅ CAT_Antihypertensiva | Seed 5: ATT = -1.2701, SE = 3.9168, p = 0.74642\n",
      "✅ CAT_Antihypertensiva | Seed 6: ATT = -1.5945, SE = 4.3657, p = 0.71572\n",
      "✅ CAT_Antihypertensiva | Seed 7: ATT = -1.1495, SE = 3.9985, p = 0.77435\n",
      "✅ CAT_Antihypertensiva | Seed 8: ATT = -1.7411, SE = 4.2259, p = 0.68122\n",
      "✅ CAT_Antihypertensiva | Seed 9: ATT = -1.2409, SE = 4.3100, p = 0.77401\n",
      "✅ CAT_Antihypertensiva | Seed 10: ATT = -1.2731, SE = 3.9092, p = 0.74537\n",
      "📊 Diagnostic plots saved for CAT_Antihypertensiva\n",
      "🏆 Best result for CAT_Antihypertensiva → Seed 10 | SE = 3.9092\n",
      "\n",
      "🚀 Running DML for CAT_Antihistaminica\n",
      "✅ CAT_Antihistaminica | Seed 1: ATT = 1.0494, SE = 3.5695, p = 0.76938\n",
      "✅ CAT_Antihistaminica | Seed 2: ATT = 0.9492, SE = 6.3918, p = 0.88225\n",
      "✅ CAT_Antihistaminica | Seed 3: ATT = 1.4944, SE = 3.9914, p = 0.70890\n",
      "✅ CAT_Antihistaminica | Seed 4: ATT = 1.3157, SE = 4.0198, p = 0.74414\n",
      "✅ CAT_Antihistaminica | Seed 5: ATT = 1.0048, SE = 3.7039, p = 0.78674\n",
      "✅ CAT_Antihistaminica | Seed 6: ATT = 0.8490, SE = 3.3619, p = 0.80116\n",
      "✅ CAT_Antihistaminica | Seed 7: ATT = 1.5276, SE = 3.9651, p = 0.70088\n",
      "✅ CAT_Antihistaminica | Seed 8: ATT = 1.4281, SE = 3.4583, p = 0.68053\n",
      "✅ CAT_Antihistaminica | Seed 9: ATT = 1.2404, SE = 4.2479, p = 0.77089\n",
      "✅ CAT_Antihistaminica | Seed 10: ATT = 0.5803, SE = 3.7209, p = 0.87639\n",
      "📊 Diagnostic plots saved for CAT_Antihistaminica\n",
      "🏆 Best result for CAT_Antihistaminica → Seed 6 | SE = 3.3619\n",
      "\n",
      "🚀 Running DML for CAT_Anti_epileptica\n",
      "✅ CAT_Anti_epileptica | Seed 1: ATT = 4.0682, SE = 3.0481, p = 0.18505\n",
      "✅ CAT_Anti_epileptica | Seed 2: ATT = 4.1659, SE = 2.9182, p = 0.15657\n",
      "✅ CAT_Anti_epileptica | Seed 3: ATT = 4.3967, SE = 2.9044, p = 0.13326\n",
      "✅ CAT_Anti_epileptica | Seed 4: ATT = 4.1300, SE = 2.9061, p = 0.15842\n",
      "✅ CAT_Anti_epileptica | Seed 5: ATT = 3.6379, SE = 2.8515, p = 0.20501\n",
      "✅ CAT_Anti_epileptica | Seed 6: ATT = 4.1544, SE = 2.9276, p = 0.15902\n",
      "✅ CAT_Anti_epileptica | Seed 7: ATT = 4.5752, SE = 3.4405, p = 0.18664\n",
      "✅ CAT_Anti_epileptica | Seed 8: ATT = 4.1149, SE = 3.2270, p = 0.20524\n",
      "✅ CAT_Anti_epileptica | Seed 9: ATT = 3.8860, SE = 2.8143, p = 0.17046\n",
      "✅ CAT_Anti_epileptica | Seed 10: ATT = 4.2798, SE = 3.4812, p = 0.22184\n",
      "📊 Diagnostic plots saved for CAT_Anti_epileptica\n",
      "🏆 Best result for CAT_Anti_epileptica → Seed 9 | SE = 2.8143\n",
      "\n",
      "🚀 Running DML for CAT_Antidepressiva\n",
      "✅ CAT_Antidepressiva | Seed 1: ATT = 0.9173, SE = 0.5764, p = 0.11471\n",
      "✅ CAT_Antidepressiva | Seed 2: ATT = 0.9669, SE = 0.6308, p = 0.12850\n",
      "✅ CAT_Antidepressiva | Seed 3: ATT = 0.9513, SE = 0.6497, p = 0.14633\n",
      "✅ CAT_Antidepressiva | Seed 4: ATT = 0.9039, SE = 0.6570, p = 0.17199\n",
      "✅ CAT_Antidepressiva | Seed 5: ATT = 0.9679, SE = 0.5964, p = 0.10777\n",
      "✅ CAT_Antidepressiva | Seed 6: ATT = 0.9517, SE = 0.5624, p = 0.09374\n",
      "✅ CAT_Antidepressiva | Seed 7: ATT = 0.9071, SE = 0.5716, p = 0.11575\n",
      "✅ CAT_Antidepressiva | Seed 8: ATT = 0.9479, SE = 0.5834, p = 0.10736\n",
      "✅ CAT_Antidepressiva | Seed 9: ATT = 0.9443, SE = 0.5745, p = 0.10341\n",
      "✅ CAT_Antidepressiva | Seed 10: ATT = 0.9688, SE = 0.6184, p = 0.12036\n",
      "📊 Diagnostic plots saved for CAT_Antidepressiva\n",
      "🏆 Best result for CAT_Antidepressiva → Seed 6 | SE = 0.5624\n",
      "\n",
      "🚀 Running DML for CAT_Antipsychotica\n",
      "✅ CAT_Antipsychotica | Seed 1: ATT = 0.0602, SE = 1.3384, p = 0.96423\n",
      "✅ CAT_Antipsychotica | Seed 2: ATT = 0.0118, SE = 1.1681, p = 0.99197\n",
      "✅ CAT_Antipsychotica | Seed 3: ATT = 0.0513, SE = 1.2220, p = 0.96663\n",
      "✅ CAT_Antipsychotica | Seed 4: ATT = 0.0583, SE = 1.3256, p = 0.96503\n",
      "✅ CAT_Antipsychotica | Seed 5: ATT = -0.0859, SE = 1.2940, p = 0.94722\n",
      "✅ CAT_Antipsychotica | Seed 6: ATT = -0.0261, SE = 1.3829, p = 0.98496\n",
      "✅ CAT_Antipsychotica | Seed 7: ATT = 0.0927, SE = 1.2925, p = 0.94294\n",
      "✅ CAT_Antipsychotica | Seed 8: ATT = 0.0984, SE = 1.1501, p = 0.93201\n",
      "✅ CAT_Antipsychotica | Seed 9: ATT = 0.0237, SE = 1.2384, p = 0.98478\n",
      "✅ CAT_Antipsychotica | Seed 10: ATT = 0.0685, SE = 1.1863, p = 0.95409\n",
      "📊 Diagnostic plots saved for CAT_Antipsychotica\n",
      "🏆 Best result for CAT_Antipsychotica → Seed 8 | SE = 1.1501\n",
      "\n",
      "🚀 Running DML for CAT_ALL_PSYCHOTROPICS_EXCL_BENZO\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_BENZO | Seed 1: ATT = 2.1013, SE = 0.8390, p = 0.01390\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_BENZO | Seed 2: ATT = 2.0745, SE = 0.7779, p = 0.00895\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_BENZO | Seed 3: ATT = 2.0548, SE = 0.8415, p = 0.01639\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_BENZO | Seed 4: ATT = 2.1236, SE = 0.8545, p = 0.01463\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_BENZO | Seed 5: ATT = 2.0215, SE = 0.7890, p = 0.01191\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_BENZO | Seed 6: ATT = 2.1132, SE = 0.7610, p = 0.00656\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_BENZO | Seed 7: ATT = 2.1050, SE = 0.7209, p = 0.00433\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_BENZO | Seed 8: ATT = 2.0591, SE = 0.7544, p = 0.00751\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_BENZO | Seed 9: ATT = 2.0591, SE = 0.7822, p = 0.00984\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_BENZO | Seed 10: ATT = 2.1015, SE = 0.8038, p = 0.01033\n",
      "📊 Diagnostic plots saved for CAT_ALL_PSYCHOTROPICS_EXCL_BENZO\n",
      "🏆 Best result for CAT_ALL_PSYCHOTROPICS_EXCL_BENZO → Seed 7 | SE = 0.7209\n",
      "\n",
      "🚀 Running DML for CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS | Seed 1: ATT = 1.7484, SE = 0.5952, p = 0.00411\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS | Seed 2: ATT = 1.6990, SE = 0.6119, p = 0.00657\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS | Seed 3: ATT = 1.6970, SE = 0.6355, p = 0.00886\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS | Seed 4: ATT = 1.7111, SE = 0.6322, p = 0.00801\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS | Seed 5: ATT = 1.7845, SE = 0.6662, p = 0.00866\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS | Seed 6: ATT = 1.7150, SE = 0.6870, p = 0.01420\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS | Seed 7: ATT = 1.7247, SE = 0.6196, p = 0.00644\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS | Seed 8: ATT = 1.7094, SE = 0.6491, p = 0.00980\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS | Seed 9: ATT = 1.7295, SE = 0.6573, p = 0.00986\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS | Seed 10: ATT = 1.7005, SE = 0.6696, p = 0.01265\n",
      "📊 Diagnostic plots saved for CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS\n",
      "🏆 Best result for CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS → Seed 1 | SE = 0.5952\n",
      "\n",
      "🚀 Running DML for CAT_ALL_PSYCHOTROPICS\n",
      "✅ CAT_ALL_PSYCHOTROPICS | Seed 1: ATT = 2.2116, SE = 0.6231, p = 0.00059\n",
      "✅ CAT_ALL_PSYCHOTROPICS | Seed 2: ATT = 2.2051, SE = 0.5700, p = 0.00020\n",
      "✅ CAT_ALL_PSYCHOTROPICS | Seed 3: ATT = 2.1709, SE = 0.6135, p = 0.00061\n",
      "✅ CAT_ALL_PSYCHOTROPICS | Seed 4: ATT = 2.1973, SE = 0.6261, p = 0.00068\n",
      "✅ CAT_ALL_PSYCHOTROPICS | Seed 5: ATT = 2.1975, SE = 0.6225, p = 0.00063\n",
      "✅ CAT_ALL_PSYCHOTROPICS | Seed 6: ATT = 2.2259, SE = 0.6456, p = 0.00083\n",
      "✅ CAT_ALL_PSYCHOTROPICS | Seed 7: ATT = 2.2151, SE = 0.6266, p = 0.00062\n",
      "✅ CAT_ALL_PSYCHOTROPICS | Seed 8: ATT = 2.1577, SE = 0.7036, p = 0.00279\n",
      "✅ CAT_ALL_PSYCHOTROPICS | Seed 9: ATT = 2.2173, SE = 0.6011, p = 0.00037\n",
      "✅ CAT_ALL_PSYCHOTROPICS | Seed 10: ATT = 2.2728, SE = 0.6043, p = 0.00029\n",
      "📊 Diagnostic plots saved for CAT_ALL_PSYCHOTROPICS\n",
      "🏆 Best result for CAT_ALL_PSYCHOTROPICS → Seed 2 | SE = 0.5700\n",
      "\n",
      "🚀 Running DML for CAT_ALL\n",
      "✅ CAT_ALL | Seed 1: ATT = 2.1911, SE = 0.6865, p = 0.00189\n",
      "✅ CAT_ALL | Seed 2: ATT = 2.1396, SE = 0.6691, p = 0.00186\n",
      "✅ CAT_ALL | Seed 3: ATT = 2.1674, SE = 0.5976, p = 0.00046\n",
      "✅ CAT_ALL | Seed 4: ATT = 2.2021, SE = 0.6310, p = 0.00072\n",
      "✅ CAT_ALL | Seed 5: ATT = 2.1853, SE = 0.6112, p = 0.00054\n",
      "✅ CAT_ALL | Seed 6: ATT = 2.1492, SE = 0.5949, p = 0.00048\n",
      "✅ CAT_ALL | Seed 7: ATT = 2.1953, SE = 0.6116, p = 0.00052\n",
      "✅ CAT_ALL | Seed 8: ATT = 2.1618, SE = 0.6114, p = 0.00062\n",
      "✅ CAT_ALL | Seed 9: ATT = 2.2230, SE = 0.6640, p = 0.00115\n",
      "✅ CAT_ALL | Seed 10: ATT = 2.1913, SE = 0.5782, p = 0.00026\n",
      "📊 Diagnostic plots saved for CAT_ALL\n",
      "🏆 Best result for CAT_ALL → Seed 10 | SE = 0.5782\n",
      "\n",
      "🎯 All summary files saved.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "from econml.dml import LinearDML\n",
    "from scipy.stats import t, probplot\n",
    "import xgboost as xgb\n",
    "\n",
    "# -----------------------------\n",
    "# Configuration\n",
    "# -----------------------------\n",
    "n_repeats = 4\n",
    "seeds = list(range(1, 11))\n",
    "imputations = 5\n",
    "output_folder = \"outputs\"\n",
    "\n",
    "# -----------------------------\n",
    "# Diagnostic Plotting Function\n",
    "# -----------------------------\n",
    "def create_diagnostic_plots(residuals_data, fitted_data, group_name):\n",
    "    \"\"\"Create 4 diagnostic plots for model validation\"\"\"\n",
    "    plots_dir = os.path.join(output_folder, \"plots\")\n",
    "    os.makedirs(plots_dir, exist_ok=True)\n",
    "    \n",
    "    # Flatten the collected data\n",
    "    all_residuals = np.concatenate(residuals_data)\n",
    "    all_fitted = np.concatenate(fitted_data)\n",
    "    \n",
    "    # Create figure with 2x2 subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    fig.suptitle(f'Diagnostic Plots - {group_name}', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. Residuals vs Fitted\n",
    "    axes[0,0].scatter(all_fitted, all_residuals, alpha=0.6, s=20)\n",
    "    axes[0,0].axhline(y=0, color='red', linestyle='--', alpha=0.8)\n",
    "    axes[0,0].set_xlabel('Fitted Values')\n",
    "    axes[0,0].set_ylabel('Residuals')\n",
    "    axes[0,0].set_title('Residuals vs Fitted')\n",
    "    axes[0,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. QQ Plot\n",
    "    probplot(all_residuals, dist=\"norm\", plot=axes[0,1])\n",
    "    axes[0,1].set_title('Q-Q Plot (Normal)')\n",
    "    axes[0,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Residual Histogram\n",
    "    axes[1,0].hist(all_residuals, bins=30, density=True, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    axes[1,0].set_xlabel('Residuals')\n",
    "    axes[1,0].set_ylabel('Density')\n",
    "    axes[1,0].set_title('Residual Distribution')\n",
    "    axes[1,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Scale-Location Plot\n",
    "    sqrt_abs_residuals = np.sqrt(np.abs(all_residuals))\n",
    "    axes[1,1].scatter(all_fitted, sqrt_abs_residuals, alpha=0.6, s=20)\n",
    "    axes[1,1].set_xlabel('Fitted Values')\n",
    "    axes[1,1].set_ylabel('√|Residuals|')\n",
    "    axes[1,1].set_title('Scale-Location Plot')\n",
    "    axes[1,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save plot\n",
    "    plot_filename = os.path.join(plots_dir, f'{group_name}.png')\n",
    "    plt.savefig(plot_filename, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"📊 Diagnostic plots saved for {group_name}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Rubin's Rule\n",
    "# -----------------------------\n",
    "def rubins_pool(estimates, ses):\n",
    "    m = len(estimates)\n",
    "    q_bar = np.mean(estimates)\n",
    "    u_bar = np.mean(np.square(ses))\n",
    "    b_m = np.var(estimates, ddof=1)\n",
    "    total_var = u_bar + ((1 + 1/m) * b_m)\n",
    "    total_se = np.sqrt(total_var)\n",
    "    ci_lower = q_bar - 1.96 * total_se\n",
    "    ci_upper = q_bar + 1.96 * total_se\n",
    "    p_value = 2 * (1 - t.cdf(np.abs(q_bar / total_se), df=m-1))\n",
    "    rounded_p = round(p_value, 5)\n",
    "    formatted_p = \"< 0.00001\" if rounded_p <= 0.00001 else f\"{rounded_p:.5f}\"\n",
    "    return q_bar, total_se, ci_lower, ci_upper, formatted_p\n",
    "\n",
    "# -----------------------------\n",
    "# SMD + Variance Ratio\n",
    "# -----------------------------\n",
    "def calculate_smd_vr(X, T, weights):\n",
    "    treated = X[T == 1]\n",
    "    control = X[T == 0]\n",
    "    w_treated = weights[T == 1]\n",
    "    w_control = weights[T == 0]\n",
    "    smd, vr = [], []\n",
    "    for col in X.columns:\n",
    "        try:\n",
    "            m1, m0 = np.average(treated[col], weights=w_treated), np.average(control[col], weights=w_control)\n",
    "            s1 = np.sqrt(np.average((treated[col] - m1) ** 2, weights=w_treated))\n",
    "            s0 = np.sqrt(np.average((control[col] - m0) ** 2, weights=w_control))\n",
    "            pooled_sd = np.sqrt((s1 ** 2 + s0 ** 2) / 2)\n",
    "            smd.append((m1 - m0) / pooled_sd if pooled_sd > 0 else 0)\n",
    "            vr.append(s1**2 / s0**2 if s0**2 > 0 else 0)\n",
    "        except Exception:\n",
    "            smd.append(np.nan)\n",
    "            vr.append(np.nan)\n",
    "    return np.nanmean(smd), np.nanmean(vr)\n",
    "\n",
    "# -----------------------------\n",
    "# DML Main Loop\n",
    "# -----------------------------\n",
    "def run_dml_with_trimmed_data(final_covariates_map):\n",
    "    att_results = []\n",
    "    balance_results = []\n",
    "\n",
    "    for group, covariates in final_covariates_map.items():\n",
    "        print(f\"\\n🚀 Running DML for {group}\")\n",
    "        group_dir = os.path.join(output_folder, group)\n",
    "        os.makedirs(group_dir, exist_ok=True)\n",
    "\n",
    "        best_result = None\n",
    "        best_se = float(\"inf\")\n",
    "        \n",
    "        # Initialize lists to collect residuals and fitted values for diagnostic plots\n",
    "        group_residuals = []\n",
    "        group_fitted = []\n",
    "\n",
    "        for seed in seeds:\n",
    "            att_list, se_list, r2_list, rmse_list, smd_list, vr_list = [], [], [], [], [], []\n",
    "\n",
    "            for imp in range(1, imputations + 1):\n",
    "                file_path = os.path.join(group_dir, f\"trimmed_data_imp{imp}.pkl\")\n",
    "                if not os.path.exists(file_path):\n",
    "                    continue\n",
    "\n",
    "                df = pd.read_pickle(file_path)\n",
    "                if group not in df.columns or \"iptw\" not in df.columns:\n",
    "                    continue\n",
    "\n",
    "                X = df[covariates].copy()\n",
    "                T = df[group]\n",
    "                Y = df[\"caps5_change_baseline\"]\n",
    "                W = df[\"iptw\"]\n",
    "\n",
    "                for repeat in range(n_repeats):\n",
    "                    kf = KFold(n_splits=5, shuffle=True, random_state=seed + repeat)\n",
    "                    for train_idx, test_idx in kf.split(X):\n",
    "                        try:\n",
    "                            X_train, T_train, Y_train, W_train = (\n",
    "                                X.iloc[train_idx],\n",
    "                                T.iloc[train_idx],\n",
    "                                Y.iloc[train_idx],\n",
    "                                W.iloc[train_idx],\n",
    "                            )\n",
    "\n",
    "                            model_y = xgb.XGBRegressor(n_estimators=100, max_depth=3, learning_rate=0.1, n_jobs=1, random_state=seed)\n",
    "                            model_t = xgb.XGBClassifier(n_estimators=100, max_depth=3, learning_rate=0.1, n_jobs=1,\n",
    "                                                        use_label_encoder=False, eval_metric=\"logloss\", random_state=seed)\n",
    "\n",
    "                            dml = LinearDML(model_y=model_y, model_t=model_t, discrete_treatment=True,\n",
    "                                            cv=KFold(n_splits=3, shuffle=True, random_state=seed), random_state=seed)\n",
    "                            dml.fit(Y_train, T_train, X=X_train, sample_weight=W_train)\n",
    "\n",
    "                            tau = dml.effect(X_train)\n",
    "                            att = np.mean(tau)\n",
    "                            influence = tau - att\n",
    "                            se = np.sqrt(np.mean(influence ** 2) / len(tau))\n",
    "\n",
    "                            att_list.append(att)\n",
    "                            se_list.append(se)\n",
    "\n",
    "                            Y_pred = model_y.fit(X_train, Y_train, sample_weight=W_train).predict(X_train)\n",
    "                            residuals = Y_train - Y_pred\n",
    "                            rmse = mean_squared_error(Y_train, Y_pred, squared=False)\n",
    "                            r2 = r2_score(Y_train, Y_pred)\n",
    "                            r2_list.append(r2)\n",
    "                            rmse_list.append(rmse)\n",
    "                            \n",
    "                            # Collect residuals and fitted values for diagnostic plots\n",
    "                            group_residuals.append(residuals.values)\n",
    "                            group_fitted.append(Y_pred)\n",
    "\n",
    "                            smd, vr = calculate_smd_vr(X_train, T_train, W_train)\n",
    "                            smd_list.append(smd)\n",
    "                            vr_list.append(vr)\n",
    "                        except Exception as e:\n",
    "                            print(f\"⚠️ Error in {group}, seed {seed}, imp {imp}, rep {repeat}: {e}\")\n",
    "\n",
    "            if att_list:\n",
    "                att, se, ci_l, ci_u, p_val = rubins_pool(att_list, se_list)\n",
    "                avg_r2 = np.mean(r2_list)\n",
    "                avg_rmse = np.mean(rmse_list)\n",
    "                avg_smd = np.mean(smd_list)\n",
    "                avg_vr = np.mean(vr_list)\n",
    "\n",
    "                balance_results.append({\n",
    "                    \"group\": group, \"seed\": seed, \"smd\": avg_smd, \"vr\": avg_vr\n",
    "                })\n",
    "\n",
    "                if se < best_se:\n",
    "                    best_se = se\n",
    "                    best_result = {\n",
    "                        \"group\": group, \"seed\": seed, \"att\": att, \"se\": se,\n",
    "                        \"ci_lower\": ci_l, \"ci_upper\": ci_u, \"p_value\": p_val,\n",
    "                        \"r2\": avg_r2, \"rmse\": avg_rmse\n",
    "                    }\n",
    "\n",
    "                print(f\"✅ {group} | Seed {seed}: ATT = {att:.4f}, SE = {se:.4f}, p = {p_val}\")\n",
    "            else:\n",
    "                print(f\"⚠️ No valid results for {group} | Seed {seed}\")\n",
    "\n",
    "        # Create diagnostic plots for this group\n",
    "        if group_residuals and group_fitted:\n",
    "            create_diagnostic_plots(group_residuals, group_fitted, group)\n",
    "\n",
    "        if best_result:\n",
    "            att_results.append(best_result)\n",
    "            print(f\"🏆 Best result for {group} → Seed {best_result['seed']} | SE = {best_result['se']:.4f}\")\n",
    "\n",
    "    # Save final output\n",
    "    pd.DataFrame(att_results).to_excel(\"dml_rubin_summary_cats.xlsx\", index=False)\n",
    "    pd.DataFrame(balance_results).to_excel(\"smd_vr_summary_cats.xlsx\", index=False)\n",
    "    print(\"\\n🎯 All summary files saved.\")\n",
    "\n",
    "run_dml_with_trimmed_data(final_covariates_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f18c032f-2250-4dc4-90ec-85ac7faa6f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unweighted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f2a2f7f2-1ca7-4fe4-a039-2c0ce9ba9a4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Running DML for CAT_ADHD\n",
      "✅ CAT_ADHD | Seed 1: ATT = 0.8440, SE = 6.2964, p = 0.89364\n",
      "✅ CAT_ADHD | Seed 2: ATT = 0.7459, SE = 4.2234, p = 0.86017\n",
      "✅ CAT_ADHD | Seed 3: ATT = 1.2770, SE = 3.7945, p = 0.73718\n",
      "✅ CAT_ADHD | Seed 4: ATT = 0.7159, SE = 4.4720, p = 0.87314\n",
      "✅ CAT_ADHD | Seed 5: ATT = 1.0250, SE = 3.8135, p = 0.78866\n",
      "✅ CAT_ADHD | Seed 6: ATT = 0.5006, SE = 3.7074, p = 0.89287\n",
      "✅ CAT_ADHD | Seed 7: ATT = 0.0798, SE = 3.8549, p = 0.98352\n",
      "✅ CAT_ADHD | Seed 8: ATT = 0.7182, SE = 4.5271, p = 0.87427\n",
      "✅ CAT_ADHD | Seed 9: ATT = 0.1170, SE = 5.4994, p = 0.98307\n",
      "✅ CAT_ADHD | Seed 10: ATT = 0.2875, SE = 3.6759, p = 0.93782\n",
      "🏆 Best result for CAT_ADHD → Seed 10 | SE = 3.6759\n",
      "📊 Creating diagnostic plots for CAT_ADHD...\n",
      "\n",
      "🚀 Running DML for CAT_Aceetanilidederivaten\n",
      "✅ CAT_Aceetanilidederivaten | Seed 1: ATT = 1.0870, SE = 4.7858, p = 0.82079\n",
      "✅ CAT_Aceetanilidederivaten | Seed 2: ATT = 1.1156, SE = 4.7204, p = 0.81366\n",
      "✅ CAT_Aceetanilidederivaten | Seed 3: ATT = 1.0095, SE = 4.7491, p = 0.83210\n",
      "✅ CAT_Aceetanilidederivaten | Seed 4: ATT = 1.8887, SE = 4.9016, p = 0.70083\n",
      "✅ CAT_Aceetanilidederivaten | Seed 5: ATT = 1.6114, SE = 5.8611, p = 0.78394\n",
      "✅ CAT_Aceetanilidederivaten | Seed 6: ATT = 1.1481, SE = 5.5415, p = 0.83630\n",
      "✅ CAT_Aceetanilidederivaten | Seed 7: ATT = 1.1509, SE = 4.9250, p = 0.81572\n",
      "✅ CAT_Aceetanilidederivaten | Seed 8: ATT = 1.0254, SE = 5.3079, p = 0.84722\n",
      "✅ CAT_Aceetanilidederivaten | Seed 9: ATT = 0.7010, SE = 5.5954, p = 0.90055\n",
      "✅ CAT_Aceetanilidederivaten | Seed 10: ATT = 0.3668, SE = 5.3451, p = 0.94543\n",
      "🏆 Best result for CAT_Aceetanilidederivaten → Seed 2 | SE = 4.7204\n",
      "📊 Creating diagnostic plots for CAT_Aceetanilidederivaten...\n",
      "\n",
      "🚀 Running DML for CAT_Z_drugs\n",
      "✅ CAT_Z_drugs | Seed 1: ATT = 4.8711, SE = 3.8033, p = 0.20327\n",
      "✅ CAT_Z_drugs | Seed 2: ATT = 5.2359, SE = 3.8964, p = 0.18210\n",
      "✅ CAT_Z_drugs | Seed 3: ATT = 4.9614, SE = 3.9146, p = 0.20799\n",
      "✅ CAT_Z_drugs | Seed 4: ATT = 4.7155, SE = 3.9916, p = 0.24029\n",
      "✅ CAT_Z_drugs | Seed 5: ATT = 5.0371, SE = 4.1162, p = 0.22396\n",
      "✅ CAT_Z_drugs | Seed 6: ATT = 4.7214, SE = 3.8276, p = 0.22030\n",
      "✅ CAT_Z_drugs | Seed 7: ATT = 4.6979, SE = 3.8576, p = 0.22618\n",
      "✅ CAT_Z_drugs | Seed 8: ATT = 5.0734, SE = 4.1021, p = 0.21909\n",
      "✅ CAT_Z_drugs | Seed 9: ATT = 5.0096, SE = 4.0153, p = 0.21511\n",
      "✅ CAT_Z_drugs | Seed 10: ATT = 5.2174, SE = 3.8319, p = 0.17642\n",
      "🏆 Best result for CAT_Z_drugs → Seed 1 | SE = 3.8033\n",
      "📊 Creating diagnostic plots for CAT_Z_drugs...\n",
      "\n",
      "🚀 Running DML for CAT_Opioden\n",
      "✅ CAT_Opioden | Seed 1: ATT = 3.4059, SE = 4.5277, p = 0.45370\n",
      "✅ CAT_Opioden | Seed 2: ATT = 3.4840, SE = 4.9420, p = 0.48248\n",
      "✅ CAT_Opioden | Seed 3: ATT = 3.2090, SE = 4.0009, p = 0.42443\n",
      "✅ CAT_Opioden | Seed 4: ATT = 3.5201, SE = 4.1388, p = 0.39710\n",
      "✅ CAT_Opioden | Seed 5: ATT = 3.4288, SE = 4.0959, p = 0.40454\n",
      "✅ CAT_Opioden | Seed 6: ATT = 3.3403, SE = 4.4777, p = 0.45743\n",
      "✅ CAT_Opioden | Seed 7: ATT = 3.7460, SE = 4.9379, p = 0.44988\n",
      "✅ CAT_Opioden | Seed 8: ATT = 3.6649, SE = 4.3467, p = 0.40117\n",
      "✅ CAT_Opioden | Seed 9: ATT = 3.5630, SE = 4.3789, p = 0.41778\n",
      "✅ CAT_Opioden | Seed 10: ATT = 3.8025, SE = 5.0065, p = 0.44936\n",
      "🏆 Best result for CAT_Opioden → Seed 3 | SE = 4.0009\n",
      "📊 Creating diagnostic plots for CAT_Opioden...\n",
      "\n",
      "🚀 Running DML for CAT_NSAIDs\n",
      "✅ CAT_NSAIDs | Seed 1: ATT = 4.1411, SE = 5.0745, p = 0.41643\n",
      "✅ CAT_NSAIDs | Seed 2: ATT = 4.0797, SE = 5.7626, p = 0.48064\n",
      "✅ CAT_NSAIDs | Seed 3: ATT = 3.8663, SE = 5.9327, p = 0.51611\n",
      "✅ CAT_NSAIDs | Seed 4: ATT = 3.9439, SE = 5.6379, p = 0.48586\n",
      "✅ CAT_NSAIDs | Seed 5: ATT = 4.7712, SE = 5.3174, p = 0.37175\n",
      "✅ CAT_NSAIDs | Seed 6: ATT = 4.1711, SE = 5.1717, p = 0.42187\n",
      "✅ CAT_NSAIDs | Seed 7: ATT = 4.3983, SE = 4.9664, p = 0.37798\n",
      "✅ CAT_NSAIDs | Seed 8: ATT = 4.2261, SE = 5.8642, p = 0.47281\n",
      "✅ CAT_NSAIDs | Seed 9: ATT = 4.0229, SE = 5.8190, p = 0.49097\n",
      "✅ CAT_NSAIDs | Seed 10: ATT = 4.3372, SE = 5.7692, p = 0.45396\n",
      "🏆 Best result for CAT_NSAIDs → Seed 7 | SE = 4.9664\n",
      "📊 Creating diagnostic plots for CAT_NSAIDs...\n",
      "\n",
      "🚀 Running DML for CAT_Benzodiazepine\n",
      "✅ CAT_Benzodiazepine | Seed 1: ATT = 0.4717, SE = 0.7004, p = 0.50225\n",
      "✅ CAT_Benzodiazepine | Seed 2: ATT = 0.4812, SE = 0.7300, p = 0.51126\n",
      "✅ CAT_Benzodiazepine | Seed 3: ATT = 0.5149, SE = 0.7216, p = 0.47719\n",
      "✅ CAT_Benzodiazepine | Seed 4: ATT = 0.5189, SE = 0.7030, p = 0.46218\n",
      "✅ CAT_Benzodiazepine | Seed 5: ATT = 0.6246, SE = 0.6235, p = 0.31896\n",
      "✅ CAT_Benzodiazepine | Seed 6: ATT = 0.5044, SE = 0.7612, p = 0.50910\n",
      "✅ CAT_Benzodiazepine | Seed 7: ATT = 0.4422, SE = 0.7452, p = 0.55429\n",
      "✅ CAT_Benzodiazepine | Seed 8: ATT = 0.4790, SE = 0.7564, p = 0.52803\n",
      "✅ CAT_Benzodiazepine | Seed 9: ATT = 0.4530, SE = 0.8051, p = 0.57494\n",
      "✅ CAT_Benzodiazepine | Seed 10: ATT = 0.5046, SE = 0.7469, p = 0.50087\n",
      "🏆 Best result for CAT_Benzodiazepine → Seed 5 | SE = 0.6235\n",
      "📊 Creating diagnostic plots for CAT_Benzodiazepine...\n",
      "\n",
      "🚀 Running DML for CAT_Antihypertensiva\n",
      "✅ CAT_Antihypertensiva | Seed 1: ATT = -1.7503, SE = 4.2030, p = 0.67800\n",
      "✅ CAT_Antihypertensiva | Seed 2: ATT = -1.8144, SE = 3.9829, p = 0.64972\n",
      "✅ CAT_Antihypertensiva | Seed 3: ATT = -1.9672, SE = 4.2522, p = 0.64465\n",
      "✅ CAT_Antihypertensiva | Seed 4: ATT = -1.6376, SE = 4.0504, p = 0.68687\n",
      "✅ CAT_Antihypertensiva | Seed 5: ATT = -1.5603, SE = 3.8613, p = 0.68701\n",
      "✅ CAT_Antihypertensiva | Seed 6: ATT = -1.7881, SE = 4.2602, p = 0.67560\n",
      "✅ CAT_Antihypertensiva | Seed 7: ATT = -1.3792, SE = 4.1883, p = 0.74261\n",
      "✅ CAT_Antihypertensiva | Seed 8: ATT = -2.0593, SE = 4.3412, p = 0.63629\n",
      "✅ CAT_Antihypertensiva | Seed 9: ATT = -1.3219, SE = 4.3990, p = 0.76442\n",
      "✅ CAT_Antihypertensiva | Seed 10: ATT = -1.4304, SE = 4.0085, p = 0.72197\n",
      "🏆 Best result for CAT_Antihypertensiva → Seed 5 | SE = 3.8613\n",
      "📊 Creating diagnostic plots for CAT_Antihypertensiva...\n",
      "\n",
      "🚀 Running DML for CAT_Antihistaminica\n",
      "✅ CAT_Antihistaminica | Seed 1: ATT = 0.9667, SE = 3.3815, p = 0.77557\n",
      "✅ CAT_Antihistaminica | Seed 2: ATT = 0.6290, SE = 7.0443, p = 0.92904\n",
      "✅ CAT_Antihistaminica | Seed 3: ATT = 1.0670, SE = 3.7085, p = 0.77417\n",
      "✅ CAT_Antihistaminica | Seed 4: ATT = 0.9146, SE = 3.6576, p = 0.80306\n",
      "✅ CAT_Antihistaminica | Seed 5: ATT = 0.8015, SE = 3.5876, p = 0.82367\n",
      "✅ CAT_Antihistaminica | Seed 6: ATT = 0.3679, SE = 3.2909, p = 0.91122\n",
      "✅ CAT_Antihistaminica | Seed 7: ATT = 0.9410, SE = 3.5020, p = 0.78872\n",
      "✅ CAT_Antihistaminica | Seed 8: ATT = 1.1560, SE = 3.5133, p = 0.74282\n",
      "✅ CAT_Antihistaminica | Seed 9: ATT = 1.1829, SE = 3.9204, p = 0.76350\n",
      "✅ CAT_Antihistaminica | Seed 10: ATT = 0.4400, SE = 3.7146, p = 0.90595\n",
      "🏆 Best result for CAT_Antihistaminica → Seed 6 | SE = 3.2909\n",
      "📊 Creating diagnostic plots for CAT_Antihistaminica...\n",
      "\n",
      "🚀 Running DML for CAT_Anti_epileptica\n",
      "✅ CAT_Anti_epileptica | Seed 1: ATT = 4.0588, SE = 3.0075, p = 0.18023\n",
      "✅ CAT_Anti_epileptica | Seed 2: ATT = 4.0624, SE = 2.6093, p = 0.12269\n",
      "✅ CAT_Anti_epileptica | Seed 3: ATT = 4.2944, SE = 2.7447, p = 0.12086\n",
      "✅ CAT_Anti_epileptica | Seed 4: ATT = 4.1411, SE = 2.7847, p = 0.14017\n",
      "✅ CAT_Anti_epileptica | Seed 5: ATT = 3.4740, SE = 2.7290, p = 0.20600\n",
      "✅ CAT_Anti_epileptica | Seed 6: ATT = 4.1687, SE = 2.9746, p = 0.16422\n",
      "✅ CAT_Anti_epileptica | Seed 7: ATT = 4.5314, SE = 3.2611, p = 0.16779\n",
      "✅ CAT_Anti_epileptica | Seed 8: ATT = 4.0855, SE = 3.1291, p = 0.19469\n",
      "✅ CAT_Anti_epileptica | Seed 9: ATT = 3.8342, SE = 2.6123, p = 0.14534\n",
      "✅ CAT_Anti_epileptica | Seed 10: ATT = 3.8513, SE = 3.0544, p = 0.21031\n",
      "🏆 Best result for CAT_Anti_epileptica → Seed 2 | SE = 2.6093\n",
      "📊 Creating diagnostic plots for CAT_Anti_epileptica...\n",
      "\n",
      "🚀 Running DML for CAT_Antidepressiva\n",
      "✅ CAT_Antidepressiva | Seed 1: ATT = 0.8586, SE = 0.4313, p = 0.04924\n",
      "✅ CAT_Antidepressiva | Seed 2: ATT = 0.8367, SE = 0.4935, p = 0.09315\n",
      "✅ CAT_Antidepressiva | Seed 3: ATT = 0.8599, SE = 0.4848, p = 0.07918\n",
      "✅ CAT_Antidepressiva | Seed 4: ATT = 0.8115, SE = 0.5183, p = 0.12066\n",
      "✅ CAT_Antidepressiva | Seed 5: ATT = 0.9109, SE = 0.5173, p = 0.08136\n",
      "✅ CAT_Antidepressiva | Seed 6: ATT = 0.8775, SE = 0.4997, p = 0.08214\n",
      "✅ CAT_Antidepressiva | Seed 7: ATT = 0.8605, SE = 0.4758, p = 0.07356\n",
      "✅ CAT_Antidepressiva | Seed 8: ATT = 0.8817, SE = 0.4414, p = 0.04852\n",
      "✅ CAT_Antidepressiva | Seed 9: ATT = 0.8510, SE = 0.4754, p = 0.07652\n",
      "✅ CAT_Antidepressiva | Seed 10: ATT = 0.8854, SE = 0.4820, p = 0.06925\n",
      "🏆 Best result for CAT_Antidepressiva → Seed 1 | SE = 0.4313\n",
      "📊 Creating diagnostic plots for CAT_Antidepressiva...\n",
      "\n",
      "🚀 Running DML for CAT_Antipsychotica\n",
      "✅ CAT_Antipsychotica | Seed 1: ATT = 1.7390, SE = 0.9568, p = 0.07217\n",
      "✅ CAT_Antipsychotica | Seed 2: ATT = 1.5959, SE = 1.0096, p = 0.11713\n",
      "✅ CAT_Antipsychotica | Seed 3: ATT = 1.6835, SE = 1.0146, p = 0.10020\n",
      "✅ CAT_Antipsychotica | Seed 4: ATT = 1.6944, SE = 1.1081, p = 0.12942\n",
      "✅ CAT_Antipsychotica | Seed 5: ATT = 1.6399, SE = 1.0092, p = 0.10734\n",
      "✅ CAT_Antipsychotica | Seed 6: ATT = 1.6533, SE = 1.0238, p = 0.10953\n",
      "✅ CAT_Antipsychotica | Seed 7: ATT = 1.7587, SE = 0.9686, p = 0.07245\n",
      "✅ CAT_Antipsychotica | Seed 8: ATT = 1.7576, SE = 0.9604, p = 0.07025\n",
      "✅ CAT_Antipsychotica | Seed 9: ATT = 1.7272, SE = 0.9557, p = 0.07376\n",
      "✅ CAT_Antipsychotica | Seed 10: ATT = 1.6961, SE = 0.8781, p = 0.05627\n",
      "🏆 Best result for CAT_Antipsychotica → Seed 10 | SE = 0.8781\n",
      "📊 Creating diagnostic plots for CAT_Antipsychotica...\n",
      "\n",
      "🚀 Running DML for CAT_ALL_PSYCHOTROPICS_EXCL_BENZO\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_BENZO | Seed 1: ATT = 2.0000, SE = 0.4162, p = < 0.00001\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_BENZO | Seed 2: ATT = 2.0092, SE = 0.4350, p = < 0.00001\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_BENZO | Seed 3: ATT = 1.9741, SE = 0.4697, p = 0.00006\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_BENZO | Seed 4: ATT = 2.0084, SE = 0.4660, p = 0.00004\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_BENZO | Seed 5: ATT = 1.9440, SE = 0.4643, p = 0.00006\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_BENZO | Seed 6: ATT = 2.0040, SE = 0.4320, p = < 0.00001\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_BENZO | Seed 7: ATT = 1.9688, SE = 0.4296, p = < 0.00001\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_BENZO | Seed 8: ATT = 1.9732, SE = 0.4105, p = < 0.00001\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_BENZO | Seed 9: ATT = 1.9818, SE = 0.4325, p = < 0.00001\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_BENZO | Seed 10: ATT = 2.0156, SE = 0.4704, p = 0.00004\n",
      "🏆 Best result for CAT_ALL_PSYCHOTROPICS_EXCL_BENZO → Seed 8 | SE = 0.4105\n",
      "📊 Creating diagnostic plots for CAT_ALL_PSYCHOTROPICS_EXCL_BENZO...\n",
      "\n",
      "🚀 Running DML for CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS | Seed 1: ATT = 1.5306, SE = 0.4260, p = 0.00051\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS | Seed 2: ATT = 1.4968, SE = 0.4594, p = 0.00154\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS | Seed 3: ATT = 1.4945, SE = 0.4639, p = 0.00172\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS | Seed 4: ATT = 1.5273, SE = 0.4399, p = 0.00077\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS | Seed 5: ATT = 1.5309, SE = 0.4697, p = 0.00153\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS | Seed 6: ATT = 1.4993, SE = 0.4675, p = 0.00181\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS | Seed 7: ATT = 1.5315, SE = 0.4330, p = 0.00062\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS | Seed 8: ATT = 1.5262, SE = 0.4351, p = 0.00068\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS | Seed 9: ATT = 1.4931, SE = 0.4794, p = 0.00241\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS | Seed 10: ATT = 1.5040, SE = 0.4838, p = 0.00245\n",
      "🏆 Best result for CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS → Seed 1 | SE = 0.4260\n",
      "📊 Creating diagnostic plots for CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS...\n",
      "\n",
      "🚀 Running DML for CAT_ALL_PSYCHOTROPICS\n",
      "✅ CAT_ALL_PSYCHOTROPICS | Seed 1: ATT = 2.4070, SE = 0.4444, p = < 0.00001\n",
      "✅ CAT_ALL_PSYCHOTROPICS | Seed 2: ATT = 2.3691, SE = 0.4179, p = < 0.00001\n",
      "✅ CAT_ALL_PSYCHOTROPICS | Seed 3: ATT = 2.3710, SE = 0.4766, p = < 0.00001\n",
      "✅ CAT_ALL_PSYCHOTROPICS | Seed 4: ATT = 2.3925, SE = 0.4535, p = < 0.00001\n",
      "✅ CAT_ALL_PSYCHOTROPICS | Seed 5: ATT = 2.3997, SE = 0.4929, p = < 0.00001\n",
      "✅ CAT_ALL_PSYCHOTROPICS | Seed 6: ATT = 2.4153, SE = 0.4851, p = < 0.00001\n",
      "✅ CAT_ALL_PSYCHOTROPICS | Seed 7: ATT = 2.3995, SE = 0.4832, p = < 0.00001\n",
      "✅ CAT_ALL_PSYCHOTROPICS | Seed 8: ATT = 2.3896, SE = 0.5323, p = 0.00002\n",
      "✅ CAT_ALL_PSYCHOTROPICS | Seed 9: ATT = 2.4174, SE = 0.4669, p = < 0.00001\n",
      "✅ CAT_ALL_PSYCHOTROPICS | Seed 10: ATT = 2.4291, SE = 0.4708, p = < 0.00001\n",
      "🏆 Best result for CAT_ALL_PSYCHOTROPICS → Seed 2 | SE = 0.4179\n",
      "📊 Creating diagnostic plots for CAT_ALL_PSYCHOTROPICS...\n",
      "\n",
      "🚀 Running DML for CAT_ALL\n",
      "✅ CAT_ALL | Seed 1: ATT = 2.8504, SE = 0.4388, p = < 0.00001\n",
      "✅ CAT_ALL | Seed 2: ATT = 2.8122, SE = 0.4884, p = < 0.00001\n",
      "✅ CAT_ALL | Seed 3: ATT = 2.8553, SE = 0.4198, p = < 0.00001\n",
      "✅ CAT_ALL | Seed 4: ATT = 2.8736, SE = 0.4717, p = < 0.00001\n",
      "✅ CAT_ALL | Seed 5: ATT = 2.8358, SE = 0.4612, p = < 0.00001\n",
      "✅ CAT_ALL | Seed 6: ATT = 2.8431, SE = 0.4355, p = < 0.00001\n",
      "✅ CAT_ALL | Seed 7: ATT = 2.8423, SE = 0.4591, p = < 0.00001\n",
      "✅ CAT_ALL | Seed 8: ATT = 2.8703, SE = 0.4391, p = < 0.00001\n",
      "✅ CAT_ALL | Seed 9: ATT = 2.8945, SE = 0.4766, p = < 0.00001\n",
      "✅ CAT_ALL | Seed 10: ATT = 2.8613, SE = 0.4538, p = < 0.00001\n",
      "🏆 Best result for CAT_ALL → Seed 3 | SE = 0.4198\n",
      "📊 Creating diagnostic plots for CAT_ALL...\n",
      "\n",
      "🎯 All summary files saved.\n",
      "📊 All diagnostic plots saved in outputs/plots/ folder.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "from econml.dml import LinearDML\n",
    "from scipy.stats import t, probplot\n",
    "import xgboost as xgb\n",
    "\n",
    "# -----------------------------\n",
    "# Configuration\n",
    "# -----------------------------\n",
    "n_repeats = 4\n",
    "seeds = list(range(1, 11))\n",
    "imputations = 5\n",
    "output_folder = \"outputs\"\n",
    "\n",
    "# -----------------------------\n",
    "# Plotting Functions\n",
    "# -----------------------------\n",
    "def create_diagnostic_plots(residuals_data, group_name, output_folder):\n",
    "    \"\"\"Create diagnostic plots for each group\"\"\"\n",
    "    plots_dir = os.path.join(output_folder, \"plots\")\n",
    "    os.makedirs(plots_dir, exist_ok=True)\n",
    "    \n",
    "    all_residuals = residuals_data['residuals']\n",
    "    all_fitted = residuals_data['fitted']\n",
    "    \n",
    "    if len(all_residuals) == 0:\n",
    "        return\n",
    "    \n",
    "    # Create figure with subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    fig.suptitle(f'Diagnostic Plots - {group_name}', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 1. Residuals vs Fitted\n",
    "    axes[0, 0].scatter(all_fitted, all_residuals, alpha=0.5, s=1)\n",
    "    axes[0, 0].axhline(y=0, color='red', linestyle='--')\n",
    "    axes[0, 0].set_xlabel('Fitted Values')\n",
    "    axes[0, 0].set_ylabel('Residuals')\n",
    "    axes[0, 0].set_title('Residuals vs Fitted')\n",
    "    \n",
    "    # 2. QQ Plot\n",
    "    probplot(all_residuals, dist=\"norm\", plot=axes[0, 1])\n",
    "    axes[0, 1].set_title('QQ Plot (Normal)')\n",
    "    \n",
    "    # 3. Histogram of Residuals\n",
    "    axes[1, 0].hist(all_residuals, bins=50, alpha=0.7, edgecolor='black')\n",
    "    axes[1, 0].axvline(x=0, color='red', linestyle='--')\n",
    "    axes[1, 0].set_xlabel('Residuals')\n",
    "    axes[1, 0].set_ylabel('Frequency')\n",
    "    axes[1, 0].set_title('Residual Distribution')\n",
    "    \n",
    "    # 4. Scale-Location Plot\n",
    "    sqrt_abs_resid = np.sqrt(np.abs(all_residuals))\n",
    "    axes[1, 1].scatter(all_fitted, sqrt_abs_resid, alpha=0.5, s=1)\n",
    "    axes[1, 1].set_xlabel('Fitted Values')\n",
    "    axes[1, 1].set_ylabel('√|Residuals|')\n",
    "    axes[1, 1].set_title('Scale-Location Plot')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(plots_dir, f'{group_name}_unweighted.png'), \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# -----------------------------\n",
    "# Rubin's Rule\n",
    "# -----------------------------\n",
    "def rubins_pool(estimates, ses):\n",
    "    m = len(estimates)\n",
    "    q_bar = np.mean(estimates)\n",
    "    u_bar = np.mean(np.square(ses))\n",
    "    b_m = np.var(estimates, ddof=1)\n",
    "    total_var = u_bar + ((1 + 1/m) * b_m)\n",
    "    total_se = np.sqrt(total_var)\n",
    "    ci_lower = q_bar - 1.96 * total_se\n",
    "    ci_upper = q_bar + 1.96 * total_se\n",
    "    p_value = 2 * (1 - t.cdf(np.abs(q_bar / total_se), df=m-1))\n",
    "    rounded_p = round(p_value, 5)\n",
    "    formatted_p = \"< 0.00001\" if rounded_p <= 0.00001 else f\"{rounded_p:.5f}\"\n",
    "    return q_bar, total_se, ci_lower, ci_upper, formatted_p\n",
    "\n",
    "# -----------------------------\n",
    "# SMD + Variance Ratio\n",
    "# -----------------------------\n",
    "def calculate_smd_vr(X, T):\n",
    "    treated = X[T == 1]\n",
    "    control = X[T == 0]\n",
    "    smd, vr = [], []\n",
    "    for col in X.columns:\n",
    "        try:\n",
    "            m1, m0 = treated[col].mean(), control[col].mean()\n",
    "            s1, s0 = treated[col].std(), control[col].std()\n",
    "            pooled_sd = np.sqrt((s1 ** 2 + s0 ** 2) / 2)\n",
    "            smd.append((m1 - m0) / pooled_sd if pooled_sd > 0 else 0)\n",
    "            vr.append(s1**2 / s0**2 if s0**2 > 0 else 0)\n",
    "        except Exception:\n",
    "            smd.append(np.nan)\n",
    "            vr.append(np.nan)\n",
    "    return np.nanmean(smd), np.nanmean(vr)\n",
    "\n",
    "# -----------------------------\n",
    "# DML Main Loop\n",
    "# -----------------------------\n",
    "def run_dml_with_trimmed_data(final_covariates_map):\n",
    "    att_results = []\n",
    "    balance_results = []\n",
    "\n",
    "    for group, covariates in final_covariates_map.items():\n",
    "        print(f\"\\n🚀 Running DML for {group}\")\n",
    "        group_dir = os.path.join(output_folder, group)\n",
    "        os.makedirs(group_dir, exist_ok=True)\n",
    "\n",
    "        best_result = None\n",
    "        best_se = float(\"inf\")\n",
    "        \n",
    "        # Initialize residuals collection for this group\n",
    "        group_residuals_data = {'residuals': [], 'fitted': []}\n",
    "\n",
    "        for seed in seeds:\n",
    "            att_list, se_list, r2_list, rmse_list, smd_list, vr_list = [], [], [], [], [], []\n",
    "\n",
    "            for imp in range(1, imputations + 1):\n",
    "                file_path = os.path.join(group_dir, f\"trimmed_data_imp{imp}.pkl\")\n",
    "                if not os.path.exists(file_path):\n",
    "                    continue\n",
    "\n",
    "                df = pd.read_pickle(file_path)\n",
    "                if group not in df.columns:\n",
    "                    continue\n",
    "\n",
    "                X = df[covariates].copy()\n",
    "                T = df[group]\n",
    "                Y = df[\"caps5_change_baseline\"]\n",
    "\n",
    "                for repeat in range(n_repeats):\n",
    "                    kf = KFold(n_splits=5, shuffle=True, random_state=seed + repeat)\n",
    "                    for train_idx, test_idx in kf.split(X):\n",
    "                        try:\n",
    "                            X_train, T_train, Y_train = (\n",
    "                                X.iloc[train_idx],\n",
    "                                T.iloc[train_idx],\n",
    "                                Y.iloc[train_idx],\n",
    "                            )\n",
    "\n",
    "                            model_y = xgb.XGBRegressor(n_estimators=100, max_depth=3, learning_rate=0.1, n_jobs=1, random_state=seed)\n",
    "                            model_t = xgb.XGBClassifier(n_estimators=100, max_depth=3, learning_rate=0.1, n_jobs=1,\n",
    "                                                        use_label_encoder=False, eval_metric=\"logloss\", random_state=seed)\n",
    "\n",
    "                            dml = LinearDML(model_y=model_y, model_t=model_t, discrete_treatment=True,\n",
    "                                            cv=KFold(n_splits=3, shuffle=True, random_state=seed), random_state=seed)\n",
    "                            dml.fit(Y_train, T_train, X=X_train)\n",
    "\n",
    "                            tau = dml.effect(X_train)\n",
    "                            att = np.mean(tau)\n",
    "                            influence = tau - att\n",
    "                            se = np.sqrt(np.mean(influence ** 2) / len(tau))\n",
    "\n",
    "                            att_list.append(att)\n",
    "                            se_list.append(se)\n",
    "\n",
    "                            Y_pred = model_y.fit(X_train, Y_train).predict(X_train)\n",
    "                            residuals = Y_train - Y_pred\n",
    "                            \n",
    "                            # Collect residuals and fitted values for plotting\n",
    "                            group_residuals_data['residuals'].extend(residuals.tolist())\n",
    "                            group_residuals_data['fitted'].extend(Y_pred.tolist())\n",
    "                            \n",
    "                            rmse = mean_squared_error(Y_train, Y_pred, squared=False)\n",
    "                            r2 = r2_score(Y_train, Y_pred)\n",
    "                            r2_list.append(r2)\n",
    "                            rmse_list.append(rmse)\n",
    "\n",
    "                            smd, vr = calculate_smd_vr(X_train, T_train)\n",
    "                            smd_list.append(smd)\n",
    "                            vr_list.append(vr)\n",
    "                        except Exception as e:\n",
    "                            print(f\"⚠️ Error in {group}, seed {seed}, imp {imp}, rep {repeat}: {e}\")\n",
    "\n",
    "            if att_list:\n",
    "                att, se, ci_l, ci_u, p_val = rubins_pool(att_list, se_list)\n",
    "                avg_r2 = np.mean(r2_list)\n",
    "                avg_rmse = np.mean(rmse_list)\n",
    "                avg_smd = np.mean(smd_list)\n",
    "                avg_vr = np.mean(vr_list)\n",
    "\n",
    "                balance_results.append({\n",
    "                    \"group\": group, \"seed\": seed, \"smd\": avg_smd, \"vr\": avg_vr\n",
    "                })\n",
    "\n",
    "                if se < best_se:\n",
    "                    best_se = se\n",
    "                    best_result = {\n",
    "                        \"group\": group, \"seed\": seed, \"att\": att, \"se\": se,\n",
    "                        \"ci_lower\": ci_l, \"ci_upper\": ci_u, \"p_value\": p_val,\n",
    "                        \"r2\": avg_r2, \"rmse\": avg_rmse\n",
    "                    }\n",
    "\n",
    "                print(f\"✅ {group} | Seed {seed}: ATT = {att:.4f}, SE = {se:.4f}, p = {p_val}\")\n",
    "            else:\n",
    "                print(f\"⚠️ No valid results for {group} | Seed {seed}\")\n",
    "\n",
    "        if best_result:\n",
    "            att_results.append(best_result)\n",
    "            print(f\"🏆 Best result for {group} → Seed {best_result['seed']} | SE = {best_result['se']:.4f}\")\n",
    "        \n",
    "        # Create diagnostic plots for this group\n",
    "        print(f\"📊 Creating diagnostic plots for {group}...\")\n",
    "        create_diagnostic_plots(group_residuals_data, group, output_folder)\n",
    "\n",
    "    # Save final output\n",
    "    pd.DataFrame(att_results).to_excel(\"dml_rubin_summary_cats_unweighted.xlsx\", index=False)\n",
    "    pd.DataFrame(balance_results).to_excel(\"smd_vr_summary_cats_unweighted.xlsx\", index=False)\n",
    "    print(\"\\n🎯 All summary files saved.\")\n",
    "    print(\"📊 All diagnostic plots saved in outputs/plots/ folder.\")\n",
    "\n",
    "run_dml_with_trimmed_data(final_covariates_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5d6cc497-ddbb-4668-86ee-8e5a2872b2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Final_ATT_Summary_Cat saved.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import sem, ttest_ind\n",
    "\n",
    "# ----------------------------------\n",
    "# File paths\n",
    "# ----------------------------------\n",
    "output_base = \"outputs\"\n",
    "att_file = \"dml_rubin_summary_cats.xlsx\"\n",
    "trimmed_file = \"trimmed_data_imp1.pkl\"\n",
    "auc_file = \"auc_scores.xlsx\"  # NEW\n",
    "\n",
    "# ----------------------------------\n",
    "# Load ATT Summary\n",
    "# ----------------------------------\n",
    "if os.path.exists(att_file):\n",
    "    att_df = pd.read_excel(att_file)\n",
    "else:\n",
    "    raise FileNotFoundError(\"❌ ATT summary file not found: dml_rubin_summary_cats.xlsx\")\n",
    "\n",
    "summary_rows = []\n",
    "\n",
    "# ----------------------------------\n",
    "# Loop over medication groups\n",
    "# ----------------------------------\n",
    "groups = [g for g in medication_groups if os.path.isdir(os.path.join(output_base, g))]\n",
    "\n",
    "for med in groups:\n",
    "    try:\n",
    "        group_path = os.path.join(output_base, med)\n",
    "\n",
    "        # Load trimmed data\n",
    "        df = pd.read_pickle(os.path.join(group_path, trimmed_file))\n",
    "\n",
    "        # Detect treatment column\n",
    "        treatment_cols = [col for col in df.columns if col.upper() == med.upper()]\n",
    "        if not treatment_cols:\n",
    "            print(f\"⚠️ Treatment column {med} not found in trimmed data. Skipping.\")\n",
    "            continue\n",
    "        treatment_var = treatment_cols[0]\n",
    "\n",
    "        # Extract treatment and outcome\n",
    "        T = df[treatment_var]\n",
    "        Y = df[\"caps5_change_baseline\"]\n",
    "\n",
    "        # Treated and control stats\n",
    "        treated = Y[T == 1]\n",
    "        control = Y[T == 0]\n",
    "\n",
    "        mean_treat = treated.mean()\n",
    "        se_treat = sem(treated) if len(treated) > 1 else np.nan\n",
    "\n",
    "        mean_ctrl = control.mean()\n",
    "        se_ctrl = sem(control) if len(control) > 1 else np.nan\n",
    "\n",
    "        # Cohen's d (unadjusted)\n",
    "        pooled_sd = np.sqrt(((treated.std() ** 2) + (control.std() ** 2)) / 2)\n",
    "        cohen_d = (mean_treat - mean_ctrl) / pooled_sd if pooled_sd > 0 else np.nan\n",
    "\n",
    "        # E-value (unadjusted)\n",
    "        delta = mean_treat - mean_ctrl\n",
    "        E = delta / abs(mean_ctrl) * 100 if mean_ctrl != 0 else np.nan\n",
    "\n",
    "        # Unadjusted p-value\n",
    "        try:\n",
    "            t_stat, p_val = ttest_ind(treated, control, equal_var=False, nan_policy=\"omit\")\n",
    "            rounded_p = round(p_val, 5)\n",
    "            formatted_p = \"< 0.00001\" if rounded_p < 0.00001 else rounded_p\n",
    "        except Exception:\n",
    "            formatted_p = np.nan\n",
    "\n",
    "        # AUC from new auc_scores.xlsx file\n",
    "        auc_val = np.nan\n",
    "        auc_path = os.path.join(group_path, auc_file)\n",
    "        if os.path.exists(auc_path):\n",
    "            auc_df = pd.read_excel(auc_path)\n",
    "            if \"AUC\" in auc_df.columns:\n",
    "                auc_val = auc_df[\"AUC\"].dropna().mean()\n",
    "\n",
    "        # Adjusted stats from Rubin summary\n",
    "        att_row = att_df[att_df[\"group\"].str.strip().str.upper() == med.strip().upper()]\n",
    "        if not att_row.empty:\n",
    "            att = att_row.iloc[0][\"att\"]\n",
    "            att_se = att_row.iloc[0][\"se\"]\n",
    "            att_p_val = att_row.iloc[0][\"p_value\"]\n",
    "            r2 = att_row.iloc[0][\"r2\"]\n",
    "            rmse = att_row.iloc[0][\"rmse\"]\n",
    "            seed = att_row.iloc[0][\"seed\"] if \"seed\" in att_row.columns else np.nan   # Seed change\n",
    "\n",
    "            try:\n",
    "                rounded_att_p = round(float(att_p_val), 5)\n",
    "                formatted_att_p = \"< 0.00001\" if rounded_att_p < 0.00001 else rounded_att_p\n",
    "            except:\n",
    "                formatted_att_p = att_p_val\n",
    "        else:\n",
    "            att, att_se, formatted_att_p, r2, rmse, seed = np.nan, np.nan, np.nan, np.nan, np.nan, np.nan  # Seed change\n",
    "\n",
    "        # Append full row\n",
    "        summary_rows.append({\n",
    "            'Medication Group': med,\n",
    "            'Mean Treated': mean_treat,\n",
    "            'SE Treated': se_treat,\n",
    "            'Mean Control': mean_ctrl,\n",
    "            'SE Control': se_ctrl,\n",
    "            'Cohen d': cohen_d,\n",
    "            'E (Unadjusted)': E,\n",
    "            'n Treated': len(treated),\n",
    "            'n Control': len(control),\n",
    "            #'Unadjusted p-value': formatted_p,\n",
    "            'ATT Estimate': att,\n",
    "            'ATT SE (Robust)': att_se,\n",
    "            'ATT p-value': formatted_att_p,\n",
    "            'R²': r2,\n",
    "            'RMSE': rmse,\n",
    "            'AUC': auc_val,\n",
    "            'Seed': seed  # Seed change\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error in {med}: {e}\")\n",
    "\n",
    "# ----------------------------------\n",
    "# Save final summary\n",
    "# ----------------------------------\n",
    "summary_df = pd.DataFrame(summary_rows)\n",
    "summary_df = summary_df.sort_values(\"Medication Group\")\n",
    "summary_df.to_excel(\"Final_ATT_Summary_Cat.xlsx\", index=False)\n",
    "print(\"✅ Final_ATT_Summary_Cat saved.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1e88cd42-b49e-4ff7-ac7d-c1e6be654c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ dml_att_barplot_cat saved.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "# ✅ Load the final summary table\n",
    "final_df = pd.read_excel(\"Final_ATT_Summary_Cat.xlsx\")\n",
    "\n",
    "# ✅ Parse DML p-values (handle \"< 0.00001\")\n",
    "def parse_pval(p):\n",
    "    try:\n",
    "        if isinstance(p, str) and \"<\" in p:\n",
    "            return 0.000001\n",
    "        return float(p)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "final_df['ATT p-value'] = final_df['ATT p-value'].apply(parse_pval)\n",
    "\n",
    "# ✅ Plot settings\n",
    "width = 0.35\n",
    "\n",
    "# ✅ Plotting function for a single medication group\n",
    "def plot_single_group(row):\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    bars1 = ax.bar(-width/2, row['Mean Control'], width, \n",
    "                   yerr=row['SE Control'], label='Control', hatch='//', color='gray', capsize=5)\n",
    "    bars2 = ax.bar(+width/2, row['Mean Treated'], width, \n",
    "                   yerr=row['SE Treated'], label='Treated', color='steelblue', capsize=5)\n",
    "\n",
    "    label = (\n",
    "        f\"ATT = {row['ATT Estimate']:.2f}\\n\"\n",
    "        f\"d = {row['Cohen d']:.2f}, p = {row['ATT p-value']:.3f}\\n\"\n",
    "        f\"nT = {row['n Treated']}, nC = {row['n Control']}\\n\"\n",
    "        f\"E = {row['E (Unadjusted)']:.1f}%\"\n",
    "    )\n",
    "    max_y = max(row['Mean Control'], row['Mean Treated']) + 1.5\n",
    "    ax.text(0, max_y, label, ha='center', va='bottom', fontsize=9, color='#FFD700')\n",
    "\n",
    "    ax.axhline(0, color='black', linewidth=0.8)\n",
    "    ax.set_xticks([-width/2, +width/2])\n",
    "    ax.set_xticklabels(['Control', 'Treated'])\n",
    "    ax.set_title(f\"Group: {row['Medication Group']}\", fontsize=12, weight='bold')\n",
    "    ax.set_ylabel(\"CAPS5 Change Score\")\n",
    "    ax.set_ylim(bottom=0, top=max_y + 2)\n",
    "    ax.legend()\n",
    "    fig.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# ✅ Generate and save all plots into a multi-page PDF\n",
    "with PdfPages(\"dml_att_barplot_cat.pdf\") as pdf:\n",
    "    for idx, row in final_df.iterrows():\n",
    "        fig = plot_single_group(row)\n",
    "        pdf.savefig(fig, dpi=300, bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "\n",
    "print(\"✅ dml_att_barplot_cat saved.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8d7f3256-bb44-495c-a2fb-023d82a82611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Love plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0fecd847-e224-4613-b4e9-5de8a3e77d73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Processing CAT_Aceetanilidederivaten...\n",
      "📊 Exported numeric summary to: outputs\\CAT_Aceetanilidederivaten\\covariate_balance_table_CAT_Aceetanilidederivaten.xlsx\n",
      "✅ Saved love plot: outputs\\CAT_Aceetanilidederivaten\\love_plot_CAT_Aceetanilidederivaten.pdf\n",
      "📏 Max weighted SMD for CAT_Aceetanilidederivaten: 0.516\n",
      "\n",
      "🔍 Processing CAT_Adhd...\n",
      "📊 Exported numeric summary to: outputs\\CAT_Adhd\\covariate_balance_table_CAT_Adhd.xlsx\n",
      "✅ Saved love plot: outputs\\CAT_Adhd\\love_plot_CAT_Adhd.pdf\n",
      "📏 Max weighted SMD for CAT_Adhd: 0.489\n",
      "\n",
      "🔍 Processing CAT_All...\n",
      "📊 Exported numeric summary to: outputs\\CAT_All\\covariate_balance_table_CAT_All.xlsx\n",
      "✅ Saved love plot: outputs\\CAT_All\\love_plot_CAT_All.pdf\n",
      "📏 Max weighted SMD for CAT_All: 0.233\n",
      "\n",
      "🔍 Processing CAT_All_Psychotropics...\n",
      "📊 Exported numeric summary to: outputs\\CAT_All_Psychotropics\\covariate_balance_table_CAT_All_Psychotropics.xlsx\n",
      "✅ Saved love plot: outputs\\CAT_All_Psychotropics\\love_plot_CAT_All_Psychotropics.pdf\n",
      "📏 Max weighted SMD for CAT_All_Psychotropics: 0.202\n",
      "\n",
      "🔍 Processing CAT_All_Psychotropics_Excl_Benzo...\n",
      "📊 Exported numeric summary to: outputs\\CAT_All_Psychotropics_Excl_Benzo\\covariate_balance_table_CAT_All_Psychotropics_Excl_Benzo.xlsx\n",
      "✅ Saved love plot: outputs\\CAT_All_Psychotropics_Excl_Benzo\\love_plot_CAT_All_Psychotropics_Excl_Benzo.pdf\n",
      "📏 Max weighted SMD for CAT_All_Psychotropics_Excl_Benzo: 0.196\n",
      "\n",
      "🔍 Processing CAT_All_Psychotropics_Excl_Sedatives_Hypnotics...\n",
      "📊 Exported numeric summary to: outputs\\CAT_All_Psychotropics_Excl_Sedatives_Hypnotics\\covariate_balance_table_CAT_All_Psychotropics_Excl_Sedatives_Hypnotics.xlsx\n",
      "✅ Saved love plot: outputs\\CAT_All_Psychotropics_Excl_Sedatives_Hypnotics\\love_plot_CAT_All_Psychotropics_Excl_Sedatives_Hypnotics.pdf\n",
      "📏 Max weighted SMD for CAT_All_Psychotropics_Excl_Sedatives_Hypnotics: 0.197\n",
      "\n",
      "🔍 Processing CAT_Antidepressiva...\n",
      "📊 Exported numeric summary to: outputs\\CAT_Antidepressiva\\covariate_balance_table_CAT_Antidepressiva.xlsx\n",
      "✅ Saved love plot: outputs\\CAT_Antidepressiva\\love_plot_CAT_Antidepressiva.pdf\n",
      "📏 Max weighted SMD for CAT_Antidepressiva: 0.128\n",
      "\n",
      "🔍 Processing CAT_Antihistaminica...\n",
      "📊 Exported numeric summary to: outputs\\CAT_Antihistaminica\\covariate_balance_table_CAT_Antihistaminica.xlsx\n",
      "✅ Saved love plot: outputs\\CAT_Antihistaminica\\love_plot_CAT_Antihistaminica.pdf\n",
      "📏 Max weighted SMD for CAT_Antihistaminica: 0.331\n",
      "\n",
      "🔍 Processing CAT_Antihypertensiva...\n",
      "📊 Exported numeric summary to: outputs\\CAT_Antihypertensiva\\covariate_balance_table_CAT_Antihypertensiva.xlsx\n",
      "✅ Saved love plot: outputs\\CAT_Antihypertensiva\\love_plot_CAT_Antihypertensiva.pdf\n",
      "📏 Max weighted SMD for CAT_Antihypertensiva: 0.311\n",
      "\n",
      "🔍 Processing CAT_Antipsychotica...\n",
      "📊 Exported numeric summary to: outputs\\CAT_Antipsychotica\\covariate_balance_table_CAT_Antipsychotica.xlsx\n",
      "✅ Saved love plot: outputs\\CAT_Antipsychotica\\love_plot_CAT_Antipsychotica.pdf\n",
      "📏 Max weighted SMD for CAT_Antipsychotica: 0.223\n",
      "\n",
      "🔍 Processing CAT_Anti_Epileptica...\n",
      "📊 Exported numeric summary to: outputs\\CAT_Anti_Epileptica\\covariate_balance_table_CAT_Anti_Epileptica.xlsx\n",
      "✅ Saved love plot: outputs\\CAT_Anti_Epileptica\\love_plot_CAT_Anti_Epileptica.pdf\n",
      "📏 Max weighted SMD for CAT_Anti_Epileptica: 0.312\n",
      "\n",
      "🔍 Processing CAT_Benzodiazepine...\n",
      "📊 Exported numeric summary to: outputs\\CAT_Benzodiazepine\\covariate_balance_table_CAT_Benzodiazepine.xlsx\n",
      "✅ Saved love plot: outputs\\CAT_Benzodiazepine\\love_plot_CAT_Benzodiazepine.pdf\n",
      "📏 Max weighted SMD for CAT_Benzodiazepine: 0.163\n",
      "\n",
      "🔍 Processing CAT_Nsaids...\n",
      "📊 Exported numeric summary to: outputs\\CAT_Nsaids\\covariate_balance_table_CAT_Nsaids.xlsx\n",
      "✅ Saved love plot: outputs\\CAT_Nsaids\\love_plot_CAT_Nsaids.pdf\n",
      "📏 Max weighted SMD for CAT_Nsaids: 0.414\n",
      "\n",
      "🔍 Processing CAT_Opioden...\n",
      "📊 Exported numeric summary to: outputs\\CAT_Opioden\\covariate_balance_table_CAT_Opioden.xlsx\n",
      "✅ Saved love plot: outputs\\CAT_Opioden\\love_plot_CAT_Opioden.pdf\n",
      "📏 Max weighted SMD for CAT_Opioden: 0.401\n",
      "\n",
      "🔍 Processing CAT_Z_Drugs...\n",
      "📊 Exported numeric summary to: outputs\\CAT_Z_Drugs\\covariate_balance_table_CAT_Z_Drugs.xlsx\n",
      "✅ Saved love plot: outputs\\CAT_Z_Drugs\\love_plot_CAT_Z_Drugs.pdf\n",
      "📏 Max weighted SMD for CAT_Z_Drugs: 0.392\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "# ----------------------------------------\n",
    "# Functions to calculate balance\n",
    "# ----------------------------------------\n",
    "def calculate_smd(x1, x2, w1=None, w2=None):\n",
    "    def weighted_mean(x, w): return np.average(x, weights=w)\n",
    "    def weighted_var(x, w):\n",
    "        m = np.average(x, weights=w)\n",
    "        return np.average((x - m) ** 2, weights=w)\n",
    "    \n",
    "    m1 = weighted_mean(x1, w1) if w1 is not None else np.mean(x1)\n",
    "    m2 = weighted_mean(x2, w2) if w2 is not None else np.mean(x2)\n",
    "    v1 = weighted_var(x1, w1) if w1 is not None else np.var(x1, ddof=1)\n",
    "    v2 = weighted_var(x2, w2) if w2 is not None else np.var(x2, ddof=1)\n",
    "    \n",
    "    pooled_sd = np.sqrt((v1 + v2) / 2)\n",
    "    return np.abs(m1 - m2) / pooled_sd if pooled_sd > 0 else 0\n",
    "\n",
    "def variance_ratio(x1, x2, w1=None, w2=None):\n",
    "    def weighted_var(x, w):\n",
    "        m = np.average(x, weights=w)\n",
    "        return np.average((x - m) ** 2, weights=w)\n",
    "    \n",
    "    v1 = weighted_var(x1, w1) if w1 is not None else np.var(x1, ddof=1)\n",
    "    v2 = weighted_var(x2, w2) if w2 is not None else np.var(x2, ddof=1)\n",
    "    \n",
    "    return max(v1 / v2, v2 / v1) if v1 > 0 and v2 > 0 else 1\n",
    "\n",
    "# ----------------------------------------\n",
    "# Setup\n",
    "# ----------------------------------------\n",
    "output_base = \"outputs\"\n",
    "groups = [g for g in os.listdir(output_base) if os.path.isdir(os.path.join(output_base, g))]\n",
    "\n",
    "# Create a case-insensitive mapping\n",
    "final_covariates_map_lower = {k.lower(): v for k, v in final_covariates_map.items()}\n",
    "\n",
    "# ----------------------------------------\n",
    "# Main Loop\n",
    "# ----------------------------------------\n",
    "for group in groups:\n",
    "    if group.lower() not in final_covariates_map_lower:\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n🔍 Processing {group}...\")\n",
    "\n",
    "    try:\n",
    "        group_path = os.path.join(output_base, group)\n",
    "        covariates = final_covariates_map_lower[group.lower()]\n",
    "        \n",
    "        column_name = None\n",
    "        for col in pd.read_pickle(os.path.join(group_path, \"trimmed_data_imp1.pkl\")).columns:\n",
    "            if col.lower() == group.lower():\n",
    "                column_name = col\n",
    "                break\n",
    "        if column_name is None:\n",
    "            print(f\"⚠️ Column not found for {group}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        smd_unw_all, smd_w_all = [], []\n",
    "        vr_unw_all, vr_w_all = [], []\n",
    "\n",
    "        for i in range(1, 6):\n",
    "            df_path = os.path.join(group_path, f\"trimmed_data_imp{i}.pkl\")\n",
    "            iptw_path = os.path.join(group_path, \"iptw_weights.xlsx\")\n",
    "\n",
    "            if not os.path.exists(df_path) or not os.path.exists(iptw_path):\n",
    "                print(f\"⚠️ Missing data for {group} imp{i}, skipping.\")\n",
    "                continue\n",
    "\n",
    "            df = pd.read_pickle(df_path)\n",
    "            iptw_df = pd.read_excel(iptw_path, index_col=0)\n",
    "            T = df[column_name]\n",
    "            W = iptw_df.loc[df.index, \"iptw_mean\"]\n",
    "\n",
    "            smd_unw_i, smd_w_i, vr_unw_i, vr_w_i = [], [], [], []\n",
    "\n",
    "            for cov in covariates:\n",
    "                x1, x0 = df.loc[T == 1, cov], df.loc[T == 0, cov]\n",
    "                w1, w0 = W[T == 1], W[T == 0]\n",
    "\n",
    "                su = calculate_smd(x1, x0)\n",
    "                sw = calculate_smd(x1, x0, w1, w0)\n",
    "\n",
    "                vu = variance_ratio(x1, x0) if cov in ['treatmentdurationdays', 'CAPS5score_baseline', 'age'] else np.nan\n",
    "                vw = variance_ratio(x1, x0, w1, w0) if cov in ['treatmentdurationdays', 'CAPS5score_baseline', 'age'] else np.nan\n",
    "\n",
    "                smd_unw_i.append(su)\n",
    "                smd_w_i.append(sw)\n",
    "                vr_unw_i.append(vu)\n",
    "                vr_w_i.append(vw)\n",
    "\n",
    "            smd_unw_all.append(smd_unw_i)\n",
    "            smd_w_all.append(smd_w_i)\n",
    "            vr_unw_all.append(vr_unw_i)\n",
    "            vr_w_all.append(vr_w_i)\n",
    "\n",
    "        smd_unw = np.mean(smd_unw_all, axis=0)\n",
    "        smd_w = np.mean(smd_w_all, axis=0)\n",
    "        vr_unw = np.nanmean(vr_unw_all, axis=0)\n",
    "        vr_w = np.nanmean(vr_w_all, axis=0)\n",
    "\n",
    "        severity = []\n",
    "        for sw in smd_w:\n",
    "            if sw <= 0.1:\n",
    "                severity.append(\"Good\")\n",
    "            elif sw <= 0.2:\n",
    "                severity.append(\"Moderate\")\n",
    "            else:\n",
    "                severity.append(\"Poor\")\n",
    "\n",
    "        covariate_names = covariates\n",
    "        numeric_df = pd.DataFrame({\n",
    "            \"Covariate\": covariate_names,\n",
    "            \"SMD_Unweighted\": smd_unw,\n",
    "            \"SMD_Weighted\": smd_w,\n",
    "            \"Imbalance_Severity\": severity,\n",
    "            \"VR_Unweighted\": vr_unw,\n",
    "            \"VR_Weighted\": vr_w\n",
    "        })\n",
    "\n",
    "        numeric_path = os.path.join(group_path, f\"covariate_balance_table_{group}.xlsx\")\n",
    "        numeric_df.to_excel(numeric_path, index=False)\n",
    "        print(f\"📊 Exported numeric summary to: {numeric_path}\")\n",
    "\n",
    "        # -------------------------\n",
    "        # Plot\n",
    "        # -------------------------\n",
    "        labels = covariates\n",
    "        y_pos = np.arange(len(labels))\n",
    "\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(18, len(labels) * 0.45))\n",
    "\n",
    "        axes[0].scatter(smd_unw, y_pos, color='red', label=\"Unweighted\")\n",
    "        axes[0].scatter(smd_w, y_pos, color='blue', label=\"Weighted\")\n",
    "        axes[0].axvline(0.1, color='gray', linestyle='--', label=\"Threshold 0.1\")\n",
    "        axes[0].axvline(0.2, color='black', linestyle='--', label=\"Threshold 0.2\")\n",
    "        axes[0].set_xlim(0, max(max(smd_unw), max(smd_w), 0.25) + 0.05)\n",
    "        axes[0].set_yticks(y_pos)\n",
    "        axes[0].set_yticklabels(labels)\n",
    "        axes[0].invert_yaxis()\n",
    "        axes[0].set_title(\"Standardized Mean Differences (SMD)\")\n",
    "        axes[0].legend(loc=\"upper right\")\n",
    "        axes[0].grid(True)\n",
    "\n",
    "        vr_mask = [cov in ['treatmentdurationdays', 'CAPS5score_baseline', 'age'] for cov in covariates]\n",
    "        filtered_y = [i for i, b in enumerate(vr_mask) if b]\n",
    "        filtered_labels = [labels[i] for i in filtered_y]\n",
    "        filtered_vr_unw = [vr_unw[i] for i in filtered_y]\n",
    "        filtered_vr_w = [vr_w[i] for i in filtered_y]\n",
    "\n",
    "        axes[1].scatter(filtered_vr_unw, filtered_y, color='blue', marker='o', label=\"Unweighted\")\n",
    "        axes[1].scatter(filtered_vr_w, filtered_y, color='red', marker='x', label=\"Weighted\")\n",
    "        axes[1].axvline(2, color='gray', linestyle='--')\n",
    "        axes[1].axvline(0.5, color='gray', linestyle='--')\n",
    "        axes[1].set_xlim(0, max(filtered_vr_unw + filtered_vr_w + [2.5]) + 0.5)\n",
    "        axes[1].set_yticks(filtered_y)\n",
    "        axes[1].set_yticklabels(filtered_labels)\n",
    "        axes[1].invert_yaxis()\n",
    "        axes[1].set_title(\"Variance Ratio (VR)\")\n",
    "        axes[1].legend()\n",
    "        axes[1].grid(True)\n",
    "\n",
    "        fig.suptitle(f\"Covariate Balance for {group.replace('CAT_', '')}\", fontsize=14, weight='bold')\n",
    "        fig.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "        plot_path = os.path.join(group_path, f\"love_plot_{group}.pdf\")\n",
    "        fig.savefig(plot_path, dpi=300)\n",
    "        plt.close()\n",
    "        print(f\"✅ Saved love plot: {plot_path}\")\n",
    "        print(f\"📏 Max weighted SMD for {group}: {np.max(smd_w):.3f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error in {group}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "04a3ba94-b9c5-49bf-8daa-ecee013104ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1f9d0b67-ec65-431f-a804-f0af2bc85c96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Creating Heatmap for CAT_ADHD ==========\n",
      "✅ Heatmap saved: outputs\\CAT_ADHD\\heatmap_smd_CAT_ADHD.png\n",
      "\n",
      "========== Creating Heatmap for CAT_Aceetanilidederivaten ==========\n",
      "✅ Heatmap saved: outputs\\CAT_Aceetanilidederivaten\\heatmap_smd_CAT_Aceetanilidederivaten.png\n",
      "\n",
      "========== Creating Heatmap for CAT_Z_drugs ==========\n",
      "✅ Heatmap saved: outputs\\CAT_Z_drugs\\heatmap_smd_CAT_Z_drugs.png\n",
      "\n",
      "========== Creating Heatmap for CAT_Opioden ==========\n",
      "✅ Heatmap saved: outputs\\CAT_Opioden\\heatmap_smd_CAT_Opioden.png\n",
      "\n",
      "========== Creating Heatmap for CAT_NSAIDs ==========\n",
      "✅ Heatmap saved: outputs\\CAT_NSAIDs\\heatmap_smd_CAT_NSAIDs.png\n",
      "\n",
      "========== Creating Heatmap for CAT_Benzodiazepine ==========\n",
      "✅ Heatmap saved: outputs\\CAT_Benzodiazepine\\heatmap_smd_CAT_Benzodiazepine.png\n",
      "\n",
      "========== Creating Heatmap for CAT_Antihypertensiva ==========\n",
      "✅ Heatmap saved: outputs\\CAT_Antihypertensiva\\heatmap_smd_CAT_Antihypertensiva.png\n",
      "\n",
      "========== Creating Heatmap for CAT_Antihistaminica ==========\n",
      "✅ Heatmap saved: outputs\\CAT_Antihistaminica\\heatmap_smd_CAT_Antihistaminica.png\n",
      "\n",
      "========== Creating Heatmap for CAT_Anti_epileptica ==========\n",
      "✅ Heatmap saved: outputs\\CAT_Anti_epileptica\\heatmap_smd_CAT_Anti_epileptica.png\n",
      "\n",
      "========== Creating Heatmap for CAT_Antidepressiva ==========\n",
      "✅ Heatmap saved: outputs\\CAT_Antidepressiva\\heatmap_smd_CAT_Antidepressiva.png\n",
      "\n",
      "========== Creating Heatmap for CAT_Antipsychotica ==========\n",
      "✅ Heatmap saved: outputs\\CAT_Antipsychotica\\heatmap_smd_CAT_Antipsychotica.png\n",
      "\n",
      "========== Creating Heatmap for CAT_ALL_PSYCHOTROPICS_EXCL_BENZO ==========\n",
      "✅ Heatmap saved: outputs\\CAT_ALL_PSYCHOTROPICS_EXCL_BENZO\\heatmap_smd_CAT_ALL_PSYCHOTROPICS_EXCL_BENZO.png\n",
      "\n",
      "========== Creating Heatmap for CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS ==========\n",
      "✅ Heatmap saved: outputs\\CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS\\heatmap_smd_CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS.png\n",
      "\n",
      "========== Creating Heatmap for CAT_ALL_PSYCHOTROPICS ==========\n",
      "✅ Heatmap saved: outputs\\CAT_ALL_PSYCHOTROPICS\\heatmap_smd_CAT_ALL_PSYCHOTROPICS.png\n",
      "\n",
      "========== Creating Heatmap for CAT_ALL ==========\n",
      "✅ Heatmap saved: outputs\\CAT_ALL\\heatmap_smd_CAT_ALL.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "#-----------------------------\n",
    "# Generate heatmaps\n",
    "# -------------------------------\n",
    "for treatment_var in medication_groups:\n",
    "    print(f\"\\n========== Creating Heatmap for {treatment_var} ==========\")\n",
    "\n",
    "    try:\n",
    "        output_folder = os.path.join('outputs', treatment_var)\n",
    "        balance_path = os.path.join(output_folder, f'covariate_balance_table_{treatment_var}.xlsx')\n",
    "\n",
    "        if not os.path.exists(balance_path):\n",
    "            print(f\"❌ Balance file not found: {balance_path}\")\n",
    "            continue\n",
    "\n",
    "        balance_df = pd.read_excel(balance_path)\n",
    "\n",
    "        # ✅ Use finalized covariates + 'Propensity Score'\n",
    "        covariates = final_covariates_map[treatment_var] + ['Propensity Score']\n",
    "        balance_df = balance_df[balance_df['Covariate'].isin(covariates)]\n",
    "\n",
    "        # ✅ Check for CAPS5score_baseline\n",
    "        highlight_caps = 'CAPS5score_baseline' in balance_df['Covariate'].values\n",
    "\n",
    "        # ✅ Format for heatmap\n",
    "        heatmap_df = balance_df[['Covariate', 'SMD_Unweighted', 'SMD_Weighted']].copy()\n",
    "        heatmap_df.columns = ['Covariate', 'Unweighted', 'Weighted']\n",
    "        heatmap_df = heatmap_df.set_index('Covariate')\n",
    "        heatmap_df = heatmap_df.sort_values(by='Unweighted', ascending=False)\n",
    "\n",
    "        # ✅ Plot\n",
    "        plt.figure(figsize=(12, max(10, len(heatmap_df) * 0.35)))\n",
    "        ax = sns.heatmap(\n",
    "            heatmap_df,\n",
    "            cmap=\"coolwarm\",\n",
    "            annot=True,\n",
    "            fmt=\".2f\",\n",
    "            linewidths=0.6,\n",
    "            linecolor='gray',\n",
    "            cbar_kws={\"label\": \"Standardized Mean Difference\"}\n",
    "        )\n",
    "\n",
    "        plt.title(f\"Covariate Balance Heatmap (Rubin IPTW)\\n{treatment_var}\", fontsize=15, weight='bold')\n",
    "        plt.xlabel(\"Condition\")\n",
    "        plt.ylabel(\"Covariate\")\n",
    "\n",
    "        # ✅ Bold CAPS5score_baseline if present\n",
    "        if highlight_caps:\n",
    "            ylabels = [label.get_text() for label in ax.get_yticklabels()]\n",
    "            ax.set_yticklabels([\n",
    "                f\"{label} ←\" if label == 'CAPS5score_baseline' else label for label in ylabels\n",
    "            ])\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # ✅ Save image\n",
    "        save_path = os.path.join(output_folder, f'heatmap_smd_{treatment_var}.png')\n",
    "        plt.savefig(save_path, dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "        print(f\"✅ Heatmap saved: {save_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error processing {treatment_var}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05acf0f-8311-4c39-b99e-780b7f48d835",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f68fb1c3-430a-4ff8-893d-7f2a9f3c2c2c",
   "metadata": {},
   "source": [
    "## Subcat analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2a961590-c301-4cfd-a108-fd1559a81ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "covariates_SUBCAT_Antipsychotica_atypisch = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antidepressiva', 'CAT_Antipsychotica',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "covariates_SUBCAT_TCA = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antipsychotica',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "covariates_SUBCAT_SSRI = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antipsychotica',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "covariates_SUBCAT_SNRI = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antipsychotica',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "\n",
    "covariates_SUBCAT_Tetracyclische_antidepressiva = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antipsychotica',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "covariates_SUBCAT_Antidepressiva_overige = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antipsychotica',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "covariates_SUBCAT_Systemische_antihistaminica = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antidepressiva', 'CAT_Antipsychotica',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "\n",
    "covariates_SUBCAT_anxiolytica_Benzodiazepine = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antidepressiva',\n",
    "    'CAT_Antipsychotica',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "covariates_SUBCAT_hypnotica_Benzodiazepine = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antidepressiva',\n",
    "    'CAT_Antipsychotica',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "\n",
    "covariates_SUBCAT_Amfetaminen = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline', 'CAT_Antidepressiva', 'CAT_Antipsychotica',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD',\n",
    "    'DIAGNOSIS_SEXUAL_TRAUMA', 'DIAGNOSIS_SUICIDALITY',\n",
    "    'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "\n",
    "covariates_SUBCAT_Paracetamol_mono = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antidepressiva', 'CAT_Antipsychotica',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "\n",
    "covariates_SUBCAT_Anti_epileptica_stemmingsstabilisatoren = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antidepressiva',\n",
    "    'CAT_Antipsychotica',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age', \n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "covariates_SUBCAT_Opioden = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antidepressiva',\n",
    "    'CAT_Antipsychotica',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "covariates_SUBCAT_Z_drugs = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antidepressiva', 'CAT_Antipsychotica',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "covariates_SUBCAT_NSAIDs = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antidepressiva',\n",
    "    'CAT_Antipsychotica',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1d14a89b-45eb-4260-bee8-4594d9f4e39e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groups found: ['SUBCAT_Antipsychotica_atypisch', 'SUBCAT_TCA', 'SUBCAT_SSRI', 'SUBCAT_SNRI', 'SUBCAT_Tetracyclische_antidepressiva', 'SUBCAT_Antidepressiva_overige', 'SUBCAT_Systemische_antihistaminica', 'SUBCAT_anxiolytica_Benzodiazepine', 'SUBCAT_hypnotica_Benzodiazepine', 'SUBCAT_Amfetaminen', 'SUBCAT_Paracetamol_mono', 'SUBCAT_Anti_epileptica_stemmingsstabilisatoren', 'SUBCAT_Opioden', 'SUBCAT_Z_drugs', 'SUBCAT_NSAIDs']\n",
      "['SUBCAT_Antipsychotica_atypisch', 'SUBCAT_TCA', 'SUBCAT_SSRI', 'SUBCAT_SNRI', 'SUBCAT_Tetracyclische_antidepressiva', 'SUBCAT_Antidepressiva_overige', 'SUBCAT_Systemische_antihistaminica', 'SUBCAT_anxiolytica_Benzodiazepine', 'SUBCAT_hypnotica_Benzodiazepine', 'SUBCAT_Amfetaminen', 'SUBCAT_Paracetamol_mono', 'SUBCAT_Anti_epileptica_stemmingsstabilisatoren', 'SUBCAT_Opioden', 'SUBCAT_Z_drugs', 'SUBCAT_NSAIDs']\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# This finds all variables that start with covariates_SUBCAT_\n",
    "final_covariates_map = defaultdict(list)\n",
    "final_covariates_map.update({\n",
    "    var.replace(\"covariates_\", \"\"): val\n",
    "    for var, val in globals().items()\n",
    "    if var.lower().startswith(\"covariates_subcat_\") and isinstance(val, list)\n",
    "})\n",
    "\n",
    "# Show detected group names\n",
    "print(\"Groups found:\", list(final_covariates_map.keys()))\n",
    "medication_groups = list(final_covariates_map.keys())\n",
    "print(medication_groups)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b68dcdf5-6a5d-4fba-9d5e-0ff3ae44f705",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Starting analysis for all SUBCAT groups\n",
      "\n",
      " Processing SUBCAT_Antipsychotica_Atypisch...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBCAT_Antipsychotica_Atypisch\n",
      "\n",
      " Processing SUBCAT_Tca...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBCAT_Tca\n",
      "\n",
      " Processing SUBCAT_Ssri...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBCAT_Ssri\n",
      "\n",
      " Processing SUBCAT_Snri...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBCAT_Snri\n",
      "\n",
      " Processing SUBCAT_Tetracyclische_Antidepressiva...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBCAT_Tetracyclische_Antidepressiva\n",
      "\n",
      " Processing SUBCAT_Antidepressiva_Overige...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBCAT_Antidepressiva_Overige\n",
      "\n",
      " Processing SUBCAT_Systemische_Antihistaminica...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBCAT_Systemische_Antihistaminica\n",
      "\n",
      " Processing SUBCAT_Anxiolytica_Benzodiazepine...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBCAT_Anxiolytica_Benzodiazepine\n",
      "\n",
      " Processing SUBCAT_Hypnotica_Benzodiazepine...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBCAT_Hypnotica_Benzodiazepine\n",
      "\n",
      " Processing SUBCAT_Amfetaminen...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBCAT_Amfetaminen\n",
      "\n",
      " Processing SUBCAT_Paracetamol_Mono...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBCAT_Paracetamol_Mono\n",
      "\n",
      " Processing SUBCAT_Anti_Epileptica_Stemmingsstabilisatoren...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBCAT_Anti_Epileptica_Stemmingsstabilisatoren\n",
      "\n",
      " Processing SUBCAT_Opioden...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBCAT_Opioden\n",
      "\n",
      " Processing SUBCAT_Z_Drugs...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBCAT_Z_Drugs\n",
      "\n",
      " Processing SUBCAT_Nsaids...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBCAT_Nsaids\n",
      "\n",
      " All SUBCAT group analyses complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def run_all_SUBCAT_group_models(imputed_dfs):\n",
    "    \"\"\"\n",
    "    Runs downstream analysis for each SUBCAT medisubcation group using imputed datasets.\n",
    "\n",
    "    Parameters:\n",
    "    - imputed_dfs: list of 5 imputed DataFrames (from df_imputed_final_imp1.pkl ... imp5.pkl)\n",
    "    \n",
    "    Notes:\n",
    "    - Covariate lists must be defined as global variables: covariates_subcat_<group>\n",
    "    - Outputs are saved in: outputs/SUBCAT_<GROUP>/\n",
    "    \"\"\"\n",
    "\n",
    "    print(\" Starting analysis for all SUBCAT groups\")\n",
    "\n",
    "    for var_name in globals():\n",
    "        if var_name.lower().startswith(\"covariates_subcat_\") and isinstance(globals()[var_name], list):\n",
    "            group_name = var_name.replace(\"covariates_\", \"\")\n",
    "            group_name = group_name.replace(\"_\", \" \").title().replace(\" \", \"_\")  # e.g., subcat_z_drugs → Subcat_Z_Drugs\n",
    "            group_name = group_name.replace(\"Subcat_\", \"SUBCAT_\")  # force prefix to uppercase\n",
    "\n",
    "            covariates = globals()[var_name]\n",
    "            output_dir = f\"outputs/{group_name}\"\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "            print(f\"\\n Processing {group_name}...\")\n",
    "\n",
    "            for k, df_imp in enumerate(imputed_dfs):\n",
    "                print(f\"  → Using imputation {k+1}\")\n",
    "\n",
    "                # Define X and Y\n",
    "                X = df_imp[covariates]\n",
    "                Y = df_imp[\"caps5_change_baseline\"]\n",
    "\n",
    "                # === Save X and Y as placeholder (replace with modeling later)\n",
    "                X.to_csv(f\"{output_dir}/X_imp{k+1}.csv\", index=False)\n",
    "                Y.to_frame(name=\"Y\").to_csv(f\"{output_dir}/Y_imp{k+1}.csv\", index=False)\n",
    "\n",
    "            print(f\" Done: {group_name}\")\n",
    "\n",
    "    print(\"\\n All SUBCAT group analyses complete.\")\n",
    "\n",
    "# ========= STEP 4: Execute ========= #\n",
    "run_all_SUBCAT_group_models(imputed_dfs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "40cd90ed-a540-4498-92a6-58c70ad1d441",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " SUBCAT_Antipsychotica_atypisch\n",
      "  Imp 1: Treated = 256, Control = 3385, Missing = 0\n",
      "  Imp 2: Treated = 256, Control = 3385, Missing = 0\n",
      "  Imp 3: Treated = 256, Control = 3385, Missing = 0\n",
      "  Imp 4: Treated = 256, Control = 3385, Missing = 0\n",
      "  Imp 5: Treated = 256, Control = 3385, Missing = 0\n",
      "\n",
      " SUBCAT_TCA\n",
      "  Imp 1: Treated = 86, Control = 3555, Missing = 0\n",
      "  Imp 2: Treated = 86, Control = 3555, Missing = 0\n",
      "  Imp 3: Treated = 86, Control = 3555, Missing = 0\n",
      "  Imp 4: Treated = 86, Control = 3555, Missing = 0\n",
      "  Imp 5: Treated = 86, Control = 3555, Missing = 0\n",
      "\n",
      " SUBCAT_SSRI\n",
      "  Imp 1: Treated = 396, Control = 3245, Missing = 0\n",
      "  Imp 2: Treated = 396, Control = 3245, Missing = 0\n",
      "  Imp 3: Treated = 396, Control = 3245, Missing = 0\n",
      "  Imp 4: Treated = 396, Control = 3245, Missing = 0\n",
      "  Imp 5: Treated = 396, Control = 3245, Missing = 0\n",
      "\n",
      " SUBCAT_SNRI\n",
      "  Imp 1: Treated = 82, Control = 3559, Missing = 0\n",
      "  Imp 2: Treated = 82, Control = 3559, Missing = 0\n",
      "  Imp 3: Treated = 82, Control = 3559, Missing = 0\n",
      "  Imp 4: Treated = 82, Control = 3559, Missing = 0\n",
      "  Imp 5: Treated = 82, Control = 3559, Missing = 0\n",
      "\n",
      " SUBCAT_Tetracyclische_antidepressiva\n",
      "  Imp 1: Treated = 87, Control = 3554, Missing = 0\n",
      "  Imp 2: Treated = 87, Control = 3554, Missing = 0\n",
      "  Imp 3: Treated = 87, Control = 3554, Missing = 0\n",
      "  Imp 4: Treated = 87, Control = 3554, Missing = 0\n",
      "  Imp 5: Treated = 87, Control = 3554, Missing = 0\n",
      "\n",
      " SUBCAT_Antidepressiva_overige\n",
      "  Imp 1: Treated = 42, Control = 3599, Missing = 0\n",
      "  Imp 2: Treated = 42, Control = 3599, Missing = 0\n",
      "  Imp 3: Treated = 42, Control = 3599, Missing = 0\n",
      "  Imp 4: Treated = 42, Control = 3599, Missing = 0\n",
      "  Imp 5: Treated = 42, Control = 3599, Missing = 0\n",
      "\n",
      " SUBCAT_Systemische_antihistaminica\n",
      "  Imp 1: Treated = 56, Control = 3585, Missing = 0\n",
      "  Imp 2: Treated = 56, Control = 3585, Missing = 0\n",
      "  Imp 3: Treated = 56, Control = 3585, Missing = 0\n",
      "  Imp 4: Treated = 56, Control = 3585, Missing = 0\n",
      "  Imp 5: Treated = 56, Control = 3585, Missing = 0\n",
      "\n",
      " SUBCAT_anxiolytica_Benzodiazepine\n",
      "  Imp 1: Treated = 311, Control = 3330, Missing = 0\n",
      "  Imp 2: Treated = 311, Control = 3330, Missing = 0\n",
      "  Imp 3: Treated = 311, Control = 3330, Missing = 0\n",
      "  Imp 4: Treated = 311, Control = 3330, Missing = 0\n",
      "  Imp 5: Treated = 311, Control = 3330, Missing = 0\n",
      "\n",
      " SUBCAT_hypnotica_Benzodiazepine\n",
      "  Imp 1: Treated = 132, Control = 3509, Missing = 0\n",
      "  Imp 2: Treated = 132, Control = 3509, Missing = 0\n",
      "  Imp 3: Treated = 132, Control = 3509, Missing = 0\n",
      "  Imp 4: Treated = 132, Control = 3509, Missing = 0\n",
      "  Imp 5: Treated = 132, Control = 3509, Missing = 0\n",
      "\n",
      " SUBCAT_Amfetaminen\n",
      "  Imp 1: Treated = 52, Control = 3589, Missing = 0\n",
      "  Imp 2: Treated = 52, Control = 3589, Missing = 0\n",
      "  Imp 3: Treated = 52, Control = 3589, Missing = 0\n",
      "  Imp 4: Treated = 52, Control = 3589, Missing = 0\n",
      "  Imp 5: Treated = 52, Control = 3589, Missing = 0\n",
      "\n",
      " SUBCAT_Paracetamol_mono\n",
      "  Imp 1: Treated = 43, Control = 3598, Missing = 0\n",
      "  Imp 2: Treated = 43, Control = 3598, Missing = 0\n",
      "  Imp 3: Treated = 43, Control = 3598, Missing = 0\n",
      "  Imp 4: Treated = 43, Control = 3598, Missing = 0\n",
      "  Imp 5: Treated = 43, Control = 3598, Missing = 0\n",
      "\n",
      " SUBCAT_Anti_epileptica_stemmingsstabilisatoren\n",
      "  Imp 1: Treated = 57, Control = 3584, Missing = 0\n",
      "  Imp 2: Treated = 57, Control = 3584, Missing = 0\n",
      "  Imp 3: Treated = 57, Control = 3584, Missing = 0\n",
      "  Imp 4: Treated = 57, Control = 3584, Missing = 0\n",
      "  Imp 5: Treated = 57, Control = 3584, Missing = 0\n",
      "\n",
      " SUBCAT_Opioden\n",
      "  Imp 1: Treated = 54, Control = 3587, Missing = 0\n",
      "  Imp 2: Treated = 54, Control = 3587, Missing = 0\n",
      "  Imp 3: Treated = 54, Control = 3587, Missing = 0\n",
      "  Imp 4: Treated = 54, Control = 3587, Missing = 0\n",
      "  Imp 5: Treated = 54, Control = 3587, Missing = 0\n",
      "\n",
      " SUBCAT_Z_drugs\n",
      "  Imp 1: Treated = 57, Control = 3584, Missing = 0\n",
      "  Imp 2: Treated = 57, Control = 3584, Missing = 0\n",
      "  Imp 3: Treated = 57, Control = 3584, Missing = 0\n",
      "  Imp 4: Treated = 57, Control = 3584, Missing = 0\n",
      "  Imp 5: Treated = 57, Control = 3584, Missing = 0\n",
      "\n",
      " SUBCAT_NSAIDs\n",
      "  Imp 1: Treated = 37, Control = 3604, Missing = 0\n",
      "  Imp 2: Treated = 37, Control = 3604, Missing = 0\n",
      "  Imp 3: Treated = 37, Control = 3604, Missing = 0\n",
      "  Imp 4: Treated = 37, Control = 3604, Missing = 0\n",
      "  Imp 5: Treated = 37, Control = 3604, Missing = 0\n"
     ]
    }
   ],
   "source": [
    "for treatment_var in medication_groups:\n",
    "    print(f\"\\n {treatment_var}\")\n",
    "    \n",
    "    for i, df in enumerate(imputed_dfs):\n",
    "        if treatment_var not in df.columns:\n",
    "            print(f\"  Imp {i+1}:  Not found in columns.\")\n",
    "            continue\n",
    "\n",
    "        treated = (df[treatment_var] == 1).sum()\n",
    "        control = (df[treatment_var] == 0).sum()\n",
    "        missing = df[treatment_var].isna().sum()\n",
    "\n",
    "        print(f\"  Imp {i+1}: Treated = {treated}, Control = {control}, Missing = {missing}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d57b3c56-b77b-40db-a63c-026f92d9214e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Processing VIF for SUBCAT_Antipsychotica_atypisch\n",
      " ✅ Saved: outputs\\SUBCAT_Antipsychotica_atypisch/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SUBCAT_TCA\n",
      " ✅ Saved: outputs\\SUBCAT_TCA/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SUBCAT_SSRI\n",
      " ✅ Saved: outputs\\SUBCAT_SSRI/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SUBCAT_SNRI\n",
      " ✅ Saved: outputs\\SUBCAT_SNRI/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SUBCAT_Tetracyclische_antidepressiva\n",
      " ✅ Saved: outputs\\SUBCAT_Tetracyclische_antidepressiva/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SUBCAT_Antidepressiva_overige\n",
      " ✅ Saved: outputs\\SUBCAT_Antidepressiva_overige/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SUBCAT_Systemische_antihistaminica\n",
      " ✅ Saved: outputs\\SUBCAT_Systemische_antihistaminica/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SUBCAT_anxiolytica_Benzodiazepine\n",
      " ✅ Saved: outputs\\SUBCAT_anxiolytica_Benzodiazepine/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SUBCAT_hypnotica_Benzodiazepine\n",
      " ✅ Saved: outputs\\SUBCAT_hypnotica_Benzodiazepine/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SUBCAT_Amfetaminen\n",
      " ✅ Saved: outputs\\SUBCAT_Amfetaminen/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SUBCAT_Paracetamol_mono\n",
      " ✅ Saved: outputs\\SUBCAT_Paracetamol_mono/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SUBCAT_Anti_epileptica_stemmingsstabilisatoren\n",
      " ✅ Saved: outputs\\SUBCAT_Anti_epileptica_stemmingsstabilisatoren/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SUBCAT_Opioden\n",
      " ✅ Saved: outputs\\SUBCAT_Opioden/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SUBCAT_Z_drugs\n",
      " ✅ Saved: outputs\\SUBCAT_Z_drugs/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SUBCAT_NSAIDs\n",
      " ✅ Saved: outputs\\SUBCAT_NSAIDs/pooled_vif.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from collections import defaultdict\n",
    "\n",
    "# ✅ VIF computation function\n",
    "def compute_vif(X):\n",
    "    X = sm.add_constant(X, has_constant='add')\n",
    "    vif_df = pd.DataFrame()\n",
    "    vif_df[\"variable\"] = X.columns\n",
    "    vif_df[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "    return vif_df\n",
    "\n",
    "# ✅ Process each group\n",
    "for group in medication_groups:\n",
    "    print(f\"\\n🔍 Processing VIF for {group}\")\n",
    "\n",
    "    if group not in final_covariates_map:\n",
    "        print(f\" ⚠️ No covariates found for {group}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    covariates = final_covariates_map[group]\n",
    "    vif_list = []\n",
    "\n",
    "    for i, df_imp in enumerate(imputed_dfs):\n",
    "        try:\n",
    "            X = df_imp[covariates].copy()\n",
    "            vif_df = compute_vif(X)\n",
    "            vif_df[\"imputation\"] = i + 1\n",
    "            vif_list.append(vif_df)\n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ Failed on imputation {i+1} for {group}: {e}\")\n",
    "\n",
    "    if vif_list:\n",
    "        all_vif = pd.concat(vif_list)\n",
    "        pooled_vif = all_vif.groupby(\"variable\")[\"VIF\"].mean().reset_index()\n",
    "        pooled_vif = pooled_vif.sort_values(by=\"VIF\", ascending=False)\n",
    "\n",
    "        output_folder = os.path.join(\"outputs\", group)\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        pooled_vif.to_csv(os.path.join(output_folder, \"pooled_vif.csv\"), index=False)\n",
    "\n",
    "        print(f\" ✅ Saved: {output_folder}/pooled_vif.csv\")\n",
    "    else:\n",
    "        print(f\" ⚠️ Skipped {group}: No valid imputations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7dc544c6-0815-4712-ac03-b378443452b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Running PS estimation for SUBCAT_Antipsychotica_atypisch\n",
      "   Imp 1: AUC = 0.998, ROC saved.\n",
      "   Imp 2: AUC = 0.998, ROC saved.\n",
      "   Imp 3: AUC = 0.998, ROC saved.\n",
      "   Imp 4: AUC = 0.998, ROC saved.\n",
      "   Imp 5: AUC = 0.998, ROC saved.\n",
      " Composite PS + AUC saved for SUBCAT_Antipsychotica_atypisch\n",
      " Running PS estimation for SUBCAT_TCA\n",
      "   Imp 1: AUC = 0.581, ROC saved.\n",
      "   Imp 2: AUC = 0.579, ROC saved.\n",
      "   Imp 3: AUC = 0.590, ROC saved.\n",
      "   Imp 4: AUC = 0.599, ROC saved.\n",
      "   Imp 5: AUC = 0.589, ROC saved.\n",
      " Composite PS + AUC saved for SUBCAT_TCA\n",
      " Running PS estimation for SUBCAT_SSRI\n",
      "   Imp 1: AUC = 0.659, ROC saved.\n",
      "   Imp 2: AUC = 0.663, ROC saved.\n",
      "   Imp 3: AUC = 0.660, ROC saved.\n",
      "   Imp 4: AUC = 0.657, ROC saved.\n",
      "   Imp 5: AUC = 0.661, ROC saved.\n",
      " Composite PS + AUC saved for SUBCAT_SSRI\n",
      " Running PS estimation for SUBCAT_SNRI\n",
      "   Imp 1: AUC = 0.684, ROC saved.\n",
      "   Imp 2: AUC = 0.671, ROC saved.\n",
      "   Imp 3: AUC = 0.649, ROC saved.\n",
      "   Imp 4: AUC = 0.656, ROC saved.\n",
      "   Imp 5: AUC = 0.680, ROC saved.\n",
      " Composite PS + AUC saved for SUBCAT_SNRI\n",
      " Running PS estimation for SUBCAT_Tetracyclische_antidepressiva\n",
      "   Imp 1: AUC = 0.587, ROC saved.\n",
      "   Imp 2: AUC = 0.543, ROC saved.\n",
      "   Imp 3: AUC = 0.564, ROC saved.\n",
      "   Imp 4: AUC = 0.578, ROC saved.\n",
      "   Imp 5: AUC = 0.603, ROC saved.\n",
      " Composite PS + AUC saved for SUBCAT_Tetracyclische_antidepressiva\n",
      " Running PS estimation for SUBCAT_Antidepressiva_overige\n",
      "   Imp 1: AUC = 0.451, ROC saved.\n",
      "   Imp 2: AUC = 0.465, ROC saved.\n",
      "   Imp 3: AUC = 0.522, ROC saved.\n",
      "   Imp 4: AUC = 0.557, ROC saved.\n",
      "   Imp 5: AUC = 0.505, ROC saved.\n",
      " Composite PS + AUC saved for SUBCAT_Antidepressiva_overige\n",
      " Running PS estimation for SUBCAT_Systemische_antihistaminica\n",
      "   Imp 1: AUC = 0.661, ROC saved.\n",
      "   Imp 2: AUC = 0.665, ROC saved.\n",
      "   Imp 3: AUC = 0.613, ROC saved.\n",
      "   Imp 4: AUC = 0.663, ROC saved.\n",
      "   Imp 5: AUC = 0.632, ROC saved.\n",
      " Composite PS + AUC saved for SUBCAT_Systemische_antihistaminica\n",
      " Running PS estimation for SUBCAT_anxiolytica_Benzodiazepine\n",
      "   Imp 1: AUC = 0.707, ROC saved.\n",
      "   Imp 2: AUC = 0.719, ROC saved.\n",
      "   Imp 3: AUC = 0.701, ROC saved.\n",
      "   Imp 4: AUC = 0.716, ROC saved.\n",
      "   Imp 5: AUC = 0.689, ROC saved.\n",
      " Composite PS + AUC saved for SUBCAT_anxiolytica_Benzodiazepine\n",
      " Running PS estimation for SUBCAT_hypnotica_Benzodiazepine\n",
      "   Imp 1: AUC = 0.573, ROC saved.\n",
      "   Imp 2: AUC = 0.573, ROC saved.\n",
      "   Imp 3: AUC = 0.631, ROC saved.\n",
      "   Imp 4: AUC = 0.601, ROC saved.\n",
      "   Imp 5: AUC = 0.600, ROC saved.\n",
      " Composite PS + AUC saved for SUBCAT_hypnotica_Benzodiazepine\n",
      " Running PS estimation for SUBCAT_Amfetaminen\n",
      "   Imp 1: AUC = 0.535, ROC saved.\n",
      "   Imp 2: AUC = 0.553, ROC saved.\n",
      "   Imp 3: AUC = 0.523, ROC saved.\n",
      "   Imp 4: AUC = 0.579, ROC saved.\n",
      "   Imp 5: AUC = 0.533, ROC saved.\n",
      " Composite PS + AUC saved for SUBCAT_Amfetaminen\n",
      " Running PS estimation for SUBCAT_Paracetamol_mono\n",
      "   Imp 1: AUC = 0.589, ROC saved.\n",
      "   Imp 2: AUC = 0.589, ROC saved.\n",
      "   Imp 3: AUC = 0.656, ROC saved.\n",
      "   Imp 4: AUC = 0.622, ROC saved.\n",
      "   Imp 5: AUC = 0.631, ROC saved.\n",
      " Composite PS + AUC saved for SUBCAT_Paracetamol_mono\n",
      " Running PS estimation for SUBCAT_Anti_epileptica_stemmingsstabilisatoren\n",
      "   Imp 1: AUC = 0.664, ROC saved.\n",
      "   Imp 2: AUC = 0.674, ROC saved.\n",
      "   Imp 3: AUC = 0.714, ROC saved.\n",
      "   Imp 4: AUC = 0.684, ROC saved.\n",
      "   Imp 5: AUC = 0.674, ROC saved.\n",
      " Composite PS + AUC saved for SUBCAT_Anti_epileptica_stemmingsstabilisatoren\n",
      " Running PS estimation for SUBCAT_Opioden\n",
      "   Imp 1: AUC = 0.621, ROC saved.\n",
      "   Imp 2: AUC = 0.630, ROC saved.\n",
      "   Imp 3: AUC = 0.640, ROC saved.\n",
      "   Imp 4: AUC = 0.702, ROC saved.\n",
      "   Imp 5: AUC = 0.662, ROC saved.\n",
      " Composite PS + AUC saved for SUBCAT_Opioden\n",
      " Running PS estimation for SUBCAT_Z_drugs\n",
      "   Imp 1: AUC = 0.558, ROC saved.\n",
      "   Imp 2: AUC = 0.634, ROC saved.\n",
      "   Imp 3: AUC = 0.570, ROC saved.\n",
      "   Imp 4: AUC = 0.561, ROC saved.\n",
      "   Imp 5: AUC = 0.605, ROC saved.\n",
      " Composite PS + AUC saved for SUBCAT_Z_drugs\n",
      " Running PS estimation for SUBCAT_NSAIDs\n",
      "   Imp 1: AUC = 0.545, ROC saved.\n",
      "   Imp 2: AUC = 0.567, ROC saved.\n",
      "   Imp 3: AUC = 0.594, ROC saved.\n",
      "   Imp 4: AUC = 0.601, ROC saved.\n",
      "   Imp 5: AUC = 0.563, ROC saved.\n",
      " Composite PS + AUC saved for SUBCAT_NSAIDs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ---------- PS Estimation Function ----------\n",
    "def run_xgboost_ps_modeling(imputed_dfs, medication_groups, final_covariates_map):\n",
    "    for group in medication_groups:\n",
    "        print(f\" Running PS estimation for {group}\")\n",
    "\n",
    "        if group not in final_covariates_map:\n",
    "            print(f\" No covariates found for {group}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        output_folder = os.path.join(\"outputs\", group)\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "        covariates = final_covariates_map[group]\n",
    "        ps_matrix = pd.DataFrame()\n",
    "        auc_list = []\n",
    "\n",
    "        for i, df_imp in enumerate(imputed_dfs):\n",
    "            if group not in df_imp.columns:\n",
    "                print(f\" {group} not found in imputed dataset {i+1}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            X = df_imp[covariates].copy()\n",
    "            T = df_imp[group]\n",
    "\n",
    "            # Drop missing treatment rows\n",
    "            valid_idx = T.dropna().index\n",
    "            X = X.loc[valid_idx]\n",
    "            T = T.loc[valid_idx]\n",
    "\n",
    "            # Train-test split for ROC\n",
    "            X_train, X_test, T_train, T_test = train_test_split(\n",
    "                X, T, stratify=T, test_size=0.3, random_state=42\n",
    "            )\n",
    "\n",
    "            try:\n",
    "                model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "                model.fit(X_train, T_train)\n",
    "\n",
    "                ps_scores = model.predict_proba(X)[:, 1]\n",
    "                ps_matrix[f\"ps_imp{i+1}\"] = pd.Series(ps_scores, index=valid_idx)\n",
    "\n",
    "                # ROC & AUC\n",
    "                auc = roc_auc_score(T_test, model.predict_proba(X_test)[:, 1])\n",
    "                auc_list.append(auc)\n",
    "\n",
    "                fpr, tpr, _ = roc_curve(T_test, model.predict_proba(X_test)[:, 1])\n",
    "                plt.figure()\n",
    "                plt.plot(fpr, tpr, label=f\"AUC = {auc:.3f}\")\n",
    "                plt.plot([0, 1], [0, 1], 'k--')\n",
    "                plt.xlabel(\"False Positive Rate\")\n",
    "                plt.ylabel(\"True Positive Rate\")\n",
    "                plt.title(f\"ROC Curve - {group} (Imp {i+1})\")\n",
    "                plt.legend()\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(os.path.join(output_folder, f\"roc_curve_imp{i+1}.png\"))\n",
    "                plt.close()\n",
    "                print(f\"   Imp {i+1}: AUC = {auc:.3f}, ROC saved.\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"   Error in {group} (imp {i+1}): {e}\")\n",
    "\n",
    "        # Save AUCs and Composite PS\n",
    "        if not ps_matrix.empty:\n",
    "            # Fill NaN rows (from dropped subjects in some imputations) with mean\n",
    "            ps_matrix[\"composite_ps\"] = ps_matrix.mean(axis=1)\n",
    "            ps_matrix.to_excel(os.path.join(output_folder, \"propensity_scores.xlsx\"))\n",
    "\n",
    "            auc_df = pd.DataFrame({\n",
    "                \"imputation\": [f\"imp{i+1}\" for i in range(len(auc_list))],\n",
    "                \"AUC\": auc_list\n",
    "            })\n",
    "            auc_df.loc[len(auc_df.index)] = [\"mean\", np.mean(auc_list) if auc_list else np.nan]\n",
    "            auc_df.to_excel(os.path.join(output_folder, \"auc_scores.xlsx\"), index=False)\n",
    "\n",
    "            print(f\" Composite PS + AUC saved for {group}\")\n",
    "        else:\n",
    "            print(f\" No valid PS scores generated for {group}\")\n",
    "\n",
    "# ---------- Run ----------\n",
    "run_xgboost_ps_modeling(imputed_dfs, medication_groups, final_covariates_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "47524442-ca28-4f91-9a75-b6d770877c44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Computing feature importance for SUBCAT_Antipsychotica_atypisch\n",
      " Saved feature importance plot and CSV for SUBCAT_Antipsychotica_atypisch\n",
      "\n",
      " Computing feature importance for SUBCAT_TCA\n",
      " Saved feature importance plot and CSV for SUBCAT_TCA\n",
      "\n",
      " Computing feature importance for SUBCAT_SSRI\n",
      " Saved feature importance plot and CSV for SUBCAT_SSRI\n",
      "\n",
      " Computing feature importance for SUBCAT_SNRI\n",
      " Saved feature importance plot and CSV for SUBCAT_SNRI\n",
      "\n",
      " Computing feature importance for SUBCAT_Tetracyclische_antidepressiva\n",
      " Saved feature importance plot and CSV for SUBCAT_Tetracyclische_antidepressiva\n",
      "\n",
      " Computing feature importance for SUBCAT_Antidepressiva_overige\n",
      " Saved feature importance plot and CSV for SUBCAT_Antidepressiva_overige\n",
      "\n",
      " Computing feature importance for SUBCAT_Systemische_antihistaminica\n",
      " Saved feature importance plot and CSV for SUBCAT_Systemische_antihistaminica\n",
      "\n",
      " Computing feature importance for SUBCAT_anxiolytica_Benzodiazepine\n",
      " Saved feature importance plot and CSV for SUBCAT_anxiolytica_Benzodiazepine\n",
      "\n",
      " Computing feature importance for SUBCAT_hypnotica_Benzodiazepine\n",
      " Saved feature importance plot and CSV for SUBCAT_hypnotica_Benzodiazepine\n",
      "\n",
      " Computing feature importance for SUBCAT_Amfetaminen\n",
      " Saved feature importance plot and CSV for SUBCAT_Amfetaminen\n",
      "\n",
      " Computing feature importance for SUBCAT_Paracetamol_mono\n",
      " Saved feature importance plot and CSV for SUBCAT_Paracetamol_mono\n",
      "\n",
      " Computing feature importance for SUBCAT_Anti_epileptica_stemmingsstabilisatoren\n",
      " Saved feature importance plot and CSV for SUBCAT_Anti_epileptica_stemmingsstabilisatoren\n",
      "\n",
      " Computing feature importance for SUBCAT_Opioden\n",
      " Saved feature importance plot and CSV for SUBCAT_Opioden\n",
      "\n",
      " Computing feature importance for SUBCAT_Z_drugs\n",
      " Saved feature importance plot and CSV for SUBCAT_Z_drugs\n",
      "\n",
      " Computing feature importance for SUBCAT_NSAIDs\n",
      " Saved feature importance plot and CSV for SUBCAT_NSAIDs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "def compute_feature_importance(imputed_dfs, medication_groups, final_covariates_map):\n",
    "    for group in medication_groups:\n",
    "        print(f\"\\n Computing feature importance for {group}\")\n",
    "\n",
    "        if group not in final_covariates_map:\n",
    "            print(f\" No covariates found for {group}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        covariates = final_covariates_map[group]\n",
    "        output_folder = os.path.join(\"outputs\", group)\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "        importance_df_list = []\n",
    "\n",
    "        for i, df_imp in enumerate(imputed_dfs):\n",
    "            if group not in df_imp.columns:\n",
    "                print(f\" {group} not in imputed dataset {i+1}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            X = df_imp[covariates].copy()\n",
    "            T = df_imp[group]\n",
    "\n",
    "            # Drop NaNs in treatment\n",
    "            valid_idx = T.dropna().index\n",
    "            X = X.loc[valid_idx]\n",
    "            T = T.loc[valid_idx]\n",
    "\n",
    "            try:\n",
    "                model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "                model.fit(X, T)\n",
    "\n",
    "                # Get feature importance\n",
    "                importances = model.get_booster().get_score(importance_type='gain')\n",
    "                df_feat = pd.DataFrame.from_dict(importances, orient='index', columns=[f\"imp{i+1}\"])\n",
    "                df_feat.index.name = 'feature'\n",
    "                importance_df_list.append(df_feat)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"   Error during modeling: {e}\")\n",
    "\n",
    "        if importance_df_list:\n",
    "            # Combine and average\n",
    "            all_feat = pd.concat(importance_df_list, axis=1).fillna(0)\n",
    "            all_feat[\"mean_importance\"] = all_feat.mean(axis=1)\n",
    "\n",
    "            # Filter top 30 non-zero\n",
    "            non_zero = all_feat[all_feat[\"mean_importance\"] > 0]\n",
    "            top30 = non_zero.sort_values(by=\"mean_importance\", ascending=False).head(30)\n",
    "\n",
    "            # Save to CSV\n",
    "            top30.to_csv(os.path.join(output_folder, \"feature_importance.csv\"))\n",
    "\n",
    "            # Plot\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            plt.barh(top30.index[::-1], top30[\"mean_importance\"][::-1])  # plot top → bottom\n",
    "            plt.xlabel(\"Mean Gain Importance\")\n",
    "            plt.title(f\"Top 30 Feature Importance - {group}\")\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(output_folder, \"feature_importance_top30.png\"))\n",
    "            plt.close()\n",
    "\n",
    "            print(f\" Saved feature importance plot and CSV for {group}\")\n",
    "        else:\n",
    "            print(f\" No valid models for {group}\")\n",
    "\n",
    "#  Run\n",
    "compute_feature_importance(imputed_dfs, medication_groups, final_covariates_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bd7b6712-1c60-44d2-96a3-f57274cc0cf1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SUBCAT_Antipsychotica_atypisch\n",
      "✅ Saved IPTW weights for SUBCAT_Antipsychotica_atypisch\n",
      "    ℹ️ Retained 35/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Antipsychotica_atypisch/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 34/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Antipsychotica_atypisch/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 37/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Antipsychotica_atypisch/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 33/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Antipsychotica_atypisch/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 33/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Antipsychotica_atypisch/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SUBCAT_TCA\n",
      "✅ Saved IPTW weights for SUBCAT_TCA\n",
      "    ℹ️ Retained 182/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_TCA/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 182/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_TCA/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 179/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_TCA/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 182/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_TCA/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 176/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_TCA/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SUBCAT_SSRI\n",
      "✅ Saved IPTW weights for SUBCAT_SSRI\n",
      "    ℹ️ Retained 1212/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_SSRI/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 1210/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_SSRI/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 1245/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_SSRI/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 1234/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_SSRI/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 1224/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_SSRI/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SUBCAT_SNRI\n",
      "✅ Saved IPTW weights for SUBCAT_SNRI\n",
      "    ℹ️ Retained 167/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_SNRI/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 175/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_SNRI/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 163/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_SNRI/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 151/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_SNRI/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 191/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_SNRI/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SUBCAT_Tetracyclische_antidepressiva\n",
      "✅ Saved IPTW weights for SUBCAT_Tetracyclische_antidepressiva\n",
      "    ℹ️ Retained 180/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Tetracyclische_antidepressiva/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 180/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Tetracyclische_antidepressiva/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 196/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Tetracyclische_antidepressiva/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 195/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Tetracyclische_antidepressiva/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 177/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Tetracyclische_antidepressiva/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SUBCAT_Antidepressiva_overige\n",
      "✅ Saved IPTW weights for SUBCAT_Antidepressiva_overige\n",
      "    ℹ️ Retained 72/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Antidepressiva_overige/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 84/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Antidepressiva_overige/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 79/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Antidepressiva_overige/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 76/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Antidepressiva_overige/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 77/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Antidepressiva_overige/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SUBCAT_Systemische_antihistaminica\n",
      "✅ Saved IPTW weights for SUBCAT_Systemische_antihistaminica\n",
      "    ℹ️ Retained 114/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Systemische_antihistaminica/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 118/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Systemische_antihistaminica/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 116/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Systemische_antihistaminica/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 113/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Systemische_antihistaminica/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 120/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Systemische_antihistaminica/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SUBCAT_anxiolytica_Benzodiazepine\n",
      "✅ Saved IPTW weights for SUBCAT_anxiolytica_Benzodiazepine\n",
      "    ℹ️ Retained 909/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_anxiolytica_Benzodiazepine/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 889/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_anxiolytica_Benzodiazepine/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 893/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_anxiolytica_Benzodiazepine/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 902/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_anxiolytica_Benzodiazepine/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 893/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_anxiolytica_Benzodiazepine/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SUBCAT_hypnotica_Benzodiazepine\n",
      "✅ Saved IPTW weights for SUBCAT_hypnotica_Benzodiazepine\n",
      "    ℹ️ Retained 325/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_hypnotica_Benzodiazepine/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 358/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_hypnotica_Benzodiazepine/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 333/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_hypnotica_Benzodiazepine/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 321/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_hypnotica_Benzodiazepine/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 335/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_hypnotica_Benzodiazepine/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SUBCAT_Amfetaminen\n",
      "✅ Saved IPTW weights for SUBCAT_Amfetaminen\n",
      "    ℹ️ Retained 109/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Amfetaminen/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 103/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Amfetaminen/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 112/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Amfetaminen/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 110/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Amfetaminen/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 103/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Amfetaminen/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SUBCAT_Paracetamol_mono\n",
      "✅ Saved IPTW weights for SUBCAT_Paracetamol_mono\n",
      "    ℹ️ Retained 72/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Paracetamol_mono/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 79/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Paracetamol_mono/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 70/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Paracetamol_mono/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 65/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Paracetamol_mono/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 72/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Paracetamol_mono/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SUBCAT_Anti_epileptica_stemmingsstabilisatoren\n",
      "✅ Saved IPTW weights for SUBCAT_Anti_epileptica_stemmingsstabilisatoren\n",
      "    ℹ️ Retained 93/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Anti_epileptica_stemmingsstabilisatoren/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 99/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Anti_epileptica_stemmingsstabilisatoren/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 93/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Anti_epileptica_stemmingsstabilisatoren/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 93/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Anti_epileptica_stemmingsstabilisatoren/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 99/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Anti_epileptica_stemmingsstabilisatoren/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SUBCAT_Opioden\n",
      "✅ Saved IPTW weights for SUBCAT_Opioden\n",
      "    ℹ️ Retained 98/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Opioden/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 117/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Opioden/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 102/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Opioden/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 121/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Opioden/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 110/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Opioden/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SUBCAT_Z_drugs\n",
      "✅ Saved IPTW weights for SUBCAT_Z_drugs\n",
      "    ℹ️ Retained 124/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Z_drugs/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 120/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Z_drugs/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 121/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Z_drugs/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 119/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Z_drugs/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 118/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Z_drugs/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SUBCAT_NSAIDs\n",
      "✅ Saved IPTW weights for SUBCAT_NSAIDs\n",
      "    ℹ️ Retained 78/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_NSAIDs/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 84/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_NSAIDs/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 78/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_NSAIDs/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 78/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_NSAIDs/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 76/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_NSAIDs/trimmed_data_imp5.*\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_trimmed_clipped_iptw(ps_df, treatment, lower=0.05, upper=0.95, clip_max=10):\n",
    "    weights = []\n",
    "    keep_mask = (ps_df > lower) & (ps_df < upper)\n",
    "\n",
    "    for i in range(ps_df.shape[1]):\n",
    "        ps = ps_df.iloc[:, i].clip(lower=1e-6, upper=1 - 1e-6)  # avoid div by zero\n",
    "        mask = keep_mask.iloc[:, i]\n",
    "        w = pd.Series(np.nan, index=ps.index)\n",
    "\n",
    "        w[mask & (treatment == 1)] = 1 / ps[mask & (treatment == 1)]\n",
    "        w[mask & (treatment == 0)] = 1 / (1 - ps[mask & (treatment == 0)])\n",
    "        w = w.clip(upper=clip_max)\n",
    "        weights.append(w)\n",
    "\n",
    "    return pd.concat(weights, axis=1)\n",
    "\n",
    "\n",
    "def apply_rubins_rule_to_iptw(iptw_matrix):\n",
    "    \"\"\"\n",
    "    Given an IPTW matrix (n rows × M imputations), return Rubin’s rule pooled mean, SD, SE.\n",
    "    \"\"\"\n",
    "    M = iptw_matrix.shape[1]\n",
    "    q_bar = iptw_matrix.mean(axis=1)\n",
    "    u_bar = iptw_matrix.var(axis=1, ddof=1)\n",
    "    B = iptw_matrix.apply(lambda x: x.mean(), axis=1).var(ddof=1)\n",
    "    total_var = u_bar + (1 + 1/M) * B\n",
    "    total_se = np.sqrt(total_var)\n",
    "    return q_bar, u_bar.pow(0.5), total_se\n",
    "\n",
    "\n",
    "def run_trim_clip_save_all(imputed_dfs, medication_groups, final_covariates_map):\n",
    "    for group in medication_groups:\n",
    "        print(f\"\\n🔍 Processing IPTW + trimming + clipping for {group}\")\n",
    "        output_folder = os.path.join(\"outputs\", group)\n",
    "        ps_path = os.path.join(output_folder, \"propensity_scores.xlsx\")\n",
    "\n",
    "        if not os.path.exists(ps_path):\n",
    "            print(f\"⚠️ Missing PS file: {ps_path}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            ps_all = pd.read_excel(ps_path, index_col=0)\n",
    "            ps_cols = [col for col in ps_all.columns if col.startswith(\"ps_imp\")]\n",
    "            composite_index = ps_all.index\n",
    "\n",
    "            # Get treatment from one imputed dataset\n",
    "            T_full = None\n",
    "            for df in imputed_dfs:\n",
    "                if group in df.columns:\n",
    "                    T_full = df.loc[composite_index, group]\n",
    "                    break\n",
    "\n",
    "            if T_full is None:\n",
    "                print(f\"❌ Treatment column {group} not found in any imputed dataset.\")\n",
    "                continue\n",
    "\n",
    "            # Compute IPTW matrix (shape: n × M)\n",
    "            iptw_matrix = compute_trimmed_clipped_iptw(ps_all[ps_cols], T_full)\n",
    "            iptw_matrix.columns = [f\"iptw_imp{i+1}\" for i in range(iptw_matrix.shape[1])]\n",
    "\n",
    "            # Apply Rubin’s Rule for mean, SD, SE\n",
    "            iptw_matrix[\"iptw_mean\"], iptw_matrix[\"iptw_sd\"], iptw_matrix[\"iptw_se\"] = apply_rubins_rule_to_iptw(\n",
    "                iptw_matrix[[f\"iptw_imp{i+1}\" for i in range(iptw_matrix.shape[1])]]\n",
    "            )\n",
    "\n",
    "            # Save IPTW matrix separately\n",
    "            iptw_matrix.to_excel(os.path.join(output_folder, \"iptw_weights.xlsx\"))\n",
    "            print(f\"✅ Saved IPTW weights for {group}\")\n",
    "\n",
    "            # Save trimmed & clipped imputed datasets with IPTW\n",
    "            for i in range(5):\n",
    "                df = imputed_dfs[i].copy()\n",
    "                if group not in df.columns:\n",
    "                    continue\n",
    "\n",
    "                trimmed_idx = iptw_matrix.index.intersection(df.index)\n",
    "                needed_cols = final_covariates_map[group] + [group, \"caps5_change_baseline\"]\n",
    "\n",
    "                # Select only necessary columns\n",
    "                df_trimmed = df.loc[trimmed_idx, needed_cols].copy()\n",
    "                df_trimmed[\"iptw\"] = iptw_matrix[f\"iptw_imp{i+1}\"].loc[trimmed_idx]\n",
    "\n",
    "                # ✅ DROP rows with missing IPTW values\n",
    "                before = len(df_trimmed)\n",
    "                df_trimmed = df_trimmed.dropna(subset=[\"iptw\"])\n",
    "                after = len(df_trimmed)\n",
    "                print(f\"    ℹ️ Retained {after}/{before} rows after IPTW NaN drop.\")\n",
    "\n",
    "                # Save to .pkl\n",
    "                df_trimmed.to_pickle(os.path.join(output_folder, f\"trimmed_data_imp{i+1}.pkl\"))\n",
    "                print(f\"  💾 Saved trimmed dataset: {output_folder}/trimmed_data_imp{i+1}.*\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error in {group}: {e}\")\n",
    "\n",
    "\n",
    "run_trim_clip_save_all(imputed_dfs, medication_groups, final_covariates_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8132b1b6-2315-4d56-9728-4f4c73cde88e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Plotting PS overlap for SUBCAT_Antipsychotica_atypisch\n",
      "✅ Saved unweighted and weighted PS plots for SUBCAT_Antipsychotica_atypisch\n",
      "\n",
      "📊 Plotting PS overlap for SUBCAT_TCA\n",
      "✅ Saved unweighted and weighted PS plots for SUBCAT_TCA\n",
      "\n",
      "📊 Plotting PS overlap for SUBCAT_SSRI\n",
      "✅ Saved unweighted and weighted PS plots for SUBCAT_SSRI\n",
      "\n",
      "📊 Plotting PS overlap for SUBCAT_SNRI\n",
      "✅ Saved unweighted and weighted PS plots for SUBCAT_SNRI\n",
      "\n",
      "📊 Plotting PS overlap for SUBCAT_Tetracyclische_antidepressiva\n",
      "✅ Saved unweighted and weighted PS plots for SUBCAT_Tetracyclische_antidepressiva\n",
      "\n",
      "📊 Plotting PS overlap for SUBCAT_Antidepressiva_overige\n",
      "✅ Saved unweighted and weighted PS plots for SUBCAT_Antidepressiva_overige\n",
      "\n",
      "📊 Plotting PS overlap for SUBCAT_Systemische_antihistaminica\n",
      "✅ Saved unweighted and weighted PS plots for SUBCAT_Systemische_antihistaminica\n",
      "\n",
      "📊 Plotting PS overlap for SUBCAT_anxiolytica_Benzodiazepine\n",
      "✅ Saved unweighted and weighted PS plots for SUBCAT_anxiolytica_Benzodiazepine\n",
      "\n",
      "📊 Plotting PS overlap for SUBCAT_hypnotica_Benzodiazepine\n",
      "✅ Saved unweighted and weighted PS plots for SUBCAT_hypnotica_Benzodiazepine\n",
      "\n",
      "📊 Plotting PS overlap for SUBCAT_Amfetaminen\n",
      "✅ Saved unweighted and weighted PS plots for SUBCAT_Amfetaminen\n",
      "\n",
      "📊 Plotting PS overlap for SUBCAT_Paracetamol_mono\n",
      "✅ Saved unweighted and weighted PS plots for SUBCAT_Paracetamol_mono\n",
      "\n",
      "📊 Plotting PS overlap for SUBCAT_Anti_epileptica_stemmingsstabilisatoren\n",
      "✅ Saved unweighted and weighted PS plots for SUBCAT_Anti_epileptica_stemmingsstabilisatoren\n",
      "\n",
      "📊 Plotting PS overlap for SUBCAT_Opioden\n",
      "✅ Saved unweighted and weighted PS plots for SUBCAT_Opioden\n",
      "\n",
      "📊 Plotting PS overlap for SUBCAT_Z_drugs\n",
      "✅ Saved unweighted and weighted PS plots for SUBCAT_Z_drugs\n",
      "\n",
      "📊 Plotting PS overlap for SUBCAT_NSAIDs\n",
      "✅ Saved unweighted and weighted PS plots for SUBCAT_NSAIDs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_ps_overlap_all_groups(medication_groups):\n",
    "    for group in medication_groups:\n",
    "        print(f\"\\n📊 Plotting PS overlap for {group}\")\n",
    "\n",
    "        folder = os.path.join(\"outputs\", group)\n",
    "        ps_file = os.path.join(folder, \"propensity_scores.xlsx\")\n",
    "        iptw_file = os.path.join(folder, \"iptw_weights.xlsx\")\n",
    "        trimmed_file = os.path.join(folder, \"trimmed_data_imp1.pkl\")\n",
    "\n",
    "        if not all(os.path.exists(f) for f in [ps_file, iptw_file, trimmed_file]):\n",
    "            print(f\"⚠️ Missing required files for {group}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            ps_df = pd.read_excel(ps_file, index_col=0)\n",
    "            iptw_df = pd.read_excel(iptw_file, index_col=0)\n",
    "            trimmed_df = pd.read_pickle(trimmed_file)\n",
    "\n",
    "            # Extract\n",
    "            ps = ps_df[\"composite_ps\"].reindex(trimmed_df.index)\n",
    "            w = iptw_df[\"iptw_mean\"].reindex(trimmed_df.index)\n",
    "            T = trimmed_df[group]\n",
    "\n",
    "            # Masks to remove NaNs\n",
    "            treated_mask = (T == 1) & ps.notna() & w.notna()\n",
    "            control_mask = (T == 0) & ps.notna() & w.notna()\n",
    "\n",
    "            treated = ps[treated_mask]\n",
    "            treated_w = w[treated_mask]\n",
    "\n",
    "            control = ps[control_mask]\n",
    "            control_w = w[control_mask]\n",
    "\n",
    "            # === Unweighted Plot ===\n",
    "            plt.figure(figsize=(8, 5))\n",
    "            plt.hist([treated, control], bins=25, label=[\"Treated\", \"Control\"], alpha=0.6)\n",
    "            plt.title(f\"Unweighted PS Overlap - {group}\")\n",
    "            plt.xlabel(\"Composite Propensity Score\")\n",
    "            plt.ylabel(\"Count\")\n",
    "            plt.legend()\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(folder, \"ps_overlap_unweighted.png\"))\n",
    "            plt.close()\n",
    "\n",
    "            # === Weighted Plot ===\n",
    "            plt.figure(figsize=(8, 5))\n",
    "            plt.hist([treated, control], bins=25, weights=[treated_w, control_w], label=[\"Treated\", \"Control\"], alpha=0.6)\n",
    "            plt.title(f\"Weighted PS Overlap - {group}\")\n",
    "            plt.xlabel(\"Composite Propensity Score\")\n",
    "            plt.ylabel(\"Weighted Count\")\n",
    "            plt.legend()\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(folder, \"ps_overlap_weighted.png\"))\n",
    "            plt.close()\n",
    "\n",
    "            print(f\"✅ Saved unweighted and weighted PS plots for {group}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error processing {group}: {e}\")\n",
    "\n",
    "# 🔁 Run\n",
    "plot_ps_overlap_all_groups(medication_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "08914d6c-189b-423c-8f41-c47cdac5c0cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ✅ Saved: outputs\\SUBCAT_Antipsychotica_atypisch\\four_panel_overlap_SUBCAT_Antipsychotica_atypisch.png\n",
      " ✅ Saved: outputs\\SUBCAT_TCA\\four_panel_overlap_SUBCAT_TCA.png\n",
      " ✅ Saved: outputs\\SUBCAT_SSRI\\four_panel_overlap_SUBCAT_SSRI.png\n",
      " ✅ Saved: outputs\\SUBCAT_SNRI\\four_panel_overlap_SUBCAT_SNRI.png\n",
      " ✅ Saved: outputs\\SUBCAT_Tetracyclische_antidepressiva\\four_panel_overlap_SUBCAT_Tetracyclische_antidepressiva.png\n",
      " ✅ Saved: outputs\\SUBCAT_Antidepressiva_overige\\four_panel_overlap_SUBCAT_Antidepressiva_overige.png\n",
      " ✅ Saved: outputs\\SUBCAT_Systemische_antihistaminica\\four_panel_overlap_SUBCAT_Systemische_antihistaminica.png\n",
      " ✅ Saved: outputs\\SUBCAT_anxiolytica_Benzodiazepine\\four_panel_overlap_SUBCAT_anxiolytica_Benzodiazepine.png\n",
      " ✅ Saved: outputs\\SUBCAT_hypnotica_Benzodiazepine\\four_panel_overlap_SUBCAT_hypnotica_Benzodiazepine.png\n",
      " ✅ Saved: outputs\\SUBCAT_Amfetaminen\\four_panel_overlap_SUBCAT_Amfetaminen.png\n",
      " ✅ Saved: outputs\\SUBCAT_Paracetamol_mono\\four_panel_overlap_SUBCAT_Paracetamol_mono.png\n",
      " ✅ Saved: outputs\\SUBCAT_Anti_epileptica_stemmingsstabilisatoren\\four_panel_overlap_SUBCAT_Anti_epileptica_stemmingsstabilisatoren.png\n",
      " ✅ Saved: outputs\\SUBCAT_Opioden\\four_panel_overlap_SUBCAT_Opioden.png\n",
      " ✅ Saved: outputs\\SUBCAT_Z_drugs\\four_panel_overlap_SUBCAT_Z_drugs.png\n",
      " ✅ Saved: outputs\\SUBCAT_NSAIDs\\four_panel_overlap_SUBCAT_NSAIDs.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set up base output folder\n",
    "output_base = \"outputs\"\n",
    "ps_file = \"propensity_scores.xlsx\"\n",
    "iptw_file = \"iptw_weights.xlsx\"\n",
    "trimmed_data_file = \"trimmed_data_imp1.pkl\"\n",
    "\n",
    "# Collect all treatment group folders\n",
    "groups = [g for g in medication_groups if os.path.isdir(os.path.join(output_base, g))]\n",
    "\n",
    "\n",
    "# Generate 4-panel overlap plots\n",
    "for group in groups:\n",
    "    group_path = os.path.join(output_base, group)\n",
    "    try:\n",
    "        # Load trimmed treatment info\n",
    "        trimmed_df = pd.read_pickle(os.path.join(group_path, trimmed_data_file))\n",
    "        index = trimmed_df.index\n",
    "\n",
    "        # Fix: case-insensitive match for treatment variable\n",
    "        possible_cols = [col for col in trimmed_df.columns if col.upper() == group.upper()]\n",
    "        if not possible_cols:\n",
    "            print(f\" Treatment variable {group} not found in {group}, skipping.\")\n",
    "            continue\n",
    "        treatment_var = possible_cols[0]\n",
    "        T = trimmed_df[treatment_var]\n",
    "\n",
    "        # Load composite PS (aligned to trimmed_df index)\n",
    "        ps_df = pd.read_excel(os.path.join(group_path, ps_file), index_col=0)\n",
    "        if 'composite_ps' not in ps_df.columns:\n",
    "            print(f\" Composite column missing in {ps_file}, skipping {group}.\")\n",
    "            continue\n",
    "        ps = ps_df.loc[index, 'composite_ps']\n",
    "\n",
    "        # Load IPTW weights (aligned to trimmed_df index)\n",
    "        weights_df = pd.read_excel(os.path.join(group_path, iptw_file), index_col=0)\n",
    "        if 'iptw_mean' not in weights_df.columns:\n",
    "            print(f\" IPTW weight column missing in {iptw_file}, skipping {group}.\")\n",
    "            continue\n",
    "        weights = weights_df.loc[index, 'iptw_mean']\n",
    "\n",
    "        # Prepare 4 datasets\n",
    "        raw_treated = ps[T == 1]\n",
    "        raw_control = ps[T == 0]\n",
    "        weighted_treated = (ps[T == 1], weights[T == 1])\n",
    "        weighted_control = (ps[T == 0], weights[T == 0])\n",
    "\n",
    "        # Create plot\n",
    "        fig, axs = plt.subplots(2, 2, figsize=(12, 8))\n",
    "        fig.suptitle(f\"Propensity Score Distribution - {group}\", fontsize=14)\n",
    "\n",
    "        axs[0, 0].hist(raw_treated, bins=20, alpha=0.7, color='blue')\n",
    "        axs[0, 0].set_title(\"Raw Treated\")\n",
    "\n",
    "        axs[0, 1].hist(raw_control, bins=20, alpha=0.7, color='green')\n",
    "        axs[0, 1].set_title(\"Raw Control\")\n",
    "\n",
    "        axs[1, 0].hist(weighted_treated[0], bins=20, weights=weighted_treated[1], alpha=0.7, color='blue')\n",
    "        axs[1, 0].set_title(\"Weighted Treated\")\n",
    "\n",
    "        axs[1, 1].hist(weighted_control[0], bins=20, weights=weighted_control[1], alpha=0.7, color='green')\n",
    "        axs[1, 1].set_title(\"Weighted Control\")\n",
    "\n",
    "        for ax in axs.flat:\n",
    "            ax.set_xlim(0, 1)\n",
    "            ax.set_xlabel(\"Propensity Score\")\n",
    "            ax.set_ylabel(\"Count\")\n",
    "\n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "\n",
    "        # Save figure\n",
    "        plot_path = os.path.join(group_path, f\"four_panel_overlap_{group}.png\")\n",
    "        plt.savefig(plot_path)\n",
    "        plt.close()\n",
    "        print(f\" ✅ Saved: {plot_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\" ❌ Error in {group}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c052e9d8-ca61-4770-893d-15ed4c07b221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ATT calculation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fb6aafea-bc26-4052-979e-60c7518866f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weighted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "378a97b3-6606-48f7-b72e-8b3612b25dfb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Running DML for SUBCAT_Antipsychotica_atypisch\n",
      "✅ SUBCAT_Antipsychotica_atypisch | Seed 1: ATT = -5.1498, SE = 28.2389, p = 0.85567\n",
      "✅ SUBCAT_Antipsychotica_atypisch | Seed 2: ATT = -6.5718, SE = 21.0024, p = 0.75501\n",
      "✅ SUBCAT_Antipsychotica_atypisch | Seed 3: ATT = -1.6032, SE = 20.7904, p = 0.93869\n",
      "⚠️ Error in SUBCAT_Antipsychotica_atypisch, seed 4, imp 4, rep 1: Provided crossfit folds contain training splits that don't contain all treatments\n",
      "✅ SUBCAT_Antipsychotica_atypisch | Seed 4: ATT = -0.7934, SE = 25.9293, p = 0.97565\n",
      "✅ SUBCAT_Antipsychotica_atypisch | Seed 5: ATT = -2.8155, SE = 25.7896, p = 0.91329\n",
      "✅ SUBCAT_Antipsychotica_atypisch | Seed 6: ATT = -6.9556, SE = 20.4718, p = 0.73475\n",
      "✅ SUBCAT_Antipsychotica_atypisch | Seed 7: ATT = -0.9481, SE = 21.1366, p = 0.96431\n",
      "✅ SUBCAT_Antipsychotica_atypisch | Seed 8: ATT = -5.9887, SE = 27.0640, p = 0.82533\n",
      "✅ SUBCAT_Antipsychotica_atypisch | Seed 9: ATT = -2.5909, SE = 23.9344, p = 0.91402\n",
      "✅ SUBCAT_Antipsychotica_atypisch | Seed 10: ATT = -3.4696, SE = 20.8469, p = 0.86816\n",
      "📊 Diagnostic plots saved for SUBCAT_Antipsychotica_atypisch\n",
      "🏆 Best result for SUBCAT_Antipsychotica_atypisch → Seed 6 | SE = 20.4718\n",
      "\n",
      "🚀 Running DML for SUBCAT_TCA\n",
      "✅ SUBCAT_TCA | Seed 1: ATT = 4.4039, SE = 2.7725, p = 0.11538\n",
      "✅ SUBCAT_TCA | Seed 2: ATT = 4.8658, SE = 2.6190, p = 0.06616\n",
      "✅ SUBCAT_TCA | Seed 3: ATT = 4.1655, SE = 2.5574, p = 0.10653\n",
      "✅ SUBCAT_TCA | Seed 4: ATT = 4.1878, SE = 2.5871, p = 0.10869\n",
      "✅ SUBCAT_TCA | Seed 5: ATT = 4.2668, SE = 2.8392, p = 0.13607\n",
      "✅ SUBCAT_TCA | Seed 6: ATT = 4.3825, SE = 2.6911, p = 0.10660\n",
      "✅ SUBCAT_TCA | Seed 7: ATT = 4.3466, SE = 2.7126, p = 0.11226\n",
      "✅ SUBCAT_TCA | Seed 8: ATT = 4.1183, SE = 2.3432, p = 0.08192\n",
      "✅ SUBCAT_TCA | Seed 9: ATT = 4.4263, SE = 2.6785, p = 0.10160\n",
      "✅ SUBCAT_TCA | Seed 10: ATT = 4.2316, SE = 2.5425, p = 0.09920\n",
      "📊 Diagnostic plots saved for SUBCAT_TCA\n",
      "🏆 Best result for SUBCAT_TCA → Seed 8 | SE = 2.3432\n",
      "\n",
      "🚀 Running DML for SUBCAT_SSRI\n",
      "✅ SUBCAT_SSRI | Seed 1: ATT = 0.0030, SE = 1.0014, p = 0.99765\n",
      "✅ SUBCAT_SSRI | Seed 2: ATT = -0.0533, SE = 0.9291, p = 0.95440\n",
      "✅ SUBCAT_SSRI | Seed 3: ATT = -0.0333, SE = 0.9759, p = 0.97281\n",
      "✅ SUBCAT_SSRI | Seed 4: ATT = 0.0837, SE = 1.0668, p = 0.93759\n",
      "✅ SUBCAT_SSRI | Seed 5: ATT = 0.0451, SE = 1.0118, p = 0.96451\n",
      "✅ SUBCAT_SSRI | Seed 6: ATT = 0.0113, SE = 1.0794, p = 0.99167\n",
      "✅ SUBCAT_SSRI | Seed 7: ATT = 0.0766, SE = 0.9642, p = 0.93685\n",
      "✅ SUBCAT_SSRI | Seed 8: ATT = -0.0804, SE = 1.1219, p = 0.94299\n",
      "✅ SUBCAT_SSRI | Seed 9: ATT = 0.0299, SE = 0.9919, p = 0.97604\n",
      "✅ SUBCAT_SSRI | Seed 10: ATT = 0.0244, SE = 0.9764, p = 0.98013\n",
      "📊 Diagnostic plots saved for SUBCAT_SSRI\n",
      "🏆 Best result for SUBCAT_SSRI → Seed 2 | SE = 0.9291\n",
      "\n",
      "🚀 Running DML for SUBCAT_SNRI\n",
      "✅ SUBCAT_SNRI | Seed 1: ATT = 2.1416, SE = 2.4346, p = 0.38118\n",
      "✅ SUBCAT_SNRI | Seed 2: ATT = 2.2063, SE = 2.5624, p = 0.39130\n",
      "✅ SUBCAT_SNRI | Seed 3: ATT = 2.3383, SE = 2.5045, p = 0.35275\n",
      "✅ SUBCAT_SNRI | Seed 4: ATT = 2.2573, SE = 2.4624, p = 0.36153\n",
      "✅ SUBCAT_SNRI | Seed 5: ATT = 2.4274, SE = 2.2762, p = 0.28883\n",
      "✅ SUBCAT_SNRI | Seed 6: ATT = 2.1571, SE = 2.3235, p = 0.35547\n",
      "✅ SUBCAT_SNRI | Seed 7: ATT = 2.4042, SE = 2.3494, p = 0.30864\n",
      "✅ SUBCAT_SNRI | Seed 8: ATT = 2.2728, SE = 2.4103, p = 0.34801\n",
      "✅ SUBCAT_SNRI | Seed 9: ATT = 2.2198, SE = 2.3373, p = 0.34455\n",
      "✅ SUBCAT_SNRI | Seed 10: ATT = 2.0483, SE = 2.5894, p = 0.43083\n",
      "📊 Diagnostic plots saved for SUBCAT_SNRI\n",
      "🏆 Best result for SUBCAT_SNRI → Seed 5 | SE = 2.2762\n",
      "\n",
      "🚀 Running DML for SUBCAT_Tetracyclische_antidepressiva\n",
      "✅ SUBCAT_Tetracyclische_antidepressiva | Seed 1: ATT = 8.0458, SE = 2.5311, p = 0.00197\n",
      "✅ SUBCAT_Tetracyclische_antidepressiva | Seed 2: ATT = 7.6498, SE = 2.6390, p = 0.00461\n",
      "✅ SUBCAT_Tetracyclische_antidepressiva | Seed 3: ATT = 7.5835, SE = 2.6577, p = 0.00527\n",
      "✅ SUBCAT_Tetracyclische_antidepressiva | Seed 4: ATT = 7.5832, SE = 2.5444, p = 0.00362\n",
      "✅ SUBCAT_Tetracyclische_antidepressiva | Seed 5: ATT = 7.7894, SE = 2.3083, p = 0.00106\n",
      "✅ SUBCAT_Tetracyclische_antidepressiva | Seed 6: ATT = 7.7070, SE = 2.5864, p = 0.00363\n",
      "✅ SUBCAT_Tetracyclische_antidepressiva | Seed 7: ATT = 7.8261, SE = 2.3351, p = 0.00114\n",
      "✅ SUBCAT_Tetracyclische_antidepressiva | Seed 8: ATT = 7.8230, SE = 2.3800, p = 0.00140\n",
      "✅ SUBCAT_Tetracyclische_antidepressiva | Seed 9: ATT = 7.9141, SE = 2.1888, p = 0.00047\n",
      "✅ SUBCAT_Tetracyclische_antidepressiva | Seed 10: ATT = 7.7042, SE = 2.5539, p = 0.00325\n",
      "📊 Diagnostic plots saved for SUBCAT_Tetracyclische_antidepressiva\n",
      "🏆 Best result for SUBCAT_Tetracyclische_antidepressiva → Seed 9 | SE = 2.1888\n",
      "\n",
      "🚀 Running DML for SUBCAT_Antidepressiva_overige\n",
      "✅ SUBCAT_Antidepressiva_overige | Seed 1: ATT = 4.1073, SE = 3.3445, p = 0.22233\n",
      "✅ SUBCAT_Antidepressiva_overige | Seed 2: ATT = 3.7512, SE = 3.9298, p = 0.34212\n",
      "✅ SUBCAT_Antidepressiva_overige | Seed 3: ATT = 3.4551, SE = 3.7447, p = 0.35843\n",
      "✅ SUBCAT_Antidepressiva_overige | Seed 4: ATT = 3.4559, SE = 4.0780, p = 0.39880\n",
      "✅ SUBCAT_Antidepressiva_overige | Seed 5: ATT = 3.3261, SE = 4.2700, p = 0.43787\n",
      "✅ SUBCAT_Antidepressiva_overige | Seed 6: ATT = 3.6969, SE = 4.0541, p = 0.36405\n",
      "✅ SUBCAT_Antidepressiva_overige | Seed 7: ATT = 3.2536, SE = 5.7847, p = 0.57508\n",
      "✅ SUBCAT_Antidepressiva_overige | Seed 8: ATT = 4.0226, SE = 4.8699, p = 0.41079\n",
      "✅ SUBCAT_Antidepressiva_overige | Seed 9: ATT = 3.8293, SE = 3.8166, p = 0.31814\n",
      "✅ SUBCAT_Antidepressiva_overige | Seed 10: ATT = 3.5321, SE = 4.0111, p = 0.38067\n",
      "📊 Diagnostic plots saved for SUBCAT_Antidepressiva_overige\n",
      "🏆 Best result for SUBCAT_Antidepressiva_overige → Seed 1 | SE = 3.3445\n",
      "\n",
      "🚀 Running DML for SUBCAT_Systemische_antihistaminica\n",
      "✅ SUBCAT_Systemische_antihistaminica | Seed 1: ATT = -0.0232, SE = 2.9635, p = 0.99377\n",
      "✅ SUBCAT_Systemische_antihistaminica | Seed 2: ATT = 0.1005, SE = 3.0806, p = 0.97404\n",
      "✅ SUBCAT_Systemische_antihistaminica | Seed 3: ATT = 0.0452, SE = 2.7279, p = 0.98682\n",
      "✅ SUBCAT_Systemische_antihistaminica | Seed 4: ATT = 0.0427, SE = 2.8307, p = 0.98799\n",
      "✅ SUBCAT_Systemische_antihistaminica | Seed 5: ATT = 0.0576, SE = 2.5805, p = 0.98223\n",
      "✅ SUBCAT_Systemische_antihistaminica | Seed 6: ATT = 0.1662, SE = 2.9886, p = 0.95577\n",
      "✅ SUBCAT_Systemische_antihistaminica | Seed 7: ATT = 0.6297, SE = 3.1487, p = 0.84190\n",
      "✅ SUBCAT_Systemische_antihistaminica | Seed 8: ATT = 0.1598, SE = 3.1290, p = 0.95937\n",
      "✅ SUBCAT_Systemische_antihistaminica | Seed 9: ATT = 0.2930, SE = 3.0993, p = 0.92487\n",
      "✅ SUBCAT_Systemische_antihistaminica | Seed 10: ATT = -0.1780, SE = 2.9258, p = 0.95161\n",
      "📊 Diagnostic plots saved for SUBCAT_Systemische_antihistaminica\n",
      "🏆 Best result for SUBCAT_Systemische_antihistaminica → Seed 5 | SE = 2.5805\n",
      "\n",
      "🚀 Running DML for SUBCAT_anxiolytica_Benzodiazepine\n",
      "✅ SUBCAT_anxiolytica_Benzodiazepine | Seed 1: ATT = 0.8948, SE = 1.0559, p = 0.39880\n",
      "✅ SUBCAT_anxiolytica_Benzodiazepine | Seed 2: ATT = 0.9013, SE = 1.0266, p = 0.38208\n",
      "✅ SUBCAT_anxiolytica_Benzodiazepine | Seed 3: ATT = 0.9068, SE = 1.1156, p = 0.41826\n",
      "✅ SUBCAT_anxiolytica_Benzodiazepine | Seed 4: ATT = 0.9618, SE = 1.0336, p = 0.35434\n",
      "✅ SUBCAT_anxiolytica_Benzodiazepine | Seed 5: ATT = 0.9488, SE = 1.1172, p = 0.39779\n",
      "✅ SUBCAT_anxiolytica_Benzodiazepine | Seed 6: ATT = 1.0315, SE = 1.1161, p = 0.35765\n",
      "✅ SUBCAT_anxiolytica_Benzodiazepine | Seed 7: ATT = 0.9052, SE = 1.0940, p = 0.40997\n",
      "✅ SUBCAT_anxiolytica_Benzodiazepine | Seed 8: ATT = 0.9488, SE = 1.0438, p = 0.36554\n",
      "✅ SUBCAT_anxiolytica_Benzodiazepine | Seed 9: ATT = 0.9411, SE = 1.0341, p = 0.36501\n",
      "✅ SUBCAT_anxiolytica_Benzodiazepine | Seed 10: ATT = 0.9013, SE = 1.1488, p = 0.43462\n",
      "📊 Diagnostic plots saved for SUBCAT_anxiolytica_Benzodiazepine\n",
      "🏆 Best result for SUBCAT_anxiolytica_Benzodiazepine → Seed 2 | SE = 1.0266\n",
      "\n",
      "🚀 Running DML for SUBCAT_hypnotica_Benzodiazepine\n",
      "✅ SUBCAT_hypnotica_Benzodiazepine | Seed 1: ATT = -0.8876, SE = 2.3188, p = 0.70268\n",
      "✅ SUBCAT_hypnotica_Benzodiazepine | Seed 2: ATT = -0.9398, SE = 2.3162, p = 0.68580\n",
      "✅ SUBCAT_hypnotica_Benzodiazepine | Seed 3: ATT = -0.8547, SE = 2.1950, p = 0.69783\n",
      "✅ SUBCAT_hypnotica_Benzodiazepine | Seed 4: ATT = -0.9029, SE = 2.1561, p = 0.67630\n",
      "✅ SUBCAT_hypnotica_Benzodiazepine | Seed 5: ATT = -0.7930, SE = 2.2089, p = 0.72037\n",
      "✅ SUBCAT_hypnotica_Benzodiazepine | Seed 6: ATT = -0.9124, SE = 2.3028, p = 0.69282\n",
      "✅ SUBCAT_hypnotica_Benzodiazepine | Seed 7: ATT = -1.1329, SE = 2.0571, p = 0.58308\n",
      "✅ SUBCAT_hypnotica_Benzodiazepine | Seed 8: ATT = -0.8858, SE = 2.1821, p = 0.68567\n",
      "✅ SUBCAT_hypnotica_Benzodiazepine | Seed 9: ATT = -0.8958, SE = 2.2028, p = 0.68513\n",
      "✅ SUBCAT_hypnotica_Benzodiazepine | Seed 10: ATT = -0.9823, SE = 2.2110, p = 0.65780\n",
      "📊 Diagnostic plots saved for SUBCAT_hypnotica_Benzodiazepine\n",
      "🏆 Best result for SUBCAT_hypnotica_Benzodiazepine → Seed 7 | SE = 2.0571\n",
      "\n",
      "🚀 Running DML for SUBCAT_Amfetaminen\n",
      "✅ SUBCAT_Amfetaminen | Seed 1: ATT = 2.8911, SE = 3.2881, p = 0.38139\n",
      "✅ SUBCAT_Amfetaminen | Seed 2: ATT = 2.7887, SE = 2.9649, p = 0.34921\n",
      "✅ SUBCAT_Amfetaminen | Seed 3: ATT = 3.0738, SE = 3.1603, p = 0.33310\n",
      "✅ SUBCAT_Amfetaminen | Seed 4: ATT = 3.0650, SE = 3.0985, p = 0.32498\n",
      "✅ SUBCAT_Amfetaminen | Seed 5: ATT = 2.8903, SE = 3.4658, p = 0.40630\n",
      "✅ SUBCAT_Amfetaminen | Seed 6: ATT = 3.2659, SE = 3.5195, p = 0.35569\n",
      "✅ SUBCAT_Amfetaminen | Seed 7: ATT = 2.8207, SE = 3.2111, p = 0.38185\n",
      "✅ SUBCAT_Amfetaminen | Seed 8: ATT = 2.8113, SE = 3.3831, p = 0.40798\n",
      "✅ SUBCAT_Amfetaminen | Seed 9: ATT = 2.9437, SE = 3.6059, p = 0.41627\n",
      "✅ SUBCAT_Amfetaminen | Seed 10: ATT = 2.7787, SE = 3.2504, p = 0.39469\n",
      "📊 Diagnostic plots saved for SUBCAT_Amfetaminen\n",
      "🏆 Best result for SUBCAT_Amfetaminen → Seed 2 | SE = 2.9649\n",
      "\n",
      "🚀 Running DML for SUBCAT_Paracetamol_mono\n",
      "✅ SUBCAT_Paracetamol_mono | Seed 1: ATT = 2.4099, SE = 4.4288, p = 0.58757\n",
      "✅ SUBCAT_Paracetamol_mono | Seed 2: ATT = 2.3358, SE = 5.1319, p = 0.64999\n",
      "✅ SUBCAT_Paracetamol_mono | Seed 3: ATT = 2.6478, SE = 5.6137, p = 0.63820\n",
      "✅ SUBCAT_Paracetamol_mono | Seed 4: ATT = 2.1962, SE = 5.1595, p = 0.67129\n",
      "✅ SUBCAT_Paracetamol_mono | Seed 5: ATT = 2.6045, SE = 4.1405, p = 0.53078\n",
      "✅ SUBCAT_Paracetamol_mono | Seed 6: ATT = 2.2797, SE = 4.5391, p = 0.61661\n",
      "✅ SUBCAT_Paracetamol_mono | Seed 7: ATT = 3.6467, SE = 11.4939, p = 0.75170\n",
      "✅ SUBCAT_Paracetamol_mono | Seed 8: ATT = 2.1486, SE = 5.7442, p = 0.70917\n",
      "✅ SUBCAT_Paracetamol_mono | Seed 9: ATT = 2.1795, SE = 5.1523, p = 0.67320\n",
      "✅ SUBCAT_Paracetamol_mono | Seed 10: ATT = 2.3577, SE = 5.2390, p = 0.65367\n",
      "📊 Diagnostic plots saved for SUBCAT_Paracetamol_mono\n",
      "🏆 Best result for SUBCAT_Paracetamol_mono → Seed 5 | SE = 4.1405\n",
      "\n",
      "🚀 Running DML for SUBCAT_Anti_epileptica_stemmingsstabilisatoren\n",
      "✅ SUBCAT_Anti_epileptica_stemmingsstabilisatoren | Seed 1: ATT = 5.7899, SE = 3.7992, p = 0.13071\n",
      "✅ SUBCAT_Anti_epileptica_stemmingsstabilisatoren | Seed 2: ATT = 5.4897, SE = 3.8789, p = 0.16013\n",
      "✅ SUBCAT_Anti_epileptica_stemmingsstabilisatoren | Seed 3: ATT = 5.5909, SE = 4.2529, p = 0.19167\n",
      "✅ SUBCAT_Anti_epileptica_stemmingsstabilisatoren | Seed 4: ATT = 6.0850, SE = 4.2538, p = 0.15573\n",
      "✅ SUBCAT_Anti_epileptica_stemmingsstabilisatoren | Seed 5: ATT = 5.8834, SE = 3.7916, p = 0.12392\n",
      "✅ SUBCAT_Anti_epileptica_stemmingsstabilisatoren | Seed 6: ATT = 5.4646, SE = 4.0451, p = 0.17980\n",
      "✅ SUBCAT_Anti_epileptica_stemmingsstabilisatoren | Seed 7: ATT = 5.2603, SE = 3.7998, p = 0.16936\n",
      "✅ SUBCAT_Anti_epileptica_stemmingsstabilisatoren | Seed 8: ATT = 5.3987, SE = 4.0146, p = 0.18177\n",
      "✅ SUBCAT_Anti_epileptica_stemmingsstabilisatoren | Seed 9: ATT = 5.6336, SE = 3.5890, p = 0.11968\n",
      "✅ SUBCAT_Anti_epileptica_stemmingsstabilisatoren | Seed 10: ATT = 5.3065, SE = 3.9319, p = 0.18023\n",
      "📊 Diagnostic plots saved for SUBCAT_Anti_epileptica_stemmingsstabilisatoren\n",
      "🏆 Best result for SUBCAT_Anti_epileptica_stemmingsstabilisatoren → Seed 9 | SE = 3.5890\n",
      "\n",
      "🚀 Running DML for SUBCAT_Opioden\n",
      "✅ SUBCAT_Opioden | Seed 1: ATT = 2.8341, SE = 3.6689, p = 0.44168\n",
      "✅ SUBCAT_Opioden | Seed 2: ATT = 2.8541, SE = 4.8000, p = 0.55347\n",
      "✅ SUBCAT_Opioden | Seed 3: ATT = 2.6857, SE = 3.2678, p = 0.41313\n",
      "✅ SUBCAT_Opioden | Seed 4: ATT = 2.9107, SE = 3.3508, p = 0.38714\n",
      "✅ SUBCAT_Opioden | Seed 5: ATT = 2.7305, SE = 3.6078, p = 0.45096\n",
      "✅ SUBCAT_Opioden | Seed 6: ATT = 2.8173, SE = 3.3080, p = 0.39645\n",
      "✅ SUBCAT_Opioden | Seed 7: ATT = 2.4828, SE = 3.3214, p = 0.45653\n",
      "✅ SUBCAT_Opioden | Seed 8: ATT = 2.7032, SE = 3.5791, p = 0.45188\n",
      "✅ SUBCAT_Opioden | Seed 9: ATT = 2.6240, SE = 3.2418, p = 0.42021\n",
      "✅ SUBCAT_Opioden | Seed 10: ATT = 2.6295, SE = 3.3356, p = 0.43239\n",
      "📊 Diagnostic plots saved for SUBCAT_Opioden\n",
      "🏆 Best result for SUBCAT_Opioden → Seed 9 | SE = 3.2418\n",
      "\n",
      "🚀 Running DML for SUBCAT_Z_drugs\n",
      "✅ SUBCAT_Z_drugs | Seed 1: ATT = 6.9286, SE = 3.1513, p = 0.03023\n",
      "✅ SUBCAT_Z_drugs | Seed 2: ATT = 7.2073, SE = 3.4349, p = 0.03843\n",
      "✅ SUBCAT_Z_drugs | Seed 3: ATT = 7.0873, SE = 3.3264, p = 0.03560\n",
      "✅ SUBCAT_Z_drugs | Seed 4: ATT = 6.9114, SE = 3.3611, p = 0.04238\n",
      "✅ SUBCAT_Z_drugs | Seed 5: ATT = 7.3823, SE = 3.0447, p = 0.01714\n",
      "✅ SUBCAT_Z_drugs | Seed 6: ATT = 6.9468, SE = 3.0047, p = 0.02285\n",
      "✅ SUBCAT_Z_drugs | Seed 7: ATT = 6.9232, SE = 3.3494, p = 0.04135\n",
      "✅ SUBCAT_Z_drugs | Seed 8: ATT = 6.7629, SE = 3.2375, p = 0.03928\n",
      "✅ SUBCAT_Z_drugs | Seed 9: ATT = 7.0054, SE = 2.8950, p = 0.01735\n",
      "✅ SUBCAT_Z_drugs | Seed 10: ATT = 6.7507, SE = 3.0462, p = 0.02897\n",
      "📊 Diagnostic plots saved for SUBCAT_Z_drugs\n",
      "🏆 Best result for SUBCAT_Z_drugs → Seed 9 | SE = 2.8950\n",
      "\n",
      "🚀 Running DML for SUBCAT_NSAIDs\n",
      "✅ SUBCAT_NSAIDs | Seed 1: ATT = -0.2015, SE = 4.0578, p = 0.96050\n",
      "✅ SUBCAT_NSAIDs | Seed 2: ATT = 0.2090, SE = 4.7751, p = 0.96518\n",
      "✅ SUBCAT_NSAIDs | Seed 3: ATT = -0.1254, SE = 4.9956, p = 0.98002\n",
      "✅ SUBCAT_NSAIDs | Seed 4: ATT = -0.1347, SE = 4.1402, p = 0.97412\n",
      "✅ SUBCAT_NSAIDs | Seed 5: ATT = 0.1150, SE = 4.0893, p = 0.97763\n",
      "✅ SUBCAT_NSAIDs | Seed 6: ATT = 0.1477, SE = 4.6692, p = 0.97483\n",
      "✅ SUBCAT_NSAIDs | Seed 7: ATT = 0.4890, SE = 4.6321, p = 0.91613\n",
      "✅ SUBCAT_NSAIDs | Seed 8: ATT = -0.4631, SE = 4.5971, p = 0.91997\n",
      "✅ SUBCAT_NSAIDs | Seed 9: ATT = 0.2550, SE = 4.7780, p = 0.95754\n",
      "✅ SUBCAT_NSAIDs | Seed 10: ATT = 0.1100, SE = 4.2210, p = 0.97927\n",
      "📊 Diagnostic plots saved for SUBCAT_NSAIDs\n",
      "🏆 Best result for SUBCAT_NSAIDs → Seed 1 | SE = 4.0578\n",
      "\n",
      "🎯 All summary files saved.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "from econml.dml import LinearDML\n",
    "from scipy.stats import t, probplot\n",
    "import xgboost as xgb\n",
    "\n",
    "# -----------------------------\n",
    "# Configuration\n",
    "# -----------------------------\n",
    "n_repeats = 4\n",
    "seeds = list(range(1, 11))\n",
    "imputations = 5\n",
    "output_folder = \"outputs\"\n",
    "\n",
    "# -----------------------------\n",
    "# Diagnostic Plotting Function\n",
    "# -----------------------------\n",
    "def create_diagnostic_plots(residuals_data, fitted_data, group_name):\n",
    "    \"\"\"Create 4 diagnostic plots for model validation\"\"\"\n",
    "    plots_dir = os.path.join(output_folder, \"plots\")\n",
    "    os.makedirs(plots_dir, exist_ok=True)\n",
    "    \n",
    "    # Flatten the collected data\n",
    "    all_residuals = np.concatenate(residuals_data)\n",
    "    all_fitted = np.concatenate(fitted_data)\n",
    "    \n",
    "    # Create figure with 2x2 subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    fig.suptitle(f'Diagnostic Plots - {group_name}', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. Residuals vs Fitted\n",
    "    axes[0,0].scatter(all_fitted, all_residuals, alpha=0.6, s=20)\n",
    "    axes[0,0].axhline(y=0, color='red', linestyle='--', alpha=0.8)\n",
    "    axes[0,0].set_xlabel('Fitted Values')\n",
    "    axes[0,0].set_ylabel('Residuals')\n",
    "    axes[0,0].set_title('Residuals vs Fitted')\n",
    "    axes[0,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. QQ Plot\n",
    "    probplot(all_residuals, dist=\"norm\", plot=axes[0,1])\n",
    "    axes[0,1].set_title('Q-Q Plot (Normal)')\n",
    "    axes[0,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Residual Histogram\n",
    "    axes[1,0].hist(all_residuals, bins=30, density=True, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    axes[1,0].set_xlabel('Residuals')\n",
    "    axes[1,0].set_ylabel('Density')\n",
    "    axes[1,0].set_title('Residual Distribution')\n",
    "    axes[1,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Scale-Location Plot\n",
    "    sqrt_abs_residuals = np.sqrt(np.abs(all_residuals))\n",
    "    axes[1,1].scatter(all_fitted, sqrt_abs_residuals, alpha=0.6, s=20)\n",
    "    axes[1,1].set_xlabel('Fitted Values')\n",
    "    axes[1,1].set_ylabel('√|Residuals|')\n",
    "    axes[1,1].set_title('Scale-Location Plot')\n",
    "    axes[1,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save plot\n",
    "    plot_filename = os.path.join(plots_dir, f'{group_name}.png')\n",
    "    plt.savefig(plot_filename, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"📊 Diagnostic plots saved for {group_name}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Rubin's Rule\n",
    "# -----------------------------\n",
    "def rubins_pool(estimates, ses):\n",
    "    m = len(estimates)\n",
    "    q_bar = np.mean(estimates)\n",
    "    u_bar = np.mean(np.square(ses))\n",
    "    b_m = np.var(estimates, ddof=1)\n",
    "    total_var = u_bar + ((1 + 1/m) * b_m)\n",
    "    total_se = np.sqrt(total_var)\n",
    "    ci_lower = q_bar - 1.96 * total_se\n",
    "    ci_upper = q_bar + 1.96 * total_se\n",
    "    p_value = 2 * (1 - t.cdf(np.abs(q_bar / total_se), df=m-1))\n",
    "    rounded_p = round(p_value, 5)\n",
    "    formatted_p = \"< 0.00001\" if rounded_p <= 0.00001 else f\"{rounded_p:.5f}\"\n",
    "    return q_bar, total_se, ci_lower, ci_upper, formatted_p\n",
    "\n",
    "# -----------------------------\n",
    "# SMD + Variance Ratio\n",
    "# -----------------------------\n",
    "def calculate_smd_vr(X, T, weights):\n",
    "    treated = X[T == 1]\n",
    "    control = X[T == 0]\n",
    "    w_treated = weights[T == 1]\n",
    "    w_control = weights[T == 0]\n",
    "    smd, vr = [], []\n",
    "    for col in X.columns:\n",
    "        try:\n",
    "            m1, m0 = np.average(treated[col], weights=w_treated), np.average(control[col], weights=w_control)\n",
    "            s1 = np.sqrt(np.average((treated[col] - m1) ** 2, weights=w_treated))\n",
    "            s0 = np.sqrt(np.average((control[col] - m0) ** 2, weights=w_control))\n",
    "            pooled_sd = np.sqrt((s1 ** 2 + s0 ** 2) / 2)\n",
    "            smd.append((m1 - m0) / pooled_sd if pooled_sd > 0 else 0)\n",
    "            vr.append(s1**2 / s0**2 if s0**2 > 0 else 0)\n",
    "        except Exception:\n",
    "            smd.append(np.nan)\n",
    "            vr.append(np.nan)\n",
    "    return np.nanmean(smd), np.nanmean(vr)\n",
    "\n",
    "# -----------------------------\n",
    "# DML Main Loop\n",
    "# -----------------------------\n",
    "def run_dml_with_trimmed_data(final_covariates_map):\n",
    "    att_results = []\n",
    "    balance_results = []\n",
    "\n",
    "    for group, covariates in final_covariates_map.items():\n",
    "        print(f\"\\n🚀 Running DML for {group}\")\n",
    "        group_dir = os.path.join(output_folder, group)\n",
    "        os.makedirs(group_dir, exist_ok=True)\n",
    "\n",
    "        best_result = None\n",
    "        best_se = float(\"inf\")\n",
    "        \n",
    "        # Initialize lists to collect residuals and fitted values for diagnostic plots\n",
    "        group_residuals = []\n",
    "        group_fitted = []\n",
    "\n",
    "        for seed in seeds:\n",
    "            att_list, se_list, r2_list, rmse_list, smd_list, vr_list = [], [], [], [], [], []\n",
    "\n",
    "            for imp in range(1, imputations + 1):\n",
    "                file_path = os.path.join(group_dir, f\"trimmed_data_imp{imp}.pkl\")\n",
    "                if not os.path.exists(file_path):\n",
    "                    continue\n",
    "\n",
    "                df = pd.read_pickle(file_path)\n",
    "                if group not in df.columns or \"iptw\" not in df.columns:\n",
    "                    continue\n",
    "\n",
    "                X = df[covariates].copy()\n",
    "                T = df[group]\n",
    "                Y = df[\"caps5_change_baseline\"]\n",
    "                W = df[\"iptw\"]\n",
    "\n",
    "                for repeat in range(n_repeats):\n",
    "                    kf = KFold(n_splits=5, shuffle=True, random_state=seed + repeat)\n",
    "                    for train_idx, test_idx in kf.split(X):\n",
    "                        try:\n",
    "                            X_train, T_train, Y_train, W_train = (\n",
    "                                X.iloc[train_idx],\n",
    "                                T.iloc[train_idx],\n",
    "                                Y.iloc[train_idx],\n",
    "                                W.iloc[train_idx],\n",
    "                            )\n",
    "\n",
    "                            model_y = xgb.XGBRegressor(n_estimators=100, max_depth=3, learning_rate=0.1, n_jobs=1, random_state=seed)\n",
    "                            model_t = xgb.XGBClassifier(n_estimators=100, max_depth=3, learning_rate=0.1, n_jobs=1,\n",
    "                                                        use_label_encoder=False, eval_metric=\"logloss\", random_state=seed)\n",
    "\n",
    "                            dml = LinearDML(model_y=model_y, model_t=model_t, discrete_treatment=True,\n",
    "                                            cv=KFold(n_splits=3, shuffle=True, random_state=seed), random_state=seed)\n",
    "                            dml.fit(Y_train, T_train, X=X_train, sample_weight=W_train)\n",
    "\n",
    "                            tau = dml.effect(X_train)\n",
    "                            att = np.mean(tau)\n",
    "                            influence = tau - att\n",
    "                            se = np.sqrt(np.mean(influence ** 2) / len(tau))\n",
    "\n",
    "                            att_list.append(att)\n",
    "                            se_list.append(se)\n",
    "\n",
    "                            Y_pred = model_y.fit(X_train, Y_train, sample_weight=W_train).predict(X_train)\n",
    "                            residuals = Y_train - Y_pred\n",
    "                            rmse = mean_squared_error(Y_train, Y_pred, squared=False)\n",
    "                            r2 = r2_score(Y_train, Y_pred)\n",
    "                            r2_list.append(r2)\n",
    "                            rmse_list.append(rmse)\n",
    "                            \n",
    "                            # Collect residuals and fitted values for diagnostic plots\n",
    "                            group_residuals.append(residuals.values)\n",
    "                            group_fitted.append(Y_pred)\n",
    "\n",
    "                            smd, vr = calculate_smd_vr(X_train, T_train, W_train)\n",
    "                            smd_list.append(smd)\n",
    "                            vr_list.append(vr)\n",
    "                        except Exception as e:\n",
    "                            print(f\"⚠️ Error in {group}, seed {seed}, imp {imp}, rep {repeat}: {e}\")\n",
    "\n",
    "            if att_list:\n",
    "                att, se, ci_l, ci_u, p_val = rubins_pool(att_list, se_list)\n",
    "                avg_r2 = np.mean(r2_list)\n",
    "                avg_rmse = np.mean(rmse_list)\n",
    "                avg_smd = np.mean(smd_list)\n",
    "                avg_vr = np.mean(vr_list)\n",
    "\n",
    "                balance_results.append({\n",
    "                    \"group\": group, \"seed\": seed, \"smd\": avg_smd, \"vr\": avg_vr\n",
    "                })\n",
    "\n",
    "                if se < best_se:\n",
    "                    best_se = se\n",
    "                    best_result = {\n",
    "                        \"group\": group, \"seed\": seed, \"att\": att, \"se\": se,\n",
    "                        \"ci_lower\": ci_l, \"ci_upper\": ci_u, \"p_value\": p_val,\n",
    "                        \"r2\": avg_r2, \"rmse\": avg_rmse\n",
    "                    }\n",
    "\n",
    "                print(f\"✅ {group} | Seed {seed}: ATT = {att:.4f}, SE = {se:.4f}, p = {p_val}\")\n",
    "            else:\n",
    "                print(f\"⚠️ No valid results for {group} | Seed {seed}\")\n",
    "\n",
    "        # Create diagnostic plots for this group\n",
    "        if group_residuals and group_fitted:\n",
    "            create_diagnostic_plots(group_residuals, group_fitted, group)\n",
    "\n",
    "        if best_result:\n",
    "            att_results.append(best_result)\n",
    "            print(f\"🏆 Best result for {group} → Seed {best_result['seed']} | SE = {best_result['se']:.4f}\")\n",
    "\n",
    "    # Save final output\n",
    "    pd.DataFrame(att_results).to_excel(\"dml_rubin_summary_subcats.xlsx\", index=False)\n",
    "    pd.DataFrame(balance_results).to_excel(\"smd_vr_summary_subcats.xlsx\", index=False)\n",
    "    print(\"\\n🎯 All summary files saved.\")\n",
    "\n",
    "run_dml_with_trimmed_data(final_covariates_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5c415b70-f8a1-4cb5-ae0a-de4ff06d2ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unweighted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "994ef029-9b41-45cd-a72f-d2fca16504ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Running DML for SUBCAT_Antipsychotica_atypisch\n",
      "✅ SUBCAT_Antipsychotica_atypisch | Seed 1: ATT = -4.2073, SE = 23.1669, p = 0.85626\n",
      "✅ SUBCAT_Antipsychotica_atypisch | Seed 2: ATT = -6.0681, SE = 19.0543, p = 0.75081\n",
      "✅ SUBCAT_Antipsychotica_atypisch | Seed 3: ATT = -2.4963, SE = 17.3770, p = 0.88607\n",
      "⚠️ Error in SUBCAT_Antipsychotica_atypisch, seed 4, imp 4, rep 1: Provided crossfit folds contain training splits that don't contain all treatments\n",
      "✅ SUBCAT_Antipsychotica_atypisch | Seed 4: ATT = -1.7639, SE = 20.1717, p = 0.93050\n",
      "✅ SUBCAT_Antipsychotica_atypisch | Seed 5: ATT = -4.5334, SE = 20.9473, p = 0.82911\n",
      "✅ SUBCAT_Antipsychotica_atypisch | Seed 6: ATT = -6.2645, SE = 16.2650, p = 0.70095\n",
      "✅ SUBCAT_Antipsychotica_atypisch | Seed 7: ATT = -1.9969, SE = 17.6485, p = 0.91014\n",
      "✅ SUBCAT_Antipsychotica_atypisch | Seed 8: ATT = -7.3821, SE = 19.3397, p = 0.70350\n",
      "✅ SUBCAT_Antipsychotica_atypisch | Seed 9: ATT = -3.8757, SE = 19.1949, p = 0.84040\n",
      "✅ SUBCAT_Antipsychotica_atypisch | Seed 10: ATT = -4.1216, SE = 18.3820, p = 0.82305\n",
      "🏆 Best result for SUBCAT_Antipsychotica_atypisch → Seed 6 | SE = 16.2650\n",
      "📊 Creating diagnostic plots for SUBCAT_Antipsychotica_atypisch...\n",
      "\n",
      "🚀 Running DML for SUBCAT_TCA\n",
      "✅ SUBCAT_TCA | Seed 1: ATT = 2.7047, SE = 2.5395, p = 0.28943\n",
      "✅ SUBCAT_TCA | Seed 2: ATT = 2.9537, SE = 2.3451, p = 0.21080\n",
      "✅ SUBCAT_TCA | Seed 3: ATT = 2.4007, SE = 2.3497, p = 0.30942\n",
      "✅ SUBCAT_TCA | Seed 4: ATT = 2.3664, SE = 2.3632, p = 0.31909\n",
      "✅ SUBCAT_TCA | Seed 5: ATT = 2.5222, SE = 2.4027, p = 0.29639\n",
      "✅ SUBCAT_TCA | Seed 6: ATT = 2.5271, SE = 2.4219, p = 0.29929\n",
      "✅ SUBCAT_TCA | Seed 7: ATT = 2.5017, SE = 2.3376, p = 0.28713\n",
      "✅ SUBCAT_TCA | Seed 8: ATT = 2.2469, SE = 2.1195, p = 0.29169\n",
      "✅ SUBCAT_TCA | Seed 9: ATT = 2.5309, SE = 2.4198, p = 0.29816\n",
      "✅ SUBCAT_TCA | Seed 10: ATT = 2.3350, SE = 2.1161, p = 0.27249\n",
      "🏆 Best result for SUBCAT_TCA → Seed 10 | SE = 2.1161\n",
      "📊 Creating diagnostic plots for SUBCAT_TCA...\n",
      "\n",
      "🚀 Running DML for SUBCAT_SSRI\n",
      "✅ SUBCAT_SSRI | Seed 1: ATT = 0.4663, SE = 0.7324, p = 0.52580\n",
      "✅ SUBCAT_SSRI | Seed 2: ATT = 0.4406, SE = 0.6629, p = 0.50784\n",
      "✅ SUBCAT_SSRI | Seed 3: ATT = 0.4062, SE = 0.7249, p = 0.57646\n",
      "✅ SUBCAT_SSRI | Seed 4: ATT = 0.4484, SE = 0.7302, p = 0.54057\n",
      "✅ SUBCAT_SSRI | Seed 5: ATT = 0.4327, SE = 0.6975, p = 0.53650\n",
      "✅ SUBCAT_SSRI | Seed 6: ATT = 0.3763, SE = 0.7570, p = 0.62026\n",
      "✅ SUBCAT_SSRI | Seed 7: ATT = 0.4404, SE = 0.6393, p = 0.49250\n",
      "✅ SUBCAT_SSRI | Seed 8: ATT = 0.4082, SE = 0.7819, p = 0.60275\n",
      "✅ SUBCAT_SSRI | Seed 9: ATT = 0.4588, SE = 0.7368, p = 0.53487\n",
      "✅ SUBCAT_SSRI | Seed 10: ATT = 0.4340, SE = 0.7230, p = 0.54966\n",
      "🏆 Best result for SUBCAT_SSRI → Seed 7 | SE = 0.6393\n",
      "📊 Creating diagnostic plots for SUBCAT_SSRI...\n",
      "\n",
      "🚀 Running DML for SUBCAT_SNRI\n",
      "✅ SUBCAT_SNRI | Seed 1: ATT = 3.0762, SE = 2.3170, p = 0.18733\n",
      "✅ SUBCAT_SNRI | Seed 2: ATT = 3.0659, SE = 2.4245, p = 0.20901\n",
      "✅ SUBCAT_SNRI | Seed 3: ATT = 3.1785, SE = 2.2706, p = 0.16468\n",
      "✅ SUBCAT_SNRI | Seed 4: ATT = 3.0993, SE = 2.1922, p = 0.16056\n",
      "✅ SUBCAT_SNRI | Seed 5: ATT = 3.2149, SE = 2.2560, p = 0.15730\n",
      "✅ SUBCAT_SNRI | Seed 6: ATT = 3.0076, SE = 2.1294, p = 0.16095\n",
      "✅ SUBCAT_SNRI | Seed 7: ATT = 3.2099, SE = 2.3231, p = 0.17017\n",
      "✅ SUBCAT_SNRI | Seed 8: ATT = 2.9730, SE = 2.2497, p = 0.18937\n",
      "✅ SUBCAT_SNRI | Seed 9: ATT = 2.9305, SE = 2.3061, p = 0.20680\n",
      "✅ SUBCAT_SNRI | Seed 10: ATT = 2.9722, SE = 2.4277, p = 0.22375\n",
      "🏆 Best result for SUBCAT_SNRI → Seed 6 | SE = 2.1294\n",
      "📊 Creating diagnostic plots for SUBCAT_SNRI...\n",
      "\n",
      "🚀 Running DML for SUBCAT_Tetracyclische_antidepressiva\n",
      "✅ SUBCAT_Tetracyclische_antidepressiva | Seed 1: ATT = 7.1850, SE = 2.3099, p = 0.00244\n",
      "✅ SUBCAT_Tetracyclische_antidepressiva | Seed 2: ATT = 7.0037, SE = 2.1859, p = 0.00182\n",
      "✅ SUBCAT_Tetracyclische_antidepressiva | Seed 3: ATT = 6.8369, SE = 2.3242, p = 0.00407\n",
      "✅ SUBCAT_Tetracyclische_antidepressiva | Seed 4: ATT = 6.9288, SE = 2.3668, p = 0.00424\n",
      "✅ SUBCAT_Tetracyclische_antidepressiva | Seed 5: ATT = 7.1314, SE = 2.1009, p = 0.00099\n",
      "✅ SUBCAT_Tetracyclische_antidepressiva | Seed 6: ATT = 6.8981, SE = 2.0555, p = 0.00112\n",
      "✅ SUBCAT_Tetracyclische_antidepressiva | Seed 7: ATT = 7.0828, SE = 2.0735, p = 0.00092\n",
      "✅ SUBCAT_Tetracyclische_antidepressiva | Seed 8: ATT = 7.1483, SE = 1.9948, p = 0.00053\n",
      "✅ SUBCAT_Tetracyclische_antidepressiva | Seed 9: ATT = 7.1713, SE = 1.9691, p = 0.00043\n",
      "✅ SUBCAT_Tetracyclische_antidepressiva | Seed 10: ATT = 7.1036, SE = 2.1248, p = 0.00117\n",
      "🏆 Best result for SUBCAT_Tetracyclische_antidepressiva → Seed 9 | SE = 1.9691\n",
      "📊 Creating diagnostic plots for SUBCAT_Tetracyclische_antidepressiva...\n",
      "\n",
      "🚀 Running DML for SUBCAT_Antidepressiva_overige\n",
      "✅ SUBCAT_Antidepressiva_overige | Seed 1: ATT = 4.9132, SE = 3.2476, p = 0.13350\n",
      "✅ SUBCAT_Antidepressiva_overige | Seed 2: ATT = 4.6955, SE = 3.6977, p = 0.20713\n",
      "✅ SUBCAT_Antidepressiva_overige | Seed 3: ATT = 4.1713, SE = 3.5547, p = 0.24342\n",
      "✅ SUBCAT_Antidepressiva_overige | Seed 4: ATT = 4.2369, SE = 3.6429, p = 0.24760\n",
      "✅ SUBCAT_Antidepressiva_overige | Seed 5: ATT = 4.0172, SE = 4.2073, p = 0.34199\n",
      "✅ SUBCAT_Antidepressiva_overige | Seed 6: ATT = 4.5054, SE = 3.8947, p = 0.25014\n",
      "✅ SUBCAT_Antidepressiva_overige | Seed 7: ATT = 4.1744, SE = 5.0853, p = 0.41368\n",
      "✅ SUBCAT_Antidepressiva_overige | Seed 8: ATT = 4.7389, SE = 3.9618, p = 0.23450\n",
      "✅ SUBCAT_Antidepressiva_overige | Seed 9: ATT = 4.4605, SE = 3.7106, p = 0.23220\n",
      "✅ SUBCAT_Antidepressiva_overige | Seed 10: ATT = 4.2180, SE = 3.8644, p = 0.27771\n",
      "🏆 Best result for SUBCAT_Antidepressiva_overige → Seed 1 | SE = 3.2476\n",
      "📊 Creating diagnostic plots for SUBCAT_Antidepressiva_overige...\n",
      "\n",
      "🚀 Running DML for SUBCAT_Systemische_antihistaminica\n",
      "✅ SUBCAT_Systemische_antihistaminica | Seed 1: ATT = 1.0330, SE = 2.8672, p = 0.71941\n",
      "✅ SUBCAT_Systemische_antihistaminica | Seed 2: ATT = 0.9728, SE = 2.8286, p = 0.73164\n",
      "✅ SUBCAT_Systemische_antihistaminica | Seed 3: ATT = 1.1198, SE = 2.5248, p = 0.65835\n",
      "✅ SUBCAT_Systemische_antihistaminica | Seed 4: ATT = 0.9746, SE = 2.7869, p = 0.72730\n",
      "✅ SUBCAT_Systemische_antihistaminica | Seed 5: ATT = 1.1207, SE = 2.6826, p = 0.67701\n",
      "✅ SUBCAT_Systemische_antihistaminica | Seed 6: ATT = 1.2523, SE = 3.0329, p = 0.68058\n",
      "✅ SUBCAT_Systemische_antihistaminica | Seed 7: ATT = 1.4646, SE = 2.9982, p = 0.62628\n",
      "✅ SUBCAT_Systemische_antihistaminica | Seed 8: ATT = 1.1253, SE = 2.8903, p = 0.69786\n",
      "✅ SUBCAT_Systemische_antihistaminica | Seed 9: ATT = 1.2658, SE = 2.8633, p = 0.65940\n",
      "✅ SUBCAT_Systemische_antihistaminica | Seed 10: ATT = 0.9449, SE = 2.8365, p = 0.73975\n",
      "🏆 Best result for SUBCAT_Systemische_antihistaminica → Seed 3 | SE = 2.5248\n",
      "📊 Creating diagnostic plots for SUBCAT_Systemische_antihistaminica...\n",
      "\n",
      "🚀 Running DML for SUBCAT_anxiolytica_Benzodiazepine\n",
      "✅ SUBCAT_anxiolytica_Benzodiazepine | Seed 1: ATT = 0.9580, SE = 0.7943, p = 0.23066\n",
      "✅ SUBCAT_anxiolytica_Benzodiazepine | Seed 2: ATT = 0.9911, SE = 0.7392, p = 0.18304\n",
      "✅ SUBCAT_anxiolytica_Benzodiazepine | Seed 3: ATT = 0.8900, SE = 0.8124, p = 0.27595\n",
      "✅ SUBCAT_anxiolytica_Benzodiazepine | Seed 4: ATT = 0.9665, SE = 0.8030, p = 0.23161\n",
      "✅ SUBCAT_anxiolytica_Benzodiazepine | Seed 5: ATT = 0.9538, SE = 0.8188, p = 0.24689\n",
      "✅ SUBCAT_anxiolytica_Benzodiazepine | Seed 6: ATT = 1.0141, SE = 0.8728, p = 0.24806\n",
      "✅ SUBCAT_anxiolytica_Benzodiazepine | Seed 7: ATT = 0.9015, SE = 0.7852, p = 0.25368\n",
      "✅ SUBCAT_anxiolytica_Benzodiazepine | Seed 8: ATT = 0.9662, SE = 0.7154, p = 0.17991\n",
      "✅ SUBCAT_anxiolytica_Benzodiazepine | Seed 9: ATT = 1.0195, SE = 0.7511, p = 0.17777\n",
      "✅ SUBCAT_anxiolytica_Benzodiazepine | Seed 10: ATT = 0.9599, SE = 0.8541, p = 0.26378\n",
      "🏆 Best result for SUBCAT_anxiolytica_Benzodiazepine → Seed 8 | SE = 0.7154\n",
      "📊 Creating diagnostic plots for SUBCAT_anxiolytica_Benzodiazepine...\n",
      "\n",
      "🚀 Running DML for SUBCAT_hypnotica_Benzodiazepine\n",
      "✅ SUBCAT_hypnotica_Benzodiazepine | Seed 1: ATT = -1.7908, SE = 1.7561, p = 0.31032\n",
      "✅ SUBCAT_hypnotica_Benzodiazepine | Seed 2: ATT = -1.7809, SE = 1.7194, p = 0.30283\n",
      "✅ SUBCAT_hypnotica_Benzodiazepine | Seed 3: ATT = -1.6747, SE = 1.6448, p = 0.31108\n",
      "✅ SUBCAT_hypnotica_Benzodiazepine | Seed 4: ATT = -1.8146, SE = 1.7754, p = 0.30924\n",
      "✅ SUBCAT_hypnotica_Benzodiazepine | Seed 5: ATT = -1.7364, SE = 1.6723, p = 0.30162\n",
      "✅ SUBCAT_hypnotica_Benzodiazepine | Seed 6: ATT = -1.7141, SE = 1.7478, p = 0.32913\n",
      "✅ SUBCAT_hypnotica_Benzodiazepine | Seed 7: ATT = -2.0014, SE = 1.6033, p = 0.21487\n",
      "✅ SUBCAT_hypnotica_Benzodiazepine | Seed 8: ATT = -1.8427, SE = 1.6495, p = 0.26665\n",
      "✅ SUBCAT_hypnotica_Benzodiazepine | Seed 9: ATT = -1.7140, SE = 1.7976, p = 0.34265\n",
      "✅ SUBCAT_hypnotica_Benzodiazepine | Seed 10: ATT = -1.7859, SE = 1.6807, p = 0.29054\n",
      "🏆 Best result for SUBCAT_hypnotica_Benzodiazepine → Seed 7 | SE = 1.6033\n",
      "📊 Creating diagnostic plots for SUBCAT_hypnotica_Benzodiazepine...\n",
      "\n",
      "🚀 Running DML for SUBCAT_Amfetaminen\n",
      "✅ SUBCAT_Amfetaminen | Seed 1: ATT = 1.5597, SE = 2.9610, p = 0.59956\n",
      "✅ SUBCAT_Amfetaminen | Seed 2: ATT = 1.5269, SE = 2.7811, p = 0.58422\n",
      "✅ SUBCAT_Amfetaminen | Seed 3: ATT = 1.6044, SE = 2.9134, p = 0.58308\n",
      "✅ SUBCAT_Amfetaminen | Seed 4: ATT = 1.6749, SE = 2.7658, p = 0.54620\n",
      "✅ SUBCAT_Amfetaminen | Seed 5: ATT = 1.6166, SE = 3.0739, p = 0.60013\n",
      "✅ SUBCAT_Amfetaminen | Seed 6: ATT = 1.9996, SE = 3.3959, p = 0.55731\n",
      "✅ SUBCAT_Amfetaminen | Seed 7: ATT = 1.5022, SE = 3.0055, p = 0.61830\n",
      "✅ SUBCAT_Amfetaminen | Seed 8: ATT = 1.5544, SE = 3.1108, p = 0.61842\n",
      "✅ SUBCAT_Amfetaminen | Seed 9: ATT = 1.6474, SE = 3.3976, p = 0.62883\n",
      "✅ SUBCAT_Amfetaminen | Seed 10: ATT = 1.4706, SE = 3.2134, p = 0.64821\n",
      "🏆 Best result for SUBCAT_Amfetaminen → Seed 4 | SE = 2.7658\n",
      "📊 Creating diagnostic plots for SUBCAT_Amfetaminen...\n",
      "\n",
      "🚀 Running DML for SUBCAT_Paracetamol_mono\n",
      "✅ SUBCAT_Paracetamol_mono | Seed 1: ATT = 2.4576, SE = 4.4287, p = 0.58020\n",
      "✅ SUBCAT_Paracetamol_mono | Seed 2: ATT = 2.3736, SE = 4.5817, p = 0.60557\n",
      "✅ SUBCAT_Paracetamol_mono | Seed 3: ATT = 2.6876, SE = 5.1305, p = 0.60155\n",
      "✅ SUBCAT_Paracetamol_mono | Seed 4: ATT = 2.3937, SE = 5.2573, p = 0.64988\n",
      "✅ SUBCAT_Paracetamol_mono | Seed 5: ATT = 2.7132, SE = 4.1045, p = 0.51013\n",
      "✅ SUBCAT_Paracetamol_mono | Seed 6: ATT = 2.1699, SE = 4.3312, p = 0.61749\n",
      "✅ SUBCAT_Paracetamol_mono | Seed 7: ATT = 3.2555, SE = 6.6632, p = 0.62621\n",
      "✅ SUBCAT_Paracetamol_mono | Seed 8: ATT = 2.1528, SE = 4.6004, p = 0.64084\n",
      "✅ SUBCAT_Paracetamol_mono | Seed 9: ATT = 2.3174, SE = 4.7271, p = 0.62504\n",
      "✅ SUBCAT_Paracetamol_mono | Seed 10: ATT = 2.4962, SE = 4.9962, p = 0.61845\n",
      "🏆 Best result for SUBCAT_Paracetamol_mono → Seed 5 | SE = 4.1045\n",
      "📊 Creating diagnostic plots for SUBCAT_Paracetamol_mono...\n",
      "\n",
      "🚀 Running DML for SUBCAT_Anti_epileptica_stemmingsstabilisatoren\n",
      "✅ SUBCAT_Anti_epileptica_stemmingsstabilisatoren | Seed 1: ATT = 6.0996, SE = 3.6697, p = 0.09965\n",
      "✅ SUBCAT_Anti_epileptica_stemmingsstabilisatoren | Seed 2: ATT = 5.6163, SE = 3.8589, p = 0.14872\n",
      "✅ SUBCAT_Anti_epileptica_stemmingsstabilisatoren | Seed 3: ATT = 5.7675, SE = 4.4255, p = 0.19552\n",
      "✅ SUBCAT_Anti_epileptica_stemmingsstabilisatoren | Seed 4: ATT = 6.0971, SE = 3.7563, p = 0.10774\n",
      "✅ SUBCAT_Anti_epileptica_stemmingsstabilisatoren | Seed 5: ATT = 6.0483, SE = 3.5846, p = 0.09470\n",
      "✅ SUBCAT_Anti_epileptica_stemmingsstabilisatoren | Seed 6: ATT = 5.6503, SE = 3.9982, p = 0.16073\n",
      "✅ SUBCAT_Anti_epileptica_stemmingsstabilisatoren | Seed 7: ATT = 5.4432, SE = 3.7841, p = 0.15346\n",
      "✅ SUBCAT_Anti_epileptica_stemmingsstabilisatoren | Seed 8: ATT = 5.4828, SE = 3.8168, p = 0.15402\n",
      "✅ SUBCAT_Anti_epileptica_stemmingsstabilisatoren | Seed 9: ATT = 5.8921, SE = 3.4220, p = 0.08822\n",
      "✅ SUBCAT_Anti_epileptica_stemmingsstabilisatoren | Seed 10: ATT = 5.5179, SE = 4.1594, p = 0.18770\n",
      "🏆 Best result for SUBCAT_Anti_epileptica_stemmingsstabilisatoren → Seed 9 | SE = 3.4220\n",
      "📊 Creating diagnostic plots for SUBCAT_Anti_epileptica_stemmingsstabilisatoren...\n",
      "\n",
      "🚀 Running DML for SUBCAT_Opioden\n",
      "✅ SUBCAT_Opioden | Seed 1: ATT = 2.9917, SE = 3.4241, p = 0.38439\n",
      "✅ SUBCAT_Opioden | Seed 2: ATT = 2.9404, SE = 4.4764, p = 0.51279\n",
      "✅ SUBCAT_Opioden | Seed 3: ATT = 2.8184, SE = 3.2095, p = 0.38199\n",
      "✅ SUBCAT_Opioden | Seed 4: ATT = 3.1833, SE = 3.2866, p = 0.33512\n",
      "✅ SUBCAT_Opioden | Seed 5: ATT = 2.9369, SE = 3.3338, p = 0.38048\n",
      "✅ SUBCAT_Opioden | Seed 6: ATT = 2.9273, SE = 3.1313, p = 0.35214\n",
      "✅ SUBCAT_Opioden | Seed 7: ATT = 2.7524, SE = 3.2006, p = 0.39188\n",
      "✅ SUBCAT_Opioden | Seed 8: ATT = 2.9990, SE = 3.4316, p = 0.38427\n",
      "✅ SUBCAT_Opioden | Seed 9: ATT = 2.6634, SE = 3.0092, p = 0.37826\n",
      "✅ SUBCAT_Opioden | Seed 10: ATT = 2.6123, SE = 3.2801, p = 0.42771\n",
      "🏆 Best result for SUBCAT_Opioden → Seed 9 | SE = 3.0092\n",
      "📊 Creating diagnostic plots for SUBCAT_Opioden...\n",
      "\n",
      "🚀 Running DML for SUBCAT_Z_drugs\n",
      "✅ SUBCAT_Z_drugs | Seed 1: ATT = 7.4010, SE = 3.0605, p = 0.01742\n",
      "✅ SUBCAT_Z_drugs | Seed 2: ATT = 7.4947, SE = 2.7902, p = 0.00848\n",
      "✅ SUBCAT_Z_drugs | Seed 3: ATT = 7.2397, SE = 3.1160, p = 0.02220\n",
      "✅ SUBCAT_Z_drugs | Seed 4: ATT = 7.1443, SE = 3.0540, p = 0.02133\n",
      "✅ SUBCAT_Z_drugs | Seed 5: ATT = 7.6474, SE = 2.8888, p = 0.00944\n",
      "✅ SUBCAT_Z_drugs | Seed 6: ATT = 7.3758, SE = 2.8618, p = 0.01143\n",
      "✅ SUBCAT_Z_drugs | Seed 7: ATT = 7.1233, SE = 3.1847, p = 0.02755\n",
      "✅ SUBCAT_Z_drugs | Seed 8: ATT = 7.1183, SE = 3.0556, p = 0.02186\n",
      "✅ SUBCAT_Z_drugs | Seed 9: ATT = 7.3154, SE = 2.8136, p = 0.01075\n",
      "✅ SUBCAT_Z_drugs | Seed 10: ATT = 6.9875, SE = 2.7827, p = 0.01366\n",
      "🏆 Best result for SUBCAT_Z_drugs → Seed 10 | SE = 2.7827\n",
      "📊 Creating diagnostic plots for SUBCAT_Z_drugs...\n",
      "\n",
      "🚀 Running DML for SUBCAT_NSAIDs\n",
      "✅ SUBCAT_NSAIDs | Seed 1: ATT = -0.2694, SE = 4.3582, p = 0.95084\n",
      "✅ SUBCAT_NSAIDs | Seed 2: ATT = -0.0451, SE = 5.1562, p = 0.99304\n",
      "✅ SUBCAT_NSAIDs | Seed 3: ATT = -0.1935, SE = 4.7976, p = 0.96790\n",
      "✅ SUBCAT_NSAIDs | Seed 4: ATT = -0.2127, SE = 4.3330, p = 0.96095\n",
      "✅ SUBCAT_NSAIDs | Seed 5: ATT = 0.0407, SE = 4.6405, p = 0.99302\n",
      "✅ SUBCAT_NSAIDs | Seed 6: ATT = -0.0284, SE = 4.8871, p = 0.99537\n",
      "✅ SUBCAT_NSAIDs | Seed 7: ATT = 0.1418, SE = 4.7352, p = 0.97618\n",
      "✅ SUBCAT_NSAIDs | Seed 8: ATT = -0.3245, SE = 4.6968, p = 0.94506\n",
      "✅ SUBCAT_NSAIDs | Seed 9: ATT = 0.0519, SE = 4.8475, p = 0.99148\n",
      "✅ SUBCAT_NSAIDs | Seed 10: ATT = 0.0147, SE = 4.7361, p = 0.99753\n",
      "🏆 Best result for SUBCAT_NSAIDs → Seed 4 | SE = 4.3330\n",
      "📊 Creating diagnostic plots for SUBCAT_NSAIDs...\n",
      "\n",
      "🎯 All summary files saved.\n",
      "📊 All diagnostic plots saved in outputs/plots/ folder.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "from econml.dml import LinearDML\n",
    "from scipy.stats import t, probplot\n",
    "import xgboost as xgb\n",
    "\n",
    "# -----------------------------\n",
    "# Configuration\n",
    "# -----------------------------\n",
    "n_repeats = 4\n",
    "seeds = list(range(1, 11))\n",
    "imputations = 5\n",
    "output_folder = \"outputs\"\n",
    "\n",
    "# -----------------------------\n",
    "# Plotting Functions\n",
    "# -----------------------------\n",
    "def create_diagnostic_plots(residuals_data, group_name, output_folder):\n",
    "    \"\"\"Create diagnostic plots for each group\"\"\"\n",
    "    plots_dir = os.path.join(output_folder, \"plots\")\n",
    "    os.makedirs(plots_dir, exist_ok=True)\n",
    "    \n",
    "    all_residuals = residuals_data['residuals']\n",
    "    all_fitted = residuals_data['fitted']\n",
    "    \n",
    "    if len(all_residuals) == 0:\n",
    "        return\n",
    "    \n",
    "    # Create figure with subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    fig.suptitle(f'Diagnostic Plots - {group_name}', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 1. Residuals vs Fitted\n",
    "    axes[0, 0].scatter(all_fitted, all_residuals, alpha=0.5, s=1)\n",
    "    axes[0, 0].axhline(y=0, color='red', linestyle='--')\n",
    "    axes[0, 0].set_xlabel('Fitted Values')\n",
    "    axes[0, 0].set_ylabel('Residuals')\n",
    "    axes[0, 0].set_title('Residuals vs Fitted')\n",
    "    \n",
    "    # 2. QQ Plot\n",
    "    probplot(all_residuals, dist=\"norm\", plot=axes[0, 1])\n",
    "    axes[0, 1].set_title('QQ Plot (Normal)')\n",
    "    \n",
    "    # 3. Histogram of Residuals\n",
    "    axes[1, 0].hist(all_residuals, bins=50, alpha=0.7, edgecolor='black')\n",
    "    axes[1, 0].axvline(x=0, color='red', linestyle='--')\n",
    "    axes[1, 0].set_xlabel('Residuals')\n",
    "    axes[1, 0].set_ylabel('Frequency')\n",
    "    axes[1, 0].set_title('Residual Distribution')\n",
    "    \n",
    "    # 4. Scale-Location Plot\n",
    "    sqrt_abs_resid = np.sqrt(np.abs(all_residuals))\n",
    "    axes[1, 1].scatter(all_fitted, sqrt_abs_resid, alpha=0.5, s=1)\n",
    "    axes[1, 1].set_xlabel('Fitted Values')\n",
    "    axes[1, 1].set_ylabel('√|Residuals|')\n",
    "    axes[1, 1].set_title('Scale-Location Plot')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(plots_dir, f'{group_name}_unweighted.png'), \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# -----------------------------\n",
    "# Rubin's Rule\n",
    "# -----------------------------\n",
    "def rubins_pool(estimates, ses):\n",
    "    m = len(estimates)\n",
    "    q_bar = np.mean(estimates)\n",
    "    u_bar = np.mean(np.square(ses))\n",
    "    b_m = np.var(estimates, ddof=1)\n",
    "    total_var = u_bar + ((1 + 1/m) * b_m)\n",
    "    total_se = np.sqrt(total_var)\n",
    "    ci_lower = q_bar - 1.96 * total_se\n",
    "    ci_upper = q_bar + 1.96 * total_se\n",
    "    p_value = 2 * (1 - t.cdf(np.abs(q_bar / total_se), df=m-1))\n",
    "    rounded_p = round(p_value, 5)\n",
    "    formatted_p = \"< 0.00001\" if rounded_p <= 0.00001 else f\"{rounded_p:.5f}\"\n",
    "    return q_bar, total_se, ci_lower, ci_upper, formatted_p\n",
    "\n",
    "# -----------------------------\n",
    "# SMD + Variance Ratio\n",
    "# -----------------------------\n",
    "def calculate_smd_vr(X, T):\n",
    "    treated = X[T == 1]\n",
    "    control = X[T == 0]\n",
    "    smd, vr = [], []\n",
    "    for col in X.columns:\n",
    "        try:\n",
    "            m1, m0 = treated[col].mean(), control[col].mean()\n",
    "            s1, s0 = treated[col].std(), control[col].std()\n",
    "            pooled_sd = np.sqrt((s1 ** 2 + s0 ** 2) / 2)\n",
    "            smd.append((m1 - m0) / pooled_sd if pooled_sd > 0 else 0)\n",
    "            vr.append(s1**2 / s0**2 if s0**2 > 0 else 0)\n",
    "        except Exception:\n",
    "            smd.append(np.nan)\n",
    "            vr.append(np.nan)\n",
    "    return np.nanmean(smd), np.nanmean(vr)\n",
    "\n",
    "# -----------------------------\n",
    "# DML Main Loop\n",
    "# -----------------------------\n",
    "def run_dml_with_trimmed_data(final_covariates_map):\n",
    "    att_results = []\n",
    "    balance_results = []\n",
    "\n",
    "    for group, covariates in final_covariates_map.items():\n",
    "        print(f\"\\n🚀 Running DML for {group}\")\n",
    "        group_dir = os.path.join(output_folder, group)\n",
    "        os.makedirs(group_dir, exist_ok=True)\n",
    "\n",
    "        best_result = None\n",
    "        best_se = float(\"inf\")\n",
    "        \n",
    "        # Initialize residuals collection for this group\n",
    "        group_residuals_data = {'residuals': [], 'fitted': []}\n",
    "\n",
    "        for seed in seeds:\n",
    "            att_list, se_list, r2_list, rmse_list, smd_list, vr_list = [], [], [], [], [], []\n",
    "\n",
    "            for imp in range(1, imputations + 1):\n",
    "                file_path = os.path.join(group_dir, f\"trimmed_data_imp{imp}.pkl\")\n",
    "                if not os.path.exists(file_path):\n",
    "                    continue\n",
    "\n",
    "                df = pd.read_pickle(file_path)\n",
    "                if group not in df.columns:\n",
    "                    continue\n",
    "\n",
    "                X = df[covariates].copy()\n",
    "                T = df[group]\n",
    "                Y = df[\"caps5_change_baseline\"]\n",
    "\n",
    "                for repeat in range(n_repeats):\n",
    "                    kf = KFold(n_splits=5, shuffle=True, random_state=seed + repeat)\n",
    "                    for train_idx, test_idx in kf.split(X):\n",
    "                        try:\n",
    "                            X_train, T_train, Y_train = (\n",
    "                                X.iloc[train_idx],\n",
    "                                T.iloc[train_idx],\n",
    "                                Y.iloc[train_idx],\n",
    "                            )\n",
    "\n",
    "                            model_y = xgb.XGBRegressor(n_estimators=100, max_depth=3, learning_rate=0.1, n_jobs=1, random_state=seed)\n",
    "                            model_t = xgb.XGBClassifier(n_estimators=100, max_depth=3, learning_rate=0.1, n_jobs=1,\n",
    "                                                        use_label_encoder=False, eval_metric=\"logloss\", random_state=seed)\n",
    "\n",
    "                            dml = LinearDML(model_y=model_y, model_t=model_t, discrete_treatment=True,\n",
    "                                            cv=KFold(n_splits=3, shuffle=True, random_state=seed), random_state=seed)\n",
    "                            dml.fit(Y_train, T_train, X=X_train)\n",
    "\n",
    "                            tau = dml.effect(X_train)\n",
    "                            att = np.mean(tau)\n",
    "                            influence = tau - att\n",
    "                            se = np.sqrt(np.mean(influence ** 2) / len(tau))\n",
    "\n",
    "                            att_list.append(att)\n",
    "                            se_list.append(se)\n",
    "\n",
    "                            Y_pred = model_y.fit(X_train, Y_train).predict(X_train)\n",
    "                            residuals = Y_train - Y_pred\n",
    "                            \n",
    "                            # Collect residuals and fitted values for plotting\n",
    "                            group_residuals_data['residuals'].extend(residuals.tolist())\n",
    "                            group_residuals_data['fitted'].extend(Y_pred.tolist())\n",
    "                            \n",
    "                            rmse = mean_squared_error(Y_train, Y_pred, squared=False)\n",
    "                            r2 = r2_score(Y_train, Y_pred)\n",
    "                            r2_list.append(r2)\n",
    "                            rmse_list.append(rmse)\n",
    "\n",
    "                            smd, vr = calculate_smd_vr(X_train, T_train)\n",
    "                            smd_list.append(smd)\n",
    "                            vr_list.append(vr)\n",
    "                        except Exception as e:\n",
    "                            print(f\"⚠️ Error in {group}, seed {seed}, imp {imp}, rep {repeat}: {e}\")\n",
    "\n",
    "            if att_list:\n",
    "                att, se, ci_l, ci_u, p_val = rubins_pool(att_list, se_list)\n",
    "                avg_r2 = np.mean(r2_list)\n",
    "                avg_rmse = np.mean(rmse_list)\n",
    "                avg_smd = np.mean(smd_list)\n",
    "                avg_vr = np.mean(vr_list)\n",
    "\n",
    "                balance_results.append({\n",
    "                    \"group\": group, \"seed\": seed, \"smd\": avg_smd, \"vr\": avg_vr\n",
    "                })\n",
    "\n",
    "                if se < best_se:\n",
    "                    best_se = se\n",
    "                    best_result = {\n",
    "                        \"group\": group, \"seed\": seed, \"att\": att, \"se\": se,\n",
    "                        \"ci_lower\": ci_l, \"ci_upper\": ci_u, \"p_value\": p_val,\n",
    "                        \"r2\": avg_r2, \"rmse\": avg_rmse\n",
    "                    }\n",
    "\n",
    "                print(f\"✅ {group} | Seed {seed}: ATT = {att:.4f}, SE = {se:.4f}, p = {p_val}\")\n",
    "            else:\n",
    "                print(f\"⚠️ No valid results for {group} | Seed {seed}\")\n",
    "\n",
    "        if best_result:\n",
    "            att_results.append(best_result)\n",
    "            print(f\"🏆 Best result for {group} → Seed {best_result['seed']} | SE = {best_result['se']:.4f}\")\n",
    "        \n",
    "        # Create diagnostic plots for this group\n",
    "        print(f\"📊 Creating diagnostic plots for {group}...\")\n",
    "        create_diagnostic_plots(group_residuals_data, group, output_folder)\n",
    "\n",
    "    # Save final output\n",
    "    pd.DataFrame(att_results).to_excel(\"dml_rubin_summary_subcats_unweighted.xlsx\", index=False)\n",
    "    pd.DataFrame(balance_results).to_excel(\"smd_vr_summary_subcats_unweighted.xlsx\", index=False)\n",
    "    print(\"\\n🎯 All summary files saved.\")\n",
    "    print(\"📊 All diagnostic plots saved in outputs/plots/ folder.\")\n",
    "\n",
    "run_dml_with_trimmed_data(final_covariates_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ea3a88b2-9215-46c0-8fd2-b0251e58352e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Final_ATT_Summary_SubCat saved\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import sem, ttest_ind\n",
    "\n",
    "# ----------------------------------\n",
    "# File paths\n",
    "# ----------------------------------\n",
    "output_base = \"outputs\"\n",
    "att_file = \"dml_rubin_summary_subcats.xlsx\"\n",
    "trimmed_file = \"trimmed_data_imp1.pkl\"\n",
    "auc_file = \"auc_scores.xlsx\"  \n",
    "\n",
    "# ----------------------------------\n",
    "# Load ATT Summary\n",
    "# ----------------------------------\n",
    "if os.path.exists(att_file):\n",
    "    att_df = pd.read_excel(att_file)\n",
    "else:\n",
    "    raise FileNotFoundError(\"❌ ATT summary file not found: dml_rubin_summary_subcats.xlsx\")\n",
    "\n",
    "summary_rows = []\n",
    "\n",
    "# ----------------------------------\n",
    "# Loop over medication groups\n",
    "# ----------------------------------\n",
    "groups = [g for g in medication_groups if os.path.isdir(os.path.join(output_base, g))]\n",
    "\n",
    "for med in groups:\n",
    "    try:\n",
    "        group_path = os.path.join(output_base, med)\n",
    "\n",
    "        # Load trimmed data\n",
    "        df = pd.read_pickle(os.path.join(group_path, trimmed_file))\n",
    "\n",
    "        # Detect treatment column\n",
    "        treatment_cols = [col for col in df.columns if col.upper() == med.upper()]\n",
    "        if not treatment_cols:\n",
    "            print(f\"⚠️ Treatment column {med} not found in trimmed data. Skipping.\")\n",
    "            continue\n",
    "        treatment_var = treatment_cols[0]\n",
    "\n",
    "        # Extract treatment and outcome\n",
    "        T = df[treatment_var]\n",
    "        Y = df[\"caps5_change_baseline\"]\n",
    "\n",
    "        # Treated and control stats\n",
    "        treated = Y[T == 1]\n",
    "        control = Y[T == 0]\n",
    "\n",
    "        mean_treat = treated.mean()\n",
    "        se_treat = sem(treated) if len(treated) > 1 else np.nan\n",
    "\n",
    "        mean_ctrl = control.mean()\n",
    "        se_ctrl = sem(control) if len(control) > 1 else np.nan\n",
    "\n",
    "        # Cohen's d (unadjusted)\n",
    "        pooled_sd = np.sqrt(((treated.std() ** 2) + (control.std() ** 2)) / 2)\n",
    "        cohen_d = (mean_treat - mean_ctrl) / pooled_sd if pooled_sd > 0 else np.nan\n",
    "\n",
    "        # E-value (unadjusted)\n",
    "        delta = mean_treat - mean_ctrl\n",
    "        E = delta / abs(mean_ctrl) * 100 if mean_ctrl != 0 else np.nan\n",
    "\n",
    "        # Unadjusted p-value\n",
    "        try:\n",
    "            t_stat, p_val = ttest_ind(treated, control, equal_var=False, nan_policy=\"omit\")\n",
    "            rounded_p = round(p_val, 5)\n",
    "            formatted_p = \"< 0.00001\" if rounded_p < 0.00001 else rounded_p\n",
    "        except Exception:\n",
    "            formatted_p = np.nan\n",
    "\n",
    "        # AUC from new auc_scores.xlsx file\n",
    "        auc_val = np.nan\n",
    "        auc_path = os.path.join(group_path, auc_file)\n",
    "        if os.path.exists(auc_path):\n",
    "            auc_df = pd.read_excel(auc_path)\n",
    "            if \"AUC\" in auc_df.columns:\n",
    "                auc_val = auc_df[\"AUC\"].dropna().mean()\n",
    "\n",
    "        # Adjusted stats from Rubin summary\n",
    "        att_row = att_df[att_df[\"group\"].str.strip().str.upper() == med.strip().upper()]\n",
    "        if not att_row.empty:\n",
    "            att = att_row.iloc[0][\"att\"]\n",
    "            att_se = att_row.iloc[0][\"se\"]\n",
    "            att_p_val = att_row.iloc[0][\"p_value\"]\n",
    "            r2 = att_row.iloc[0][\"r2\"]\n",
    "            rmse = att_row.iloc[0][\"rmse\"]\n",
    "\n",
    "            try:\n",
    "                rounded_att_p = round(float(att_p_val), 5)\n",
    "                formatted_att_p = \"< 0.00001\" if rounded_att_p < 0.00001 else rounded_att_p\n",
    "            except:\n",
    "                formatted_att_p = att_p_val\n",
    "        else:\n",
    "            att, att_se, formatted_att_p, r2, rmse = np.nan, np.nan, np.nan, np.nan, np.nan\n",
    "\n",
    "        # Append full row\n",
    "        summary_rows.append({\n",
    "            'Medication Group': med,\n",
    "            'Mean Treated': mean_treat,\n",
    "            'SE Treated': se_treat,\n",
    "            'Mean Control': mean_ctrl,\n",
    "            'SE Control': se_ctrl,\n",
    "            'Cohen d': cohen_d,\n",
    "            'E (Unadjusted)': E,\n",
    "            'n Treated': len(treated),\n",
    "            'n Control': len(control),\n",
    "            #'Unadjusted p-value': formatted_p,\n",
    "            'ATT Estimate': att,\n",
    "            'ATT SE (Robust)': att_se,\n",
    "            'ATT p-value': formatted_att_p,\n",
    "            'R²': r2,\n",
    "            'RMSE': rmse,\n",
    "            'AUC': auc_val\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error in {med}: {e}\")\n",
    "\n",
    "# ----------------------------------\n",
    "# Save final summary\n",
    "# ----------------------------------\n",
    "summary_df = pd.DataFrame(summary_rows)\n",
    "summary_df = summary_df.sort_values(\"Medication Group\")\n",
    "summary_df.to_excel(\"Final_ATT_Summary_SubCat.xlsx\", index=False)\n",
    "print(\"✅ Final_ATT_Summary_SubCat saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fd753254-1fa1-4c8e-8a3c-cbec86b6169a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ dml_att_barplot_subcat saved\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "# ✅ Load the final summary table\n",
    "final_df = pd.read_excel(\"Final_ATT_Summary_SubCat.xlsx\")\n",
    "\n",
    "# ✅ Parse DML p-values (handle \"< 0.00001\")\n",
    "def parse_pval(p):\n",
    "    try:\n",
    "        if isinstance(p, str) and \"<\" in p:\n",
    "            return 0.000001\n",
    "        return float(p)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "final_df['ATT p-value'] = final_df['ATT p-value'].apply(parse_pval)\n",
    "\n",
    "# ✅ Plot settings\n",
    "width = 0.35\n",
    "\n",
    "# ✅ Plotting function for a single medication group\n",
    "def plot_single_group(row):\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    bars1 = ax.bar(-width/2, row['Mean Control'], width, \n",
    "                   yerr=row['SE Control'], label='Control', hatch='//', color='gray', capsize=5)\n",
    "    bars2 = ax.bar(+width/2, row['Mean Treated'], width, \n",
    "                   yerr=row['SE Treated'], label='Treated', color='steelblue', capsize=5)\n",
    "\n",
    "    label = (\n",
    "        f\"ATT = {row['ATT Estimate']:.2f}\\n\"\n",
    "        f\"d = {row['Cohen d']:.2f}, p = {row['ATT p-value']:.3f}\\n\"\n",
    "        f\"nT = {row['n Treated']}, nC = {row['n Control']}\\n\"\n",
    "        f\"E = {row['E (Unadjusted)']:.1f}%\"\n",
    "    )\n",
    "    max_y = max(row['Mean Control'], row['Mean Treated']) + 1.5\n",
    "    ax.text(0, max_y, label, ha='center', va='bottom', fontsize=9, color='#FFD700')\n",
    "\n",
    "    ax.axhline(0, color='black', linewidth=0.8)\n",
    "    ax.set_xticks([-width/2, +width/2])\n",
    "    ax.set_xticklabels(['Control', 'Treated'])\n",
    "    ax.set_title(f\"Group: {row['Medication Group']}\", fontsize=12, weight='bold')\n",
    "    ax.set_ylabel(\"CAPS5 Change Score\")\n",
    "    ax.set_ylim(bottom=0, top=max_y + 2)\n",
    "    ax.legend()\n",
    "    fig.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# ✅ Generate and save all plots into a multi-page PDF\n",
    "with PdfPages(\"dml_att_barplot_subcat.pdf\") as pdf:\n",
    "    for idx, row in final_df.iterrows():\n",
    "        fig = plot_single_group(row)\n",
    "        pdf.savefig(fig, dpi=300, bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "print(\"✅ dml_att_barplot_subcat saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "808a2609-b153-43da-9068-afb6bbf09dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Love plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9ba20ca3-c1b5-4c2b-a48b-f90d8b1734fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Processing SUBCAT_Amfetaminen...\n",
      "📊 Exported numeric summary to: outputs\\SUBCAT_Amfetaminen\\covariate_balance_table_SUBCAT_Amfetaminen.xlsx\n",
      "✅ Saved love plot: outputs\\SUBCAT_Amfetaminen\\love_plot_SUBCAT_Amfetaminen.pdf\n",
      "📏 Max weighted SMD for SUBCAT_Amfetaminen: 0.369\n",
      "\n",
      "🔍 Processing SUBCAT_Antidepressiva_Overige...\n",
      "📊 Exported numeric summary to: outputs\\SUBCAT_Antidepressiva_Overige\\covariate_balance_table_SUBCAT_Antidepressiva_Overige.xlsx\n",
      "✅ Saved love plot: outputs\\SUBCAT_Antidepressiva_Overige\\love_plot_SUBCAT_Antidepressiva_Overige.pdf\n",
      "📏 Max weighted SMD for SUBCAT_Antidepressiva_Overige: 0.288\n",
      "\n",
      "🔍 Processing SUBCAT_Antipsychotica_Atypisch...\n",
      "📊 Exported numeric summary to: outputs\\SUBCAT_Antipsychotica_Atypisch\\covariate_balance_table_SUBCAT_Antipsychotica_Atypisch.xlsx\n",
      "✅ Saved love plot: outputs\\SUBCAT_Antipsychotica_Atypisch\\love_plot_SUBCAT_Antipsychotica_Atypisch.pdf\n",
      "📏 Max weighted SMD for SUBCAT_Antipsychotica_Atypisch: 0.583\n",
      "\n",
      "🔍 Processing SUBCAT_Anti_Epileptica_Stemmingsstabilisatoren...\n",
      "📊 Exported numeric summary to: outputs\\SUBCAT_Anti_Epileptica_Stemmingsstabilisatoren\\covariate_balance_table_SUBCAT_Anti_Epileptica_Stemmingsstabilisatoren.xlsx\n",
      "✅ Saved love plot: outputs\\SUBCAT_Anti_Epileptica_Stemmingsstabilisatoren\\love_plot_SUBCAT_Anti_Epileptica_Stemmingsstabilisatoren.pdf\n",
      "📏 Max weighted SMD for SUBCAT_Anti_Epileptica_Stemmingsstabilisatoren: 0.262\n",
      "\n",
      "🔍 Processing SUBCAT_Anxiolytica_Benzodiazepine...\n",
      "📊 Exported numeric summary to: outputs\\SUBCAT_Anxiolytica_Benzodiazepine\\covariate_balance_table_SUBCAT_Anxiolytica_Benzodiazepine.xlsx\n",
      "✅ Saved love plot: outputs\\SUBCAT_Anxiolytica_Benzodiazepine\\love_plot_SUBCAT_Anxiolytica_Benzodiazepine.pdf\n",
      "📏 Max weighted SMD for SUBCAT_Anxiolytica_Benzodiazepine: 0.227\n",
      "\n",
      "🔍 Processing SUBCAT_Hypnotica_Benzodiazepine...\n",
      "📊 Exported numeric summary to: outputs\\SUBCAT_Hypnotica_Benzodiazepine\\covariate_balance_table_SUBCAT_Hypnotica_Benzodiazepine.xlsx\n",
      "✅ Saved love plot: outputs\\SUBCAT_Hypnotica_Benzodiazepine\\love_plot_SUBCAT_Hypnotica_Benzodiazepine.pdf\n",
      "📏 Max weighted SMD for SUBCAT_Hypnotica_Benzodiazepine: 0.211\n",
      "\n",
      "🔍 Processing SUBCAT_Nsaids...\n",
      "📊 Exported numeric summary to: outputs\\SUBCAT_Nsaids\\covariate_balance_table_SUBCAT_Nsaids.xlsx\n",
      "✅ Saved love plot: outputs\\SUBCAT_Nsaids\\love_plot_SUBCAT_Nsaids.pdf\n",
      "📏 Max weighted SMD for SUBCAT_Nsaids: 0.241\n",
      "\n",
      "🔍 Processing SUBCAT_Opioden...\n",
      "📊 Exported numeric summary to: outputs\\SUBCAT_Opioden\\covariate_balance_table_SUBCAT_Opioden.xlsx\n",
      "✅ Saved love plot: outputs\\SUBCAT_Opioden\\love_plot_SUBCAT_Opioden.pdf\n",
      "📏 Max weighted SMD for SUBCAT_Opioden: 0.333\n",
      "\n",
      "🔍 Processing SUBCAT_Paracetamol_Mono...\n",
      "📊 Exported numeric summary to: outputs\\SUBCAT_Paracetamol_Mono\\covariate_balance_table_SUBCAT_Paracetamol_Mono.xlsx\n",
      "✅ Saved love plot: outputs\\SUBCAT_Paracetamol_Mono\\love_plot_SUBCAT_Paracetamol_Mono.pdf\n",
      "📏 Max weighted SMD for SUBCAT_Paracetamol_Mono: 0.255\n",
      "\n",
      "🔍 Processing SUBCAT_Snri...\n",
      "📊 Exported numeric summary to: outputs\\SUBCAT_Snri\\covariate_balance_table_SUBCAT_Snri.xlsx\n",
      "✅ Saved love plot: outputs\\SUBCAT_Snri\\love_plot_SUBCAT_Snri.pdf\n",
      "📏 Max weighted SMD for SUBCAT_Snri: 0.287\n",
      "\n",
      "🔍 Processing SUBCAT_Ssri...\n",
      "📊 Exported numeric summary to: outputs\\SUBCAT_Ssri\\covariate_balance_table_SUBCAT_Ssri.xlsx\n",
      "✅ Saved love plot: outputs\\SUBCAT_Ssri\\love_plot_SUBCAT_Ssri.pdf\n",
      "📏 Max weighted SMD for SUBCAT_Ssri: 0.187\n",
      "\n",
      "🔍 Processing SUBCAT_Systemische_Antihistaminica...\n",
      "📊 Exported numeric summary to: outputs\\SUBCAT_Systemische_Antihistaminica\\covariate_balance_table_SUBCAT_Systemische_Antihistaminica.xlsx\n",
      "✅ Saved love plot: outputs\\SUBCAT_Systemische_Antihistaminica\\love_plot_SUBCAT_Systemische_Antihistaminica.pdf\n",
      "📏 Max weighted SMD for SUBCAT_Systemische_Antihistaminica: 0.391\n",
      "\n",
      "🔍 Processing SUBCAT_Tca...\n",
      "📊 Exported numeric summary to: outputs\\SUBCAT_Tca\\covariate_balance_table_SUBCAT_Tca.xlsx\n",
      "✅ Saved love plot: outputs\\SUBCAT_Tca\\love_plot_SUBCAT_Tca.pdf\n",
      "📏 Max weighted SMD for SUBCAT_Tca: 0.283\n",
      "\n",
      "🔍 Processing SUBCAT_Tetracyclische_Antidepressiva...\n",
      "📊 Exported numeric summary to: outputs\\SUBCAT_Tetracyclische_Antidepressiva\\covariate_balance_table_SUBCAT_Tetracyclische_Antidepressiva.xlsx\n",
      "✅ Saved love plot: outputs\\SUBCAT_Tetracyclische_Antidepressiva\\love_plot_SUBCAT_Tetracyclische_Antidepressiva.pdf\n",
      "📏 Max weighted SMD for SUBCAT_Tetracyclische_Antidepressiva: 0.247\n",
      "\n",
      "🔍 Processing SUBCAT_Z_Drugs...\n",
      "📊 Exported numeric summary to: outputs\\SUBCAT_Z_Drugs\\covariate_balance_table_SUBCAT_Z_Drugs.xlsx\n",
      "✅ Saved love plot: outputs\\SUBCAT_Z_Drugs\\love_plot_SUBCAT_Z_Drugs.pdf\n",
      "📏 Max weighted SMD for SUBCAT_Z_Drugs: 0.181\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "# ----------------------------------------\n",
    "# Functions to calculate balance\n",
    "# ----------------------------------------\n",
    "def calculate_smd(x1, x2, w1=None, w2=None):\n",
    "    def weighted_mean(x, w): return np.average(x, weights=w)\n",
    "    def weighted_var(x, w):\n",
    "        m = np.average(x, weights=w)\n",
    "        return np.average((x - m) ** 2, weights=w)\n",
    "    \n",
    "    m1 = weighted_mean(x1, w1) if w1 is not None else np.mean(x1)\n",
    "    m2 = weighted_mean(x2, w2) if w2 is not None else np.mean(x2)\n",
    "    v1 = weighted_var(x1, w1) if w1 is not None else np.var(x1, ddof=1)\n",
    "    v2 = weighted_var(x2, w2) if w2 is not None else np.var(x2, ddof=1)\n",
    "    \n",
    "    pooled_sd = np.sqrt((v1 + v2) / 2)\n",
    "    return np.abs(m1 - m2) / pooled_sd if pooled_sd > 0 else 0\n",
    "\n",
    "def variance_ratio(x1, x2, w1=None, w2=None):\n",
    "    def weighted_var(x, w):\n",
    "        m = np.average(x, weights=w)\n",
    "        return np.average((x - m) ** 2, weights=w)\n",
    "    \n",
    "    v1 = weighted_var(x1, w1) if w1 is not None else np.var(x1, ddof=1)\n",
    "    v2 = weighted_var(x2, w2) if w2 is not None else np.var(x2, ddof=1)\n",
    "    \n",
    "    return max(v1 / v2, v2 / v1) if v1 > 0 and v2 > 0 else 1\n",
    "\n",
    "# ----------------------------------------\n",
    "# Setup\n",
    "# ----------------------------------------\n",
    "output_base = \"outputs\"\n",
    "groups = [g for g in os.listdir(output_base) if os.path.isdir(os.path.join(output_base, g))]\n",
    "\n",
    "# Create a case-insensitive mapping\n",
    "final_covariates_map_lower = {k.lower(): v for k, v in final_covariates_map.items()}\n",
    "\n",
    "# ----------------------------------------\n",
    "# Main Loop\n",
    "# ----------------------------------------\n",
    "for group in groups:\n",
    "    if group.lower() not in final_covariates_map_lower:\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n🔍 Processing {group}...\")\n",
    "\n",
    "    try:\n",
    "        group_path = os.path.join(output_base, group)\n",
    "        covariates = final_covariates_map_lower[group.lower()]\n",
    "        \n",
    "        column_name = None\n",
    "        for col in pd.read_pickle(os.path.join(group_path, \"trimmed_data_imp1.pkl\")).columns:\n",
    "            if col.lower() == group.lower():\n",
    "                column_name = col\n",
    "                break\n",
    "        if column_name is None:\n",
    "            print(f\"⚠️ Column not found for {group}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        smd_unw_all, smd_w_all = [], []\n",
    "        vr_unw_all, vr_w_all = [], []\n",
    "\n",
    "        for i in range(1, 6):\n",
    "            df_path = os.path.join(group_path, f\"trimmed_data_imp{i}.pkl\")\n",
    "            iptw_path = os.path.join(group_path, \"iptw_weights.xlsx\")\n",
    "\n",
    "            if not os.path.exists(df_path) or not os.path.exists(iptw_path):\n",
    "                print(f\"⚠️ Missing data for {group} imp{i}, skipping.\")\n",
    "                continue\n",
    "\n",
    "            df = pd.read_pickle(df_path)\n",
    "            iptw_df = pd.read_excel(iptw_path, index_col=0)\n",
    "            T = df[column_name]\n",
    "            W = iptw_df.loc[df.index, \"iptw_mean\"]\n",
    "\n",
    "            smd_unw_i, smd_w_i, vr_unw_i, vr_w_i = [], [], [], []\n",
    "\n",
    "            for cov in covariates:\n",
    "                x1, x0 = df.loc[T == 1, cov], df.loc[T == 0, cov]\n",
    "                w1, w0 = W[T == 1], W[T == 0]\n",
    "\n",
    "                su = calculate_smd(x1, x0)\n",
    "                sw = calculate_smd(x1, x0, w1, w0)\n",
    "\n",
    "                vu = variance_ratio(x1, x0) if cov in ['treatmentdurationdays', 'CAPS5score_baseline', 'age'] else np.nan\n",
    "                vw = variance_ratio(x1, x0, w1, w0) if cov in ['treatmentdurationdays', 'CAPS5score_baseline', 'age'] else np.nan\n",
    "\n",
    "                smd_unw_i.append(su)\n",
    "                smd_w_i.append(sw)\n",
    "                vr_unw_i.append(vu)\n",
    "                vr_w_i.append(vw)\n",
    "\n",
    "            smd_unw_all.append(smd_unw_i)\n",
    "            smd_w_all.append(smd_w_i)\n",
    "            vr_unw_all.append(vr_unw_i)\n",
    "            vr_w_all.append(vr_w_i)\n",
    "\n",
    "        smd_unw = np.mean(smd_unw_all, axis=0)\n",
    "        smd_w = np.mean(smd_w_all, axis=0)\n",
    "        vr_unw = np.nanmean(vr_unw_all, axis=0)\n",
    "        vr_w = np.nanmean(vr_w_all, axis=0)\n",
    "\n",
    "        severity = []\n",
    "        for sw in smd_w:\n",
    "            if sw <= 0.1:\n",
    "                severity.append(\"Good\")\n",
    "            elif sw <= 0.2:\n",
    "                severity.append(\"Moderate\")\n",
    "            else:\n",
    "                severity.append(\"Poor\")\n",
    "\n",
    "        covariate_names = covariates\n",
    "        numeric_df = pd.DataFrame({\n",
    "            \"Covariate\": covariate_names,\n",
    "            \"SMD_Unweighted\": smd_unw,\n",
    "            \"SMD_Weighted\": smd_w,\n",
    "            \"Imbalance_Severity\": severity,\n",
    "            \"VR_Unweighted\": vr_unw,\n",
    "            \"VR_Weighted\": vr_w\n",
    "        })\n",
    "\n",
    "        numeric_path = os.path.join(group_path, f\"covariate_balance_table_{group}.xlsx\")\n",
    "        numeric_df.to_excel(numeric_path, index=False)\n",
    "        print(f\"📊 Exported numeric summary to: {numeric_path}\")\n",
    "\n",
    "        # -------------------------\n",
    "        # Plot\n",
    "        # -------------------------\n",
    "        labels = covariates\n",
    "        y_pos = np.arange(len(labels))\n",
    "\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(18, len(labels) * 0.45))\n",
    "\n",
    "        axes[0].scatter(smd_unw, y_pos, color='red', label=\"Unweighted\")\n",
    "        axes[0].scatter(smd_w, y_pos, color='blue', label=\"Weighted\")\n",
    "        axes[0].axvline(0.1, color='gray', linestyle='--', label=\"Threshold 0.1\")\n",
    "        axes[0].axvline(0.2, color='black', linestyle='--', label=\"Threshold 0.2\")\n",
    "        axes[0].set_xlim(0, max(max(smd_unw), max(smd_w), 0.25) + 0.05)\n",
    "        axes[0].set_yticks(y_pos)\n",
    "        axes[0].set_yticklabels(labels)\n",
    "        axes[0].invert_yaxis()\n",
    "        axes[0].set_title(\"Standardized Mean Differences (SMD)\")\n",
    "        axes[0].legend(loc=\"upper right\")\n",
    "        axes[0].grid(True)\n",
    "\n",
    "        vr_mask = [cov in ['treatmentdurationdays', 'CAPS5score_baseline', 'age'] for cov in covariates]\n",
    "        filtered_y = [i for i, b in enumerate(vr_mask) if b]\n",
    "        filtered_labels = [labels[i] for i in filtered_y]\n",
    "        filtered_vr_unw = [vr_unw[i] for i in filtered_y]\n",
    "        filtered_vr_w = [vr_w[i] for i in filtered_y]\n",
    "\n",
    "        axes[1].scatter(filtered_vr_unw, filtered_y, color='blue', marker='o', label=\"Unweighted\")\n",
    "        axes[1].scatter(filtered_vr_w, filtered_y, color='red', marker='x', label=\"Weighted\")\n",
    "        axes[1].axvline(2, color='gray', linestyle='--')\n",
    "        axes[1].axvline(0.5, color='gray', linestyle='--')\n",
    "        axes[1].set_xlim(0, max(filtered_vr_unw + filtered_vr_w + [2.5]) + 0.5)\n",
    "        axes[1].set_yticks(filtered_y)\n",
    "        axes[1].set_yticklabels(filtered_labels)\n",
    "        axes[1].invert_yaxis()\n",
    "        axes[1].set_title(\"Variance Ratio (VR)\")\n",
    "        axes[1].legend()\n",
    "        axes[1].grid(True)\n",
    "\n",
    "        fig.suptitle(f\"Covariate Balance for {group.replace('CAT_', '')}\", fontsize=14, weight='bold')\n",
    "        fig.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "        plot_path = os.path.join(group_path, f\"love_plot_{group}.pdf\")\n",
    "        fig.savefig(plot_path, dpi=300)\n",
    "        plt.close()\n",
    "        print(f\"✅ Saved love plot: {plot_path}\")\n",
    "        print(f\"📏 Max weighted SMD for {group}: {np.max(smd_w):.3f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error in {group}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0ab142d4-d10c-4ad7-ba2a-fdeb4d489dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1bb78ca6-383e-4d8c-95c9-43271e6ecc64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Creating Heatmap for SUBCAT_Antipsychotica_atypisch ==========\n",
      "✅ Heatmap saved: outputs\\SUBCAT_Antipsychotica_atypisch\\heatmap_smd_SUBCAT_Antipsychotica_atypisch.png\n",
      "\n",
      "========== Creating Heatmap for SUBCAT_TCA ==========\n",
      "✅ Heatmap saved: outputs\\SUBCAT_TCA\\heatmap_smd_SUBCAT_TCA.png\n",
      "\n",
      "========== Creating Heatmap for SUBCAT_SSRI ==========\n",
      "✅ Heatmap saved: outputs\\SUBCAT_SSRI\\heatmap_smd_SUBCAT_SSRI.png\n",
      "\n",
      "========== Creating Heatmap for SUBCAT_SNRI ==========\n",
      "✅ Heatmap saved: outputs\\SUBCAT_SNRI\\heatmap_smd_SUBCAT_SNRI.png\n",
      "\n",
      "========== Creating Heatmap for SUBCAT_Tetracyclische_antidepressiva ==========\n",
      "✅ Heatmap saved: outputs\\SUBCAT_Tetracyclische_antidepressiva\\heatmap_smd_SUBCAT_Tetracyclische_antidepressiva.png\n",
      "\n",
      "========== Creating Heatmap for SUBCAT_Antidepressiva_overige ==========\n",
      "✅ Heatmap saved: outputs\\SUBCAT_Antidepressiva_overige\\heatmap_smd_SUBCAT_Antidepressiva_overige.png\n",
      "\n",
      "========== Creating Heatmap for SUBCAT_Systemische_antihistaminica ==========\n",
      "✅ Heatmap saved: outputs\\SUBCAT_Systemische_antihistaminica\\heatmap_smd_SUBCAT_Systemische_antihistaminica.png\n",
      "\n",
      "========== Creating Heatmap for SUBCAT_anxiolytica_Benzodiazepine ==========\n",
      "✅ Heatmap saved: outputs\\SUBCAT_anxiolytica_Benzodiazepine\\heatmap_smd_SUBCAT_anxiolytica_Benzodiazepine.png\n",
      "\n",
      "========== Creating Heatmap for SUBCAT_hypnotica_Benzodiazepine ==========\n",
      "✅ Heatmap saved: outputs\\SUBCAT_hypnotica_Benzodiazepine\\heatmap_smd_SUBCAT_hypnotica_Benzodiazepine.png\n",
      "\n",
      "========== Creating Heatmap for SUBCAT_Amfetaminen ==========\n",
      "✅ Heatmap saved: outputs\\SUBCAT_Amfetaminen\\heatmap_smd_SUBCAT_Amfetaminen.png\n",
      "\n",
      "========== Creating Heatmap for SUBCAT_Paracetamol_mono ==========\n",
      "✅ Heatmap saved: outputs\\SUBCAT_Paracetamol_mono\\heatmap_smd_SUBCAT_Paracetamol_mono.png\n",
      "\n",
      "========== Creating Heatmap for SUBCAT_Anti_epileptica_stemmingsstabilisatoren ==========\n",
      "✅ Heatmap saved: outputs\\SUBCAT_Anti_epileptica_stemmingsstabilisatoren\\heatmap_smd_SUBCAT_Anti_epileptica_stemmingsstabilisatoren.png\n",
      "\n",
      "========== Creating Heatmap for SUBCAT_Opioden ==========\n",
      "✅ Heatmap saved: outputs\\SUBCAT_Opioden\\heatmap_smd_SUBCAT_Opioden.png\n",
      "\n",
      "========== Creating Heatmap for SUBCAT_Z_drugs ==========\n",
      "✅ Heatmap saved: outputs\\SUBCAT_Z_drugs\\heatmap_smd_SUBCAT_Z_drugs.png\n",
      "\n",
      "========== Creating Heatmap for SUBCAT_NSAIDs ==========\n",
      "✅ Heatmap saved: outputs\\SUBCAT_NSAIDs\\heatmap_smd_SUBCAT_NSAIDs.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "#-----------------------------\n",
    "# Generate heatmaps\n",
    "# -------------------------------\n",
    "for treatment_var in medication_groups:\n",
    "    print(f\"\\n========== Creating Heatmap for {treatment_var} ==========\")\n",
    "\n",
    "    try:\n",
    "        output_folder = os.path.join('outputs', treatment_var)\n",
    "        balance_path = os.path.join(output_folder, f'covariate_balance_table_{treatment_var}.xlsx')\n",
    "\n",
    "        if not os.path.exists(balance_path):\n",
    "            print(f\"❌ Balance file not found: {balance_path}\")\n",
    "            continue\n",
    "\n",
    "        balance_df = pd.read_excel(balance_path)\n",
    "\n",
    "        # ✅ Use finalized covariates + 'Propensity Score'\n",
    "        covariates = final_covariates_map[treatment_var] + ['Propensity Score']\n",
    "        balance_df = balance_df[balance_df['Covariate'].isin(covariates)]\n",
    "\n",
    "        # ✅ Check for CAPS5score_baseline\n",
    "        highlight_caps = 'CAPS5score_baseline' in balance_df['Covariate'].values\n",
    "\n",
    "        # ✅ Format for heatmap\n",
    "        heatmap_df = balance_df[['Covariate', 'SMD_Unweighted', 'SMD_Weighted']].copy()\n",
    "        heatmap_df.columns = ['Covariate', 'Unweighted', 'Weighted']\n",
    "        heatmap_df = heatmap_df.set_index('Covariate')\n",
    "        heatmap_df = heatmap_df.sort_values(by='Unweighted', ascending=False)\n",
    "\n",
    "        # ✅ Plot\n",
    "        plt.figure(figsize=(12, max(10, len(heatmap_df) * 0.35)))\n",
    "        ax = sns.heatmap(\n",
    "            heatmap_df,\n",
    "            cmap=\"coolwarm\",\n",
    "            annot=True,\n",
    "            fmt=\".2f\",\n",
    "            linewidths=0.6,\n",
    "            linecolor='gray',\n",
    "            cbar_kws={\"label\": \"Standardized Mean Difference\"}\n",
    "        )\n",
    "\n",
    "        plt.title(f\"Covariate Balance Heatmap (Rubin IPTW)\\n{treatment_var}\", fontsize=15, weight='bold')\n",
    "        plt.xlabel(\"Condition\")\n",
    "        plt.ylabel(\"Covariate\")\n",
    "\n",
    "        # ✅ Bold CAPS5score_baseline if present\n",
    "        if highlight_caps:\n",
    "            ylabels = [label.get_text() for label in ax.get_yticklabels()]\n",
    "            ax.set_yticklabels([\n",
    "                f\"{label} ←\" if label == 'CAPS5score_baseline' else label for label in ylabels\n",
    "            ])\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # ✅ Save image\n",
    "        save_path = os.path.join(output_folder, f'heatmap_smd_{treatment_var}.png')\n",
    "        plt.savefig(save_path, dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "        print(f\"✅ Heatmap saved: {save_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error processing {treatment_var}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8017939-91a9-45e2-90b0-e309b89f8a89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa951dd2-27ff-43ba-b9fd-c07e234136ff",
   "metadata": {},
   "source": [
    "## SubSubCat Analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "69094b37-2a1f-4e4f-9430-b1f89e29fdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "covariates_SubSubCat_Oxazepam = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antidepressiva', 'CAT_Antipsychotica',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "covariates_SubSubCat_Diazepam = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antidepressiva', 'CAT_Antipsychotica',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "\n",
    "covariates_SubSubCat_Paracetamol = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antidepressiva',\n",
    "    'CAT_Antipsychotica',\n",
    "    'CAT_Benzodiazepine',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "covariates_SubSubCat_Lorazepam = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antidepressiva', 'CAT_Antipsychotica',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "covariates_SubSubCat_Mirtazapine = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antipsychotica',\n",
    "    'CAT_Benzodiazepine',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "covariates_SubSubCat_Escitalopram = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antipsychotica',\n",
    "    'CAT_Benzodiazepine',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "\n",
    "covariates_SubSubCat_Sertraline = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antipsychotica',\n",
    "    'CAT_Benzodiazepine',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "covariates_SubSubCat_Temazepam = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antidepressiva', 'CAT_Antipsychotica',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "covariates_SubSubCat_Citalopram = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antipsychotica',\n",
    "    'CAT_Benzodiazepine',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "covariates_SubSubCat_Quetiapine = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antidepressiva',\n",
    "    'CAT_Benzodiazepine',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "covariates_SubSubCat_Amitriptyline = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antipsychotica',\n",
    "    'CAT_Benzodiazepine',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "\n",
    "covariates_SubSubCat_Venlafaxine = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antipsychotica',\n",
    "    'CAT_Benzodiazepine',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "covariates_SubSubCat_Fluoxetine = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antipsychotica',\n",
    "    'CAT_Benzodiazepine',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "covariates_SubSubCat_Topiramaat = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antidepressiva',\n",
    "    'CAT_Antipsychotica',\n",
    "    'CAT_Benzodiazepine',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "covariates_SubSubCat_Zopiclon = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antidepressiva',\n",
    "    'CAT_Antipsychotica',\n",
    "    'CAT_Benzodiazepine',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "covariates_SubSubCat_Bupropion = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antipsychotica',\n",
    "    'CAT_Benzodiazepine',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "covariates_SubSubCat_Methylfenidaat = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antidepressiva',\n",
    "    'CAT_Antipsychotica',\n",
    "    'CAT_Benzodiazepine',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD',\n",
    "    'DIAGNOSIS_SEXUAL_TRAUMA', 'DIAGNOSIS_SUICIDALITY',\n",
    "    'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "covariates_SubSubCat_Olanzapine = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antidepressiva',\n",
    "    'CAT_Benzodiazepine',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d96d7337-d69e-4554-8337-57adf4d3c977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groups found: ['SubSubCat_Oxazepam', 'SubSubCat_Diazepam', 'SubSubCat_Paracetamol', 'SubSubCat_Lorazepam', 'SubSubCat_Mirtazapine', 'SubSubCat_Escitalopram', 'SubSubCat_Sertraline', 'SubSubCat_Temazepam', 'SubSubCat_Citalopram', 'SubSubCat_Quetiapine', 'SubSubCat_Amitriptyline', 'SubSubCat_Venlafaxine', 'SubSubCat_Fluoxetine', 'SubSubCat_Topiramaat', 'SubSubCat_Zopiclon', 'SubSubCat_Bupropion', 'SubSubCat_Methylfenidaat', 'SubSubCat_Olanzapine']\n",
      "['SubSubCat_Oxazepam', 'SubSubCat_Diazepam', 'SubSubCat_Paracetamol', 'SubSubCat_Lorazepam', 'SubSubCat_Mirtazapine', 'SubSubCat_Escitalopram', 'SubSubCat_Sertraline', 'SubSubCat_Temazepam', 'SubSubCat_Citalopram', 'SubSubCat_Quetiapine', 'SubSubCat_Amitriptyline', 'SubSubCat_Venlafaxine', 'SubSubCat_Fluoxetine', 'SubSubCat_Topiramaat', 'SubSubCat_Zopiclon', 'SubSubCat_Bupropion', 'SubSubCat_Methylfenidaat', 'SubSubCat_Olanzapine']\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# This finds all variables that start with covariates_SUbSubCAT_ or covariates_SubSubcat_\n",
    "final_covariates_map = defaultdict(list)\n",
    "final_covariates_map.update({\n",
    "    var.replace(\"covariates_\", \"\"): val\n",
    "    for var, val in globals().items()\n",
    "    if var.lower().startswith(\"covariates_subsubcat_\") and isinstance(val, list)\n",
    "})\n",
    "\n",
    "# Show detected group names\n",
    "print(\"Groups found:\", list(final_covariates_map.keys()))\n",
    "medication_groups = list(final_covariates_map.keys())\n",
    "print(medication_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0640ebd5-cfed-4ddb-a643-ec647517528a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Starting analysis for all SUBSUBCAT groups\n",
      "\n",
      " Processing SUBSUBCAT_Oxazepam...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBSUBCAT_Oxazepam\n",
      "\n",
      " Processing SUBSUBCAT_Diazepam...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBSUBCAT_Diazepam\n",
      "\n",
      " Processing SUBSUBCAT_Paracetamol...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBSUBCAT_Paracetamol\n",
      "\n",
      " Processing SUBSUBCAT_Lorazepam...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBSUBCAT_Lorazepam\n",
      "\n",
      " Processing SUBSUBCAT_Mirtazapine...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBSUBCAT_Mirtazapine\n",
      "\n",
      " Processing SUBSUBCAT_Escitalopram...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBSUBCAT_Escitalopram\n",
      "\n",
      " Processing SUBSUBCAT_Sertraline...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBSUBCAT_Sertraline\n",
      "\n",
      " Processing SUBSUBCAT_Temazepam...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBSUBCAT_Temazepam\n",
      "\n",
      " Processing SUBSUBCAT_Citalopram...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBSUBCAT_Citalopram\n",
      "\n",
      " Processing SUBSUBCAT_Quetiapine...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBSUBCAT_Quetiapine\n",
      "\n",
      " Processing SUBSUBCAT_Amitriptyline...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBSUBCAT_Amitriptyline\n",
      "\n",
      " Processing SUBSUBCAT_Venlafaxine...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBSUBCAT_Venlafaxine\n",
      "\n",
      " Processing SUBSUBCAT_Fluoxetine...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBSUBCAT_Fluoxetine\n",
      "\n",
      " Processing SUBSUBCAT_Topiramaat...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBSUBCAT_Topiramaat\n",
      "\n",
      " Processing SUBSUBCAT_Zopiclon...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBSUBCAT_Zopiclon\n",
      "\n",
      " Processing SUBSUBCAT_Bupropion...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBSUBCAT_Bupropion\n",
      "\n",
      " Processing SUBSUBCAT_Methylfenidaat...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBSUBCAT_Methylfenidaat\n",
      "\n",
      " Processing SUBSUBCAT_Olanzapine...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBSUBCAT_Olanzapine\n",
      "\n",
      " All SUBSUBCAT group analyses complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def run_all_SUBSUBCAT_group_models(imputed_dfs):\n",
    "    \"\"\"\n",
    "    Runs downstream analysis for each SUBSUBCAT medisubsubcation group using imputed datasets.\n",
    "\n",
    "    Parameters:\n",
    "    - imputed_dfs: list of 5 imputed DataFrames (from df_imputed_final_imp1.pkl ... imp5.pkl)\n",
    "    \n",
    "    Notes:\n",
    "    - Covariate lists must be defined as global variables: covariates_subsubcat_<group>\n",
    "    - Outputs are saved in: outputs/SUBSUBCAT_<GROUP>/\n",
    "    \"\"\"\n",
    "\n",
    "    print(\" Starting analysis for all SUBSUBCAT groups\")\n",
    "\n",
    "    for var_name in globals():\n",
    "        if var_name.lower().startswith(\"covariates_subsubcat_\") and isinstance(globals()[var_name], list):\n",
    "            group_name = var_name.replace(\"covariates_\", \"\")\n",
    "            group_name = group_name.replace(\"_\", \" \").title().replace(\" \", \"_\")  # e.g., subsubcat_z_drugs → Subsubcat_Z_Drugs\n",
    "            group_name = group_name.replace(\"Subsubcat_\", \"SUBSUBCAT_\")  # force prefix to uppercase\n",
    "\n",
    "            covariates = globals()[var_name]\n",
    "            output_dir = f\"outputs/{group_name}\"\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "            print(f\"\\n Processing {group_name}...\")\n",
    "\n",
    "            for k, df_imp in enumerate(imputed_dfs):\n",
    "                print(f\"  → Using imputation {k+1}\")\n",
    "\n",
    "                # Define X and Y\n",
    "                X = df_imp[covariates]\n",
    "                Y = df_imp[\"caps5_change_baseline\"]\n",
    "\n",
    "                # === Save X and Y as placeholder (replace with modeling later)\n",
    "                X.to_csv(f\"{output_dir}/X_imp{k+1}.csv\", index=False)\n",
    "                Y.to_frame(name=\"Y\").to_csv(f\"{output_dir}/Y_imp{k+1}.csv\", index=False)\n",
    "\n",
    "            print(f\" Done: {group_name}\")\n",
    "\n",
    "    print(\"\\n All SUBSUBCAT group analyses complete.\")\n",
    "\n",
    "# ========= STEP 4: Execute ========= #\n",
    "run_all_SUBSUBCAT_group_models(imputed_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c77713ae-0355-4e4f-9a8c-910b53ed4871",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " SubSubCat_Oxazepam\n",
      "  Imp 1: Treated = 206, Control = 3435, Missing = 0\n",
      "  Imp 2: Treated = 206, Control = 3435, Missing = 0\n",
      "  Imp 3: Treated = 206, Control = 3435, Missing = 0\n",
      "  Imp 4: Treated = 206, Control = 3435, Missing = 0\n",
      "  Imp 5: Treated = 206, Control = 3435, Missing = 0\n",
      "\n",
      " SubSubCat_Diazepam\n",
      "  Imp 1: Treated = 42, Control = 3599, Missing = 0\n",
      "  Imp 2: Treated = 42, Control = 3599, Missing = 0\n",
      "  Imp 3: Treated = 42, Control = 3599, Missing = 0\n",
      "  Imp 4: Treated = 42, Control = 3599, Missing = 0\n",
      "  Imp 5: Treated = 42, Control = 3599, Missing = 0\n",
      "\n",
      " SubSubCat_Paracetamol\n",
      "  Imp 1: Treated = 43, Control = 3598, Missing = 0\n",
      "  Imp 2: Treated = 43, Control = 3598, Missing = 0\n",
      "  Imp 3: Treated = 43, Control = 3598, Missing = 0\n",
      "  Imp 4: Treated = 43, Control = 3598, Missing = 0\n",
      "  Imp 5: Treated = 43, Control = 3598, Missing = 0\n",
      "\n",
      " SubSubCat_Lorazepam\n",
      "  Imp 1: Treated = 67, Control = 3574, Missing = 0\n",
      "  Imp 2: Treated = 67, Control = 3574, Missing = 0\n",
      "  Imp 3: Treated = 67, Control = 3574, Missing = 0\n",
      "  Imp 4: Treated = 67, Control = 3574, Missing = 0\n",
      "  Imp 5: Treated = 67, Control = 3574, Missing = 0\n",
      "\n",
      " SubSubCat_Mirtazapine\n",
      "  Imp 1: Treated = 87, Control = 3554, Missing = 0\n",
      "  Imp 2: Treated = 87, Control = 3554, Missing = 0\n",
      "  Imp 3: Treated = 87, Control = 3554, Missing = 0\n",
      "  Imp 4: Treated = 87, Control = 3554, Missing = 0\n",
      "  Imp 5: Treated = 87, Control = 3554, Missing = 0\n",
      "\n",
      " SubSubCat_Escitalopram\n",
      "  Imp 1: Treated = 69, Control = 3572, Missing = 0\n",
      "  Imp 2: Treated = 69, Control = 3572, Missing = 0\n",
      "  Imp 3: Treated = 69, Control = 3572, Missing = 0\n",
      "  Imp 4: Treated = 69, Control = 3572, Missing = 0\n",
      "  Imp 5: Treated = 69, Control = 3572, Missing = 0\n",
      "\n",
      " SubSubCat_Sertraline\n",
      "  Imp 1: Treated = 102, Control = 3539, Missing = 0\n",
      "  Imp 2: Treated = 102, Control = 3539, Missing = 0\n",
      "  Imp 3: Treated = 102, Control = 3539, Missing = 0\n",
      "  Imp 4: Treated = 102, Control = 3539, Missing = 0\n",
      "  Imp 5: Treated = 102, Control = 3539, Missing = 0\n",
      "\n",
      " SubSubCat_Temazepam\n",
      "  Imp 1: Treated = 93, Control = 3548, Missing = 0\n",
      "  Imp 2: Treated = 93, Control = 3548, Missing = 0\n",
      "  Imp 3: Treated = 93, Control = 3548, Missing = 0\n",
      "  Imp 4: Treated = 93, Control = 3548, Missing = 0\n",
      "  Imp 5: Treated = 93, Control = 3548, Missing = 0\n",
      "\n",
      " SubSubCat_Citalopram\n",
      "  Imp 1: Treated = 125, Control = 3516, Missing = 0\n",
      "  Imp 2: Treated = 125, Control = 3516, Missing = 0\n",
      "  Imp 3: Treated = 125, Control = 3516, Missing = 0\n",
      "  Imp 4: Treated = 125, Control = 3516, Missing = 0\n",
      "  Imp 5: Treated = 125, Control = 3516, Missing = 0\n",
      "\n",
      " SubSubCat_Quetiapine\n",
      "  Imp 1: Treated = 203, Control = 3438, Missing = 0\n",
      "  Imp 2: Treated = 203, Control = 3438, Missing = 0\n",
      "  Imp 3: Treated = 203, Control = 3438, Missing = 0\n",
      "  Imp 4: Treated = 203, Control = 3438, Missing = 0\n",
      "  Imp 5: Treated = 203, Control = 3438, Missing = 0\n",
      "\n",
      " SubSubCat_Amitriptyline\n",
      "  Imp 1: Treated = 52, Control = 3589, Missing = 0\n",
      "  Imp 2: Treated = 52, Control = 3589, Missing = 0\n",
      "  Imp 3: Treated = 52, Control = 3589, Missing = 0\n",
      "  Imp 4: Treated = 52, Control = 3589, Missing = 0\n",
      "  Imp 5: Treated = 52, Control = 3589, Missing = 0\n",
      "\n",
      " SubSubCat_Venlafaxine\n",
      "  Imp 1: Treated = 59, Control = 3582, Missing = 0\n",
      "  Imp 2: Treated = 59, Control = 3582, Missing = 0\n",
      "  Imp 3: Treated = 59, Control = 3582, Missing = 0\n",
      "  Imp 4: Treated = 59, Control = 3582, Missing = 0\n",
      "  Imp 5: Treated = 59, Control = 3582, Missing = 0\n",
      "\n",
      " SubSubCat_Fluoxetine\n",
      "  Imp 1: Treated = 71, Control = 3570, Missing = 0\n",
      "  Imp 2: Treated = 71, Control = 3570, Missing = 0\n",
      "  Imp 3: Treated = 71, Control = 3570, Missing = 0\n",
      "  Imp 4: Treated = 71, Control = 3570, Missing = 0\n",
      "  Imp 5: Treated = 71, Control = 3570, Missing = 0\n",
      "\n",
      " SubSubCat_Topiramaat\n",
      "  Imp 1: Treated = 41, Control = 3600, Missing = 0\n",
      "  Imp 2: Treated = 41, Control = 3600, Missing = 0\n",
      "  Imp 3: Treated = 41, Control = 3600, Missing = 0\n",
      "  Imp 4: Treated = 41, Control = 3600, Missing = 0\n",
      "  Imp 5: Treated = 41, Control = 3600, Missing = 0\n",
      "\n",
      " SubSubCat_Zopiclon\n",
      "  Imp 1: Treated = 32, Control = 3609, Missing = 0\n",
      "  Imp 2: Treated = 32, Control = 3609, Missing = 0\n",
      "  Imp 3: Treated = 32, Control = 3609, Missing = 0\n",
      "  Imp 4: Treated = 32, Control = 3609, Missing = 0\n",
      "  Imp 5: Treated = 32, Control = 3609, Missing = 0\n",
      "\n",
      " SubSubCat_Bupropion\n",
      "  Imp 1: Treated = 34, Control = 3607, Missing = 0\n",
      "  Imp 2: Treated = 34, Control = 3607, Missing = 0\n",
      "  Imp 3: Treated = 34, Control = 3607, Missing = 0\n",
      "  Imp 4: Treated = 34, Control = 3607, Missing = 0\n",
      "  Imp 5: Treated = 34, Control = 3607, Missing = 0\n",
      "\n",
      " SubSubCat_Methylfenidaat\n",
      "  Imp 1: Treated = 38, Control = 3603, Missing = 0\n",
      "  Imp 2: Treated = 38, Control = 3603, Missing = 0\n",
      "  Imp 3: Treated = 38, Control = 3603, Missing = 0\n",
      "  Imp 4: Treated = 38, Control = 3603, Missing = 0\n",
      "  Imp 5: Treated = 38, Control = 3603, Missing = 0\n",
      "\n",
      " SubSubCat_Olanzapine\n",
      "  Imp 1: Treated = 33, Control = 3608, Missing = 0\n",
      "  Imp 2: Treated = 33, Control = 3608, Missing = 0\n",
      "  Imp 3: Treated = 33, Control = 3608, Missing = 0\n",
      "  Imp 4: Treated = 33, Control = 3608, Missing = 0\n",
      "  Imp 5: Treated = 33, Control = 3608, Missing = 0\n"
     ]
    }
   ],
   "source": [
    "for treatment_var in medication_groups:\n",
    "    print(f\"\\n {treatment_var}\")\n",
    "    \n",
    "    for i, df in enumerate(imputed_dfs):\n",
    "        if treatment_var not in df.columns:\n",
    "            print(f\"  Imp {i+1}:  Not found in columns.\")\n",
    "            continue\n",
    "\n",
    "        treated = (df[treatment_var] == 1).sum()\n",
    "        control = (df[treatment_var] == 0).sum()\n",
    "        missing = df[treatment_var].isna().sum()\n",
    "\n",
    "        print(f\"  Imp {i+1}: Treated = {treated}, Control = {control}, Missing = {missing}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c34e2dcc-a576-4532-bbb3-69af4010257b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Processing VIF for SubSubCat_Oxazepam\n",
      " ✅ Saved: outputs\\SubSubCat_Oxazepam/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SubSubCat_Diazepam\n",
      " ✅ Saved: outputs\\SubSubCat_Diazepam/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SubSubCat_Paracetamol\n",
      " ✅ Saved: outputs\\SubSubCat_Paracetamol/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SubSubCat_Lorazepam\n",
      " ✅ Saved: outputs\\SubSubCat_Lorazepam/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SubSubCat_Mirtazapine\n",
      " ✅ Saved: outputs\\SubSubCat_Mirtazapine/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SubSubCat_Escitalopram\n",
      " ✅ Saved: outputs\\SubSubCat_Escitalopram/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SubSubCat_Sertraline\n",
      " ✅ Saved: outputs\\SubSubCat_Sertraline/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SubSubCat_Temazepam\n",
      " ✅ Saved: outputs\\SubSubCat_Temazepam/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SubSubCat_Citalopram\n",
      " ✅ Saved: outputs\\SubSubCat_Citalopram/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SubSubCat_Quetiapine\n",
      " ✅ Saved: outputs\\SubSubCat_Quetiapine/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SubSubCat_Amitriptyline\n",
      " ✅ Saved: outputs\\SubSubCat_Amitriptyline/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SubSubCat_Venlafaxine\n",
      " ✅ Saved: outputs\\SubSubCat_Venlafaxine/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SubSubCat_Fluoxetine\n",
      " ✅ Saved: outputs\\SubSubCat_Fluoxetine/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SubSubCat_Topiramaat\n",
      " ✅ Saved: outputs\\SubSubCat_Topiramaat/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SubSubCat_Zopiclon\n",
      " ✅ Saved: outputs\\SubSubCat_Zopiclon/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SubSubCat_Bupropion\n",
      " ✅ Saved: outputs\\SubSubCat_Bupropion/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SubSubCat_Methylfenidaat\n",
      " ✅ Saved: outputs\\SubSubCat_Methylfenidaat/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SubSubCat_Olanzapine\n",
      " ✅ Saved: outputs\\SubSubCat_Olanzapine/pooled_vif.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from collections import defaultdict\n",
    "\n",
    "# ✅ VIF computation function\n",
    "def compute_vif(X):\n",
    "    X = sm.add_constant(X, has_constant='add')\n",
    "    vif_df = pd.DataFrame()\n",
    "    vif_df[\"variable\"] = X.columns\n",
    "    vif_df[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "    return vif_df\n",
    "\n",
    "# ✅ Process each group\n",
    "for group in medication_groups:\n",
    "    print(f\"\\n🔍 Processing VIF for {group}\")\n",
    "\n",
    "    if group not in final_covariates_map:\n",
    "        print(f\" ⚠️ No covariates found for {group}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    covariates = final_covariates_map[group]\n",
    "    vif_list = []\n",
    "\n",
    "    for i, df_imp in enumerate(imputed_dfs):\n",
    "        try:\n",
    "            X = df_imp[covariates].copy()\n",
    "            vif_df = compute_vif(X)\n",
    "            vif_df[\"imputation\"] = i + 1\n",
    "            vif_list.append(vif_df)\n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ Failed on imputation {i+1} for {group}: {e}\")\n",
    "\n",
    "    if vif_list:\n",
    "        all_vif = pd.concat(vif_list)\n",
    "        pooled_vif = all_vif.groupby(\"variable\")[\"VIF\"].mean().reset_index()\n",
    "        pooled_vif = pooled_vif.sort_values(by=\"VIF\", ascending=False)\n",
    "\n",
    "        output_folder = os.path.join(\"outputs\", group)\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        pooled_vif.to_csv(os.path.join(output_folder, \"pooled_vif.csv\"), index=False)\n",
    "\n",
    "        print(f\" ✅ Saved: {output_folder}/pooled_vif.csv\")\n",
    "    else:\n",
    "        print(f\" ⚠️ Skipped {group}: No valid imputations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7a8d4450-4832-4ef7-b6d2-d897899a857b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Running PS estimation for SubSubCat_Oxazepam\n",
      "   Imp 1: AUC = 0.672, ROC saved.\n",
      "   Imp 2: AUC = 0.653, ROC saved.\n",
      "   Imp 3: AUC = 0.651, ROC saved.\n",
      "   Imp 4: AUC = 0.652, ROC saved.\n",
      "   Imp 5: AUC = 0.627, ROC saved.\n",
      " Composite PS + AUC saved for SubSubCat_Oxazepam\n",
      " Running PS estimation for SubSubCat_Diazepam\n",
      "   Imp 1: AUC = 0.719, ROC saved.\n",
      "   Imp 2: AUC = 0.723, ROC saved.\n",
      "   Imp 3: AUC = 0.726, ROC saved.\n",
      "   Imp 4: AUC = 0.746, ROC saved.\n",
      "   Imp 5: AUC = 0.712, ROC saved.\n",
      " Composite PS + AUC saved for SubSubCat_Diazepam\n",
      " Running PS estimation for SubSubCat_Paracetamol\n",
      "   Imp 1: AUC = 0.586, ROC saved.\n",
      "   Imp 2: AUC = 0.618, ROC saved.\n",
      "   Imp 3: AUC = 0.666, ROC saved.\n",
      "   Imp 4: AUC = 0.689, ROC saved.\n",
      "   Imp 5: AUC = 0.654, ROC saved.\n",
      " Composite PS + AUC saved for SubSubCat_Paracetamol\n",
      " Running PS estimation for SubSubCat_Lorazepam\n",
      "   Imp 1: AUC = 0.682, ROC saved.\n",
      "   Imp 2: AUC = 0.690, ROC saved.\n",
      "   Imp 3: AUC = 0.686, ROC saved.\n",
      "   Imp 4: AUC = 0.712, ROC saved.\n",
      "   Imp 5: AUC = 0.650, ROC saved.\n",
      " Composite PS + AUC saved for SubSubCat_Lorazepam\n",
      " Running PS estimation for SubSubCat_Mirtazapine\n",
      "   Imp 1: AUC = 0.643, ROC saved.\n",
      "   Imp 2: AUC = 0.600, ROC saved.\n",
      "   Imp 3: AUC = 0.624, ROC saved.\n",
      "   Imp 4: AUC = 0.644, ROC saved.\n",
      "   Imp 5: AUC = 0.650, ROC saved.\n",
      " Composite PS + AUC saved for SubSubCat_Mirtazapine\n",
      " Running PS estimation for SubSubCat_Escitalopram\n",
      "   Imp 1: AUC = 0.503, ROC saved.\n",
      "   Imp 2: AUC = 0.502, ROC saved.\n",
      "   Imp 3: AUC = 0.494, ROC saved.\n",
      "   Imp 4: AUC = 0.512, ROC saved.\n",
      "   Imp 5: AUC = 0.543, ROC saved.\n",
      " Composite PS + AUC saved for SubSubCat_Escitalopram\n",
      " Running PS estimation for SubSubCat_Sertraline\n",
      "   Imp 1: AUC = 0.682, ROC saved.\n",
      "   Imp 2: AUC = 0.667, ROC saved.\n",
      "   Imp 3: AUC = 0.697, ROC saved.\n",
      "   Imp 4: AUC = 0.715, ROC saved.\n",
      "   Imp 5: AUC = 0.690, ROC saved.\n",
      " Composite PS + AUC saved for SubSubCat_Sertraline\n",
      " Running PS estimation for SubSubCat_Temazepam\n",
      "   Imp 1: AUC = 0.557, ROC saved.\n",
      "   Imp 2: AUC = 0.553, ROC saved.\n",
      "   Imp 3: AUC = 0.537, ROC saved.\n",
      "   Imp 4: AUC = 0.461, ROC saved.\n",
      "   Imp 5: AUC = 0.527, ROC saved.\n",
      " Composite PS + AUC saved for SubSubCat_Temazepam\n",
      " Running PS estimation for SubSubCat_Citalopram\n",
      "   Imp 1: AUC = 0.636, ROC saved.\n",
      "   Imp 2: AUC = 0.679, ROC saved.\n",
      "   Imp 3: AUC = 0.635, ROC saved.\n",
      "   Imp 4: AUC = 0.649, ROC saved.\n",
      "   Imp 5: AUC = 0.657, ROC saved.\n",
      " Composite PS + AUC saved for SubSubCat_Citalopram\n",
      " Running PS estimation for SubSubCat_Quetiapine\n",
      "   Imp 1: AUC = 0.783, ROC saved.\n",
      "   Imp 2: AUC = 0.785, ROC saved.\n",
      "   Imp 3: AUC = 0.787, ROC saved.\n",
      "   Imp 4: AUC = 0.783, ROC saved.\n",
      "   Imp 5: AUC = 0.772, ROC saved.\n",
      " Composite PS + AUC saved for SubSubCat_Quetiapine\n",
      " Running PS estimation for SubSubCat_Amitriptyline\n",
      "   Imp 1: AUC = 0.578, ROC saved.\n",
      "   Imp 2: AUC = 0.485, ROC saved.\n",
      "   Imp 3: AUC = 0.527, ROC saved.\n",
      "   Imp 4: AUC = 0.533, ROC saved.\n",
      "   Imp 5: AUC = 0.584, ROC saved.\n",
      " Composite PS + AUC saved for SubSubCat_Amitriptyline\n",
      " Running PS estimation for SubSubCat_Venlafaxine\n",
      "   Imp 1: AUC = 0.673, ROC saved.\n",
      "   Imp 2: AUC = 0.703, ROC saved.\n",
      "   Imp 3: AUC = 0.654, ROC saved.\n",
      "   Imp 4: AUC = 0.679, ROC saved.\n",
      "   Imp 5: AUC = 0.687, ROC saved.\n",
      " Composite PS + AUC saved for SubSubCat_Venlafaxine\n",
      " Running PS estimation for SubSubCat_Fluoxetine\n",
      "   Imp 1: AUC = 0.690, ROC saved.\n",
      "   Imp 2: AUC = 0.673, ROC saved.\n",
      "   Imp 3: AUC = 0.688, ROC saved.\n",
      "   Imp 4: AUC = 0.700, ROC saved.\n",
      "   Imp 5: AUC = 0.721, ROC saved.\n",
      " Composite PS + AUC saved for SubSubCat_Fluoxetine\n",
      " Running PS estimation for SubSubCat_Topiramaat\n",
      "   Imp 1: AUC = 0.754, ROC saved.\n",
      "   Imp 2: AUC = 0.771, ROC saved.\n",
      "   Imp 3: AUC = 0.779, ROC saved.\n",
      "   Imp 4: AUC = 0.823, ROC saved.\n",
      "   Imp 5: AUC = 0.803, ROC saved.\n",
      " Composite PS + AUC saved for SubSubCat_Topiramaat\n",
      " Running PS estimation for SubSubCat_Zopiclon\n",
      "   Imp 1: AUC = 0.660, ROC saved.\n",
      "   Imp 2: AUC = 0.646, ROC saved.\n",
      "   Imp 3: AUC = 0.669, ROC saved.\n",
      "   Imp 4: AUC = 0.673, ROC saved.\n",
      "   Imp 5: AUC = 0.632, ROC saved.\n",
      " Composite PS + AUC saved for SubSubCat_Zopiclon\n",
      " Running PS estimation for SubSubCat_Bupropion\n",
      "   Imp 1: AUC = 0.477, ROC saved.\n",
      "   Imp 2: AUC = 0.537, ROC saved.\n",
      "   Imp 3: AUC = 0.501, ROC saved.\n",
      "   Imp 4: AUC = 0.524, ROC saved.\n",
      "   Imp 5: AUC = 0.545, ROC saved.\n",
      " Composite PS + AUC saved for SubSubCat_Bupropion\n",
      " Running PS estimation for SubSubCat_Methylfenidaat\n",
      "   Imp 1: AUC = 0.650, ROC saved.\n",
      "   Imp 2: AUC = 0.654, ROC saved.\n",
      "   Imp 3: AUC = 0.621, ROC saved.\n",
      "   Imp 4: AUC = 0.700, ROC saved.\n",
      "   Imp 5: AUC = 0.640, ROC saved.\n",
      " Composite PS + AUC saved for SubSubCat_Methylfenidaat\n",
      " Running PS estimation for SubSubCat_Olanzapine\n",
      "   Imp 1: AUC = 0.595, ROC saved.\n",
      "   Imp 2: AUC = 0.626, ROC saved.\n",
      "   Imp 3: AUC = 0.625, ROC saved.\n",
      "   Imp 4: AUC = 0.656, ROC saved.\n",
      "   Imp 5: AUC = 0.621, ROC saved.\n",
      " Composite PS + AUC saved for SubSubCat_Olanzapine\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ---------- PS Estimation Function ----------\n",
    "def run_xgboost_ps_modeling(imputed_dfs, medication_groups, final_covariates_map):\n",
    "    for group in medication_groups:\n",
    "        print(f\" Running PS estimation for {group}\")\n",
    "\n",
    "        if group not in final_covariates_map:\n",
    "            print(f\" No covariates found for {group}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        output_folder = os.path.join(\"outputs\", group)\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "        covariates = final_covariates_map[group]\n",
    "        ps_matrix = pd.DataFrame()\n",
    "        auc_list = []\n",
    "\n",
    "        for i, df_imp in enumerate(imputed_dfs):\n",
    "            if group not in df_imp.columns:\n",
    "                print(f\" {group} not found in imputed dataset {i+1}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            X = df_imp[covariates].copy()\n",
    "            T = df_imp[group]\n",
    "\n",
    "            # Drop missing treatment rows\n",
    "            valid_idx = T.dropna().index\n",
    "            X = X.loc[valid_idx]\n",
    "            T = T.loc[valid_idx]\n",
    "\n",
    "            # Train-test split for ROC\n",
    "            X_train, X_test, T_train, T_test = train_test_split(\n",
    "                X, T, stratify=T, test_size=0.3, random_state=42\n",
    "            )\n",
    "\n",
    "            try:\n",
    "                model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "                model.fit(X_train, T_train)\n",
    "\n",
    "                ps_scores = model.predict_proba(X)[:, 1]\n",
    "                ps_matrix[f\"ps_imp{i+1}\"] = pd.Series(ps_scores, index=valid_idx)\n",
    "\n",
    "                # ROC & AUC\n",
    "                auc = roc_auc_score(T_test, model.predict_proba(X_test)[:, 1])\n",
    "                auc_list.append(auc)\n",
    "\n",
    "                fpr, tpr, _ = roc_curve(T_test, model.predict_proba(X_test)[:, 1])\n",
    "                plt.figure()\n",
    "                plt.plot(fpr, tpr, label=f\"AUC = {auc:.3f}\")\n",
    "                plt.plot([0, 1], [0, 1], 'k--')\n",
    "                plt.xlabel(\"False Positive Rate\")\n",
    "                plt.ylabel(\"True Positive Rate\")\n",
    "                plt.title(f\"ROC Curve - {group} (Imp {i+1})\")\n",
    "                plt.legend()\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(os.path.join(output_folder, f\"roc_curve_imp{i+1}.png\"))\n",
    "                plt.close()\n",
    "                print(f\"   Imp {i+1}: AUC = {auc:.3f}, ROC saved.\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"   Error in {group} (imp {i+1}): {e}\")\n",
    "\n",
    "        # Save AUCs and Composite PS\n",
    "        if not ps_matrix.empty:\n",
    "            # Fill NaN rows (from dropped subjects in some imputations) with mean\n",
    "            ps_matrix[\"composite_ps\"] = ps_matrix.mean(axis=1)\n",
    "            ps_matrix.to_excel(os.path.join(output_folder, \"propensity_scores.xlsx\"))\n",
    "\n",
    "            auc_df = pd.DataFrame({\n",
    "                \"imputation\": [f\"imp{i+1}\" for i in range(len(auc_list))],\n",
    "                \"AUC\": auc_list\n",
    "            })\n",
    "            auc_df.loc[len(auc_df.index)] = [\"mean\", np.mean(auc_list) if auc_list else np.nan]\n",
    "            auc_df.to_excel(os.path.join(output_folder, \"auc_scores.xlsx\"), index=False)\n",
    "\n",
    "            print(f\" Composite PS + AUC saved for {group}\")\n",
    "        else:\n",
    "            print(f\" No valid PS scores generated for {group}\")\n",
    "\n",
    "# ---------- Run ----------\n",
    "run_xgboost_ps_modeling(imputed_dfs, medication_groups, final_covariates_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "72499bbd-b193-4443-8b30-450bd11aa408",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Computing feature importance for SubSubCat_Oxazepam\n",
      " Saved feature importance plot and CSV for SubSubCat_Oxazepam\n",
      "\n",
      " Computing feature importance for SubSubCat_Diazepam\n",
      " Saved feature importance plot and CSV for SubSubCat_Diazepam\n",
      "\n",
      " Computing feature importance for SubSubCat_Paracetamol\n",
      " Saved feature importance plot and CSV for SubSubCat_Paracetamol\n",
      "\n",
      " Computing feature importance for SubSubCat_Lorazepam\n",
      " Saved feature importance plot and CSV for SubSubCat_Lorazepam\n",
      "\n",
      " Computing feature importance for SubSubCat_Mirtazapine\n",
      " Saved feature importance plot and CSV for SubSubCat_Mirtazapine\n",
      "\n",
      " Computing feature importance for SubSubCat_Escitalopram\n",
      " Saved feature importance plot and CSV for SubSubCat_Escitalopram\n",
      "\n",
      " Computing feature importance for SubSubCat_Sertraline\n",
      " Saved feature importance plot and CSV for SubSubCat_Sertraline\n",
      "\n",
      " Computing feature importance for SubSubCat_Temazepam\n",
      " Saved feature importance plot and CSV for SubSubCat_Temazepam\n",
      "\n",
      " Computing feature importance for SubSubCat_Citalopram\n",
      " Saved feature importance plot and CSV for SubSubCat_Citalopram\n",
      "\n",
      " Computing feature importance for SubSubCat_Quetiapine\n",
      " Saved feature importance plot and CSV for SubSubCat_Quetiapine\n",
      "\n",
      " Computing feature importance for SubSubCat_Amitriptyline\n",
      " Saved feature importance plot and CSV for SubSubCat_Amitriptyline\n",
      "\n",
      " Computing feature importance for SubSubCat_Venlafaxine\n",
      " Saved feature importance plot and CSV for SubSubCat_Venlafaxine\n",
      "\n",
      " Computing feature importance for SubSubCat_Fluoxetine\n",
      " Saved feature importance plot and CSV for SubSubCat_Fluoxetine\n",
      "\n",
      " Computing feature importance for SubSubCat_Topiramaat\n",
      " Saved feature importance plot and CSV for SubSubCat_Topiramaat\n",
      "\n",
      " Computing feature importance for SubSubCat_Zopiclon\n",
      " Saved feature importance plot and CSV for SubSubCat_Zopiclon\n",
      "\n",
      " Computing feature importance for SubSubCat_Bupropion\n",
      " Saved feature importance plot and CSV for SubSubCat_Bupropion\n",
      "\n",
      " Computing feature importance for SubSubCat_Methylfenidaat\n",
      " Saved feature importance plot and CSV for SubSubCat_Methylfenidaat\n",
      "\n",
      " Computing feature importance for SubSubCat_Olanzapine\n",
      " Saved feature importance plot and CSV for SubSubCat_Olanzapine\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "def compute_feature_importance(imputed_dfs, medication_groups, final_covariates_map):\n",
    "    for group in medication_groups:\n",
    "        print(f\"\\n Computing feature importance for {group}\")\n",
    "\n",
    "        if group not in final_covariates_map:\n",
    "            print(f\" No covariates found for {group}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        covariates = final_covariates_map[group]\n",
    "        output_folder = os.path.join(\"outputs\", group)\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "        importance_df_list = []\n",
    "\n",
    "        for i, df_imp in enumerate(imputed_dfs):\n",
    "            if group not in df_imp.columns:\n",
    "                print(f\" {group} not in imputed dataset {i+1}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            X = df_imp[covariates].copy()\n",
    "            T = df_imp[group]\n",
    "\n",
    "            # Drop NaNs in treatment\n",
    "            valid_idx = T.dropna().index\n",
    "            X = X.loc[valid_idx]\n",
    "            T = T.loc[valid_idx]\n",
    "\n",
    "            try:\n",
    "                model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "                model.fit(X, T)\n",
    "\n",
    "                # Get feature importance\n",
    "                importances = model.get_booster().get_score(importance_type='gain')\n",
    "                df_feat = pd.DataFrame.from_dict(importances, orient='index', columns=[f\"imp{i+1}\"])\n",
    "                df_feat.index.name = 'feature'\n",
    "                importance_df_list.append(df_feat)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"   Error during modeling: {e}\")\n",
    "\n",
    "        if importance_df_list:\n",
    "            # Combine and average\n",
    "            all_feat = pd.concat(importance_df_list, axis=1).fillna(0)\n",
    "            all_feat[\"mean_importance\"] = all_feat.mean(axis=1)\n",
    "\n",
    "            # Filter top 30 non-zero\n",
    "            non_zero = all_feat[all_feat[\"mean_importance\"] > 0]\n",
    "            top30 = non_zero.sort_values(by=\"mean_importance\", ascending=False).head(30)\n",
    "\n",
    "            # Save to CSV\n",
    "            top30.to_csv(os.path.join(output_folder, \"feature_importance.csv\"))\n",
    "\n",
    "            # Plot\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            plt.barh(top30.index[::-1], top30[\"mean_importance\"][::-1])  # plot top → bottom\n",
    "            plt.xlabel(\"Mean Gain Importance\")\n",
    "            plt.title(f\"Top 30 Feature Importance - {group}\")\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(output_folder, \"feature_importance_top30.png\"))\n",
    "            plt.close()\n",
    "\n",
    "            print(f\" Saved feature importance plot and CSV for {group}\")\n",
    "        else:\n",
    "            print(f\" No valid models for {group}\")\n",
    "\n",
    "#  Run\n",
    "compute_feature_importance(imputed_dfs, medication_groups, final_covariates_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f765c036-655f-4b4b-abee-ae90a001eb24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SubSubCat_Oxazepam\n",
      "✅ Saved IPTW weights for SubSubCat_Oxazepam\n",
      "    ℹ️ Retained 610/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Oxazepam/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 576/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Oxazepam/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 603/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Oxazepam/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 578/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Oxazepam/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 584/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Oxazepam/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SubSubCat_Diazepam\n",
      "✅ Saved IPTW weights for SubSubCat_Diazepam\n",
      "    ℹ️ Retained 88/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Diazepam/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 95/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Diazepam/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 99/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Diazepam/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 90/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Diazepam/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 101/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Diazepam/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SubSubCat_Paracetamol\n",
      "✅ Saved IPTW weights for SubSubCat_Paracetamol\n",
      "    ℹ️ Retained 78/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Paracetamol/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 76/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Paracetamol/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 67/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Paracetamol/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 62/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Paracetamol/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 68/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Paracetamol/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SubSubCat_Lorazepam\n",
      "✅ Saved IPTW weights for SubSubCat_Lorazepam\n",
      "    ℹ️ Retained 127/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Lorazepam/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 148/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Lorazepam/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 147/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Lorazepam/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 139/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Lorazepam/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 143/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Lorazepam/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SubSubCat_Mirtazapine\n",
      "✅ Saved IPTW weights for SubSubCat_Mirtazapine\n",
      "    ℹ️ Retained 154/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Mirtazapine/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 169/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Mirtazapine/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 174/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Mirtazapine/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 170/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Mirtazapine/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 164/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Mirtazapine/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SubSubCat_Escitalopram\n",
      "✅ Saved IPTW weights for SubSubCat_Escitalopram\n",
      "    ℹ️ Retained 142/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Escitalopram/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 149/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Escitalopram/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 156/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Escitalopram/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 152/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Escitalopram/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 144/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Escitalopram/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SubSubCat_Sertraline\n",
      "✅ Saved IPTW weights for SubSubCat_Sertraline\n",
      "    ℹ️ Retained 240/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Sertraline/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 261/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Sertraline/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 225/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Sertraline/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 263/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Sertraline/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 251/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Sertraline/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SubSubCat_Temazepam\n",
      "✅ Saved IPTW weights for SubSubCat_Temazepam\n",
      "    ℹ️ Retained 195/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Temazepam/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 200/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Temazepam/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 202/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Temazepam/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 203/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Temazepam/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 186/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Temazepam/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SubSubCat_Citalopram\n",
      "✅ Saved IPTW weights for SubSubCat_Citalopram\n",
      "    ℹ️ Retained 359/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Citalopram/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 345/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Citalopram/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 362/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Citalopram/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 333/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Citalopram/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 341/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Citalopram/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SubSubCat_Quetiapine\n",
      "✅ Saved IPTW weights for SubSubCat_Quetiapine\n",
      "    ℹ️ Retained 510/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Quetiapine/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 524/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Quetiapine/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 493/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Quetiapine/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 540/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Quetiapine/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 486/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Quetiapine/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SubSubCat_Amitriptyline\n",
      "✅ Saved IPTW weights for SubSubCat_Amitriptyline\n",
      "    ℹ️ Retained 107/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Amitriptyline/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 109/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Amitriptyline/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 102/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Amitriptyline/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 108/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Amitriptyline/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 101/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Amitriptyline/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SubSubCat_Venlafaxine\n",
      "✅ Saved IPTW weights for SubSubCat_Venlafaxine\n",
      "    ℹ️ Retained 121/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Venlafaxine/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 114/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Venlafaxine/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 109/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Venlafaxine/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 114/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Venlafaxine/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 120/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Venlafaxine/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SubSubCat_Fluoxetine\n",
      "✅ Saved IPTW weights for SubSubCat_Fluoxetine\n",
      "    ℹ️ Retained 147/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Fluoxetine/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 148/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Fluoxetine/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 137/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Fluoxetine/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 145/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Fluoxetine/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 152/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Fluoxetine/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SubSubCat_Topiramaat\n",
      "✅ Saved IPTW weights for SubSubCat_Topiramaat\n",
      "    ℹ️ Retained 75/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Topiramaat/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 81/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Topiramaat/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 74/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Topiramaat/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 69/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Topiramaat/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 72/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Topiramaat/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SubSubCat_Zopiclon\n",
      "✅ Saved IPTW weights for SubSubCat_Zopiclon\n",
      "    ℹ️ Retained 58/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Zopiclon/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 71/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Zopiclon/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 65/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Zopiclon/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 67/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Zopiclon/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 65/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Zopiclon/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SubSubCat_Bupropion\n",
      "✅ Saved IPTW weights for SubSubCat_Bupropion\n",
      "    ℹ️ Retained 53/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Bupropion/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 62/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Bupropion/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 57/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Bupropion/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 62/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Bupropion/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 52/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Bupropion/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SubSubCat_Methylfenidaat\n",
      "✅ Saved IPTW weights for SubSubCat_Methylfenidaat\n",
      "    ℹ️ Retained 80/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Methylfenidaat/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 73/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Methylfenidaat/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 81/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Methylfenidaat/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 73/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Methylfenidaat/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 74/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Methylfenidaat/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SubSubCat_Olanzapine\n",
      "✅ Saved IPTW weights for SubSubCat_Olanzapine\n",
      "    ℹ️ Retained 59/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Olanzapine/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 58/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Olanzapine/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 59/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Olanzapine/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 62/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Olanzapine/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 58/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Olanzapine/trimmed_data_imp5.*\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_trimmed_clipped_iptw(ps_df, treatment, lower=0.05, upper=0.95, clip_max=10):\n",
    "    weights = []\n",
    "    keep_mask = (ps_df > lower) & (ps_df < upper)\n",
    "\n",
    "    for i in range(ps_df.shape[1]):\n",
    "        ps = ps_df.iloc[:, i].clip(lower=1e-6, upper=1 - 1e-6)  # avoid div by zero\n",
    "        mask = keep_mask.iloc[:, i]\n",
    "        w = pd.Series(np.nan, index=ps.index)\n",
    "\n",
    "        w[mask & (treatment == 1)] = 1 / ps[mask & (treatment == 1)]\n",
    "        w[mask & (treatment == 0)] = 1 / (1 - ps[mask & (treatment == 0)])\n",
    "        w = w.clip(upper=clip_max)\n",
    "        weights.append(w)\n",
    "\n",
    "    return pd.concat(weights, axis=1)\n",
    "\n",
    "\n",
    "def apply_rubins_rule_to_iptw(iptw_matrix):\n",
    "    \"\"\"\n",
    "    Given an IPTW matrix (n rows × M imputations), return Rubin’s rule pooled mean, SD, SE.\n",
    "    \"\"\"\n",
    "    M = iptw_matrix.shape[1]\n",
    "    q_bar = iptw_matrix.mean(axis=1)\n",
    "    u_bar = iptw_matrix.var(axis=1, ddof=1)\n",
    "    B = iptw_matrix.apply(lambda x: x.mean(), axis=1).var(ddof=1)\n",
    "    total_var = u_bar + (1 + 1/M) * B\n",
    "    total_se = np.sqrt(total_var)\n",
    "    return q_bar, u_bar.pow(0.5), total_se\n",
    "\n",
    "\n",
    "def run_trim_clip_save_all(imputed_dfs, medication_groups, final_covariates_map):\n",
    "    for group in medication_groups:\n",
    "        print(f\"\\n🔍 Processing IPTW + trimming + clipping for {group}\")\n",
    "        output_folder = os.path.join(\"outputs\", group)\n",
    "        ps_path = os.path.join(output_folder, \"propensity_scores.xlsx\")\n",
    "\n",
    "        if not os.path.exists(ps_path):\n",
    "            print(f\"⚠️ Missing PS file: {ps_path}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            ps_all = pd.read_excel(ps_path, index_col=0)\n",
    "            ps_cols = [col for col in ps_all.columns if col.startswith(\"ps_imp\")]\n",
    "            composite_index = ps_all.index\n",
    "\n",
    "            # Get treatment from one imputed dataset\n",
    "            T_full = None\n",
    "            for df in imputed_dfs:\n",
    "                if group in df.columns:\n",
    "                    T_full = df.loc[composite_index, group]\n",
    "                    break\n",
    "\n",
    "            if T_full is None:\n",
    "                print(f\"❌ Treatment column {group} not found in any imputed dataset.\")\n",
    "                continue\n",
    "\n",
    "            # Compute IPTW matrix (shape: n × M)\n",
    "            iptw_matrix = compute_trimmed_clipped_iptw(ps_all[ps_cols], T_full)\n",
    "            iptw_matrix.columns = [f\"iptw_imp{i+1}\" for i in range(iptw_matrix.shape[1])]\n",
    "\n",
    "            # Apply Rubin’s Rule for mean, SD, SE\n",
    "            iptw_matrix[\"iptw_mean\"], iptw_matrix[\"iptw_sd\"], iptw_matrix[\"iptw_se\"] = apply_rubins_rule_to_iptw(\n",
    "                iptw_matrix[[f\"iptw_imp{i+1}\" for i in range(iptw_matrix.shape[1])]]\n",
    "            )\n",
    "\n",
    "            # Save IPTW matrix separately\n",
    "            iptw_matrix.to_excel(os.path.join(output_folder, \"iptw_weights.xlsx\"))\n",
    "            print(f\"✅ Saved IPTW weights for {group}\")\n",
    "\n",
    "            # Save trimmed & clipped imputed datasets with IPTW\n",
    "            for i in range(5):\n",
    "                df = imputed_dfs[i].copy()\n",
    "                if group not in df.columns:\n",
    "                    continue\n",
    "\n",
    "                trimmed_idx = iptw_matrix.index.intersection(df.index)\n",
    "                needed_cols = final_covariates_map[group] + [group, \"caps5_change_baseline\"]\n",
    "\n",
    "                # Select only necessary columns\n",
    "                df_trimmed = df.loc[trimmed_idx, needed_cols].copy()\n",
    "                df_trimmed[\"iptw\"] = iptw_matrix[f\"iptw_imp{i+1}\"].loc[trimmed_idx]\n",
    "\n",
    "                # ✅ DROP rows with missing IPTW values\n",
    "                before = len(df_trimmed)\n",
    "                df_trimmed = df_trimmed.dropna(subset=[\"iptw\"])\n",
    "                after = len(df_trimmed)\n",
    "                print(f\"    ℹ️ Retained {after}/{before} rows after IPTW NaN drop.\")\n",
    "\n",
    "                # Save to .pkl\n",
    "                df_trimmed.to_pickle(os.path.join(output_folder, f\"trimmed_data_imp{i+1}.pkl\"))\n",
    "                print(f\"  💾 Saved trimmed dataset: {output_folder}/trimmed_data_imp{i+1}.*\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error in {group}: {e}\")\n",
    "\n",
    "\n",
    "run_trim_clip_save_all(imputed_dfs, medication_groups, final_covariates_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "268b3d7e-ac3b-4300-9aeb-6089727c4787",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Plotting PS overlap for SubSubCat_Oxazepam\n",
      "✅ Saved unweighted and weighted PS plots for SubSubCat_Oxazepam\n",
      "\n",
      "📊 Plotting PS overlap for SubSubCat_Diazepam\n",
      "✅ Saved unweighted and weighted PS plots for SubSubCat_Diazepam\n",
      "\n",
      "📊 Plotting PS overlap for SubSubCat_Paracetamol\n",
      "✅ Saved unweighted and weighted PS plots for SubSubCat_Paracetamol\n",
      "\n",
      "📊 Plotting PS overlap for SubSubCat_Lorazepam\n",
      "✅ Saved unweighted and weighted PS plots for SubSubCat_Lorazepam\n",
      "\n",
      "📊 Plotting PS overlap for SubSubCat_Mirtazapine\n",
      "✅ Saved unweighted and weighted PS plots for SubSubCat_Mirtazapine\n",
      "\n",
      "📊 Plotting PS overlap for SubSubCat_Escitalopram\n",
      "✅ Saved unweighted and weighted PS plots for SubSubCat_Escitalopram\n",
      "\n",
      "📊 Plotting PS overlap for SubSubCat_Sertraline\n",
      "✅ Saved unweighted and weighted PS plots for SubSubCat_Sertraline\n",
      "\n",
      "📊 Plotting PS overlap for SubSubCat_Temazepam\n",
      "✅ Saved unweighted and weighted PS plots for SubSubCat_Temazepam\n",
      "\n",
      "📊 Plotting PS overlap for SubSubCat_Citalopram\n",
      "✅ Saved unweighted and weighted PS plots for SubSubCat_Citalopram\n",
      "\n",
      "📊 Plotting PS overlap for SubSubCat_Quetiapine\n",
      "✅ Saved unweighted and weighted PS plots for SubSubCat_Quetiapine\n",
      "\n",
      "📊 Plotting PS overlap for SubSubCat_Amitriptyline\n",
      "✅ Saved unweighted and weighted PS plots for SubSubCat_Amitriptyline\n",
      "\n",
      "📊 Plotting PS overlap for SubSubCat_Venlafaxine\n",
      "✅ Saved unweighted and weighted PS plots for SubSubCat_Venlafaxine\n",
      "\n",
      "📊 Plotting PS overlap for SubSubCat_Fluoxetine\n",
      "✅ Saved unweighted and weighted PS plots for SubSubCat_Fluoxetine\n",
      "\n",
      "📊 Plotting PS overlap for SubSubCat_Topiramaat\n",
      "✅ Saved unweighted and weighted PS plots for SubSubCat_Topiramaat\n",
      "\n",
      "📊 Plotting PS overlap for SubSubCat_Zopiclon\n",
      "✅ Saved unweighted and weighted PS plots for SubSubCat_Zopiclon\n",
      "\n",
      "📊 Plotting PS overlap for SubSubCat_Bupropion\n",
      "✅ Saved unweighted and weighted PS plots for SubSubCat_Bupropion\n",
      "\n",
      "📊 Plotting PS overlap for SubSubCat_Methylfenidaat\n",
      "✅ Saved unweighted and weighted PS plots for SubSubCat_Methylfenidaat\n",
      "\n",
      "📊 Plotting PS overlap for SubSubCat_Olanzapine\n",
      "✅ Saved unweighted and weighted PS plots for SubSubCat_Olanzapine\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_ps_overlap_all_groups(medication_groups):\n",
    "    for group in medication_groups:\n",
    "        print(f\"\\n📊 Plotting PS overlap for {group}\")\n",
    "\n",
    "        folder = os.path.join(\"outputs\", group)\n",
    "        ps_file = os.path.join(folder, \"propensity_scores.xlsx\")\n",
    "        iptw_file = os.path.join(folder, \"iptw_weights.xlsx\")\n",
    "        trimmed_file = os.path.join(folder, \"trimmed_data_imp1.pkl\")\n",
    "\n",
    "        if not all(os.path.exists(f) for f in [ps_file, iptw_file, trimmed_file]):\n",
    "            print(f\"⚠️ Missing required files for {group}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            ps_df = pd.read_excel(ps_file, index_col=0)\n",
    "            iptw_df = pd.read_excel(iptw_file, index_col=0)\n",
    "            trimmed_df = pd.read_pickle(trimmed_file)\n",
    "\n",
    "            # Extract\n",
    "            ps = ps_df[\"composite_ps\"].reindex(trimmed_df.index)\n",
    "            w = iptw_df[\"iptw_mean\"].reindex(trimmed_df.index)\n",
    "            T = trimmed_df[group]\n",
    "\n",
    "            # Masks to remove NaNs\n",
    "            treated_mask = (T == 1) & ps.notna() & w.notna()\n",
    "            control_mask = (T == 0) & ps.notna() & w.notna()\n",
    "\n",
    "            treated = ps[treated_mask]\n",
    "            treated_w = w[treated_mask]\n",
    "\n",
    "            control = ps[control_mask]\n",
    "            control_w = w[control_mask]\n",
    "\n",
    "            # === Unweighted Plot ===\n",
    "            plt.figure(figsize=(8, 5))\n",
    "            plt.hist([treated, control], bins=25, label=[\"Treated\", \"Control\"], alpha=0.6)\n",
    "            plt.title(f\"Unweighted PS Overlap - {group}\")\n",
    "            plt.xlabel(\"Composite Propensity Score\")\n",
    "            plt.ylabel(\"Count\")\n",
    "            plt.legend()\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(folder, \"ps_overlap_unweighted.png\"))\n",
    "            plt.close()\n",
    "\n",
    "            # === Weighted Plot ===\n",
    "            plt.figure(figsize=(8, 5))\n",
    "            plt.hist([treated, control], bins=25, weights=[treated_w, control_w], label=[\"Treated\", \"Control\"], alpha=0.6)\n",
    "            plt.title(f\"Weighted PS Overlap - {group}\")\n",
    "            plt.xlabel(\"Composite Propensity Score\")\n",
    "            plt.ylabel(\"Weighted Count\")\n",
    "            plt.legend()\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(folder, \"ps_overlap_weighted.png\"))\n",
    "            plt.close()\n",
    "\n",
    "            print(f\"✅ Saved unweighted and weighted PS plots for {group}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error processing {group}: {e}\")\n",
    "\n",
    "# 🔁 Run\n",
    "plot_ps_overlap_all_groups(medication_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1bd15f13-2739-42d0-9532-0904b6f03336",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ✅ Saved: outputs\\SubSubCat_Oxazepam\\four_panel_overlap_SubSubCat_Oxazepam.png\n",
      " ✅ Saved: outputs\\SubSubCat_Diazepam\\four_panel_overlap_SubSubCat_Diazepam.png\n",
      " ✅ Saved: outputs\\SubSubCat_Paracetamol\\four_panel_overlap_SubSubCat_Paracetamol.png\n",
      " ✅ Saved: outputs\\SubSubCat_Lorazepam\\four_panel_overlap_SubSubCat_Lorazepam.png\n",
      " ✅ Saved: outputs\\SubSubCat_Mirtazapine\\four_panel_overlap_SubSubCat_Mirtazapine.png\n",
      " ✅ Saved: outputs\\SubSubCat_Escitalopram\\four_panel_overlap_SubSubCat_Escitalopram.png\n",
      " ✅ Saved: outputs\\SubSubCat_Sertraline\\four_panel_overlap_SubSubCat_Sertraline.png\n",
      " ✅ Saved: outputs\\SubSubCat_Temazepam\\four_panel_overlap_SubSubCat_Temazepam.png\n",
      " ✅ Saved: outputs\\SubSubCat_Citalopram\\four_panel_overlap_SubSubCat_Citalopram.png\n",
      " ✅ Saved: outputs\\SubSubCat_Quetiapine\\four_panel_overlap_SubSubCat_Quetiapine.png\n",
      " ✅ Saved: outputs\\SubSubCat_Amitriptyline\\four_panel_overlap_SubSubCat_Amitriptyline.png\n",
      " ✅ Saved: outputs\\SubSubCat_Venlafaxine\\four_panel_overlap_SubSubCat_Venlafaxine.png\n",
      " ✅ Saved: outputs\\SubSubCat_Fluoxetine\\four_panel_overlap_SubSubCat_Fluoxetine.png\n",
      " ✅ Saved: outputs\\SubSubCat_Topiramaat\\four_panel_overlap_SubSubCat_Topiramaat.png\n",
      " ✅ Saved: outputs\\SubSubCat_Zopiclon\\four_panel_overlap_SubSubCat_Zopiclon.png\n",
      " ✅ Saved: outputs\\SubSubCat_Bupropion\\four_panel_overlap_SubSubCat_Bupropion.png\n",
      " ✅ Saved: outputs\\SubSubCat_Methylfenidaat\\four_panel_overlap_SubSubCat_Methylfenidaat.png\n",
      " ✅ Saved: outputs\\SubSubCat_Olanzapine\\four_panel_overlap_SubSubCat_Olanzapine.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set up base output folder\n",
    "output_base = \"outputs\"\n",
    "ps_file = \"propensity_scores.xlsx\"\n",
    "iptw_file = \"iptw_weights.xlsx\"\n",
    "trimmed_data_file = \"trimmed_data_imp1.pkl\"\n",
    "\n",
    "# Collect all treatment group folders\n",
    "groups = [g for g in medication_groups if os.path.isdir(os.path.join(output_base, g))]\n",
    "\n",
    "# Generate 4-panel overlap plots\n",
    "for group in groups:\n",
    "    group_path = os.path.join(output_base, group)\n",
    "    try:\n",
    "        # Load trimmed treatment info\n",
    "        trimmed_df = pd.read_pickle(os.path.join(group_path, trimmed_data_file))\n",
    "        index = trimmed_df.index\n",
    "\n",
    "        # Fix: case-insensitive match for treatment variable\n",
    "        possible_cols = [col for col in trimmed_df.columns if col.upper() == group.upper()]\n",
    "        if not possible_cols:\n",
    "            print(f\" Treatment variable {group} not found in {group}, skipping.\")\n",
    "            continue\n",
    "        treatment_var = possible_cols[0]\n",
    "        T = trimmed_df[treatment_var]\n",
    "\n",
    "        # Load composite PS (aligned to trimmed_df index)\n",
    "        ps_df = pd.read_excel(os.path.join(group_path, ps_file), index_col=0)\n",
    "        if 'composite_ps' not in ps_df.columns:\n",
    "            print(f\" Composite column missing in {ps_file}, skipping {group}.\")\n",
    "            continue\n",
    "        ps = ps_df.loc[index, 'composite_ps']\n",
    "\n",
    "        # Load IPTW weights (aligned to trimmed_df index)\n",
    "        weights_df = pd.read_excel(os.path.join(group_path, iptw_file), index_col=0)\n",
    "        if 'iptw_mean' not in weights_df.columns:\n",
    "            print(f\" IPTW weight column missing in {iptw_file}, skipping {group}.\")\n",
    "            continue\n",
    "        weights = weights_df.loc[index, 'iptw_mean']\n",
    "\n",
    "        # Prepare 4 datasets\n",
    "        raw_treated = ps[T == 1]\n",
    "        raw_control = ps[T == 0]\n",
    "        weighted_treated = (ps[T == 1], weights[T == 1])\n",
    "        weighted_control = (ps[T == 0], weights[T == 0])\n",
    "\n",
    "        # Create plot\n",
    "        fig, axs = plt.subplots(2, 2, figsize=(12, 8))\n",
    "        fig.suptitle(f\"Propensity Score Distribution - {group}\", fontsize=14)\n",
    "\n",
    "        axs[0, 0].hist(raw_treated, bins=20, alpha=0.7, color='blue')\n",
    "        axs[0, 0].set_title(\"Raw Treated\")\n",
    "\n",
    "        axs[0, 1].hist(raw_control, bins=20, alpha=0.7, color='green')\n",
    "        axs[0, 1].set_title(\"Raw Control\")\n",
    "\n",
    "        axs[1, 0].hist(weighted_treated[0], bins=20, weights=weighted_treated[1], alpha=0.7, color='blue')\n",
    "        axs[1, 0].set_title(\"Weighted Treated\")\n",
    "\n",
    "        axs[1, 1].hist(weighted_control[0], bins=20, weights=weighted_control[1], alpha=0.7, color='green')\n",
    "        axs[1, 1].set_title(\"Weighted Control\")\n",
    "\n",
    "        for ax in axs.flat:\n",
    "            ax.set_xlim(0, 1)\n",
    "            ax.set_xlabel(\"Propensity Score\")\n",
    "            ax.set_ylabel(\"Count\")\n",
    "\n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "\n",
    "        # Save figure\n",
    "        plot_path = os.path.join(group_path, f\"four_panel_overlap_{group}.png\")\n",
    "        plt.savefig(plot_path)\n",
    "        plt.close()\n",
    "        print(f\" ✅ Saved: {plot_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\" ❌ Error in {group}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "35e9e7aa-87a4-4cba-bfcd-245fd505fec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ATT calculation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "37ecf92b-090c-4b5f-8a78-cc19d881e434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weighted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "31fa2d03-12f9-4dc4-b4d1-06ce5b1731cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Running DML for SubSubCat_Oxazepam\n",
      "✅ SubSubCat_Oxazepam | Seed 1: ATT = 0.6527, SE = 1.3843, p = 0.63834\n",
      "✅ SubSubCat_Oxazepam | Seed 2: ATT = 0.7134, SE = 1.4110, p = 0.61426\n",
      "✅ SubSubCat_Oxazepam | Seed 3: ATT = 0.6063, SE = 1.5022, p = 0.68737\n",
      "✅ SubSubCat_Oxazepam | Seed 4: ATT = 0.6071, SE = 1.4114, p = 0.66800\n",
      "✅ SubSubCat_Oxazepam | Seed 5: ATT = 0.6610, SE = 1.4360, p = 0.64630\n",
      "✅ SubSubCat_Oxazepam | Seed 6: ATT = 0.5329, SE = 1.4188, p = 0.70803\n",
      "✅ SubSubCat_Oxazepam | Seed 7: ATT = 0.6002, SE = 1.3367, p = 0.65441\n",
      "✅ SubSubCat_Oxazepam | Seed 8: ATT = 0.4871, SE = 1.5357, p = 0.75176\n",
      "✅ SubSubCat_Oxazepam | Seed 9: ATT = 0.6092, SE = 1.4326, p = 0.67160\n",
      "✅ SubSubCat_Oxazepam | Seed 10: ATT = 0.6056, SE = 1.4057, p = 0.66755\n",
      "📊 Diagnostic plots saved for SubSubCat_Oxazepam\n",
      "🏆 Best result for SubSubCat_Oxazepam → Seed 7 | SE = 1.3367\n",
      "\n",
      "🚀 Running DML for SubSubCat_Diazepam\n",
      "✅ SubSubCat_Diazepam | Seed 1: ATT = -1.3232, SE = 3.7871, p = 0.72754\n",
      "✅ SubSubCat_Diazepam | Seed 2: ATT = -1.4191, SE = 4.1503, p = 0.73313\n",
      "✅ SubSubCat_Diazepam | Seed 3: ATT = -1.3169, SE = 3.7653, p = 0.72728\n",
      "✅ SubSubCat_Diazepam | Seed 4: ATT = -1.4382, SE = 4.0496, p = 0.72325\n",
      "✅ SubSubCat_Diazepam | Seed 5: ATT = -1.1518, SE = 4.0410, p = 0.77622\n",
      "✅ SubSubCat_Diazepam | Seed 6: ATT = -1.1376, SE = 3.5616, p = 0.75009\n",
      "✅ SubSubCat_Diazepam | Seed 7: ATT = -1.3825, SE = 3.3470, p = 0.68045\n",
      "✅ SubSubCat_Diazepam | Seed 8: ATT = -1.0571, SE = 3.4623, p = 0.76076\n",
      "✅ SubSubCat_Diazepam | Seed 9: ATT = -0.8227, SE = 3.9887, p = 0.83702\n",
      "✅ SubSubCat_Diazepam | Seed 10: ATT = -1.0244, SE = 3.4116, p = 0.76459\n",
      "📊 Diagnostic plots saved for SubSubCat_Diazepam\n",
      "🏆 Best result for SubSubCat_Diazepam → Seed 7 | SE = 3.3470\n",
      "\n",
      "🚀 Running DML for SubSubCat_Paracetamol\n",
      "✅ SubSubCat_Paracetamol | Seed 1: ATT = 2.0393, SE = 4.3711, p = 0.64185\n",
      "✅ SubSubCat_Paracetamol | Seed 2: ATT = 2.7907, SE = 4.2355, p = 0.51150\n",
      "✅ SubSubCat_Paracetamol | Seed 3: ATT = 2.8694, SE = 4.5707, p = 0.53159\n",
      "✅ SubSubCat_Paracetamol | Seed 4: ATT = 2.1570, SE = 4.4108, p = 0.62591\n",
      "✅ SubSubCat_Paracetamol | Seed 5: ATT = 2.4375, SE = 4.3892, p = 0.57991\n",
      "✅ SubSubCat_Paracetamol | Seed 6: ATT = 2.3889, SE = 4.5852, p = 0.60354\n",
      "✅ SubSubCat_Paracetamol | Seed 7: ATT = 2.5179, SE = 4.8509, p = 0.60488\n",
      "✅ SubSubCat_Paracetamol | Seed 8: ATT = 2.3308, SE = 4.6639, p = 0.61836\n",
      "✅ SubSubCat_Paracetamol | Seed 9: ATT = 2.3820, SE = 4.8038, p = 0.62109\n",
      "✅ SubSubCat_Paracetamol | Seed 10: ATT = 2.3697, SE = 4.8779, p = 0.62818\n",
      "📊 Diagnostic plots saved for SubSubCat_Paracetamol\n",
      "🏆 Best result for SubSubCat_Paracetamol → Seed 2 | SE = 4.2355\n",
      "\n",
      "🚀 Running DML for SubSubCat_Lorazepam\n",
      "✅ SubSubCat_Lorazepam | Seed 1: ATT = 1.1563, SE = 3.0307, p = 0.70362\n",
      "✅ SubSubCat_Lorazepam | Seed 2: ATT = 0.8529, SE = 2.9947, p = 0.77639\n",
      "✅ SubSubCat_Lorazepam | Seed 3: ATT = 0.9185, SE = 3.2865, p = 0.78045\n",
      "✅ SubSubCat_Lorazepam | Seed 4: ATT = 0.8674, SE = 3.1949, p = 0.78657\n",
      "✅ SubSubCat_Lorazepam | Seed 5: ATT = 1.3621, SE = 2.8281, p = 0.63112\n",
      "✅ SubSubCat_Lorazepam | Seed 6: ATT = 0.9842, SE = 2.7087, p = 0.71713\n",
      "✅ SubSubCat_Lorazepam | Seed 7: ATT = 0.8184, SE = 2.8787, p = 0.77678\n",
      "✅ SubSubCat_Lorazepam | Seed 8: ATT = 0.6718, SE = 2.8390, p = 0.81343\n",
      "✅ SubSubCat_Lorazepam | Seed 9: ATT = 0.9912, SE = 3.0773, p = 0.74805\n",
      "✅ SubSubCat_Lorazepam | Seed 10: ATT = 0.5370, SE = 2.7393, p = 0.84498\n",
      "📊 Diagnostic plots saved for SubSubCat_Lorazepam\n",
      "🏆 Best result for SubSubCat_Lorazepam → Seed 6 | SE = 2.7087\n",
      "\n",
      "🚀 Running DML for SubSubCat_Mirtazapine\n",
      "✅ SubSubCat_Mirtazapine | Seed 1: ATT = 8.8453, SE = 2.9544, p = 0.00348\n",
      "✅ SubSubCat_Mirtazapine | Seed 2: ATT = 8.7660, SE = 2.8774, p = 0.00297\n",
      "✅ SubSubCat_Mirtazapine | Seed 3: ATT = 8.7492, SE = 2.7258, p = 0.00179\n",
      "✅ SubSubCat_Mirtazapine | Seed 4: ATT = 8.5771, SE = 2.8307, p = 0.00312\n",
      "✅ SubSubCat_Mirtazapine | Seed 5: ATT = 8.7557, SE = 2.9581, p = 0.00385\n",
      "✅ SubSubCat_Mirtazapine | Seed 6: ATT = 8.6977, SE = 2.6920, p = 0.00168\n",
      "✅ SubSubCat_Mirtazapine | Seed 7: ATT = 8.7939, SE = 3.0799, p = 0.00524\n",
      "✅ SubSubCat_Mirtazapine | Seed 8: ATT = 8.8507, SE = 3.0207, p = 0.00421\n",
      "✅ SubSubCat_Mirtazapine | Seed 9: ATT = 8.6696, SE = 2.9896, p = 0.00460\n",
      "✅ SubSubCat_Mirtazapine | Seed 10: ATT = 8.4923, SE = 2.9715, p = 0.00520\n",
      "📊 Diagnostic plots saved for SubSubCat_Mirtazapine\n",
      "🏆 Best result for SubSubCat_Mirtazapine → Seed 6 | SE = 2.6920\n",
      "\n",
      "🚀 Running DML for SubSubCat_Escitalopram\n",
      "✅ SubSubCat_Escitalopram | Seed 1: ATT = 0.1966, SE = 2.4541, p = 0.93630\n",
      "✅ SubSubCat_Escitalopram | Seed 2: ATT = 0.4981, SE = 2.5910, p = 0.84794\n",
      "✅ SubSubCat_Escitalopram | Seed 3: ATT = 0.4340, SE = 2.7187, p = 0.87349\n",
      "✅ SubSubCat_Escitalopram | Seed 4: ATT = 0.4350, SE = 2.6587, p = 0.87038\n",
      "✅ SubSubCat_Escitalopram | Seed 5: ATT = 0.3349, SE = 2.3212, p = 0.88558\n",
      "✅ SubSubCat_Escitalopram | Seed 6: ATT = 0.7932, SE = 2.3717, p = 0.73876\n",
      "✅ SubSubCat_Escitalopram | Seed 7: ATT = 0.4450, SE = 2.4224, p = 0.85462\n",
      "✅ SubSubCat_Escitalopram | Seed 8: ATT = 0.2534, SE = 2.6672, p = 0.92452\n",
      "✅ SubSubCat_Escitalopram | Seed 9: ATT = 0.4624, SE = 2.4170, p = 0.84868\n",
      "✅ SubSubCat_Escitalopram | Seed 10: ATT = 0.4433, SE = 2.5709, p = 0.86343\n",
      "📊 Diagnostic plots saved for SubSubCat_Escitalopram\n",
      "🏆 Best result for SubSubCat_Escitalopram → Seed 5 | SE = 2.3212\n",
      "\n",
      "🚀 Running DML for SubSubCat_Sertraline\n",
      "✅ SubSubCat_Sertraline | Seed 1: ATT = 0.5238, SE = 1.8419, p = 0.77671\n",
      "✅ SubSubCat_Sertraline | Seed 2: ATT = 0.2312, SE = 1.9544, p = 0.90607\n",
      "✅ SubSubCat_Sertraline | Seed 3: ATT = 0.3969, SE = 2.1489, p = 0.85383\n",
      "✅ SubSubCat_Sertraline | Seed 4: ATT = 0.3160, SE = 1.8292, p = 0.86322\n",
      "✅ SubSubCat_Sertraline | Seed 5: ATT = 0.3894, SE = 2.0592, p = 0.85038\n",
      "✅ SubSubCat_Sertraline | Seed 6: ATT = 0.3213, SE = 1.7509, p = 0.85477\n",
      "✅ SubSubCat_Sertraline | Seed 7: ATT = 0.3184, SE = 1.7735, p = 0.85787\n",
      "✅ SubSubCat_Sertraline | Seed 8: ATT = 0.2716, SE = 1.7489, p = 0.87688\n",
      "✅ SubSubCat_Sertraline | Seed 9: ATT = 0.2944, SE = 1.7014, p = 0.86298\n",
      "✅ SubSubCat_Sertraline | Seed 10: ATT = 0.3241, SE = 1.7609, p = 0.85436\n",
      "📊 Diagnostic plots saved for SubSubCat_Sertraline\n",
      "🏆 Best result for SubSubCat_Sertraline → Seed 9 | SE = 1.7014\n",
      "\n",
      "🚀 Running DML for SubSubCat_Temazepam\n",
      "✅ SubSubCat_Temazepam | Seed 1: ATT = -0.3017, SE = 2.2241, p = 0.89236\n",
      "✅ SubSubCat_Temazepam | Seed 2: ATT = 0.0155, SE = 2.2429, p = 0.99450\n",
      "✅ SubSubCat_Temazepam | Seed 3: ATT = -0.3720, SE = 2.1375, p = 0.86220\n",
      "✅ SubSubCat_Temazepam | Seed 4: ATT = -0.1711, SE = 1.9734, p = 0.93109\n",
      "✅ SubSubCat_Temazepam | Seed 5: ATT = -0.5194, SE = 2.3110, p = 0.82263\n",
      "✅ SubSubCat_Temazepam | Seed 6: ATT = -0.4595, SE = 2.2809, p = 0.84076\n",
      "✅ SubSubCat_Temazepam | Seed 7: ATT = -0.2792, SE = 2.0926, p = 0.89412\n",
      "✅ SubSubCat_Temazepam | Seed 8: ATT = -0.3069, SE = 2.1562, p = 0.88710\n",
      "✅ SubSubCat_Temazepam | Seed 9: ATT = -0.3453, SE = 2.3902, p = 0.88542\n",
      "✅ SubSubCat_Temazepam | Seed 10: ATT = -0.2872, SE = 2.0755, p = 0.89022\n",
      "📊 Diagnostic plots saved for SubSubCat_Temazepam\n",
      "🏆 Best result for SubSubCat_Temazepam → Seed 4 | SE = 1.9734\n",
      "\n",
      "🚀 Running DML for SubSubCat_Citalopram\n",
      "✅ SubSubCat_Citalopram | Seed 1: ATT = -3.2279, SE = 1.8197, p = 0.07916\n",
      "✅ SubSubCat_Citalopram | Seed 2: ATT = -3.2054, SE = 1.9687, p = 0.10667\n",
      "✅ SubSubCat_Citalopram | Seed 3: ATT = -3.1389, SE = 2.0491, p = 0.12876\n",
      "✅ SubSubCat_Citalopram | Seed 4: ATT = -3.1384, SE = 1.9064, p = 0.10289\n",
      "✅ SubSubCat_Citalopram | Seed 5: ATT = -3.2287, SE = 1.7981, p = 0.07560\n",
      "✅ SubSubCat_Citalopram | Seed 6: ATT = -3.4447, SE = 1.8798, p = 0.06990\n",
      "✅ SubSubCat_Citalopram | Seed 7: ATT = -3.2367, SE = 1.9653, p = 0.10275\n",
      "✅ SubSubCat_Citalopram | Seed 8: ATT = -3.1659, SE = 1.9899, p = 0.11479\n",
      "✅ SubSubCat_Citalopram | Seed 9: ATT = -3.2362, SE = 1.9459, p = 0.09945\n",
      "✅ SubSubCat_Citalopram | Seed 10: ATT = -3.0967, SE = 1.8858, p = 0.10375\n",
      "📊 Diagnostic plots saved for SubSubCat_Citalopram\n",
      "🏆 Best result for SubSubCat_Citalopram → Seed 5 | SE = 1.7981\n",
      "\n",
      "🚀 Running DML for SubSubCat_Quetiapine\n",
      "✅ SubSubCat_Quetiapine | Seed 1: ATT = 1.6134, SE = 1.7131, p = 0.34858\n",
      "✅ SubSubCat_Quetiapine | Seed 2: ATT = 1.4029, SE = 1.5253, p = 0.35994\n",
      "✅ SubSubCat_Quetiapine | Seed 3: ATT = 1.5053, SE = 1.7141, p = 0.38196\n",
      "✅ SubSubCat_Quetiapine | Seed 4: ATT = 1.6057, SE = 1.6939, p = 0.34545\n",
      "✅ SubSubCat_Quetiapine | Seed 5: ATT = 1.5086, SE = 1.6131, p = 0.35195\n",
      "✅ SubSubCat_Quetiapine | Seed 6: ATT = 1.4680, SE = 1.7839, p = 0.41253\n",
      "✅ SubSubCat_Quetiapine | Seed 7: ATT = 1.6238, SE = 1.7595, p = 0.35831\n",
      "✅ SubSubCat_Quetiapine | Seed 8: ATT = 1.4698, SE = 1.6664, p = 0.37990\n",
      "✅ SubSubCat_Quetiapine | Seed 9: ATT = 1.5487, SE = 1.5934, p = 0.33344\n",
      "✅ SubSubCat_Quetiapine | Seed 10: ATT = 1.5426, SE = 1.6235, p = 0.34434\n",
      "📊 Diagnostic plots saved for SubSubCat_Quetiapine\n",
      "🏆 Best result for SubSubCat_Quetiapine → Seed 2 | SE = 1.5253\n",
      "\n",
      "🚀 Running DML for SubSubCat_Amitriptyline\n",
      "✅ SubSubCat_Amitriptyline | Seed 1: ATT = 4.6490, SE = 3.5496, p = 0.19331\n",
      "✅ SubSubCat_Amitriptyline | Seed 2: ATT = 4.3387, SE = 3.4989, p = 0.21790\n",
      "✅ SubSubCat_Amitriptyline | Seed 3: ATT = 4.4433, SE = 3.7854, p = 0.24329\n",
      "✅ SubSubCat_Amitriptyline | Seed 4: ATT = 4.5808, SE = 3.3340, p = 0.17256\n",
      "✅ SubSubCat_Amitriptyline | Seed 5: ATT = 4.7673, SE = 3.2978, p = 0.15145\n",
      "✅ SubSubCat_Amitriptyline | Seed 6: ATT = 4.2046, SE = 4.4584, p = 0.34795\n",
      "✅ SubSubCat_Amitriptyline | Seed 7: ATT = 4.8078, SE = 3.7875, p = 0.20728\n",
      "✅ SubSubCat_Amitriptyline | Seed 8: ATT = 4.5218, SE = 4.2883, p = 0.29425\n",
      "✅ SubSubCat_Amitriptyline | Seed 9: ATT = 4.7955, SE = 3.8829, p = 0.21974\n",
      "✅ SubSubCat_Amitriptyline | Seed 10: ATT = 4.9822, SE = 3.2112, p = 0.12397\n",
      "📊 Diagnostic plots saved for SubSubCat_Amitriptyline\n",
      "🏆 Best result for SubSubCat_Amitriptyline → Seed 10 | SE = 3.2112\n",
      "\n",
      "🚀 Running DML for SubSubCat_Venlafaxine\n",
      "✅ SubSubCat_Venlafaxine | Seed 1: ATT = 2.0775, SE = 3.3320, p = 0.53438\n",
      "✅ SubSubCat_Venlafaxine | Seed 2: ATT = 1.4582, SE = 3.4414, p = 0.67270\n",
      "✅ SubSubCat_Venlafaxine | Seed 3: ATT = 1.9661, SE = 3.5331, p = 0.57914\n",
      "✅ SubSubCat_Venlafaxine | Seed 4: ATT = 1.9169, SE = 3.3814, p = 0.57206\n",
      "✅ SubSubCat_Venlafaxine | Seed 5: ATT = 1.9263, SE = 3.1907, p = 0.54740\n",
      "✅ SubSubCat_Venlafaxine | Seed 6: ATT = 1.6692, SE = 3.4734, p = 0.63189\n",
      "✅ SubSubCat_Venlafaxine | Seed 7: ATT = 1.6872, SE = 3.6553, p = 0.64540\n",
      "✅ SubSubCat_Venlafaxine | Seed 8: ATT = 2.0200, SE = 3.3220, p = 0.54454\n",
      "✅ SubSubCat_Venlafaxine | Seed 9: ATT = 2.3639, SE = 3.4984, p = 0.50079\n",
      "✅ SubSubCat_Venlafaxine | Seed 10: ATT = 2.0985, SE = 3.5614, p = 0.55706\n",
      "📊 Diagnostic plots saved for SubSubCat_Venlafaxine\n",
      "🏆 Best result for SubSubCat_Venlafaxine → Seed 5 | SE = 3.1907\n",
      "\n",
      "🚀 Running DML for SubSubCat_Fluoxetine\n",
      "✅ SubSubCat_Fluoxetine | Seed 1: ATT = 4.5066, SE = 3.0167, p = 0.13839\n",
      "✅ SubSubCat_Fluoxetine | Seed 2: ATT = 4.8799, SE = 2.8279, p = 0.08754\n",
      "✅ SubSubCat_Fluoxetine | Seed 3: ATT = 4.8613, SE = 2.9608, p = 0.10379\n",
      "✅ SubSubCat_Fluoxetine | Seed 4: ATT = 5.1212, SE = 2.8052, p = 0.07093\n",
      "✅ SubSubCat_Fluoxetine | Seed 5: ATT = 5.2372, SE = 3.0643, p = 0.09057\n",
      "✅ SubSubCat_Fluoxetine | Seed 6: ATT = 4.9068, SE = 3.0700, p = 0.11317\n",
      "✅ SubSubCat_Fluoxetine | Seed 7: ATT = 4.6555, SE = 3.3378, p = 0.16620\n",
      "✅ SubSubCat_Fluoxetine | Seed 8: ATT = 5.1241, SE = 2.8146, p = 0.07170\n",
      "✅ SubSubCat_Fluoxetine | Seed 9: ATT = 5.0199, SE = 3.0580, p = 0.10385\n",
      "✅ SubSubCat_Fluoxetine | Seed 10: ATT = 4.8991, SE = 2.9179, p = 0.09631\n",
      "📊 Diagnostic plots saved for SubSubCat_Fluoxetine\n",
      "🏆 Best result for SubSubCat_Fluoxetine → Seed 4 | SE = 2.8052\n",
      "\n",
      "🚀 Running DML for SubSubCat_Topiramaat\n",
      "✅ SubSubCat_Topiramaat | Seed 1: ATT = 7.1274, SE = 5.6473, p = 0.20988\n",
      "✅ SubSubCat_Topiramaat | Seed 2: ATT = 7.3441, SE = 6.6016, p = 0.26862\n",
      "✅ SubSubCat_Topiramaat | Seed 3: ATT = 8.6964, SE = 8.4120, p = 0.30375\n",
      "✅ SubSubCat_Topiramaat | Seed 4: ATT = 8.0655, SE = 12.2565, p = 0.51202\n",
      "✅ SubSubCat_Topiramaat | Seed 5: ATT = 7.7918, SE = 7.0322, p = 0.27053\n",
      "✅ SubSubCat_Topiramaat | Seed 6: ATT = 7.2091, SE = 7.3665, p = 0.33015\n",
      "✅ SubSubCat_Topiramaat | Seed 7: ATT = 7.3087, SE = 6.1638, p = 0.23856\n",
      "✅ SubSubCat_Topiramaat | Seed 8: ATT = 8.3569, SE = 7.9155, p = 0.29364\n",
      "✅ SubSubCat_Topiramaat | Seed 9: ATT = 8.2950, SE = 9.8076, p = 0.39972\n",
      "✅ SubSubCat_Topiramaat | Seed 10: ATT = 7.2182, SE = 6.2251, p = 0.24903\n",
      "📊 Diagnostic plots saved for SubSubCat_Topiramaat\n",
      "🏆 Best result for SubSubCat_Topiramaat → Seed 1 | SE = 5.6473\n",
      "\n",
      "🚀 Running DML for SubSubCat_Zopiclon\n",
      "✅ SubSubCat_Zopiclon | Seed 1: ATT = 1.0251, SE = 10.2480, p = 0.92052\n",
      "✅ SubSubCat_Zopiclon | Seed 2: ATT = 0.4405, SE = 10.2092, p = 0.96567\n",
      "✅ SubSubCat_Zopiclon | Seed 3: ATT = 0.6628, SE = 8.6882, p = 0.93935\n",
      "✅ SubSubCat_Zopiclon | Seed 4: ATT = 0.1910, SE = 11.4958, p = 0.98678\n",
      "✅ SubSubCat_Zopiclon | Seed 5: ATT = 0.3667, SE = 6.5287, p = 0.95532\n",
      "✅ SubSubCat_Zopiclon | Seed 6: ATT = 1.6562, SE = 6.3178, p = 0.79375\n",
      "✅ SubSubCat_Zopiclon | Seed 7: ATT = 0.9971, SE = 9.4529, p = 0.91621\n",
      "✅ SubSubCat_Zopiclon | Seed 8: ATT = 1.1025, SE = 7.7315, p = 0.88690\n",
      "✅ SubSubCat_Zopiclon | Seed 9: ATT = 2.5886, SE = 16.1902, p = 0.87329\n",
      "✅ SubSubCat_Zopiclon | Seed 10: ATT = 2.1027, SE = 15.3774, p = 0.89151\n",
      "📊 Diagnostic plots saved for SubSubCat_Zopiclon\n",
      "🏆 Best result for SubSubCat_Zopiclon → Seed 6 | SE = 6.3178\n",
      "\n",
      "🚀 Running DML for SubSubCat_Bupropion\n",
      "✅ SubSubCat_Bupropion | Seed 1: ATT = 2.9073, SE = 5.4649, p = 0.59592\n",
      "✅ SubSubCat_Bupropion | Seed 2: ATT = 3.8209, SE = 5.5643, p = 0.49389\n",
      "✅ SubSubCat_Bupropion | Seed 3: ATT = 3.4532, SE = 6.3474, p = 0.58764\n",
      "✅ SubSubCat_Bupropion | Seed 4: ATT = 3.1377, SE = 6.3388, p = 0.62170\n",
      "✅ SubSubCat_Bupropion | Seed 5: ATT = 3.3692, SE = 6.5833, p = 0.60995\n",
      "✅ SubSubCat_Bupropion | Seed 6: ATT = 3.2916, SE = 7.0730, p = 0.64269\n",
      "✅ SubSubCat_Bupropion | Seed 7: ATT = 3.8932, SE = 6.0209, p = 0.51938\n",
      "✅ SubSubCat_Bupropion | Seed 8: ATT = 3.2358, SE = 5.9981, p = 0.59077\n",
      "✅ SubSubCat_Bupropion | Seed 9: ATT = 2.8553, SE = 5.6852, p = 0.61662\n",
      "✅ SubSubCat_Bupropion | Seed 10: ATT = 3.1450, SE = 6.6174, p = 0.63564\n",
      "📊 Diagnostic plots saved for SubSubCat_Bupropion\n",
      "🏆 Best result for SubSubCat_Bupropion → Seed 1 | SE = 5.4649\n",
      "\n",
      "🚀 Running DML for SubSubCat_Methylfenidaat\n",
      "✅ SubSubCat_Methylfenidaat | Seed 1: ATT = -0.7484, SE = 4.4270, p = 0.86609\n",
      "✅ SubSubCat_Methylfenidaat | Seed 2: ATT = -0.7586, SE = 4.6987, p = 0.87207\n",
      "✅ SubSubCat_Methylfenidaat | Seed 3: ATT = -0.5290, SE = 4.2693, p = 0.90165\n",
      "✅ SubSubCat_Methylfenidaat | Seed 4: ATT = -0.3121, SE = 4.7528, p = 0.94777\n",
      "✅ SubSubCat_Methylfenidaat | Seed 5: ATT = -0.4045, SE = 4.1304, p = 0.92219\n",
      "✅ SubSubCat_Methylfenidaat | Seed 6: ATT = -0.3439, SE = 4.0180, p = 0.93197\n",
      "✅ SubSubCat_Methylfenidaat | Seed 7: ATT = -1.2674, SE = 4.3500, p = 0.77139\n",
      "✅ SubSubCat_Methylfenidaat | Seed 8: ATT = -0.0668, SE = 5.3294, p = 0.99002\n",
      "✅ SubSubCat_Methylfenidaat | Seed 9: ATT = -0.4513, SE = 4.1317, p = 0.91324\n",
      "✅ SubSubCat_Methylfenidaat | Seed 10: ATT = -0.2132, SE = 4.6424, p = 0.96346\n",
      "📊 Diagnostic plots saved for SubSubCat_Methylfenidaat\n",
      "🏆 Best result for SubSubCat_Methylfenidaat → Seed 6 | SE = 4.0180\n",
      "\n",
      "🚀 Running DML for SubSubCat_Olanzapine\n",
      "✅ SubSubCat_Olanzapine | Seed 1: ATT = 2.5668, SE = 8.8625, p = 0.77271\n",
      "✅ SubSubCat_Olanzapine | Seed 2: ATT = 2.7274, SE = 8.4931, p = 0.74879\n",
      "✅ SubSubCat_Olanzapine | Seed 3: ATT = 2.2632, SE = 8.7422, p = 0.79627\n",
      "✅ SubSubCat_Olanzapine | Seed 4: ATT = 1.7907, SE = 8.2512, p = 0.82863\n",
      "✅ SubSubCat_Olanzapine | Seed 5: ATT = 2.2532, SE = 9.5122, p = 0.81324\n",
      "✅ SubSubCat_Olanzapine | Seed 6: ATT = 2.1699, SE = 7.4068, p = 0.77016\n",
      "✅ SubSubCat_Olanzapine | Seed 7: ATT = 1.7464, SE = 7.7035, p = 0.82112\n",
      "✅ SubSubCat_Olanzapine | Seed 8: ATT = 2.1646, SE = 7.5800, p = 0.77580\n",
      "✅ SubSubCat_Olanzapine | Seed 9: ATT = 0.8563, SE = 7.4907, p = 0.90922\n",
      "✅ SubSubCat_Olanzapine | Seed 10: ATT = 2.3691, SE = 7.1173, p = 0.73994\n",
      "📊 Diagnostic plots saved for SubSubCat_Olanzapine\n",
      "🏆 Best result for SubSubCat_Olanzapine → Seed 10 | SE = 7.1173\n",
      "\n",
      "🎯 All summary files saved.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "from econml.dml import LinearDML\n",
    "from scipy.stats import t, probplot\n",
    "import xgboost as xgb\n",
    "\n",
    "# -----------------------------\n",
    "# Configuration\n",
    "# -----------------------------\n",
    "n_repeats = 4\n",
    "seeds = list(range(1, 11))\n",
    "imputations = 5\n",
    "output_folder = \"outputs\"\n",
    "\n",
    "# -----------------------------\n",
    "# Diagnostic Plotting Function\n",
    "# -----------------------------\n",
    "def create_diagnostic_plots(residuals_data, fitted_data, group_name):\n",
    "    \"\"\"Create 4 diagnostic plots for model validation\"\"\"\n",
    "    plots_dir = os.path.join(output_folder, \"plots\")\n",
    "    os.makedirs(plots_dir, exist_ok=True)\n",
    "    \n",
    "    # Flatten the collected data\n",
    "    all_residuals = np.concatenate(residuals_data)\n",
    "    all_fitted = np.concatenate(fitted_data)\n",
    "    \n",
    "    # Create figure with 2x2 subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    fig.suptitle(f'Diagnostic Plots - {group_name}', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. Residuals vs Fitted\n",
    "    axes[0,0].scatter(all_fitted, all_residuals, alpha=0.6, s=20)\n",
    "    axes[0,0].axhline(y=0, color='red', linestyle='--', alpha=0.8)\n",
    "    axes[0,0].set_xlabel('Fitted Values')\n",
    "    axes[0,0].set_ylabel('Residuals')\n",
    "    axes[0,0].set_title('Residuals vs Fitted')\n",
    "    axes[0,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. QQ Plot\n",
    "    probplot(all_residuals, dist=\"norm\", plot=axes[0,1])\n",
    "    axes[0,1].set_title('Q-Q Plot (Normal)')\n",
    "    axes[0,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Residual Histogram\n",
    "    axes[1,0].hist(all_residuals, bins=30, density=True, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    axes[1,0].set_xlabel('Residuals')\n",
    "    axes[1,0].set_ylabel('Density')\n",
    "    axes[1,0].set_title('Residual Distribution')\n",
    "    axes[1,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Scale-Location Plot\n",
    "    sqrt_abs_residuals = np.sqrt(np.abs(all_residuals))\n",
    "    axes[1,1].scatter(all_fitted, sqrt_abs_residuals, alpha=0.6, s=20)\n",
    "    axes[1,1].set_xlabel('Fitted Values')\n",
    "    axes[1,1].set_ylabel('√|Residuals|')\n",
    "    axes[1,1].set_title('Scale-Location Plot')\n",
    "    axes[1,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save plot\n",
    "    plot_filename = os.path.join(plots_dir, f'{group_name}.png')\n",
    "    plt.savefig(plot_filename, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"📊 Diagnostic plots saved for {group_name}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Rubin's Rule\n",
    "# -----------------------------\n",
    "def rubins_pool(estimates, ses):\n",
    "    m = len(estimates)\n",
    "    q_bar = np.mean(estimates)\n",
    "    u_bar = np.mean(np.square(ses))\n",
    "    b_m = np.var(estimates, ddof=1)\n",
    "    total_var = u_bar + ((1 + 1/m) * b_m)\n",
    "    total_se = np.sqrt(total_var)\n",
    "    ci_lower = q_bar - 1.96 * total_se\n",
    "    ci_upper = q_bar + 1.96 * total_se\n",
    "    p_value = 2 * (1 - t.cdf(np.abs(q_bar / total_se), df=m-1))\n",
    "    rounded_p = round(p_value, 5)\n",
    "    formatted_p = \"< 0.00001\" if rounded_p <= 0.00001 else f\"{rounded_p:.5f}\"\n",
    "    return q_bar, total_se, ci_lower, ci_upper, formatted_p\n",
    "\n",
    "# -----------------------------\n",
    "# SMD + Variance Ratio\n",
    "# -----------------------------\n",
    "def calculate_smd_vr(X, T, weights):\n",
    "    treated = X[T == 1]\n",
    "    control = X[T == 0]\n",
    "    w_treated = weights[T == 1]\n",
    "    w_control = weights[T == 0]\n",
    "    smd, vr = [], []\n",
    "    for col in X.columns:\n",
    "        try:\n",
    "            m1, m0 = np.average(treated[col], weights=w_treated), np.average(control[col], weights=w_control)\n",
    "            s1 = np.sqrt(np.average((treated[col] - m1) ** 2, weights=w_treated))\n",
    "            s0 = np.sqrt(np.average((control[col] - m0) ** 2, weights=w_control))\n",
    "            pooled_sd = np.sqrt((s1 ** 2 + s0 ** 2) / 2)\n",
    "            smd.append((m1 - m0) / pooled_sd if pooled_sd > 0 else 0)\n",
    "            vr.append(s1**2 / s0**2 if s0**2 > 0 else 0)\n",
    "        except Exception:\n",
    "            smd.append(np.nan)\n",
    "            vr.append(np.nan)\n",
    "    return np.nanmean(smd), np.nanmean(vr)\n",
    "\n",
    "# -----------------------------\n",
    "# DML Main Loop\n",
    "# -----------------------------\n",
    "def run_dml_with_trimmed_data(final_covariates_map):\n",
    "    att_results = []\n",
    "    balance_results = []\n",
    "\n",
    "    for group, covariates in final_covariates_map.items():\n",
    "        print(f\"\\n🚀 Running DML for {group}\")\n",
    "        group_dir = os.path.join(output_folder, group)\n",
    "        os.makedirs(group_dir, exist_ok=True)\n",
    "\n",
    "        best_result = None\n",
    "        best_se = float(\"inf\")\n",
    "        \n",
    "        # Initialize lists to collect residuals and fitted values for diagnostic plots\n",
    "        group_residuals = []\n",
    "        group_fitted = []\n",
    "\n",
    "        for seed in seeds:\n",
    "            att_list, se_list, r2_list, rmse_list, smd_list, vr_list = [], [], [], [], [], []\n",
    "\n",
    "            for imp in range(1, imputations + 1):\n",
    "                file_path = os.path.join(group_dir, f\"trimmed_data_imp{imp}.pkl\")\n",
    "                if not os.path.exists(file_path):\n",
    "                    continue\n",
    "\n",
    "                df = pd.read_pickle(file_path)\n",
    "                if group not in df.columns or \"iptw\" not in df.columns:\n",
    "                    continue\n",
    "\n",
    "                X = df[covariates].copy()\n",
    "                T = df[group]\n",
    "                Y = df[\"caps5_change_baseline\"]\n",
    "                W = df[\"iptw\"]\n",
    "\n",
    "                for repeat in range(n_repeats):\n",
    "                    kf = KFold(n_splits=5, shuffle=True, random_state=seed + repeat)\n",
    "                    for train_idx, test_idx in kf.split(X):\n",
    "                        try:\n",
    "                            X_train, T_train, Y_train, W_train = (\n",
    "                                X.iloc[train_idx],\n",
    "                                T.iloc[train_idx],\n",
    "                                Y.iloc[train_idx],\n",
    "                                W.iloc[train_idx],\n",
    "                            )\n",
    "\n",
    "                            model_y = xgb.XGBRegressor(n_estimators=100, max_depth=3, learning_rate=0.1, n_jobs=1, random_state=seed)\n",
    "                            model_t = xgb.XGBClassifier(n_estimators=100, max_depth=3, learning_rate=0.1, n_jobs=1,\n",
    "                                                        use_label_encoder=False, eval_metric=\"logloss\", random_state=seed)\n",
    "\n",
    "                            dml = LinearDML(model_y=model_y, model_t=model_t, discrete_treatment=True,\n",
    "                                            cv=KFold(n_splits=3, shuffle=True, random_state=seed), random_state=seed)\n",
    "                            dml.fit(Y_train, T_train, X=X_train, sample_weight=W_train)\n",
    "\n",
    "                            tau = dml.effect(X_train)\n",
    "                            att = np.mean(tau)\n",
    "                            influence = tau - att\n",
    "                            se = np.sqrt(np.mean(influence ** 2) / len(tau))\n",
    "\n",
    "                            att_list.append(att)\n",
    "                            se_list.append(se)\n",
    "\n",
    "                            Y_pred = model_y.fit(X_train, Y_train, sample_weight=W_train).predict(X_train)\n",
    "                            residuals = Y_train - Y_pred\n",
    "                            rmse = mean_squared_error(Y_train, Y_pred, squared=False)\n",
    "                            r2 = r2_score(Y_train, Y_pred)\n",
    "                            r2_list.append(r2)\n",
    "                            rmse_list.append(rmse)\n",
    "                            \n",
    "                            # Collect residuals and fitted values for diagnostic plots\n",
    "                            group_residuals.append(residuals.values)\n",
    "                            group_fitted.append(Y_pred)\n",
    "\n",
    "                            smd, vr = calculate_smd_vr(X_train, T_train, W_train)\n",
    "                            smd_list.append(smd)\n",
    "                            vr_list.append(vr)\n",
    "                        except Exception as e:\n",
    "                            print(f\"⚠️ Error in {group}, seed {seed}, imp {imp}, rep {repeat}: {e}\")\n",
    "\n",
    "            if att_list:\n",
    "                att, se, ci_l, ci_u, p_val = rubins_pool(att_list, se_list)\n",
    "                avg_r2 = np.mean(r2_list)\n",
    "                avg_rmse = np.mean(rmse_list)\n",
    "                avg_smd = np.mean(smd_list)\n",
    "                avg_vr = np.mean(vr_list)\n",
    "\n",
    "                balance_results.append({\n",
    "                    \"group\": group, \"seed\": seed, \"smd\": avg_smd, \"vr\": avg_vr\n",
    "                })\n",
    "\n",
    "                if se < best_se:\n",
    "                    best_se = se\n",
    "                    best_result = {\n",
    "                        \"group\": group, \"seed\": seed, \"att\": att, \"se\": se,\n",
    "                        \"ci_lower\": ci_l, \"ci_upper\": ci_u, \"p_value\": p_val,\n",
    "                        \"r2\": avg_r2, \"rmse\": avg_rmse\n",
    "                    }\n",
    "\n",
    "                print(f\"✅ {group} | Seed {seed}: ATT = {att:.4f}, SE = {se:.4f}, p = {p_val}\")\n",
    "            else:\n",
    "                print(f\"⚠️ No valid results for {group} | Seed {seed}\")\n",
    "\n",
    "        # Create diagnostic plots for this group\n",
    "        if group_residuals and group_fitted:\n",
    "            create_diagnostic_plots(group_residuals, group_fitted, group)\n",
    "\n",
    "        if best_result:\n",
    "            att_results.append(best_result)\n",
    "            print(f\"🏆 Best result for {group} → Seed {best_result['seed']} | SE = {best_result['se']:.4f}\")\n",
    "\n",
    "    # Save final output\n",
    "    pd.DataFrame(att_results).to_excel(\"dml_rubin_summary_subsubcats.xlsx\", index=False)\n",
    "    pd.DataFrame(balance_results).to_excel(\"smd_vr_summary_subsubcats.xlsx\", index=False)\n",
    "    print(\"\\n🎯 All summary files saved.\")\n",
    "\n",
    "run_dml_with_trimmed_data(final_covariates_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "bf3e1c00-9abe-425a-972e-c96b06b05f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unweighted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b2f22f4a-6eb0-41c2-9404-d412340c7710",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Running DML for SubSubCat_Oxazepam\n",
      "✅ SubSubCat_Oxazepam | Seed 1: ATT = 0.5675, SE = 1.0441, p = 0.58796\n",
      "✅ SubSubCat_Oxazepam | Seed 2: ATT = 0.5492, SE = 1.1033, p = 0.61977\n",
      "✅ SubSubCat_Oxazepam | Seed 3: ATT = 0.5046, SE = 1.1584, p = 0.66408\n",
      "✅ SubSubCat_Oxazepam | Seed 4: ATT = 0.4367, SE = 1.1760, p = 0.71121\n",
      "✅ SubSubCat_Oxazepam | Seed 5: ATT = 0.5302, SE = 1.0705, p = 0.62149\n",
      "✅ SubSubCat_Oxazepam | Seed 6: ATT = 0.3997, SE = 1.0026, p = 0.69097\n",
      "✅ SubSubCat_Oxazepam | Seed 7: ATT = 0.5618, SE = 1.1810, p = 0.63538\n",
      "✅ SubSubCat_Oxazepam | Seed 8: ATT = 0.4690, SE = 1.2144, p = 0.70019\n",
      "✅ SubSubCat_Oxazepam | Seed 9: ATT = 0.4623, SE = 1.1280, p = 0.68279\n",
      "✅ SubSubCat_Oxazepam | Seed 10: ATT = 0.4741, SE = 1.1514, p = 0.68139\n",
      "🏆 Best result for SubSubCat_Oxazepam → Seed 6 | SE = 1.0026\n",
      "📊 Creating diagnostic plots for SubSubCat_Oxazepam...\n",
      "\n",
      "🚀 Running DML for SubSubCat_Diazepam\n",
      "✅ SubSubCat_Diazepam | Seed 1: ATT = -1.8528, SE = 3.5834, p = 0.60627\n",
      "✅ SubSubCat_Diazepam | Seed 2: ATT = -1.9226, SE = 3.8832, p = 0.62162\n",
      "✅ SubSubCat_Diazepam | Seed 3: ATT = -1.7790, SE = 3.6235, p = 0.62454\n",
      "✅ SubSubCat_Diazepam | Seed 4: ATT = -1.9888, SE = 3.9226, p = 0.61326\n",
      "✅ SubSubCat_Diazepam | Seed 5: ATT = -1.9895, SE = 3.5797, p = 0.57962\n",
      "✅ SubSubCat_Diazepam | Seed 6: ATT = -1.5851, SE = 3.5276, p = 0.65417\n",
      "✅ SubSubCat_Diazepam | Seed 7: ATT = -1.6450, SE = 3.4960, p = 0.63900\n",
      "✅ SubSubCat_Diazepam | Seed 8: ATT = -1.3827, SE = 3.5326, p = 0.69633\n",
      "✅ SubSubCat_Diazepam | Seed 9: ATT = -1.3818, SE = 3.6056, p = 0.70236\n",
      "✅ SubSubCat_Diazepam | Seed 10: ATT = -1.4638, SE = 3.3587, p = 0.66391\n",
      "🏆 Best result for SubSubCat_Diazepam → Seed 10 | SE = 3.3587\n",
      "📊 Creating diagnostic plots for SubSubCat_Diazepam...\n",
      "\n",
      "🚀 Running DML for SubSubCat_Paracetamol\n",
      "✅ SubSubCat_Paracetamol | Seed 1: ATT = 2.3857, SE = 4.2411, p = 0.57504\n",
      "✅ SubSubCat_Paracetamol | Seed 2: ATT = 2.9607, SE = 4.1582, p = 0.47813\n",
      "✅ SubSubCat_Paracetamol | Seed 3: ATT = 3.1305, SE = 4.4566, p = 0.48406\n",
      "✅ SubSubCat_Paracetamol | Seed 4: ATT = 2.5546, SE = 4.4281, p = 0.56531\n",
      "✅ SubSubCat_Paracetamol | Seed 5: ATT = 2.9071, SE = 4.2280, p = 0.49332\n",
      "✅ SubSubCat_Paracetamol | Seed 6: ATT = 2.7115, SE = 4.4135, p = 0.54038\n",
      "✅ SubSubCat_Paracetamol | Seed 7: ATT = 2.5881, SE = 4.5464, p = 0.57047\n",
      "✅ SubSubCat_Paracetamol | Seed 8: ATT = 2.5996, SE = 4.5495, p = 0.56901\n",
      "✅ SubSubCat_Paracetamol | Seed 9: ATT = 2.5571, SE = 4.4143, p = 0.56372\n",
      "✅ SubSubCat_Paracetamol | Seed 10: ATT = 2.9035, SE = 4.7623, p = 0.54347\n",
      "🏆 Best result for SubSubCat_Paracetamol → Seed 2 | SE = 4.1582\n",
      "📊 Creating diagnostic plots for SubSubCat_Paracetamol...\n",
      "\n",
      "🚀 Running DML for SubSubCat_Lorazepam\n",
      "✅ SubSubCat_Lorazepam | Seed 1: ATT = 0.7186, SE = 2.8524, p = 0.80161\n",
      "✅ SubSubCat_Lorazepam | Seed 2: ATT = 0.6426, SE = 2.8071, p = 0.81939\n",
      "✅ SubSubCat_Lorazepam | Seed 3: ATT = 0.8222, SE = 3.1674, p = 0.79572\n",
      "✅ SubSubCat_Lorazepam | Seed 4: ATT = 0.4984, SE = 3.0267, p = 0.86955\n",
      "✅ SubSubCat_Lorazepam | Seed 5: ATT = 0.9509, SE = 2.7837, p = 0.73337\n",
      "✅ SubSubCat_Lorazepam | Seed 6: ATT = 0.8526, SE = 2.4832, p = 0.73206\n",
      "✅ SubSubCat_Lorazepam | Seed 7: ATT = 0.7001, SE = 2.7284, p = 0.79801\n",
      "✅ SubSubCat_Lorazepam | Seed 8: ATT = 0.5159, SE = 2.7240, p = 0.85016\n",
      "✅ SubSubCat_Lorazepam | Seed 9: ATT = 0.6919, SE = 2.9639, p = 0.81590\n",
      "✅ SubSubCat_Lorazepam | Seed 10: ATT = 0.2482, SE = 2.6614, p = 0.92589\n",
      "🏆 Best result for SubSubCat_Lorazepam → Seed 6 | SE = 2.4832\n",
      "📊 Creating diagnostic plots for SubSubCat_Lorazepam...\n",
      "\n",
      "🚀 Running DML for SubSubCat_Mirtazapine\n",
      "✅ SubSubCat_Mirtazapine | Seed 1: ATT = 7.6999, SE = 2.4700, p = 0.00239\n",
      "✅ SubSubCat_Mirtazapine | Seed 2: ATT = 7.4652, SE = 2.4382, p = 0.00283\n",
      "✅ SubSubCat_Mirtazapine | Seed 3: ATT = 7.3973, SE = 2.2849, p = 0.00164\n",
      "✅ SubSubCat_Mirtazapine | Seed 4: ATT = 7.4711, SE = 2.5823, p = 0.00469\n",
      "✅ SubSubCat_Mirtazapine | Seed 5: ATT = 7.6013, SE = 2.6826, p = 0.00558\n",
      "✅ SubSubCat_Mirtazapine | Seed 6: ATT = 7.5080, SE = 2.5094, p = 0.00350\n",
      "✅ SubSubCat_Mirtazapine | Seed 7: ATT = 7.6771, SE = 2.6720, p = 0.00497\n",
      "✅ SubSubCat_Mirtazapine | Seed 8: ATT = 7.7898, SE = 2.7459, p = 0.00553\n",
      "✅ SubSubCat_Mirtazapine | Seed 9: ATT = 7.4435, SE = 2.4542, p = 0.00309\n",
      "✅ SubSubCat_Mirtazapine | Seed 10: ATT = 7.3712, SE = 2.6324, p = 0.00614\n",
      "🏆 Best result for SubSubCat_Mirtazapine → Seed 3 | SE = 2.2849\n",
      "📊 Creating diagnostic plots for SubSubCat_Mirtazapine...\n",
      "\n",
      "🚀 Running DML for SubSubCat_Escitalopram\n",
      "✅ SubSubCat_Escitalopram | Seed 1: ATT = 0.4862, SE = 2.6646, p = 0.85559\n",
      "✅ SubSubCat_Escitalopram | Seed 2: ATT = 0.9598, SE = 2.6441, p = 0.71737\n",
      "✅ SubSubCat_Escitalopram | Seed 3: ATT = 0.6558, SE = 2.6577, p = 0.80562\n",
      "✅ SubSubCat_Escitalopram | Seed 4: ATT = 0.8798, SE = 2.7426, p = 0.74905\n",
      "✅ SubSubCat_Escitalopram | Seed 5: ATT = 0.9322, SE = 2.4745, p = 0.70719\n",
      "✅ SubSubCat_Escitalopram | Seed 6: ATT = 1.1090, SE = 2.5253, p = 0.66151\n",
      "✅ SubSubCat_Escitalopram | Seed 7: ATT = 0.8568, SE = 2.5232, p = 0.73490\n",
      "✅ SubSubCat_Escitalopram | Seed 8: ATT = 0.6292, SE = 2.6056, p = 0.80969\n",
      "✅ SubSubCat_Escitalopram | Seed 9: ATT = 0.7844, SE = 2.5232, p = 0.75656\n",
      "✅ SubSubCat_Escitalopram | Seed 10: ATT = 0.8350, SE = 2.4194, p = 0.73072\n",
      "🏆 Best result for SubSubCat_Escitalopram → Seed 10 | SE = 2.4194\n",
      "📊 Creating diagnostic plots for SubSubCat_Escitalopram...\n",
      "\n",
      "🚀 Running DML for SubSubCat_Sertraline\n",
      "✅ SubSubCat_Sertraline | Seed 1: ATT = -0.0755, SE = 1.8036, p = 0.96670\n",
      "✅ SubSubCat_Sertraline | Seed 2: ATT = -0.3205, SE = 1.9406, p = 0.86914\n",
      "✅ SubSubCat_Sertraline | Seed 3: ATT = -0.2510, SE = 2.3764, p = 0.91609\n",
      "✅ SubSubCat_Sertraline | Seed 4: ATT = -0.3702, SE = 1.8525, p = 0.84200\n",
      "✅ SubSubCat_Sertraline | Seed 5: ATT = -0.1055, SE = 2.7946, p = 0.96997\n",
      "✅ SubSubCat_Sertraline | Seed 6: ATT = -0.2465, SE = 1.8690, p = 0.89532\n",
      "✅ SubSubCat_Sertraline | Seed 7: ATT = -0.3122, SE = 1.8047, p = 0.86299\n",
      "✅ SubSubCat_Sertraline | Seed 8: ATT = -0.4568, SE = 1.6449, p = 0.78183\n",
      "✅ SubSubCat_Sertraline | Seed 9: ATT = -0.3408, SE = 1.8143, p = 0.85138\n",
      "✅ SubSubCat_Sertraline | Seed 10: ATT = -0.2742, SE = 1.7827, p = 0.87807\n",
      "🏆 Best result for SubSubCat_Sertraline → Seed 8 | SE = 1.6449\n",
      "📊 Creating diagnostic plots for SubSubCat_Sertraline...\n",
      "\n",
      "🚀 Running DML for SubSubCat_Temazepam\n",
      "✅ SubSubCat_Temazepam | Seed 1: ATT = -0.5295, SE = 2.3588, p = 0.82284\n",
      "✅ SubSubCat_Temazepam | Seed 2: ATT = -0.2870, SE = 2.1735, p = 0.89521\n",
      "✅ SubSubCat_Temazepam | Seed 3: ATT = -0.4951, SE = 2.0864, p = 0.81293\n",
      "✅ SubSubCat_Temazepam | Seed 4: ATT = -0.4062, SE = 1.8955, p = 0.83078\n",
      "✅ SubSubCat_Temazepam | Seed 5: ATT = -0.5982, SE = 2.2304, p = 0.78912\n",
      "✅ SubSubCat_Temazepam | Seed 6: ATT = -0.6605, SE = 2.1932, p = 0.76391\n",
      "✅ SubSubCat_Temazepam | Seed 7: ATT = -0.4497, SE = 2.0140, p = 0.82378\n",
      "✅ SubSubCat_Temazepam | Seed 8: ATT = -0.5910, SE = 2.0453, p = 0.77324\n",
      "✅ SubSubCat_Temazepam | Seed 9: ATT = -0.4741, SE = 2.6315, p = 0.85740\n",
      "✅ SubSubCat_Temazepam | Seed 10: ATT = -0.5028, SE = 1.9738, p = 0.79946\n",
      "🏆 Best result for SubSubCat_Temazepam → Seed 4 | SE = 1.8955\n",
      "📊 Creating diagnostic plots for SubSubCat_Temazepam...\n",
      "\n",
      "🚀 Running DML for SubSubCat_Citalopram\n",
      "✅ SubSubCat_Citalopram | Seed 1: ATT = -2.7352, SE = 1.6432, p = 0.09917\n",
      "✅ SubSubCat_Citalopram | Seed 2: ATT = -2.6968, SE = 1.6230, p = 0.09975\n",
      "✅ SubSubCat_Citalopram | Seed 3: ATT = -2.5446, SE = 1.8263, p = 0.16666\n",
      "✅ SubSubCat_Citalopram | Seed 4: ATT = -2.6037, SE = 1.7839, p = 0.14757\n",
      "✅ SubSubCat_Citalopram | Seed 5: ATT = -2.6860, SE = 1.6164, p = 0.09972\n",
      "✅ SubSubCat_Citalopram | Seed 6: ATT = -2.9507, SE = 1.7801, p = 0.10055\n",
      "✅ SubSubCat_Citalopram | Seed 7: ATT = -2.7028, SE = 1.7454, p = 0.12469\n",
      "✅ SubSubCat_Citalopram | Seed 8: ATT = -2.6098, SE = 1.8332, p = 0.15769\n",
      "✅ SubSubCat_Citalopram | Seed 9: ATT = -2.6151, SE = 1.8581, p = 0.16242\n",
      "✅ SubSubCat_Citalopram | Seed 10: ATT = -2.5305, SE = 1.6269, p = 0.12304\n",
      "🏆 Best result for SubSubCat_Citalopram → Seed 5 | SE = 1.6164\n",
      "📊 Creating diagnostic plots for SubSubCat_Citalopram...\n",
      "\n",
      "🚀 Running DML for SubSubCat_Quetiapine\n",
      "✅ SubSubCat_Quetiapine | Seed 1: ATT = 1.9648, SE = 1.2549, p = 0.12060\n",
      "✅ SubSubCat_Quetiapine | Seed 2: ATT = 1.9546, SE = 1.0821, p = 0.07392\n",
      "✅ SubSubCat_Quetiapine | Seed 3: ATT = 2.0357, SE = 1.2684, p = 0.11171\n",
      "✅ SubSubCat_Quetiapine | Seed 4: ATT = 1.9775, SE = 1.2053, p = 0.10404\n",
      "✅ SubSubCat_Quetiapine | Seed 5: ATT = 1.9437, SE = 1.2326, p = 0.11799\n",
      "✅ SubSubCat_Quetiapine | Seed 6: ATT = 1.8805, SE = 1.2646, p = 0.14018\n",
      "✅ SubSubCat_Quetiapine | Seed 7: ATT = 1.9974, SE = 1.2795, p = 0.12170\n",
      "✅ SubSubCat_Quetiapine | Seed 8: ATT = 1.8432, SE = 1.1995, p = 0.12758\n",
      "✅ SubSubCat_Quetiapine | Seed 9: ATT = 1.8929, SE = 1.1374, p = 0.09922\n",
      "✅ SubSubCat_Quetiapine | Seed 10: ATT = 1.9935, SE = 1.1756, p = 0.09308\n",
      "🏆 Best result for SubSubCat_Quetiapine → Seed 2 | SE = 1.0821\n",
      "📊 Creating diagnostic plots for SubSubCat_Quetiapine...\n",
      "\n",
      "🚀 Running DML for SubSubCat_Amitriptyline\n",
      "✅ SubSubCat_Amitriptyline | Seed 1: ATT = 3.9856, SE = 3.3930, p = 0.24295\n",
      "✅ SubSubCat_Amitriptyline | Seed 2: ATT = 3.7154, SE = 3.1849, p = 0.24619\n",
      "✅ SubSubCat_Amitriptyline | Seed 3: ATT = 3.9466, SE = 4.0069, p = 0.32705\n",
      "✅ SubSubCat_Amitriptyline | Seed 4: ATT = 3.9972, SE = 3.1239, p = 0.20368\n",
      "✅ SubSubCat_Amitriptyline | Seed 5: ATT = 4.0227, SE = 3.2292, p = 0.21580\n",
      "✅ SubSubCat_Amitriptyline | Seed 6: ATT = 3.8173, SE = 3.6114, p = 0.29309\n",
      "✅ SubSubCat_Amitriptyline | Seed 7: ATT = 3.8845, SE = 3.6439, p = 0.28901\n",
      "✅ SubSubCat_Amitriptyline | Seed 8: ATT = 3.5152, SE = 3.8168, p = 0.35931\n",
      "✅ SubSubCat_Amitriptyline | Seed 9: ATT = 4.1922, SE = 3.5111, p = 0.23534\n",
      "✅ SubSubCat_Amitriptyline | Seed 10: ATT = 4.4097, SE = 3.1623, p = 0.16631\n",
      "🏆 Best result for SubSubCat_Amitriptyline → Seed 4 | SE = 3.1239\n",
      "📊 Creating diagnostic plots for SubSubCat_Amitriptyline...\n",
      "\n",
      "🚀 Running DML for SubSubCat_Venlafaxine\n",
      "✅ SubSubCat_Venlafaxine | Seed 1: ATT = 2.1155, SE = 2.9767, p = 0.47895\n",
      "✅ SubSubCat_Venlafaxine | Seed 2: ATT = 1.6280, SE = 3.6573, p = 0.65718\n",
      "✅ SubSubCat_Venlafaxine | Seed 3: ATT = 1.8984, SE = 3.4468, p = 0.58303\n",
      "✅ SubSubCat_Venlafaxine | Seed 4: ATT = 2.1534, SE = 3.3573, p = 0.52275\n",
      "✅ SubSubCat_Venlafaxine | Seed 5: ATT = 1.9479, SE = 3.1398, p = 0.53642\n",
      "✅ SubSubCat_Venlafaxine | Seed 6: ATT = 1.7582, SE = 3.4327, p = 0.60966\n",
      "✅ SubSubCat_Venlafaxine | Seed 7: ATT = 1.8212, SE = 3.2918, p = 0.58133\n",
      "✅ SubSubCat_Venlafaxine | Seed 8: ATT = 1.8570, SE = 3.1668, p = 0.55894\n",
      "✅ SubSubCat_Venlafaxine | Seed 9: ATT = 2.3000, SE = 3.3556, p = 0.49467\n",
      "✅ SubSubCat_Venlafaxine | Seed 10: ATT = 2.1692, SE = 3.4175, p = 0.52706\n",
      "🏆 Best result for SubSubCat_Venlafaxine → Seed 1 | SE = 2.9767\n",
      "📊 Creating diagnostic plots for SubSubCat_Venlafaxine...\n",
      "\n",
      "🚀 Running DML for SubSubCat_Fluoxetine\n",
      "✅ SubSubCat_Fluoxetine | Seed 1: ATT = 4.9423, SE = 3.1422, p = 0.11894\n",
      "✅ SubSubCat_Fluoxetine | Seed 2: ATT = 5.3046, SE = 3.0117, p = 0.08126\n",
      "✅ SubSubCat_Fluoxetine | Seed 3: ATT = 5.2561, SE = 2.8319, p = 0.06642\n",
      "✅ SubSubCat_Fluoxetine | Seed 4: ATT = 5.3888, SE = 2.7711, p = 0.05466\n",
      "✅ SubSubCat_Fluoxetine | Seed 5: ATT = 5.2930, SE = 2.7354, p = 0.05585\n",
      "✅ SubSubCat_Fluoxetine | Seed 6: ATT = 5.1291, SE = 2.8356, p = 0.07352\n",
      "✅ SubSubCat_Fluoxetine | Seed 7: ATT = 4.9381, SE = 3.3237, p = 0.14053\n",
      "✅ SubSubCat_Fluoxetine | Seed 8: ATT = 5.4240, SE = 2.5627, p = 0.03681\n",
      "✅ SubSubCat_Fluoxetine | Seed 9: ATT = 5.3388, SE = 3.1371, p = 0.09192\n",
      "✅ SubSubCat_Fluoxetine | Seed 10: ATT = 5.2369, SE = 2.7981, p = 0.06422\n",
      "🏆 Best result for SubSubCat_Fluoxetine → Seed 8 | SE = 2.5627\n",
      "📊 Creating diagnostic plots for SubSubCat_Fluoxetine...\n",
      "\n",
      "🚀 Running DML for SubSubCat_Topiramaat\n",
      "✅ SubSubCat_Topiramaat | Seed 1: ATT = 8.6175, SE = 4.8319, p = 0.07758\n",
      "✅ SubSubCat_Topiramaat | Seed 2: ATT = 8.5584, SE = 5.3505, p = 0.11288\n",
      "✅ SubSubCat_Topiramaat | Seed 3: ATT = 9.8178, SE = 7.9495, p = 0.21975\n",
      "✅ SubSubCat_Topiramaat | Seed 4: ATT = 8.9772, SE = 8.6095, p = 0.29963\n",
      "✅ SubSubCat_Topiramaat | Seed 5: ATT = 8.8682, SE = 5.7369, p = 0.12534\n",
      "✅ SubSubCat_Topiramaat | Seed 6: ATT = 8.7930, SE = 5.9357, p = 0.14168\n",
      "✅ SubSubCat_Topiramaat | Seed 7: ATT = 8.4931, SE = 5.1258, p = 0.10070\n",
      "✅ SubSubCat_Topiramaat | Seed 8: ATT = 8.9110, SE = 5.8805, p = 0.13287\n",
      "✅ SubSubCat_Topiramaat | Seed 9: ATT = 9.2228, SE = 6.8566, p = 0.18167\n",
      "✅ SubSubCat_Topiramaat | Seed 10: ATT = 8.4505, SE = 5.8056, p = 0.14868\n",
      "🏆 Best result for SubSubCat_Topiramaat → Seed 1 | SE = 4.8319\n",
      "📊 Creating diagnostic plots for SubSubCat_Topiramaat...\n",
      "\n",
      "🚀 Running DML for SubSubCat_Zopiclon\n",
      "✅ SubSubCat_Zopiclon | Seed 1: ATT = 0.6749, SE = 6.6428, p = 0.91928\n",
      "✅ SubSubCat_Zopiclon | Seed 2: ATT = 1.2168, SE = 6.9180, p = 0.86074\n",
      "✅ SubSubCat_Zopiclon | Seed 3: ATT = 1.4737, SE = 9.1712, p = 0.87267\n",
      "✅ SubSubCat_Zopiclon | Seed 4: ATT = 1.1205, SE = 8.2785, p = 0.89261\n",
      "✅ SubSubCat_Zopiclon | Seed 5: ATT = 1.0118, SE = 5.5790, p = 0.85646\n",
      "✅ SubSubCat_Zopiclon | Seed 6: ATT = 1.7120, SE = 6.1902, p = 0.78269\n",
      "✅ SubSubCat_Zopiclon | Seed 7: ATT = 1.3729, SE = 8.3469, p = 0.86969\n",
      "✅ SubSubCat_Zopiclon | Seed 8: ATT = 1.7490, SE = 6.4881, p = 0.78805\n",
      "✅ SubSubCat_Zopiclon | Seed 9: ATT = 2.4149, SE = 9.6740, p = 0.80340\n",
      "✅ SubSubCat_Zopiclon | Seed 10: ATT = 2.4064, SE = 13.7240, p = 0.86117\n",
      "🏆 Best result for SubSubCat_Zopiclon → Seed 5 | SE = 5.5790\n",
      "📊 Creating diagnostic plots for SubSubCat_Zopiclon...\n",
      "\n",
      "🚀 Running DML for SubSubCat_Bupropion\n",
      "✅ SubSubCat_Bupropion | Seed 1: ATT = 2.9781, SE = 5.4429, p = 0.58550\n",
      "✅ SubSubCat_Bupropion | Seed 2: ATT = 3.5492, SE = 5.5891, p = 0.52688\n",
      "✅ SubSubCat_Bupropion | Seed 3: ATT = 3.3624, SE = 6.3586, p = 0.59813\n",
      "✅ SubSubCat_Bupropion | Seed 4: ATT = 2.9209, SE = 6.4160, p = 0.64992\n",
      "✅ SubSubCat_Bupropion | Seed 5: ATT = 3.4347, SE = 7.3615, p = 0.64183\n",
      "✅ SubSubCat_Bupropion | Seed 6: ATT = 2.8863, SE = 6.6230, p = 0.66393\n",
      "✅ SubSubCat_Bupropion | Seed 7: ATT = 3.9808, SE = 6.6701, p = 0.55199\n",
      "✅ SubSubCat_Bupropion | Seed 8: ATT = 2.8330, SE = 5.8414, p = 0.62876\n",
      "✅ SubSubCat_Bupropion | Seed 9: ATT = 2.7305, SE = 5.7008, p = 0.63302\n",
      "✅ SubSubCat_Bupropion | Seed 10: ATT = 2.9274, SE = 6.3918, p = 0.64796\n",
      "🏆 Best result for SubSubCat_Bupropion → Seed 1 | SE = 5.4429\n",
      "📊 Creating diagnostic plots for SubSubCat_Bupropion...\n",
      "\n",
      "🚀 Running DML for SubSubCat_Methylfenidaat\n",
      "✅ SubSubCat_Methylfenidaat | Seed 1: ATT = -1.2436, SE = 4.2315, p = 0.76945\n",
      "✅ SubSubCat_Methylfenidaat | Seed 2: ATT = -1.3408, SE = 4.2475, p = 0.75292\n",
      "✅ SubSubCat_Methylfenidaat | Seed 3: ATT = -1.2801, SE = 4.4359, p = 0.77352\n",
      "✅ SubSubCat_Methylfenidaat | Seed 4: ATT = -0.7618, SE = 4.6168, p = 0.86927\n",
      "✅ SubSubCat_Methylfenidaat | Seed 5: ATT = -0.9340, SE = 4.2476, p = 0.82642\n",
      "✅ SubSubCat_Methylfenidaat | Seed 6: ATT = -0.8615, SE = 3.9648, p = 0.82844\n",
      "✅ SubSubCat_Methylfenidaat | Seed 7: ATT = -1.7033, SE = 4.2637, p = 0.69040\n",
      "✅ SubSubCat_Methylfenidaat | Seed 8: ATT = -0.7975, SE = 4.4506, p = 0.85815\n",
      "✅ SubSubCat_Methylfenidaat | Seed 9: ATT = -0.9203, SE = 3.9465, p = 0.81610\n",
      "✅ SubSubCat_Methylfenidaat | Seed 10: ATT = -0.4140, SE = 5.3079, p = 0.93799\n",
      "🏆 Best result for SubSubCat_Methylfenidaat → Seed 9 | SE = 3.9465\n",
      "📊 Creating diagnostic plots for SubSubCat_Methylfenidaat...\n",
      "\n",
      "🚀 Running DML for SubSubCat_Olanzapine\n",
      "✅ SubSubCat_Olanzapine | Seed 1: ATT = 2.7136, SE = 7.7744, p = 0.72780\n",
      "✅ SubSubCat_Olanzapine | Seed 2: ATT = 3.7471, SE = 7.5859, p = 0.62243\n",
      "✅ SubSubCat_Olanzapine | Seed 3: ATT = 2.4701, SE = 7.0796, p = 0.72790\n",
      "✅ SubSubCat_Olanzapine | Seed 4: ATT = 2.6093, SE = 7.6485, p = 0.73372\n",
      "✅ SubSubCat_Olanzapine | Seed 5: ATT = 3.1347, SE = 7.9178, p = 0.69303\n",
      "✅ SubSubCat_Olanzapine | Seed 6: ATT = 2.7574, SE = 6.8306, p = 0.68732\n",
      "✅ SubSubCat_Olanzapine | Seed 7: ATT = 2.6819, SE = 6.6208, p = 0.68630\n",
      "✅ SubSubCat_Olanzapine | Seed 8: ATT = 2.8319, SE = 6.5008, p = 0.66406\n",
      "✅ SubSubCat_Olanzapine | Seed 9: ATT = 2.2067, SE = 7.1894, p = 0.75954\n",
      "✅ SubSubCat_Olanzapine | Seed 10: ATT = 3.2222, SE = 6.7514, p = 0.63422\n",
      "🏆 Best result for SubSubCat_Olanzapine → Seed 8 | SE = 6.5008\n",
      "📊 Creating diagnostic plots for SubSubCat_Olanzapine...\n",
      "\n",
      "🎯 All summary files saved.\n",
      "📊 All diagnostic plots saved in outputs/plots/ folder.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "from econml.dml import LinearDML\n",
    "from scipy.stats import t, probplot\n",
    "import xgboost as xgb\n",
    "\n",
    "# -----------------------------\n",
    "# Configuration\n",
    "# -----------------------------\n",
    "n_repeats = 4\n",
    "seeds = list(range(1, 11))\n",
    "imputations = 5\n",
    "output_folder = \"outputs\"\n",
    "\n",
    "# -----------------------------\n",
    "# Plotting Functions\n",
    "# -----------------------------\n",
    "def create_diagnostic_plots(residuals_data, group_name, output_folder):\n",
    "    \"\"\"Create diagnostic plots for each group\"\"\"\n",
    "    plots_dir = os.path.join(output_folder, \"plots\")\n",
    "    os.makedirs(plots_dir, exist_ok=True)\n",
    "    \n",
    "    all_residuals = residuals_data['residuals']\n",
    "    all_fitted = residuals_data['fitted']\n",
    "    \n",
    "    if len(all_residuals) == 0:\n",
    "        return\n",
    "    \n",
    "    # Create figure with subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    fig.suptitle(f'Diagnostic Plots - {group_name}', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 1. Residuals vs Fitted\n",
    "    axes[0, 0].scatter(all_fitted, all_residuals, alpha=0.5, s=1)\n",
    "    axes[0, 0].axhline(y=0, color='red', linestyle='--')\n",
    "    axes[0, 0].set_xlabel('Fitted Values')\n",
    "    axes[0, 0].set_ylabel('Residuals')\n",
    "    axes[0, 0].set_title('Residuals vs Fitted')\n",
    "    \n",
    "    # 2. QQ Plot\n",
    "    probplot(all_residuals, dist=\"norm\", plot=axes[0, 1])\n",
    "    axes[0, 1].set_title('QQ Plot (Normal)')\n",
    "    \n",
    "    # 3. Histogram of Residuals\n",
    "    axes[1, 0].hist(all_residuals, bins=50, alpha=0.7, edgecolor='black')\n",
    "    axes[1, 0].axvline(x=0, color='red', linestyle='--')\n",
    "    axes[1, 0].set_xlabel('Residuals')\n",
    "    axes[1, 0].set_ylabel('Frequency')\n",
    "    axes[1, 0].set_title('Residual Distribution')\n",
    "    \n",
    "    # 4. Scale-Location Plot\n",
    "    sqrt_abs_resid = np.sqrt(np.abs(all_residuals))\n",
    "    axes[1, 1].scatter(all_fitted, sqrt_abs_resid, alpha=0.5, s=1)\n",
    "    axes[1, 1].set_xlabel('Fitted Values')\n",
    "    axes[1, 1].set_ylabel('√|Residuals|')\n",
    "    axes[1, 1].set_title('Scale-Location Plot')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(plots_dir, f'{group_name}_unweighted.png'), \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# -----------------------------\n",
    "# Rubin's Rule\n",
    "# -----------------------------\n",
    "def rubins_pool(estimates, ses):\n",
    "    m = len(estimates)\n",
    "    q_bar = np.mean(estimates)\n",
    "    u_bar = np.mean(np.square(ses))\n",
    "    b_m = np.var(estimates, ddof=1)\n",
    "    total_var = u_bar + ((1 + 1/m) * b_m)\n",
    "    total_se = np.sqrt(total_var)\n",
    "    ci_lower = q_bar - 1.96 * total_se\n",
    "    ci_upper = q_bar + 1.96 * total_se\n",
    "    p_value = 2 * (1 - t.cdf(np.abs(q_bar / total_se), df=m-1))\n",
    "    rounded_p = round(p_value, 5)\n",
    "    formatted_p = \"< 0.00001\" if rounded_p <= 0.00001 else f\"{rounded_p:.5f}\"\n",
    "    return q_bar, total_se, ci_lower, ci_upper, formatted_p\n",
    "\n",
    "# -----------------------------\n",
    "# SMD + Variance Ratio\n",
    "# -----------------------------\n",
    "def calculate_smd_vr(X, T):\n",
    "    treated = X[T == 1]\n",
    "    control = X[T == 0]\n",
    "    smd, vr = [], []\n",
    "    for col in X.columns:\n",
    "        try:\n",
    "            m1, m0 = treated[col].mean(), control[col].mean()\n",
    "            s1, s0 = treated[col].std(), control[col].std()\n",
    "            pooled_sd = np.sqrt((s1 ** 2 + s0 ** 2) / 2)\n",
    "            smd.append((m1 - m0) / pooled_sd if pooled_sd > 0 else 0)\n",
    "            vr.append(s1**2 / s0**2 if s0**2 > 0 else 0)\n",
    "        except Exception:\n",
    "            smd.append(np.nan)\n",
    "            vr.append(np.nan)\n",
    "    return np.nanmean(smd), np.nanmean(vr)\n",
    "\n",
    "# -----------------------------\n",
    "# DML Main Loop\n",
    "# -----------------------------\n",
    "def run_dml_with_trimmed_data(final_covariates_map):\n",
    "    att_results = []\n",
    "    balance_results = []\n",
    "\n",
    "    for group, covariates in final_covariates_map.items():\n",
    "        print(f\"\\n🚀 Running DML for {group}\")\n",
    "        group_dir = os.path.join(output_folder, group)\n",
    "        os.makedirs(group_dir, exist_ok=True)\n",
    "\n",
    "        best_result = None\n",
    "        best_se = float(\"inf\")\n",
    "        \n",
    "        # Initialize residuals collection for this group\n",
    "        group_residuals_data = {'residuals': [], 'fitted': []}\n",
    "\n",
    "        for seed in seeds:\n",
    "            att_list, se_list, r2_list, rmse_list, smd_list, vr_list = [], [], [], [], [], []\n",
    "\n",
    "            for imp in range(1, imputations + 1):\n",
    "                file_path = os.path.join(group_dir, f\"trimmed_data_imp{imp}.pkl\")\n",
    "                if not os.path.exists(file_path):\n",
    "                    continue\n",
    "\n",
    "                df = pd.read_pickle(file_path)\n",
    "                if group not in df.columns:\n",
    "                    continue\n",
    "\n",
    "                X = df[covariates].copy()\n",
    "                T = df[group]\n",
    "                Y = df[\"caps5_change_baseline\"]\n",
    "\n",
    "                for repeat in range(n_repeats):\n",
    "                    kf = KFold(n_splits=5, shuffle=True, random_state=seed + repeat)\n",
    "                    for train_idx, test_idx in kf.split(X):\n",
    "                        try:\n",
    "                            X_train, T_train, Y_train = (\n",
    "                                X.iloc[train_idx],\n",
    "                                T.iloc[train_idx],\n",
    "                                Y.iloc[train_idx],\n",
    "                            )\n",
    "\n",
    "                            model_y = xgb.XGBRegressor(n_estimators=100, max_depth=3, learning_rate=0.1, n_jobs=1, random_state=seed)\n",
    "                            model_t = xgb.XGBClassifier(n_estimators=100, max_depth=3, learning_rate=0.1, n_jobs=1,\n",
    "                                                        use_label_encoder=False, eval_metric=\"logloss\", random_state=seed)\n",
    "\n",
    "                            dml = LinearDML(model_y=model_y, model_t=model_t, discrete_treatment=True,\n",
    "                                            cv=KFold(n_splits=3, shuffle=True, random_state=seed), random_state=seed)\n",
    "                            dml.fit(Y_train, T_train, X=X_train)\n",
    "\n",
    "                            tau = dml.effect(X_train)\n",
    "                            att = np.mean(tau)\n",
    "                            influence = tau - att\n",
    "                            se = np.sqrt(np.mean(influence ** 2) / len(tau))\n",
    "\n",
    "                            att_list.append(att)\n",
    "                            se_list.append(se)\n",
    "\n",
    "                            Y_pred = model_y.fit(X_train, Y_train).predict(X_train)\n",
    "                            residuals = Y_train - Y_pred\n",
    "                            \n",
    "                            # Collect residuals and fitted values for plotting\n",
    "                            group_residuals_data['residuals'].extend(residuals.tolist())\n",
    "                            group_residuals_data['fitted'].extend(Y_pred.tolist())\n",
    "                            \n",
    "                            rmse = mean_squared_error(Y_train, Y_pred, squared=False)\n",
    "                            r2 = r2_score(Y_train, Y_pred)\n",
    "                            r2_list.append(r2)\n",
    "                            rmse_list.append(rmse)\n",
    "\n",
    "                            smd, vr = calculate_smd_vr(X_train, T_train)\n",
    "                            smd_list.append(smd)\n",
    "                            vr_list.append(vr)\n",
    "                        except Exception as e:\n",
    "                            print(f\"⚠️ Error in {group}, seed {seed}, imp {imp}, rep {repeat}: {e}\")\n",
    "\n",
    "            if att_list:\n",
    "                att, se, ci_l, ci_u, p_val = rubins_pool(att_list, se_list)\n",
    "                avg_r2 = np.mean(r2_list)\n",
    "                avg_rmse = np.mean(rmse_list)\n",
    "                avg_smd = np.mean(smd_list)\n",
    "                avg_vr = np.mean(vr_list)\n",
    "\n",
    "                balance_results.append({\n",
    "                    \"group\": group, \"seed\": seed, \"smd\": avg_smd, \"vr\": avg_vr\n",
    "                })\n",
    "\n",
    "                if se < best_se:\n",
    "                    best_se = se\n",
    "                    best_result = {\n",
    "                        \"group\": group, \"seed\": seed, \"att\": att, \"se\": se,\n",
    "                        \"ci_lower\": ci_l, \"ci_upper\": ci_u, \"p_value\": p_val,\n",
    "                        \"r2\": avg_r2, \"rmse\": avg_rmse\n",
    "                    }\n",
    "\n",
    "                print(f\"✅ {group} | Seed {seed}: ATT = {att:.4f}, SE = {se:.4f}, p = {p_val}\")\n",
    "            else:\n",
    "                print(f\"⚠️ No valid results for {group} | Seed {seed}\")\n",
    "\n",
    "        if best_result:\n",
    "            att_results.append(best_result)\n",
    "            print(f\"🏆 Best result for {group} → Seed {best_result['seed']} | SE = {best_result['se']:.4f}\")\n",
    "        \n",
    "        # Create diagnostic plots for this group\n",
    "        print(f\"📊 Creating diagnostic plots for {group}...\")\n",
    "        create_diagnostic_plots(group_residuals_data, group, output_folder)\n",
    "\n",
    "    # Save final output\n",
    "    pd.DataFrame(att_results).to_excel(\"dml_rubin_summary_subsubcats_unweighted.xlsx\", index=False)\n",
    "    pd.DataFrame(balance_results).to_excel(\"smd_vr_summary_subsubcats_unweighted.xlsx\", index=False)\n",
    "    print(\"\\n🎯 All summary files saved.\")\n",
    "    print(\"📊 All diagnostic plots saved in outputs/plots/ folder.\")\n",
    "\n",
    "run_dml_with_trimmed_data(final_covariates_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b23bb9b1-4751-49b5-a763-e0e5fdcafc3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Final_ATT_Summary_SubSubCat saved\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import sem, ttest_ind\n",
    "\n",
    "# ----------------------------------\n",
    "# File paths\n",
    "# ----------------------------------\n",
    "output_base = \"outputs\"\n",
    "att_file = \"dml_rubin_summary_subsubcats.xlsx\"\n",
    "trimmed_file = \"trimmed_data_imp1.pkl\"\n",
    "auc_file = \"auc_scores.xlsx\"  # NEW\n",
    "\n",
    "# ----------------------------------\n",
    "# Load ATT Summary\n",
    "# ----------------------------------\n",
    "if os.path.exists(att_file):\n",
    "    att_df = pd.read_excel(att_file)\n",
    "else:\n",
    "    raise FileNotFoundError(\"❌ ATT summary file not found: dml_rubin_summary_subsubcats.xlsx\")\n",
    "\n",
    "summary_rows = []\n",
    "\n",
    "# ----------------------------------\n",
    "# Loop over medication groups\n",
    "# ----------------------------------\n",
    "groups = [g for g in medication_groups if os.path.isdir(os.path.join(output_base, g))]\n",
    "\n",
    "for med in groups:\n",
    "    try:\n",
    "        group_path = os.path.join(output_base, med)\n",
    "\n",
    "        # Load trimmed data\n",
    "        df = pd.read_pickle(os.path.join(group_path, trimmed_file))\n",
    "\n",
    "        # Detect treatment column\n",
    "        treatment_cols = [col for col in df.columns if col.upper() == med.upper()]\n",
    "        if not treatment_cols:\n",
    "            print(f\"⚠️ Treatment column {med} not found in trimmed data. Skipping.\")\n",
    "            continue\n",
    "        treatment_var = treatment_cols[0]\n",
    "\n",
    "        # Extract treatment and outcome\n",
    "        T = df[treatment_var]\n",
    "        Y = df[\"caps5_change_baseline\"]\n",
    "\n",
    "        # Treated and control stats\n",
    "        treated = Y[T == 1]\n",
    "        control = Y[T == 0]\n",
    "\n",
    "        mean_treat = treated.mean()\n",
    "        se_treat = sem(treated) if len(treated) > 1 else np.nan\n",
    "\n",
    "        mean_ctrl = control.mean()\n",
    "        se_ctrl = sem(control) if len(control) > 1 else np.nan\n",
    "\n",
    "        # Cohen's d (unadjusted)\n",
    "        pooled_sd = np.sqrt(((treated.std() ** 2) + (control.std() ** 2)) / 2)\n",
    "        cohen_d = (mean_treat - mean_ctrl) / pooled_sd if pooled_sd > 0 else np.nan\n",
    "\n",
    "        # E-value (unadjusted)\n",
    "        delta = mean_treat - mean_ctrl\n",
    "        E = delta / abs(mean_ctrl) * 100 if mean_ctrl != 0 else np.nan\n",
    "\n",
    "        # Unadjusted p-value\n",
    "        try:\n",
    "            t_stat, p_val = ttest_ind(treated, control, equal_var=False, nan_policy=\"omit\")\n",
    "            rounded_p = round(p_val, 5)\n",
    "            formatted_p = \"< 0.00001\" if rounded_p < 0.00001 else rounded_p\n",
    "        except Exception:\n",
    "            formatted_p = np.nan\n",
    "\n",
    "        # AUC from new auc_scores.xlsx file\n",
    "        auc_val = np.nan\n",
    "        auc_path = os.path.join(group_path, auc_file)\n",
    "        if os.path.exists(auc_path):\n",
    "            auc_df = pd.read_excel(auc_path)\n",
    "            if \"AUC\" in auc_df.columns:\n",
    "                auc_val = auc_df[\"AUC\"].dropna().mean()\n",
    "\n",
    "        # Adjusted stats from Rubin summary\n",
    "        att_row = att_df[att_df[\"group\"].str.strip().str.upper() == med.strip().upper()]\n",
    "        if not att_row.empty:\n",
    "            att = att_row.iloc[0][\"att\"]\n",
    "            att_se = att_row.iloc[0][\"se\"]\n",
    "            att_p_val = att_row.iloc[0][\"p_value\"]\n",
    "            r2 = att_row.iloc[0][\"r2\"]\n",
    "            rmse = att_row.iloc[0][\"rmse\"]\n",
    "\n",
    "            try:\n",
    "                rounded_att_p = round(float(att_p_val), 5)\n",
    "                formatted_att_p = \"< 0.00001\" if rounded_att_p < 0.00001 else rounded_att_p\n",
    "            except:\n",
    "                formatted_att_p = att_p_val\n",
    "        else:\n",
    "            att, att_se, formatted_att_p, r2, rmse = np.nan, np.nan, np.nan, np.nan, np.nan\n",
    "\n",
    "        # Append full row\n",
    "        summary_rows.append({\n",
    "            'Medication Group': med,\n",
    "            'Mean Treated': mean_treat,\n",
    "            'SE Treated': se_treat,\n",
    "            'Mean Control': mean_ctrl,\n",
    "            'SE Control': se_ctrl,\n",
    "            'Cohen d': cohen_d,\n",
    "            'E (Unadjusted)': E,\n",
    "            'n Treated': len(treated),\n",
    "            'n Control': len(control),\n",
    "            #'Unadjusted p-value': formatted_p,\n",
    "            'ATT Estimate': att,\n",
    "            'ATT SE (Robust)': att_se,\n",
    "            'ATT p-value': formatted_att_p,\n",
    "            'R²': r2,\n",
    "            'RMSE': rmse,\n",
    "            'AUC': auc_val\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error in {med}: {e}\")\n",
    "\n",
    "# ----------------------------------\n",
    "# Save final summary\n",
    "# ----------------------------------\n",
    "summary_df = pd.DataFrame(summary_rows)\n",
    "summary_df = summary_df.sort_values(\"Medication Group\")\n",
    "summary_df.to_excel(\"Final_ATT_Summary_SubSubCat.xlsx\", index=False)\n",
    "print(\"✅ Final_ATT_Summary_SubSubCat saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e0b5aa46-fbe0-494a-9624-19a4b9e2d32b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ dml_att_barplot_subsubcat is saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "# ✅ Load the final summary table\n",
    "final_df = pd.read_excel(\"Final_ATT_Summary_SubSubCat.xlsx\")\n",
    "\n",
    "# ✅ Parse DML p-values (handle \"< 0.00001\")\n",
    "def parse_pval(p):\n",
    "    try:\n",
    "        if isinstance(p, str) and \"<\" in p:\n",
    "            return 0.000001\n",
    "        return float(p)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "final_df['ATT p-value'] = final_df['ATT p-value'].apply(parse_pval)\n",
    "\n",
    "# ✅ Plot settings\n",
    "width = 0.35\n",
    "\n",
    "# ✅ Plotting function for a single medication group\n",
    "def plot_single_group(row):\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    bars1 = ax.bar(-width/2, row['Mean Control'], width, \n",
    "                   yerr=row['SE Control'], label='Control', hatch='//', color='gray', capsize=5)\n",
    "    bars2 = ax.bar(+width/2, row['Mean Treated'], width, \n",
    "                   yerr=row['SE Treated'], label='Treated', color='steelblue', capsize=5)\n",
    "\n",
    "    label = (\n",
    "        f\"ATT = {row['ATT Estimate']:.2f}\\n\"\n",
    "        f\"d = {row['Cohen d']:.2f}, p = {row['ATT p-value']:.3f}\\n\"\n",
    "        f\"nT = {row['n Treated']}, nC = {row['n Control']}\\n\"\n",
    "        f\"E = {row['E (Unadjusted)']:.1f}%\"\n",
    "    )\n",
    "    max_y = max(row['Mean Control'], row['Mean Treated']) + 1.5\n",
    "    ax.text(0, max_y, label, ha='center', va='bottom', fontsize=9, color='#FFD700')\n",
    "\n",
    "    ax.axhline(0, color='black', linewidth=0.8)\n",
    "    ax.set_xticks([-width/2, +width/2])\n",
    "    ax.set_xticklabels(['Control', 'Treated'])\n",
    "    ax.set_title(f\"Group: {row['Medication Group']}\", fontsize=12, weight='bold')\n",
    "    ax.set_ylabel(\"CAPS5 Change Score\")\n",
    "    ax.set_ylim(bottom=0, top=max_y + 2)\n",
    "    ax.legend()\n",
    "    fig.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# ✅ Generate and save all plots into a multi-page PDF\n",
    "with PdfPages(\"dml_att_barplot_subsubcat.pdf\") as pdf:\n",
    "    for idx, row in final_df.iterrows():\n",
    "        fig = plot_single_group(row)\n",
    "        pdf.savefig(fig, dpi=300, bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "print(\"✅ dml_att_barplot_subsubcat is saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "114d4815-ba90-4c26-b19c-95420b6cfd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Love plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "fe90a956-216d-4c92-8adb-1a2611aa0b0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Processing SUBSUBCAT_Amitriptyline...\n",
      "📊 Exported numeric summary to: outputs\\SUBSUBCAT_Amitriptyline\\covariate_balance_table_SUBSUBCAT_Amitriptyline.xlsx\n",
      "✅ Saved love plot: outputs\\SUBSUBCAT_Amitriptyline\\love_plot_SUBSUBCAT_Amitriptyline.pdf\n",
      "📏 Max weighted SMD for SUBSUBCAT_Amitriptyline: 0.364\n",
      "\n",
      "🔍 Processing SUBSUBCAT_Bupropion...\n",
      "📊 Exported numeric summary to: outputs\\SUBSUBCAT_Bupropion\\covariate_balance_table_SUBSUBCAT_Bupropion.xlsx\n",
      "✅ Saved love plot: outputs\\SUBSUBCAT_Bupropion\\love_plot_SUBSUBCAT_Bupropion.pdf\n",
      "📏 Max weighted SMD for SUBSUBCAT_Bupropion: 0.309\n",
      "\n",
      "🔍 Processing SUBSUBCAT_Citalopram...\n",
      "📊 Exported numeric summary to: outputs\\SUBSUBCAT_Citalopram\\covariate_balance_table_SUBSUBCAT_Citalopram.xlsx\n",
      "✅ Saved love plot: outputs\\SUBSUBCAT_Citalopram\\love_plot_SUBSUBCAT_Citalopram.pdf\n",
      "📏 Max weighted SMD for SUBSUBCAT_Citalopram: 0.224\n",
      "\n",
      "🔍 Processing SUBSUBCAT_Diazepam...\n",
      "📊 Exported numeric summary to: outputs\\SUBSUBCAT_Diazepam\\covariate_balance_table_SUBSUBCAT_Diazepam.xlsx\n",
      "✅ Saved love plot: outputs\\SUBSUBCAT_Diazepam\\love_plot_SUBSUBCAT_Diazepam.pdf\n",
      "📏 Max weighted SMD for SUBSUBCAT_Diazepam: 0.398\n",
      "\n",
      "🔍 Processing SUBSUBCAT_Escitalopram...\n",
      "📊 Exported numeric summary to: outputs\\SUBSUBCAT_Escitalopram\\covariate_balance_table_SUBSUBCAT_Escitalopram.xlsx\n",
      "✅ Saved love plot: outputs\\SUBSUBCAT_Escitalopram\\love_plot_SUBSUBCAT_Escitalopram.pdf\n",
      "📏 Max weighted SMD for SUBSUBCAT_Escitalopram: 0.261\n",
      "\n",
      "🔍 Processing SUBSUBCAT_Fluoxetine...\n",
      "📊 Exported numeric summary to: outputs\\SUBSUBCAT_Fluoxetine\\covariate_balance_table_SUBSUBCAT_Fluoxetine.xlsx\n",
      "✅ Saved love plot: outputs\\SUBSUBCAT_Fluoxetine\\love_plot_SUBSUBCAT_Fluoxetine.pdf\n",
      "📏 Max weighted SMD for SUBSUBCAT_Fluoxetine: 0.307\n",
      "\n",
      "🔍 Processing SUBSUBCAT_Lorazepam...\n",
      "📊 Exported numeric summary to: outputs\\SUBSUBCAT_Lorazepam\\covariate_balance_table_SUBSUBCAT_Lorazepam.xlsx\n",
      "✅ Saved love plot: outputs\\SUBSUBCAT_Lorazepam\\love_plot_SUBSUBCAT_Lorazepam.pdf\n",
      "📏 Max weighted SMD for SUBSUBCAT_Lorazepam: 0.424\n",
      "\n",
      "🔍 Processing SUBSUBCAT_Methylfenidaat...\n",
      "📊 Exported numeric summary to: outputs\\SUBSUBCAT_Methylfenidaat\\covariate_balance_table_SUBSUBCAT_Methylfenidaat.xlsx\n",
      "✅ Saved love plot: outputs\\SUBSUBCAT_Methylfenidaat\\love_plot_SUBSUBCAT_Methylfenidaat.pdf\n",
      "📏 Max weighted SMD for SUBSUBCAT_Methylfenidaat: 0.466\n",
      "\n",
      "🔍 Processing SUBSUBCAT_Mirtazapine...\n",
      "📊 Exported numeric summary to: outputs\\SUBSUBCAT_Mirtazapine\\covariate_balance_table_SUBSUBCAT_Mirtazapine.xlsx\n",
      "✅ Saved love plot: outputs\\SUBSUBCAT_Mirtazapine\\love_plot_SUBSUBCAT_Mirtazapine.pdf\n",
      "📏 Max weighted SMD for SUBSUBCAT_Mirtazapine: 0.263\n",
      "\n",
      "🔍 Processing SUBSUBCAT_Olanzapine...\n",
      "📊 Exported numeric summary to: outputs\\SUBSUBCAT_Olanzapine\\covariate_balance_table_SUBSUBCAT_Olanzapine.xlsx\n",
      "✅ Saved love plot: outputs\\SUBSUBCAT_Olanzapine\\love_plot_SUBSUBCAT_Olanzapine.pdf\n",
      "📏 Max weighted SMD for SUBSUBCAT_Olanzapine: 0.297\n",
      "\n",
      "🔍 Processing SUBSUBCAT_Oxazepam...\n",
      "📊 Exported numeric summary to: outputs\\SUBSUBCAT_Oxazepam\\covariate_balance_table_SUBSUBCAT_Oxazepam.xlsx\n",
      "✅ Saved love plot: outputs\\SUBSUBCAT_Oxazepam\\love_plot_SUBSUBCAT_Oxazepam.pdf\n",
      "📏 Max weighted SMD for SUBSUBCAT_Oxazepam: 0.162\n",
      "\n",
      "🔍 Processing SUBSUBCAT_Paracetamol...\n",
      "📊 Exported numeric summary to: outputs\\SUBSUBCAT_Paracetamol\\covariate_balance_table_SUBSUBCAT_Paracetamol.xlsx\n",
      "✅ Saved love plot: outputs\\SUBSUBCAT_Paracetamol\\love_plot_SUBSUBCAT_Paracetamol.pdf\n",
      "📏 Max weighted SMD for SUBSUBCAT_Paracetamol: 0.388\n",
      "\n",
      "🔍 Processing SUBSUBCAT_Quetiapine...\n",
      "📊 Exported numeric summary to: outputs\\SUBSUBCAT_Quetiapine\\covariate_balance_table_SUBSUBCAT_Quetiapine.xlsx\n",
      "✅ Saved love plot: outputs\\SUBSUBCAT_Quetiapine\\love_plot_SUBSUBCAT_Quetiapine.pdf\n",
      "📏 Max weighted SMD for SUBSUBCAT_Quetiapine: 0.189\n",
      "\n",
      "🔍 Processing SUBSUBCAT_Sertraline...\n",
      "📊 Exported numeric summary to: outputs\\SUBSUBCAT_Sertraline\\covariate_balance_table_SUBSUBCAT_Sertraline.xlsx\n",
      "✅ Saved love plot: outputs\\SUBSUBCAT_Sertraline\\love_plot_SUBSUBCAT_Sertraline.pdf\n",
      "📏 Max weighted SMD for SUBSUBCAT_Sertraline: 0.141\n",
      "\n",
      "🔍 Processing SUBSUBCAT_Temazepam...\n",
      "📊 Exported numeric summary to: outputs\\SUBSUBCAT_Temazepam\\covariate_balance_table_SUBSUBCAT_Temazepam.xlsx\n",
      "✅ Saved love plot: outputs\\SUBSUBCAT_Temazepam\\love_plot_SUBSUBCAT_Temazepam.pdf\n",
      "📏 Max weighted SMD for SUBSUBCAT_Temazepam: 0.249\n",
      "\n",
      "🔍 Processing SUBSUBCAT_Topiramaat...\n",
      "📊 Exported numeric summary to: outputs\\SUBSUBCAT_Topiramaat\\covariate_balance_table_SUBSUBCAT_Topiramaat.xlsx\n",
      "✅ Saved love plot: outputs\\SUBSUBCAT_Topiramaat\\love_plot_SUBSUBCAT_Topiramaat.pdf\n",
      "📏 Max weighted SMD for SUBSUBCAT_Topiramaat: 0.516\n",
      "\n",
      "🔍 Processing SUBSUBCAT_Venlafaxine...\n",
      "📊 Exported numeric summary to: outputs\\SUBSUBCAT_Venlafaxine\\covariate_balance_table_SUBSUBCAT_Venlafaxine.xlsx\n",
      "✅ Saved love plot: outputs\\SUBSUBCAT_Venlafaxine\\love_plot_SUBSUBCAT_Venlafaxine.pdf\n",
      "📏 Max weighted SMD for SUBSUBCAT_Venlafaxine: 0.220\n",
      "\n",
      "🔍 Processing SUBSUBCAT_Zopiclon...\n",
      "📊 Exported numeric summary to: outputs\\SUBSUBCAT_Zopiclon\\covariate_balance_table_SUBSUBCAT_Zopiclon.xlsx\n",
      "✅ Saved love plot: outputs\\SUBSUBCAT_Zopiclon\\love_plot_SUBSUBCAT_Zopiclon.pdf\n",
      "📏 Max weighted SMD for SUBSUBCAT_Zopiclon: 0.393\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "# ----------------------------------------\n",
    "# Functions to calculate balance\n",
    "# ----------------------------------------\n",
    "def calculate_smd(x1, x2, w1=None, w2=None):\n",
    "    def weighted_mean(x, w): return np.average(x, weights=w)\n",
    "    def weighted_var(x, w):\n",
    "        m = np.average(x, weights=w)\n",
    "        return np.average((x - m) ** 2, weights=w)\n",
    "    \n",
    "    m1 = weighted_mean(x1, w1) if w1 is not None else np.mean(x1)\n",
    "    m2 = weighted_mean(x2, w2) if w2 is not None else np.mean(x2)\n",
    "    v1 = weighted_var(x1, w1) if w1 is not None else np.var(x1, ddof=1)\n",
    "    v2 = weighted_var(x2, w2) if w2 is not None else np.var(x2, ddof=1)\n",
    "    \n",
    "    pooled_sd = np.sqrt((v1 + v2) / 2)\n",
    "    return np.abs(m1 - m2) / pooled_sd if pooled_sd > 0 else 0\n",
    "\n",
    "def variance_ratio(x1, x2, w1=None, w2=None):\n",
    "    def weighted_var(x, w):\n",
    "        m = np.average(x, weights=w)\n",
    "        return np.average((x - m) ** 2, weights=w)\n",
    "    \n",
    "    v1 = weighted_var(x1, w1) if w1 is not None else np.var(x1, ddof=1)\n",
    "    v2 = weighted_var(x2, w2) if w2 is not None else np.var(x2, ddof=1)\n",
    "    \n",
    "    return max(v1 / v2, v2 / v1) if v1 > 0 and v2 > 0 else 1\n",
    "\n",
    "# ----------------------------------------\n",
    "# Setup\n",
    "# ----------------------------------------\n",
    "output_base = \"outputs\"\n",
    "groups = [g for g in os.listdir(output_base) if os.path.isdir(os.path.join(output_base, g))]\n",
    "\n",
    "# Create a case-insensitive mapping\n",
    "final_covariates_map_lower = {k.lower(): v for k, v in final_covariates_map.items()}\n",
    "\n",
    "# ----------------------------------------\n",
    "# Main Loop\n",
    "# ----------------------------------------\n",
    "for group in groups:\n",
    "    if group.lower() not in final_covariates_map_lower:\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n🔍 Processing {group}...\")\n",
    "\n",
    "    try:\n",
    "        group_path = os.path.join(output_base, group)\n",
    "        covariates = final_covariates_map_lower[group.lower()]\n",
    "        \n",
    "        column_name = None\n",
    "        for col in pd.read_pickle(os.path.join(group_path, \"trimmed_data_imp1.pkl\")).columns:\n",
    "            if col.lower() == group.lower():\n",
    "                column_name = col\n",
    "                break\n",
    "        if column_name is None:\n",
    "            print(f\"⚠️ Column not found for {group}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        smd_unw_all, smd_w_all = [], []\n",
    "        vr_unw_all, vr_w_all = [], []\n",
    "\n",
    "        for i in range(1, 6):\n",
    "            df_path = os.path.join(group_path, f\"trimmed_data_imp{i}.pkl\")\n",
    "            iptw_path = os.path.join(group_path, \"iptw_weights.xlsx\")\n",
    "\n",
    "            if not os.path.exists(df_path) or not os.path.exists(iptw_path):\n",
    "                print(f\"⚠️ Missing data for {group} imp{i}, skipping.\")\n",
    "                continue\n",
    "\n",
    "            df = pd.read_pickle(df_path)\n",
    "            iptw_df = pd.read_excel(iptw_path, index_col=0)\n",
    "            T = df[column_name]\n",
    "            W = iptw_df.loc[df.index, \"iptw_mean\"]\n",
    "\n",
    "            smd_unw_i, smd_w_i, vr_unw_i, vr_w_i = [], [], [], []\n",
    "\n",
    "            for cov in covariates:\n",
    "                x1, x0 = df.loc[T == 1, cov], df.loc[T == 0, cov]\n",
    "                w1, w0 = W[T == 1], W[T == 0]\n",
    "\n",
    "                su = calculate_smd(x1, x0)\n",
    "                sw = calculate_smd(x1, x0, w1, w0)\n",
    "\n",
    "                vu = variance_ratio(x1, x0) if cov in ['treatmentdurationdays', 'CAPS5score_baseline', 'age'] else np.nan\n",
    "                vw = variance_ratio(x1, x0, w1, w0) if cov in ['treatmentdurationdays', 'CAPS5score_baseline', 'age'] else np.nan\n",
    "\n",
    "                smd_unw_i.append(su)\n",
    "                smd_w_i.append(sw)\n",
    "                vr_unw_i.append(vu)\n",
    "                vr_w_i.append(vw)\n",
    "\n",
    "            smd_unw_all.append(smd_unw_i)\n",
    "            smd_w_all.append(smd_w_i)\n",
    "            vr_unw_all.append(vr_unw_i)\n",
    "            vr_w_all.append(vr_w_i)\n",
    "\n",
    "        smd_unw = np.mean(smd_unw_all, axis=0)\n",
    "        smd_w = np.mean(smd_w_all, axis=0)\n",
    "        vr_unw = np.nanmean(vr_unw_all, axis=0)\n",
    "        vr_w = np.nanmean(vr_w_all, axis=0)\n",
    "\n",
    "        severity = []\n",
    "        for sw in smd_w:\n",
    "            if sw <= 0.1:\n",
    "                severity.append(\"Good\")\n",
    "            elif sw <= 0.2:\n",
    "                severity.append(\"Moderate\")\n",
    "            else:\n",
    "                severity.append(\"Poor\")\n",
    "\n",
    "        covariate_names = covariates\n",
    "        numeric_df = pd.DataFrame({\n",
    "            \"Covariate\": covariate_names,\n",
    "            \"SMD_Unweighted\": smd_unw,\n",
    "            \"SMD_Weighted\": smd_w,\n",
    "            \"Imbalance_Severity\": severity,\n",
    "            \"VR_Unweighted\": vr_unw,\n",
    "            \"VR_Weighted\": vr_w\n",
    "        })\n",
    "\n",
    "        numeric_path = os.path.join(group_path, f\"covariate_balance_table_{group}.xlsx\")\n",
    "        numeric_df.to_excel(numeric_path, index=False)\n",
    "        print(f\"📊 Exported numeric summary to: {numeric_path}\")\n",
    "\n",
    "        # -------------------------\n",
    "        # Plot\n",
    "        # -------------------------\n",
    "        labels = covariates\n",
    "        y_pos = np.arange(len(labels))\n",
    "\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(18, len(labels) * 0.45))\n",
    "\n",
    "        axes[0].scatter(smd_unw, y_pos, color='red', label=\"Unweighted\")\n",
    "        axes[0].scatter(smd_w, y_pos, color='blue', label=\"Weighted\")\n",
    "        axes[0].axvline(0.1, color='gray', linestyle='--', label=\"Threshold 0.1\")\n",
    "        axes[0].axvline(0.2, color='black', linestyle='--', label=\"Threshold 0.2\")\n",
    "        axes[0].set_xlim(0, max(max(smd_unw), max(smd_w), 0.25) + 0.05)\n",
    "        axes[0].set_yticks(y_pos)\n",
    "        axes[0].set_yticklabels(labels)\n",
    "        axes[0].invert_yaxis()\n",
    "        axes[0].set_title(\"Standardized Mean Differences (SMD)\")\n",
    "        axes[0].legend(loc=\"upper right\")\n",
    "        axes[0].grid(True)\n",
    "\n",
    "        vr_mask = [cov in ['treatmentdurationdays', 'CAPS5score_baseline', 'age'] for cov in covariates]\n",
    "        filtered_y = [i for i, b in enumerate(vr_mask) if b]\n",
    "        filtered_labels = [labels[i] for i in filtered_y]\n",
    "        filtered_vr_unw = [vr_unw[i] for i in filtered_y]\n",
    "        filtered_vr_w = [vr_w[i] for i in filtered_y]\n",
    "\n",
    "        axes[1].scatter(filtered_vr_unw, filtered_y, color='blue', marker='o', label=\"Unweighted\")\n",
    "        axes[1].scatter(filtered_vr_w, filtered_y, color='red', marker='x', label=\"Weighted\")\n",
    "        axes[1].axvline(2, color='gray', linestyle='--')\n",
    "        axes[1].axvline(0.5, color='gray', linestyle='--')\n",
    "        axes[1].set_xlim(0, max(filtered_vr_unw + filtered_vr_w + [2.5]) + 0.5)\n",
    "        axes[1].set_yticks(filtered_y)\n",
    "        axes[1].set_yticklabels(filtered_labels)\n",
    "        axes[1].invert_yaxis()\n",
    "        axes[1].set_title(\"Variance Ratio (VR)\")\n",
    "        axes[1].legend()\n",
    "        axes[1].grid(True)\n",
    "\n",
    "        fig.suptitle(f\"Covariate Balance for {group.replace('CAT_', '')}\", fontsize=14, weight='bold')\n",
    "        fig.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "        plot_path = os.path.join(group_path, f\"love_plot_{group}.pdf\")\n",
    "        fig.savefig(plot_path, dpi=300)\n",
    "        plt.close()\n",
    "        print(f\"✅ Saved love plot: {plot_path}\")\n",
    "        print(f\"📏 Max weighted SMD for {group}: {np.max(smd_w):.3f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error in {group}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "04890d8f-3ebd-485f-8faa-42e595e1b1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "691f11f8-4131-4292-8b21-03e8f19df707",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Creating Heatmap for SubSubCat_Oxazepam ==========\n",
      "✅ Heatmap saved: outputs\\SubSubCat_Oxazepam\\heatmap_smd_SubSubCat_Oxazepam.png\n",
      "\n",
      "========== Creating Heatmap for SubSubCat_Diazepam ==========\n",
      "✅ Heatmap saved: outputs\\SubSubCat_Diazepam\\heatmap_smd_SubSubCat_Diazepam.png\n",
      "\n",
      "========== Creating Heatmap for SubSubCat_Paracetamol ==========\n",
      "✅ Heatmap saved: outputs\\SubSubCat_Paracetamol\\heatmap_smd_SubSubCat_Paracetamol.png\n",
      "\n",
      "========== Creating Heatmap for SubSubCat_Lorazepam ==========\n",
      "✅ Heatmap saved: outputs\\SubSubCat_Lorazepam\\heatmap_smd_SubSubCat_Lorazepam.png\n",
      "\n",
      "========== Creating Heatmap for SubSubCat_Mirtazapine ==========\n",
      "✅ Heatmap saved: outputs\\SubSubCat_Mirtazapine\\heatmap_smd_SubSubCat_Mirtazapine.png\n",
      "\n",
      "========== Creating Heatmap for SubSubCat_Escitalopram ==========\n",
      "✅ Heatmap saved: outputs\\SubSubCat_Escitalopram\\heatmap_smd_SubSubCat_Escitalopram.png\n",
      "\n",
      "========== Creating Heatmap for SubSubCat_Sertraline ==========\n",
      "✅ Heatmap saved: outputs\\SubSubCat_Sertraline\\heatmap_smd_SubSubCat_Sertraline.png\n",
      "\n",
      "========== Creating Heatmap for SubSubCat_Temazepam ==========\n",
      "✅ Heatmap saved: outputs\\SubSubCat_Temazepam\\heatmap_smd_SubSubCat_Temazepam.png\n",
      "\n",
      "========== Creating Heatmap for SubSubCat_Citalopram ==========\n",
      "✅ Heatmap saved: outputs\\SubSubCat_Citalopram\\heatmap_smd_SubSubCat_Citalopram.png\n",
      "\n",
      "========== Creating Heatmap for SubSubCat_Quetiapine ==========\n",
      "✅ Heatmap saved: outputs\\SubSubCat_Quetiapine\\heatmap_smd_SubSubCat_Quetiapine.png\n",
      "\n",
      "========== Creating Heatmap for SubSubCat_Amitriptyline ==========\n",
      "✅ Heatmap saved: outputs\\SubSubCat_Amitriptyline\\heatmap_smd_SubSubCat_Amitriptyline.png\n",
      "\n",
      "========== Creating Heatmap for SubSubCat_Venlafaxine ==========\n",
      "✅ Heatmap saved: outputs\\SubSubCat_Venlafaxine\\heatmap_smd_SubSubCat_Venlafaxine.png\n",
      "\n",
      "========== Creating Heatmap for SubSubCat_Fluoxetine ==========\n",
      "✅ Heatmap saved: outputs\\SubSubCat_Fluoxetine\\heatmap_smd_SubSubCat_Fluoxetine.png\n",
      "\n",
      "========== Creating Heatmap for SubSubCat_Topiramaat ==========\n",
      "✅ Heatmap saved: outputs\\SubSubCat_Topiramaat\\heatmap_smd_SubSubCat_Topiramaat.png\n",
      "\n",
      "========== Creating Heatmap for SubSubCat_Zopiclon ==========\n",
      "✅ Heatmap saved: outputs\\SubSubCat_Zopiclon\\heatmap_smd_SubSubCat_Zopiclon.png\n",
      "\n",
      "========== Creating Heatmap for SubSubCat_Bupropion ==========\n",
      "✅ Heatmap saved: outputs\\SubSubCat_Bupropion\\heatmap_smd_SubSubCat_Bupropion.png\n",
      "\n",
      "========== Creating Heatmap for SubSubCat_Methylfenidaat ==========\n",
      "✅ Heatmap saved: outputs\\SubSubCat_Methylfenidaat\\heatmap_smd_SubSubCat_Methylfenidaat.png\n",
      "\n",
      "========== Creating Heatmap for SubSubCat_Olanzapine ==========\n",
      "✅ Heatmap saved: outputs\\SubSubCat_Olanzapine\\heatmap_smd_SubSubCat_Olanzapine.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "#-----------------------------\n",
    "# Generate heatmaps\n",
    "# -------------------------------\n",
    "for treatment_var in medication_groups:\n",
    "    print(f\"\\n========== Creating Heatmap for {treatment_var} ==========\")\n",
    "\n",
    "    try:\n",
    "        output_folder = os.path.join('outputs', treatment_var)\n",
    "        balance_path = os.path.join(output_folder, f'covariate_balance_table_{treatment_var}.xlsx')\n",
    "\n",
    "        if not os.path.exists(balance_path):\n",
    "            print(f\"❌ Balance file not found: {balance_path}\")\n",
    "            continue\n",
    "\n",
    "        balance_df = pd.read_excel(balance_path)\n",
    "\n",
    "        # ✅ Use finalized covariates + 'Propensity Score'\n",
    "        covariates = final_covariates_map[treatment_var] + ['Propensity Score']\n",
    "        balance_df = balance_df[balance_df['Covariate'].isin(covariates)]\n",
    "\n",
    "        # ✅ Check for CAPS5score_baseline\n",
    "        highlight_caps = 'CAPS5score_baseline' in balance_df['Covariate'].values\n",
    "\n",
    "        # ✅ Format for heatmap\n",
    "        heatmap_df = balance_df[['Covariate', 'SMD_Unweighted', 'SMD_Weighted']].copy()\n",
    "        heatmap_df.columns = ['Covariate', 'Unweighted', 'Weighted']\n",
    "        heatmap_df = heatmap_df.set_index('Covariate')\n",
    "        heatmap_df = heatmap_df.sort_values(by='Unweighted', ascending=False)\n",
    "\n",
    "        # ✅ Plot\n",
    "        plt.figure(figsize=(12, max(10, len(heatmap_df) * 0.35)))\n",
    "        ax = sns.heatmap(\n",
    "            heatmap_df,\n",
    "            cmap=\"coolwarm\",\n",
    "            annot=True,\n",
    "            fmt=\".2f\",\n",
    "            linewidths=0.6,\n",
    "            linecolor='gray',\n",
    "            cbar_kws={\"label\": \"Standardized Mean Difference\"}\n",
    "        )\n",
    "\n",
    "        plt.title(f\"Covariate Balance Heatmap (Rubin IPTW)\\n{treatment_var}\", fontsize=15, weight='bold')\n",
    "        plt.xlabel(\"Condition\")\n",
    "        plt.ylabel(\"Covariate\")\n",
    "\n",
    "        # ✅ Bold CAPS5score_baseline if present\n",
    "        if highlight_caps:\n",
    "            ylabels = [label.get_text() for label in ax.get_yticklabels()]\n",
    "            ax.set_yticklabels([\n",
    "                f\"{label} ←\" if label == 'CAPS5score_baseline' else label for label in ylabels\n",
    "            ])\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # ✅ Save image\n",
    "        save_path = os.path.join(output_folder, f'heatmap_smd_{treatment_var}.png')\n",
    "        plt.savefig(save_path, dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "        print(f\"✅ Heatmap saved: {save_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error processing {treatment_var}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8b09ff-b822-4215-914f-d0c7eff9d1e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a106ae6e-11d7-4f9a-88a0-aece43009c21",
   "metadata": {},
   "source": [
    "#### XGBOOST:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "07982f2f-0c44-4cb6-b160-9503e73823f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed to: D:\\Work\\PTSD_Followup\\XGBoost\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")  # optional\n",
    "\n",
    "# Option 1 (recommended)\n",
    "new_path = r\"D:\\Work\\PTSD_Followup\\XGBoost\"\n",
    "\n",
    "os.chdir(new_path)  # Change working directory\n",
    "print(\"Changed to:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2621a257-5400-454e-b562-e4fe7819d2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(r\"data_baseline.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c01f361-e551-42fc-924c-069010cd0a3d",
   "metadata": {},
   "source": [
    "## CAT analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "03c51cc7-4bbe-48de-88d5-4c1ad720814c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "# For visualization and future steps\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer  # Needed to enable the experimental feature\n",
    "from sklearn.impute import IterativeImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "47fb8af6-310c-42fc-89c1-39f8ea616894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataset: (6125, 465)\n",
      "\n",
      "Sample columns: ['CIN5', 'StartDatum', 'BEH_MOD', 'BEHDAGEN_GEPLAND', 'AANTAL_PCL', 'TOESTWO', 'BEH_AFG', 'TK', 'MM_CAPS_IN', 'MM_CAPS_TK']\n",
      "\n",
      "Missing values:\n",
      " instrument_SDV_IN    6125\n",
      "Eaantal_TK           6125\n",
      "Dcriterium_FU        6125\n",
      "Cernst_FU            6125\n",
      "Caantal_FU           6125\n",
      "Ccriterium_FU        6125\n",
      "Bernst_FU            6125\n",
      "Baantal_FU           6125\n",
      "Bcriterium_FU        6125\n",
      "Eernst_TK            6125\n",
      "dtype: int64\n",
      "Shape after removing duplicates: (6125, 465)\n"
     ]
    }
   ],
   "source": [
    "# Check basic structure\n",
    "print(\"Shape of dataset:\", df.shape)\n",
    "print(\"\\nSample columns:\", df.columns.tolist()[:10])\n",
    "print(\"\\nMissing values:\\n\", df.isnull().sum().sort_values(ascending=False).head(10))\n",
    "\n",
    "# Remove duplicate rows\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Confirm shape after removing duplicates\n",
    "print(\"Shape after removing duplicates:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2eb247f3-f275-4664-8ff6-6a31c04a8607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDV_SEXE  gender_label\n",
      "2.0       Female          4602\n",
      "1.0       Male            1475\n",
      "3.0       Other             48\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pyreadstat\n",
    "\n",
    "# Load gender info\n",
    "gender_df, meta = pyreadstat.read_sav(\"SDV_IN_Gender_2019_2024.sav\")\n",
    "\n",
    "# Just extract SDV_SEXE column and append to df\n",
    "df[\"SDV_SEXE\"] = gender_df[\"SDV_SEXE\"].reset_index(drop=True)\n",
    "\n",
    "# Optional: map to labels\n",
    "gender_map = {1.0: \"Male\", 2.0: \"Female\", 3.0: \"Other\"}\n",
    "df[\"gender_label\"] = df[\"SDV_SEXE\"].map(gender_map)\n",
    "\n",
    "# Done! Check a sample\n",
    "print(df[[\"SDV_SEXE\", \"gender_label\"]].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "aa490857-cce0-4727-b0bb-2bc44c774b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'gender' and 'SDV_SEXE' columns are in df\n",
    "\n",
    "# Gender dummy variables\n",
    "df['gender_1'] = (df['gender'] == 1).astype(int)\n",
    "df['gender_2'] = (df['gender'] == 2).astype(int)\n",
    "\n",
    "# SDV_SEXE dummy variables\n",
    "df['SDV_SEXE_1'] = (df['SDV_SEXE'] == 1).astype(int)\n",
    "df['SDV_SEXE_2'] = (df['SDV_SEXE'] == 2).astype(int)\n",
    "df['SDV_SEXE_3'] = (df['SDV_SEXE'] == 3).astype(int)\n",
    "\n",
    "# Create binary columns\n",
    "df['ethnicity_Dutch'] = np.where(df['ethnicity'] == 1, 1, 0)\n",
    "df['ethnicity_other'] = np.where(df['ethnicity'] != 1, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "58abf5c6-b900-48da-b440-c1363e17e6a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining columns: 458\n"
     ]
    }
   ],
   "source": [
    "# Columns manually identified for removal (example set from the R script)\n",
    "cols_to_drop = [\n",
    "    'gender', 'ethnicity', 'CIN5', 'SDV_SEXE', 'StartDatum', 'STARTDATUM', 'DROPOUT_EARLYCOMPLETER', 'TOEST_WO',\n",
    "    'depressie_IN', 'TERUGKOMER', 'VROEGK_ST', 'gender_label',\n",
    "    'depr_m_psychose_huid', 'depr_z_psychose_huid', 'depr_z_psychose_verl',\n",
    "    'depr_m_psychose_verl', 'CAPS5score_followup', 'CAPS5_DAT_IN'\n",
    "]\n",
    "\n",
    "df = df.drop(columns=[col for col in cols_to_drop if col in df.columns])\n",
    "print(\"Remaining columns:\", df.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "aed28f36-9f83-46ee-ad68-ce8bb17f0b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'BEH_DAGEN' in df.columns:\n",
    "    df.rename(columns={'BEH_DAGEN': 'treatmentdurationdays'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7ebe3d23-51c4-450e-9401-3653a8d2f548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean and standardize column names\n",
    "df.columns = (\n",
    "    df.columns\n",
    "    .str.replace(r\"\\.+\", \"_\", regex=True)\n",
    "    .str.replace(r\"[^a-zA-Z0-9_]\", \"\", regex=True)\n",
    "    .str.replace(\" \", \"_\")\n",
    "    .str.strip()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "63bf737a-7d2b-40ae-a33a-78fb08d6fa41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAPS5score_baseline: 0 missing\n",
      "CAPS5Score_TK: 0 missing\n"
     ]
    }
   ],
   "source": [
    "# Preview key outcome variables\n",
    "outcome_vars = ['CAPS5score_baseline', 'CAPS5Score_TK']\n",
    "for col in outcome_vars:\n",
    "    if col in df.columns:\n",
    "        print(f\"{col}: {df[col].isnull().sum()} missing\")\n",
    "\n",
    "# Calculate change score\n",
    "if 'CAPS5score_baseline' in df.columns and 'CAPS5Score_TK' in df.columns:\n",
    "    df['caps5_change_baseline'] = df['CAPS5Score_TK'] - df['CAPS5score_baseline'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "db544569-90b1-428a-9dfa-181d1fbd95e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define exceptions to keep\n",
    "protected_cols = [\n",
    "    \"DIAGNOSIS_ANXIETY_OCD\",\n",
    "    \"DIAGNOSIS_PSYCHOTIC\",\n",
    "    \"DIAGNOSIS_EATING_DISORDER\",\n",
    "    \"DIAGNOSIS_SUBSTANCE_DISORDER\", \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"EB_NON_TF_THERAPY\", \"OTHER_TREATM_APPROACH\", \"Bipolar_and_Mood_disorder\", 'SUBCAT_Selectieve_immunosuppresiva', 'treatmentdurationdays',\n",
    "'SUBCAT_Corticosteroiden',\n",
    "'SUBCAT_Immunomodulerend_Coxibs',\n",
    "'SUBCAT_Aminosalicylaten',\n",
    "'SUBCAT_calcineurineremmers',\n",
    "'SUBCAT_Anti_epileptica_Benzodiazepine',\n",
    "'SUBCAT_Paracetamol_overig_combinatie', 'SUBCAT_MAO_remmers', 'SUBCAT_psychostimulans_overige', 'SUBCAT_Interleukine_remmers'\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "# ----------------------------------------\n",
    "# 1. Drop columns with >95% missing values (except protected)\n",
    "thresh_missing = int(0.95 * len(df))\n",
    "missing_cols = [col for col in df.columns if df[col].isnull().sum() > (len(df) - thresh_missing)]\n",
    "missing_cols_to_drop = [col for col in missing_cols if col not in protected_cols]\n",
    "df = df.drop(columns=missing_cols_to_drop)\n",
    "\n",
    "# ----------------------------------------\n",
    "# 2. Drop near-zero variance columns (except protected)\n",
    "low_variance_cols = [col for col in df.columns if df[col].nunique(dropna=True) <= 1 and col not in protected_cols]\n",
    "df = df.drop(columns=low_variance_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "164fa95f-9ce8-447a-816d-51da2b57ecd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Step 1 Complete: Cleaned dataset saved.\n"
     ]
    }
   ],
   "source": [
    "df.to_csv(\"cleaned_data_baseline.csv\", index=False)\n",
    "print(\" Step 1 Complete: Cleaned dataset saved.\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dd6e4a9d-b159-4880-9d2a-9ad28594f5f4",
   "metadata": {},
   "source": [
    "# Target variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "78ea46c7-ce76-4f28-9eaa-27b33c562d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from fancyimpute import IterativeImputer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "822895b2-d0b1-420a-a390-033db2fa9314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6125, 204)\n",
      "DIAGNOSIS_ANXIETY_OCD           float64\n",
      "DIAGNOSIS_SMOKING               float64\n",
      "DIAGNOSIS_EATING_DISORDER       float64\n",
      "DIAGNOSIS_SUBSTANCE_DISORDER    float64\n",
      "DIAGNOSIS_PSYCHOTIC             float64\n",
      "DIAGNOSIS_SUICIDALITY           float64\n",
      "DIAGNOSIS_SEXUAL_TRAUMA         float64\n",
      "DIAGNOSIS_CHILDHOOD_TRAUMA        int64\n",
      "DIAGNOSIS_CPTSD                 float64\n",
      "treatmentdurationdays           float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Load the cleaned dataset from Step 1\n",
    "df = pd.read_csv(\"cleaned_data_baseline.csv\")\n",
    "\n",
    "# Quick check\n",
    "print(df.shape)\n",
    "print(df.dtypes.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "62c27ae4-cfe3-4ba7-9a9a-f2fd7b63f3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate Numerical and Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "0f9e1b8d-adda-4f10-8cb7-e65d17ae31a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical Columns: 204\n",
      "Categorical Columns: 0\n"
     ]
    }
   ],
   "source": [
    "# Identify numerical and categorical columns\n",
    "numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "print(f\"Numerical Columns: {len(numerical_cols)}\")\n",
    "print(f\"Categorical Columns: {len(categorical_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "33da4410-c1a9-492b-b1da-00f1cf6b1281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values summary:\n",
      "DIAGNOSIS_PSYCHOTIC_missing: 2484\n",
      "DIAGNOSIS_ANXIETY_OCD_missing: 2484\n",
      "Bipolar_and_Mood_disorder_missing: 2484\n",
      "DIAGNOSIS_EATING_DISORDER_missing: 2484\n",
      "total_rows: 6125\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Check missing values for each variable\n",
    "missing_summary = {\n",
    "    'DIAGNOSIS_PSYCHOTIC_missing': df['DIAGNOSIS_PSYCHOTIC'].isna().sum(),\n",
    "    'DIAGNOSIS_ANXIETY_OCD_missing': df['DIAGNOSIS_ANXIETY_OCD'].isna().sum(),\n",
    "    'Bipolar_and_Mood_disorder_missing': df['Bipolar_and_Mood_disorder'].isna().sum(),\n",
    "    'DIAGNOSIS_EATING_DISORDER_missing': df['DIAGNOSIS_EATING_DISORDER'].isna().sum(),\n",
    "    'total_rows': len(df)\n",
    "}\n",
    "\n",
    "print(\"Missing values summary:\")\n",
    "for key, value in missing_summary.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d32dd334-5787-4cc8-a9f7-39d96bba8507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing data pattern:\n",
      "has_missing\n",
      "False    3641\n",
      "True     2484\n",
      "Name: count, dtype: int64\n",
      "Patients with missing data: 2484\n",
      "Patients with complete data: 3641\n"
     ]
    }
   ],
   "source": [
    "# Define the mental health variables\n",
    "mental_health_vars = ['DIAGNOSIS_PSYCHOTIC', 'DIAGNOSIS_ANXIETY_OCD', \n",
    "                      'Bipolar_and_Mood_disorder', 'DIAGNOSIS_EATING_DISORDER']\n",
    "\n",
    "# Check patients with missing data on any of the 4 variables\n",
    "df['has_missing'] = df[mental_health_vars].isna().any(axis=1)\n",
    "\n",
    "# Summary of missing pattern\n",
    "print(\"\\nMissing data pattern:\")\n",
    "print(df['has_missing'].value_counts())\n",
    "print(f\"Patients with missing data: {df['has_missing'].sum()}\")\n",
    "print(f\"Patients with complete data: {(~df['has_missing']).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e2775c75-504b-41b0-a2c1-dc66adc7ce20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset summary:\n",
      "Original dataset: 6125 observations\n",
      "Complete cases: 3641 observations\n",
      "Excluded (missing): 2484 observations\n"
     ]
    }
   ],
   "source": [
    "# Store original count before filtering\n",
    "original_count = len(df)\n",
    "\n",
    "# Filter to keep only complete cases (this modifies df)\n",
    "df = df.dropna(subset=mental_health_vars)\n",
    "\n",
    "# Get the count after filtering\n",
    "complete_count = len(df)\n",
    "\n",
    "# Calculate excluded count\n",
    "excluded_count = original_count - complete_count\n",
    "\n",
    "# Verify the counts\n",
    "print(f\"\\nDataset summary:\")\n",
    "print(f\"Original dataset: {original_count} observations\")\n",
    "print(f\"Complete cases: {complete_count} observations\")\n",
    "print(f\"Excluded (missing): {excluded_count} observations\")\n",
    "\n",
    "# Remove the temporary column (if it exists)\n",
    "if 'has_missing' in df.columns:\n",
    "    df = df.drop('has_missing', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "07fc6774-6010-4ea8-8f35-f4b56d239ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values in mental health variables:\n",
      "DIAGNOSIS_PSYCHOTIC: 0\n",
      "DIAGNOSIS_ANXIETY_OCD: 0\n",
      "Bipolar_and_Mood_disorder: 0\n",
      "DIAGNOSIS_EATING_DISORDER: 0\n"
     ]
    }
   ],
   "source": [
    "# Check the 4 variables you filtered on (should be 0 missing)\n",
    "mental_health_vars = ['DIAGNOSIS_PSYCHOTIC', 'DIAGNOSIS_ANXIETY_OCD', \n",
    "                      'Bipolar_and_Mood_disorder', 'DIAGNOSIS_EATING_DISORDER']\n",
    "\n",
    "print(f\"\\nMissing values in mental health variables:\")\n",
    "for var in mental_health_vars:\n",
    "    missing = df[var].isnull().sum()\n",
    "    print(f\"{var}: {missing}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b0580f30-66e5-49c6-94a6-7d15a9d5b573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3641 entries, 0 to 6124\n",
      "Columns: 204 entries, DIAGNOSIS_ANXIETY_OCD to ethnicity_other\n",
      "dtypes: float64(10), int64(194)\n",
      "memory usage: 5.7 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "715a4034-509e-4e7d-973e-ee50bbb33fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Step 2 Complete: Final prepared dataset saved as 'final_prepared_data.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Save the fully prepared data\n",
    "df.to_csv(\"final_prepared_data.csv\", index=False)\n",
    "print(\" Step 2 Complete: Final prepared dataset saved as 'final_prepared_data.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ad70e2d4-5b39-4d75-9165-77a7f6b99979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "STEP 1: MICE IMPUTATION\n",
      "==================================================\n",
      "\n",
      "=== Running MICE Imputation: Dataset 1 ===\n",
      " Completed imputation 1\n",
      "\n",
      "=== Running MICE Imputation: Dataset 2 ===\n",
      " Completed imputation 2\n",
      "\n",
      "=== Running MICE Imputation: Dataset 3 ===\n",
      " Completed imputation 3\n",
      "\n",
      "=== Running MICE Imputation: Dataset 4 ===\n",
      " Completed imputation 4\n",
      "\n",
      "=== Running MICE Imputation: Dataset 5 ===\n",
      " Completed imputation 5\n",
      "\n",
      "==================================================\n",
      "STEP 2: ROUNDING NUMERIC COLUMNS\n",
      "==================================================\n",
      " Imputation 1: Rounded 204 numeric columns to 0 decimal place(s).\n",
      " Imputation 2: Rounded 204 numeric columns to 0 decimal place(s).\n",
      " Imputation 3: Rounded 204 numeric columns to 0 decimal place(s).\n",
      " Imputation 4: Rounded 204 numeric columns to 0 decimal place(s).\n",
      " Imputation 5: Rounded 204 numeric columns to 0 decimal place(s).\n",
      "\n",
      "==================================================\n",
      "STEP 3: SAVING FINAL DATASETS\n",
      "==================================================\n",
      " Saved files for imputation 1:\n",
      "   → imputed_data/df_imputed_final_imp1.pkl\n",
      "   → imputed_data/df_imputed_final_imp1.csv\n",
      "   → imputed_data/df_imputed_final_imp1.xlsx\n",
      " Saved files for imputation 2:\n",
      "   → imputed_data/df_imputed_final_imp2.pkl\n",
      "   → imputed_data/df_imputed_final_imp2.csv\n",
      "   → imputed_data/df_imputed_final_imp2.xlsx\n",
      " Saved files for imputation 3:\n",
      "   → imputed_data/df_imputed_final_imp3.pkl\n",
      "   → imputed_data/df_imputed_final_imp3.csv\n",
      "   → imputed_data/df_imputed_final_imp3.xlsx\n",
      " Saved files for imputation 4:\n",
      "   → imputed_data/df_imputed_final_imp4.pkl\n",
      "   → imputed_data/df_imputed_final_imp4.csv\n",
      "   → imputed_data/df_imputed_final_imp4.xlsx\n",
      " Saved files for imputation 5:\n",
      "   → imputed_data/df_imputed_final_imp5.pkl\n",
      "   → imputed_data/df_imputed_final_imp5.csv\n",
      "   → imputed_data/df_imputed_final_imp5.xlsx\n",
      "\n",
      "==================================================\n",
      "STEP 4: VERIFYING DATASET DIFFERENCES\n",
      "==================================================\n",
      " Checking differences in 4 columns that had missing values...\n",
      " Column 'DIAGNOSIS_SMOKING': 34 different values between datasets 1 & 2\n",
      " Column 'DIAGNOSIS_SEXUAL_TRAUMA': 11 different values between datasets 1 & 2\n",
      " Column 'DIAGNOSIS_CPTSD': 21 different values between datasets 1 & 2\n",
      "\n",
      " SUCCESS: Datasets show proper variability!\n",
      "\n",
      "==================================================\n",
      " MICE IMPUTATION COMPLETE!\n",
      "==================================================\n",
      " Created 5 imputed datasets\n",
      " Applied rounding to all numeric columns\n",
      " Saved files in: imputed_data/\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "# ========== CONFIG ==========\n",
    "save_folder = \"imputed_data\"\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "n_imputations = 5\n",
    "\n",
    "# ========== LOAD ==========\n",
    "# Ensure df is already defined\n",
    "assert 'df' in globals(), \"Please load the original DataFrame as `df` before running this script.\"\n",
    "\n",
    "# ========== IDENTIFY NUMERIC COLUMNS ==========\n",
    "numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "\n",
    "# ========== STEP 1: MICE IMPUTATION ==========\n",
    "print(\"=\" * 50)\n",
    "print(\"STEP 1: MICE IMPUTATION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "imputed_dfs = []\n",
    "for i in range(1, n_imputations + 1):\n",
    "    print(f\"\\n=== Running MICE Imputation: Dataset {i} ===\")\n",
    "    #  NEW instance with different seed AND sample_posterior=True for randomness\n",
    "    mice_imputer = IterativeImputer(\n",
    "        max_iter=10, \n",
    "        random_state=42+i,  # Different base to avoid low numbers\n",
    "        sample_posterior=True,  #  KEY: This adds randomness!\n",
    "        n_nearest_features=None,\n",
    "        initial_strategy='mean'\n",
    "    )\n",
    "    # Fit-transform on numeric columns\n",
    "    imputed_array = mice_imputer.fit_transform(df[numeric_cols])\n",
    "    # Replace numeric columns in a copy of the original df\n",
    "    df_imputed = df.copy()\n",
    "    df_imputed[numeric_cols] = pd.DataFrame(imputed_array, columns=numeric_cols, index=df.index)\n",
    "    # Append to list\n",
    "    imputed_dfs.append(df_imputed)\n",
    "    print(f\" Completed imputation {i}\")\n",
    "\n",
    "# ========== STEP 2: ROUNDING ==========\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"STEP 2: ROUNDING NUMERIC COLUMNS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "def round_all_numeric_columns_all_imputations(imputed_dfs, decimals=0, verbose=True):\n",
    "    rounded_dfs = []\n",
    "    for i, df in enumerate(imputed_dfs):\n",
    "        df_copy = df.copy()\n",
    "        numeric_cols = df_copy.select_dtypes(include=[np.number]).columns\n",
    "        df_copy[numeric_cols] = df_copy[numeric_cols].round(decimals)\n",
    "        rounded_dfs.append(df_copy)\n",
    "        if verbose:\n",
    "            print(f\" Imputation {i+1}: Rounded {len(numeric_cols)} numeric columns to {decimals} decimal place(s).\")\n",
    "    return rounded_dfs\n",
    "\n",
    "# Apply rounding to all imputed datasets\n",
    "imputed_dfs = round_all_numeric_columns_all_imputations(imputed_dfs)\n",
    "\n",
    "# ========== STEP 3: SAVE FINAL DATASETS ==========\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"STEP 3: SAVING FINAL DATASETS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for i, df_imputed in enumerate(imputed_dfs, 1):\n",
    "    # Save outputs\n",
    "    pkl_path = f\"{save_folder}/df_imputed_final_imp{i}.pkl\"\n",
    "    csv_path = f\"{save_folder}/df_imputed_final_imp{i}.csv\"\n",
    "    excel_path = f\"{save_folder}/df_imputed_final_imp{i}.xlsx\"\n",
    "    \n",
    "    df_imputed.to_pickle(pkl_path)\n",
    "    df_imputed.to_csv(csv_path, index=False)\n",
    "    df_imputed.to_excel(excel_path, index=False)\n",
    "    \n",
    "    print(f\" Saved files for imputation {i}:\")\n",
    "    print(f\"   → {pkl_path}\")\n",
    "    print(f\"   → {csv_path}\")\n",
    "    print(f\"   → {excel_path}\")\n",
    "\n",
    "# ========== STEP 4: VERIFY DATASETS ARE DIFFERENT ==========\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"STEP 4: VERIFYING DATASET DIFFERENCES\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "def check_imputation_differences(imputed_dfs, verbose=True):\n",
    "    \"\"\"Check if imputed datasets are actually different from each other\"\"\"\n",
    "    if len(imputed_dfs) < 2:\n",
    "        print(\"  Only one dataset - cannot check differences\")\n",
    "        return\n",
    "    \n",
    "    # Get numeric columns that had missing values originally\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    missing_cols = [col for col in numeric_cols if df[col].isnull().any()]\n",
    "    \n",
    "    if not missing_cols:\n",
    "        print(\"  No missing values found in original data\")\n",
    "        return\n",
    "    \n",
    "    print(f\" Checking differences in {len(missing_cols)} columns that had missing values...\")\n",
    "    \n",
    "    differences_found = False\n",
    "    \n",
    "    for col in missing_cols[:3]:  # Check first 3 columns with missing values\n",
    "        # Compare first two datasets for this column\n",
    "        values_1 = imputed_dfs[0][col].values\n",
    "        values_2 = imputed_dfs[1][col].values\n",
    "        \n",
    "        if not np.array_equal(values_1, values_2):\n",
    "            differences_found = True\n",
    "            # Count how many values are different\n",
    "            diff_count = np.sum(values_1 != values_2)\n",
    "            print(f\" Column '{col}': {diff_count} different values between datasets 1 & 2\")\n",
    "        else:\n",
    "            print(f\" Column '{col}': IDENTICAL values between datasets 1 & 2\")\n",
    "    \n",
    "    if differences_found:\n",
    "        print(f\"\\n SUCCESS: Datasets show proper variability!\")\n",
    "    else:\n",
    "        print(f\"\\n  WARNING: Datasets appear identical - check random_state implementation\")\n",
    "    \n",
    "    return differences_found\n",
    "\n",
    "# Run the check\n",
    "check_imputation_differences(imputed_dfs)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\" MICE IMPUTATION COMPLETE!\")\n",
    "print(\"=\" * 50)\n",
    "print(f\" Created {n_imputations} imputed datasets\")\n",
    "print(f\" Applied rounding to all numeric columns\")\n",
    "print(f\" Saved files in: {save_folder}/\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "7b53723b-bc90-45e1-b949-260ede598f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CHECKING IMPUTATION DIFFERENCES\n",
      "============================================================\n",
      "Dataset 1 vs Dataset 2: DIFFERENT ✅\n",
      "  'DIAGNOSIS_SMOKING': 34 different values\n",
      "  'DIAGNOSIS_SEXUAL_TRAUMA': 11 different values\n",
      "  'DIAGNOSIS_CPTSD': 21 different values\n",
      "  'treatmentdurationdays': 1127 different values\n",
      "  Total different values: 1193\n",
      "\n",
      "=== Checking all 5 datasets ===\n",
      "Dataset 1 vs Dataset 2: DIFFERENT ✅\n",
      "Dataset 1 vs Dataset 3: DIFFERENT ✅\n",
      "Dataset 1 vs Dataset 4: DIFFERENT ✅\n",
      "Dataset 1 vs Dataset 5: DIFFERENT ✅\n",
      "Dataset 2 vs Dataset 3: DIFFERENT ✅\n",
      "Dataset 2 vs Dataset 4: DIFFERENT ✅\n",
      "Dataset 2 vs Dataset 5: DIFFERENT ✅\n",
      "Dataset 3 vs Dataset 4: DIFFERENT ✅\n",
      "Dataset 3 vs Dataset 5: DIFFERENT ✅\n",
      "Dataset 4 vs Dataset 5: DIFFERENT ✅\n",
      "\n",
      "=== Checking differences in originally missing positions ===\n",
      "\n",
      "Column 'DIAGNOSIS_SMOKING' (64 missing values):\n",
      "  Dataset 1 vs 2: 34/64 different imputed values ✅\n",
      "  Dataset 2 vs 3: 35/64 different imputed values ✅\n",
      "  Dataset 3 vs 4: 33/64 different imputed values ✅\n",
      "  Dataset 4 vs 5: 35/64 different imputed values ✅\n",
      "\n",
      "Column 'DIAGNOSIS_SEXUAL_TRAUMA' (29 missing values):\n",
      "  Dataset 1 vs 2: 11/29 different imputed values ✅\n",
      "  Dataset 2 vs 3: 14/29 different imputed values ✅\n",
      "  Dataset 3 vs 4: 16/29 different imputed values ✅\n",
      "  Dataset 4 vs 5: 17/29 different imputed values ✅\n",
      "\n",
      "Column 'DIAGNOSIS_CPTSD' (51 missing values):\n",
      "  Dataset 1 vs 2: 21/51 different imputed values ✅\n",
      "  Dataset 2 vs 3: 24/51 different imputed values ✅\n",
      "  Dataset 3 vs 4: 29/51 different imputed values ✅\n",
      "  Dataset 4 vs 5: 22/51 different imputed values ✅\n",
      "\n",
      "Column 'treatmentdurationdays' (1412 missing values):\n",
      "  Dataset 1 vs 2: 1127/1412 different imputed values ✅\n",
      "  Dataset 2 vs 3: 1151/1412 different imputed values ✅\n",
      "  Dataset 3 vs 4: 1175/1412 different imputed values ✅\n",
      "  Dataset 4 vs 5: 1146/1412 different imputed values ✅\n",
      "\n",
      "🎉 SUCCESS: Found differences in imputed values!\n",
      "\n",
      "=== Sample imputed values (first 3 missing positions) ===\n",
      "\n",
      "Column 'DIAGNOSIS_SMOKING' at positions [5, 8, 65]:\n",
      "  Dataset 1: [-1.  0.  1.]\n",
      "  Dataset 2: [ 0. -1.  1.]\n",
      "  Dataset 3: [ 0. -0.  1.]\n",
      "  Dataset 4: [ 1. -1.  1.]\n",
      "  Dataset 5: [0. 0. 0.]\n",
      "\n",
      "Column 'DIAGNOSIS_SEXUAL_TRAUMA' at positions [34, 35, 36]:\n",
      "  Dataset 1: [1. 1. 1.]\n",
      "  Dataset 2: [1. 1. 1.]\n",
      "  Dataset 3: [1. 2. 0.]\n",
      "  Dataset 4: [ 0.  1. -0.]\n",
      "  Dataset 5: [0. 1. 1.]\n",
      "\n",
      "Column 'DIAGNOSIS_CPTSD' at positions [8, 65, 248]:\n",
      "  Dataset 1: [0. 1. 1.]\n",
      "  Dataset 2: [1. 1. 1.]\n",
      "  Dataset 3: [1. 1. 1.]\n",
      "  Dataset 4: [0. 1. 1.]\n",
      "  Dataset 5: [0. 1. 1.]\n",
      "\n",
      "Column 'treatmentdurationdays' at positions [0, 1, 6]:\n",
      "  Dataset 1: [3. 5. 2.]\n",
      "  Dataset 2: [3. 4. 5.]\n",
      "  Dataset 3: [3. 3. 3.]\n",
      "  Dataset 4: [3. 4. 4.]\n",
      "  Dataset 5: [5. 4. 1.]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ========== METHOD 1: QUICK CHECK - Compare first 2 datasets ==========\n",
    "def quick_difference_check(imputed_dfs):\n",
    "    \"\"\"Quick check to see if first two datasets are different\"\"\"\n",
    "    if len(imputed_dfs) < 2:\n",
    "        print(\"Need at least 2 datasets to compare\")\n",
    "        return\n",
    "    \n",
    "    df1 = imputed_dfs[0]\n",
    "    df2 = imputed_dfs[1]\n",
    "    \n",
    "    # Check if dataframes are identical\n",
    "    are_identical = df1.equals(df2)\n",
    "    print(f\"Dataset 1 vs Dataset 2: {'IDENTICAL ❌' if are_identical else 'DIFFERENT ✅'}\")\n",
    "    \n",
    "    if not are_identical:\n",
    "        # Count different values\n",
    "        numeric_cols = df1.select_dtypes(include=[np.number]).columns\n",
    "        total_diff = 0\n",
    "        for col in numeric_cols:\n",
    "            diff_count = np.sum(df1[col] != df2[col])\n",
    "            if diff_count > 0:\n",
    "                total_diff += diff_count\n",
    "                print(f\"  '{col}': {diff_count} different values\")\n",
    "        print(f\"  Total different values: {total_diff}\")\n",
    "\n",
    "# ========== METHOD 2: DETAILED CHECK - All pairwise comparisons ==========\n",
    "def detailed_difference_check(imputed_dfs):\n",
    "    \"\"\"Check differences between all pairs of datasets\"\"\"\n",
    "    n_datasets = len(imputed_dfs)\n",
    "    print(f\"\\n=== Checking all {n_datasets} datasets ===\")\n",
    "    \n",
    "    numeric_cols = imputed_dfs[0].select_dtypes(include=[np.number]).columns\n",
    "    \n",
    "    for i in range(n_datasets):\n",
    "        for j in range(i+1, n_datasets):\n",
    "            are_identical = imputed_dfs[i].equals(imputed_dfs[j])\n",
    "            print(f\"Dataset {i+1} vs Dataset {j+1}: {'IDENTICAL ❌' if are_identical else 'DIFFERENT ✅'}\")\n",
    "\n",
    "# ========== METHOD 3: FOCUS ON ORIGINALLY MISSING VALUES ==========\n",
    "def check_missing_value_differences(original_df, imputed_dfs):\n",
    "    \"\"\"Check differences only in originally missing positions\"\"\"\n",
    "    print(f\"\\n=== Checking differences in originally missing positions ===\")\n",
    "    \n",
    "    numeric_cols = original_df.select_dtypes(include=[np.number]).columns\n",
    "    \n",
    "    differences_found = False\n",
    "    for col in numeric_cols:\n",
    "        if original_df[col].isnull().any():\n",
    "            missing_mask = original_df[col].isnull()\n",
    "            print(f\"\\nColumn '{col}' ({missing_mask.sum()} missing values):\")\n",
    "            \n",
    "            # Compare imputed values at missing positions\n",
    "            for i in range(len(imputed_dfs)-1):\n",
    "                imp1_values = imputed_dfs[i].loc[missing_mask, col]\n",
    "                imp2_values = imputed_dfs[i+1].loc[missing_mask, col]\n",
    "                \n",
    "                are_same = np.array_equal(imp1_values.values, imp2_values.values)\n",
    "                if not are_same:\n",
    "                    differences_found = True\n",
    "                    diff_count = np.sum(imp1_values.values != imp2_values.values)\n",
    "                    print(f\"  Dataset {i+1} vs {i+2}: {diff_count}/{len(imp1_values)} different imputed values ✅\")\n",
    "                else:\n",
    "                    print(f\"  Dataset {i+1} vs {i+2}: IDENTICAL imputed values ❌\")\n",
    "    \n",
    "    return differences_found\n",
    "\n",
    "# ========== METHOD 4: SAMPLE VALUES FROM EACH DATASET ==========\n",
    "def show_sample_imputed_values(original_df, imputed_dfs, n_samples=5):\n",
    "    \"\"\"Show sample imputed values from each dataset\"\"\"\n",
    "    print(f\"\\n=== Sample imputed values (first {n_samples} missing positions) ===\")\n",
    "    \n",
    "    numeric_cols = original_df.select_dtypes(include=[np.number]).columns\n",
    "    \n",
    "    for col in numeric_cols:\n",
    "        if original_df[col].isnull().any():\n",
    "            missing_positions = original_df[original_df[col].isnull()].index[:n_samples]\n",
    "            \n",
    "            print(f\"\\nColumn '{col}' at positions {list(missing_positions)}:\")\n",
    "            for i, df_imp in enumerate(imputed_dfs):\n",
    "                values = df_imp.loc[missing_positions, col].values\n",
    "                print(f\"  Dataset {i+1}: {values}\")\n",
    "\n",
    "# ========== RUN ALL CHECKS ==========\n",
    "print(\"=\" * 60)\n",
    "print(\"CHECKING IMPUTATION DIFFERENCES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Method 1: Quick check\n",
    "quick_difference_check(imputed_dfs)\n",
    "\n",
    "# Method 2: All pairwise comparisons  \n",
    "detailed_difference_check(imputed_dfs)\n",
    "\n",
    "# Method 3: Focus on originally missing values (assumes 'df' is your original dataframe)\n",
    "if 'df' in globals():\n",
    "    differences_found = check_missing_value_differences(df, imputed_dfs)\n",
    "    if differences_found:\n",
    "        print(f\"\\n🎉 SUCCESS: Found differences in imputed values!\")\n",
    "    else:\n",
    "        print(f\"\\n⚠️ WARNING: No differences found in imputed values!\")\n",
    "\n",
    "# Method 4: Show sample values\n",
    "if 'df' in globals():\n",
    "    show_sample_imputed_values(df, imputed_dfs, n_samples=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "711fb48b-df58-47c5-ab5a-1bf448defe1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y for imputation 1 defined. Sample values:\n",
      "0   -41.0\n",
      "1   -15.0\n",
      "2   -46.0\n",
      "3   -41.0\n",
      "4   -20.0\n",
      "Name: caps5_change_baseline, dtype: float64\n",
      "Y for imputation 2 defined. Sample values:\n",
      "0   -41.0\n",
      "1   -15.0\n",
      "2   -46.0\n",
      "3   -41.0\n",
      "4   -20.0\n",
      "Name: caps5_change_baseline, dtype: float64\n",
      "Y for imputation 3 defined. Sample values:\n",
      "0   -41.0\n",
      "1   -15.0\n",
      "2   -46.0\n",
      "3   -41.0\n",
      "4   -20.0\n",
      "Name: caps5_change_baseline, dtype: float64\n",
      "Y for imputation 4 defined. Sample values:\n",
      "0   -41.0\n",
      "1   -15.0\n",
      "2   -46.0\n",
      "3   -41.0\n",
      "4   -20.0\n",
      "Name: caps5_change_baseline, dtype: float64\n",
      "Y for imputation 5 defined. Sample values:\n",
      "0   -41.0\n",
      "1   -15.0\n",
      "2   -46.0\n",
      "3   -41.0\n",
      "4   -20.0\n",
      "Name: caps5_change_baseline, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "imputed_folder = \"imputed_data\"\n",
    "n_imputations = 5\n",
    "\n",
    "# Lists to hold DataFrames and Y vectors\n",
    "imputed_dfs = []\n",
    "Y_list = []\n",
    "\n",
    "for i in range(1, n_imputations + 1):\n",
    "    file_path = f\"{imputed_folder}/df_imputed_final_imp{i}.pkl\"\n",
    "    \n",
    "    # Load imputed DataFrame\n",
    "    df_imp = pd.read_pickle(file_path)\n",
    "    imputed_dfs.append(df_imp)\n",
    "\n",
    "    # Define Y for this imputation\n",
    "    Y = df_imp[\"caps5_change_baseline\"]\n",
    "    Y_list.append(Y)\n",
    "\n",
    "    print(f\"Y for imputation {i} defined. Sample values:\")\n",
    "    print(Y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "867d7aa7-2678-4d61-b04d-49183d36f6dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Imputed Dataset 1 ===\n",
      "Medication Groups:\n",
      "['CAT_Antidepressiva', 'CAT_Benzodiazepine', 'CAT_Anti_epileptica', 'CAT_Antihistaminica', 'CAT_Opioden', 'CAT_Antipsychotica', 'CAT_Aceetanilidederivaten', 'CAT_Antihypertensiva', 'CAT_Salicylaat', 'CAT_NSAIDs', 'CAT_Migrainemiddelen', 'CAT_ADHD', 'CAT_Anticonceptiva', 'CAT_Z_drugs', 'CAT_Spierrelaxantia', 'CAT_Immunomodulerende_middelen', 'CAT_Alcoholverslaving', 'CAT_Stemmingsstabilisatoren', 'CAT_Parkinson', 'CAT_ALL', 'CAT_ALL_PSYCHOTROPICS', 'CAT_ALL_PSYCHOTROPICS_EXCL_BENZO', 'CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS']\n",
      "Total Medication Groups Found: 23\n",
      "\n",
      "=== Imputed Dataset 2 ===\n",
      "Medication Groups:\n",
      "['CAT_Antidepressiva', 'CAT_Benzodiazepine', 'CAT_Anti_epileptica', 'CAT_Antihistaminica', 'CAT_Opioden', 'CAT_Antipsychotica', 'CAT_Aceetanilidederivaten', 'CAT_Antihypertensiva', 'CAT_Salicylaat', 'CAT_NSAIDs', 'CAT_Migrainemiddelen', 'CAT_ADHD', 'CAT_Anticonceptiva', 'CAT_Z_drugs', 'CAT_Spierrelaxantia', 'CAT_Immunomodulerende_middelen', 'CAT_Alcoholverslaving', 'CAT_Stemmingsstabilisatoren', 'CAT_Parkinson', 'CAT_ALL', 'CAT_ALL_PSYCHOTROPICS', 'CAT_ALL_PSYCHOTROPICS_EXCL_BENZO', 'CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS']\n",
      "Total Medication Groups Found: 23\n",
      "\n",
      "=== Imputed Dataset 3 ===\n",
      "Medication Groups:\n",
      "['CAT_Antidepressiva', 'CAT_Benzodiazepine', 'CAT_Anti_epileptica', 'CAT_Antihistaminica', 'CAT_Opioden', 'CAT_Antipsychotica', 'CAT_Aceetanilidederivaten', 'CAT_Antihypertensiva', 'CAT_Salicylaat', 'CAT_NSAIDs', 'CAT_Migrainemiddelen', 'CAT_ADHD', 'CAT_Anticonceptiva', 'CAT_Z_drugs', 'CAT_Spierrelaxantia', 'CAT_Immunomodulerende_middelen', 'CAT_Alcoholverslaving', 'CAT_Stemmingsstabilisatoren', 'CAT_Parkinson', 'CAT_ALL', 'CAT_ALL_PSYCHOTROPICS', 'CAT_ALL_PSYCHOTROPICS_EXCL_BENZO', 'CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS']\n",
      "Total Medication Groups Found: 23\n",
      "\n",
      "=== Imputed Dataset 4 ===\n",
      "Medication Groups:\n",
      "['CAT_Antidepressiva', 'CAT_Benzodiazepine', 'CAT_Anti_epileptica', 'CAT_Antihistaminica', 'CAT_Opioden', 'CAT_Antipsychotica', 'CAT_Aceetanilidederivaten', 'CAT_Antihypertensiva', 'CAT_Salicylaat', 'CAT_NSAIDs', 'CAT_Migrainemiddelen', 'CAT_ADHD', 'CAT_Anticonceptiva', 'CAT_Z_drugs', 'CAT_Spierrelaxantia', 'CAT_Immunomodulerende_middelen', 'CAT_Alcoholverslaving', 'CAT_Stemmingsstabilisatoren', 'CAT_Parkinson', 'CAT_ALL', 'CAT_ALL_PSYCHOTROPICS', 'CAT_ALL_PSYCHOTROPICS_EXCL_BENZO', 'CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS']\n",
      "Total Medication Groups Found: 23\n",
      "\n",
      "=== Imputed Dataset 5 ===\n",
      "Medication Groups:\n",
      "['CAT_Antidepressiva', 'CAT_Benzodiazepine', 'CAT_Anti_epileptica', 'CAT_Antihistaminica', 'CAT_Opioden', 'CAT_Antipsychotica', 'CAT_Aceetanilidederivaten', 'CAT_Antihypertensiva', 'CAT_Salicylaat', 'CAT_NSAIDs', 'CAT_Migrainemiddelen', 'CAT_ADHD', 'CAT_Anticonceptiva', 'CAT_Z_drugs', 'CAT_Spierrelaxantia', 'CAT_Immunomodulerende_middelen', 'CAT_Alcoholverslaving', 'CAT_Stemmingsstabilisatoren', 'CAT_Parkinson', 'CAT_ALL', 'CAT_ALL_PSYCHOTROPICS', 'CAT_ALL_PSYCHOTROPICS_EXCL_BENZO', 'CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS']\n",
      "Total Medication Groups Found: 23\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load imputed DataFrames from saved files\n",
    "imputed_folder = \"imputed_data\"\n",
    "n_imputations = 5\n",
    "\n",
    "for i in range(1, n_imputations + 1):\n",
    "    print(f\"\\n=== Imputed Dataset {i} ===\")\n",
    "\n",
    "    # Load each imputed dataset\n",
    "    df_imp = pd.read_pickle(f\"{imputed_folder}/df_imputed_final_imp{i}.pkl\")\n",
    "\n",
    "    # Get all CAT_* columns\n",
    "    cat_columns = [col for col in df_imp.columns if col.startswith('CAT_')]\n",
    "\n",
    "    print(\"Medication Groups:\")\n",
    "    print(cat_columns)\n",
    "    print(\"Total Medication Groups Found:\", len(cat_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "e17e7f0c-2653-4a13-9d3f-d96b63ee9397",
   "metadata": {},
   "outputs": [],
   "source": [
    "covariates_CAT_ADHD = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline', 'CAT_Anti_epileptica', 'CAT_Antidepressiva', 'CAT_Antipsychotica',\n",
    "    'CAT_Benzodiazepine', 'CAT_Opioden',\n",
    "    'CAT_Z_drugs', 'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD',\n",
    "    'DIAGNOSIS_SEXUAL_TRAUMA', 'DIAGNOSIS_SMOKING', 'DIAGNOSIS_SUICIDALITY',\n",
    "    'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"EB_NON_TF_THERAPY\", \"OTHER_TREATM_APPROACH\", \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "\n",
    "covariates_CAT_Aceetanilidederivaten = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline', 'CAT_Anti_epileptica', 'CAT_Antidepressiva', 'CAT_Antipsychotica',\n",
    "    'CAT_Benzodiazepine', 'CAT_Opioden', 'CAT_Z_drugs',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SMOKING', 'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"EB_NON_TF_THERAPY\", \"OTHER_TREATM_APPROACH\", \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "\n",
    "covariates_CAT_Z_drugs = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline', 'CAT_Anti_epileptica', 'CAT_Antidepressiva', 'CAT_Antipsychotica',\n",
    "    'CAT_Benzodiazepine', 'CAT_Opioden',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SMOKING', 'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"EB_NON_TF_THERAPY\", \"OTHER_TREATM_APPROACH\", \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "\n",
    "covariates_CAT_Opioden = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline', 'CAT_Anti_epileptica',\n",
    "    'CAT_Antidepressiva',\n",
    "    'CAT_Antipsychotica', 'CAT_Benzodiazepine', 'CAT_Z_drugs',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SMOKING', 'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"EB_NON_TF_THERAPY\", \"OTHER_TREATM_APPROACH\", \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "\n",
    "covariates_CAT_NSAIDs = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline', 'CAT_Anti_epileptica',\n",
    "    'CAT_Antidepressiva',\n",
    "    'CAT_Antipsychotica', 'CAT_Benzodiazepine', 'CAT_Opioden', 'CAT_Z_drugs',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SMOKING', 'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"EB_NON_TF_THERAPY\", \"OTHER_TREATM_APPROACH\", \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "covariates_CAT_Benzodiazepine = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline', 'CAT_Anti_epileptica',\n",
    "    'CAT_Antidepressiva',\n",
    "    'CAT_Antipsychotica', 'CAT_Opioden', 'CAT_Z_drugs',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SMOKING', 'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"EB_NON_TF_THERAPY\", \"OTHER_TREATM_APPROACH\", \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "\n",
    "covariates_CAT_Antihypertensiva = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline', 'CAT_Anti_epileptica',\n",
    "    'CAT_Antidepressiva', 'CAT_Antipsychotica',\n",
    "    'CAT_Benzodiazepine', 'CAT_Opioden', 'CAT_Z_drugs',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SMOKING', 'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"EB_NON_TF_THERAPY\", \"OTHER_TREATM_APPROACH\", \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "\n",
    "covariates_CAT_Antihistaminica = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline', 'CAT_Anti_epileptica',\n",
    "    'CAT_Antidepressiva', 'CAT_Antipsychotica',\n",
    "    'CAT_Benzodiazepine', 'CAT_Opioden', 'CAT_Z_drugs',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SMOKING', 'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"EB_NON_TF_THERAPY\", \"OTHER_TREATM_APPROACH\", \"Bipolar_and_Mood_disorder\"\n",
    "]\n",
    "\n",
    "\n",
    "covariates_CAT_Anti_epileptica = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline', 'CAT_Antidepressiva', 'CAT_Antipsychotica',\n",
    "    'CAT_Benzodiazepine', 'CAT_Opioden', 'CAT_Z_drugs',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SMOKING', 'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"EB_NON_TF_THERAPY\", \"OTHER_TREATM_APPROACH\", \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "\n",
    "covariates_CAT_Antidepressiva = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline', 'CAT_Anti_epileptica', 'CAT_Antipsychotica',\n",
    "    'CAT_Benzodiazepine', 'CAT_Opioden', 'CAT_Z_drugs',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SMOKING', 'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"EB_NON_TF_THERAPY\", \"OTHER_TREATM_APPROACH\", \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "\n",
    "covariates_CAT_Antipsychotica = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline', 'CAT_Anti_epileptica',\n",
    "    'CAT_Antidepressiva',\n",
    "    'CAT_Benzodiazepine', 'CAT_Opioden', 'CAT_Z_drugs',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SMOKING', 'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"EB_NON_TF_THERAPY\", \"OTHER_TREATM_APPROACH\", \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "covariates_CAT_ALL_PSYCHOTROPICS_EXCL_BENZO = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Benzodiazepine', 'CAT_Anticonceptiva',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SMOKING', 'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"EB_NON_TF_THERAPY\", \"OTHER_TREATM_APPROACH\", \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "covariates_CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Benzodiazepine', 'CAT_Z_drugs', 'CAT_Anticonceptiva',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SMOKING', 'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"EB_NON_TF_THERAPY\", \"OTHER_TREATM_APPROACH\", \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "\n",
    "covariates_CAT_ALL_PSYCHOTROPICS = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SMOKING', 'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"EB_NON_TF_THERAPY\", \"OTHER_TREATM_APPROACH\", \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "\n",
    "covariates_CAT_ALL = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA',\n",
    "    'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SMOKING', 'DIAGNOSIS_SUICIDALITY',\n",
    "    'age', 'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"EB_NON_TF_THERAPY\", \"OTHER_TREATM_APPROACH\", \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e8659b20-ab67-4388-bd8f-11c2dedcb4e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groups found: ['CAT_ADHD', 'CAT_Aceetanilidederivaten', 'CAT_Z_drugs', 'CAT_Opioden', 'CAT_NSAIDs', 'CAT_Benzodiazepine', 'CAT_Antihypertensiva', 'CAT_Antihistaminica', 'CAT_Anti_epileptica', 'CAT_Antidepressiva', 'CAT_Antipsychotica', 'CAT_ALL_PSYCHOTROPICS_EXCL_BENZO', 'CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS', 'CAT_ALL_PSYCHOTROPICS', 'CAT_ALL']\n",
      "['CAT_ADHD', 'CAT_Aceetanilidederivaten', 'CAT_Z_drugs', 'CAT_Opioden', 'CAT_NSAIDs', 'CAT_Benzodiazepine', 'CAT_Antihypertensiva', 'CAT_Antihistaminica', 'CAT_Anti_epileptica', 'CAT_Antidepressiva', 'CAT_Antipsychotica', 'CAT_ALL_PSYCHOTROPICS_EXCL_BENZO', 'CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS', 'CAT_ALL_PSYCHOTROPICS', 'CAT_ALL']\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# This finds all variables that start with covariates_CAT_ or covariates_cat_\n",
    "final_covariates_map = defaultdict(list)\n",
    "final_covariates_map.update({\n",
    "    var.replace(\"covariates_\", \"\"): val\n",
    "    for var, val in globals().items()\n",
    "    if var.lower().startswith(\"covariates_cat_\") and isinstance(val, list)\n",
    "})\n",
    "\n",
    "# Show detected group names\n",
    "print(\"Groups found:\", list(final_covariates_map.keys()))\n",
    "medication_groups = list(final_covariates_map.keys())\n",
    "print(medication_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "9f8c8ff1-c3d0-48d3-9fbf-98a6762e001e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Starting analysis for all CAT groups\n",
      "\n",
      " Processing CAT_Adhd...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: CAT_Adhd\n",
      "\n",
      " Processing CAT_Aceetanilidederivaten...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: CAT_Aceetanilidederivaten\n",
      "\n",
      " Processing CAT_Z_Drugs...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: CAT_Z_Drugs\n",
      "\n",
      " Processing CAT_Opioden...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: CAT_Opioden\n",
      "\n",
      " Processing CAT_Nsaids...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: CAT_Nsaids\n",
      "\n",
      " Processing CAT_Benzodiazepine...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: CAT_Benzodiazepine\n",
      "\n",
      " Processing CAT_Antihypertensiva...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: CAT_Antihypertensiva\n",
      "\n",
      " Processing CAT_Antihistaminica...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: CAT_Antihistaminica\n",
      "\n",
      " Processing CAT_Anti_Epileptica...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: CAT_Anti_Epileptica\n",
      "\n",
      " Processing CAT_Antidepressiva...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: CAT_Antidepressiva\n",
      "\n",
      " Processing CAT_Antipsychotica...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: CAT_Antipsychotica\n",
      "\n",
      " Processing CAT_All_Psychotropics_Excl_Benzo...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: CAT_All_Psychotropics_Excl_Benzo\n",
      "\n",
      " Processing CAT_All_Psychotropics_Excl_Sedatives_Hypnotics...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: CAT_All_Psychotropics_Excl_Sedatives_Hypnotics\n",
      "\n",
      " Processing CAT_All_Psychotropics...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: CAT_All_Psychotropics\n",
      "\n",
      " Processing CAT_All...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: CAT_All\n",
      "\n",
      " All CAT group analyses complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def run_all_CAT_group_models(imputed_dfs):\n",
    "    \"\"\"\n",
    "    Runs downstream analysis for each CAT medication group using imputed datasets.\n",
    "\n",
    "    Parameters:\n",
    "    - imputed_dfs: list of 5 imputed DataFrames (from df_imputed_final_imp1.pkl ... imp5.pkl)\n",
    "    \n",
    "    Notes:\n",
    "    - Covariate lists must be defined as global variables: covariates_cat_<group>\n",
    "    - Outputs are saved in: outputs/CAT_<GROUP>/\n",
    "    \"\"\"\n",
    "\n",
    "    print(\" Starting analysis for all CAT groups\")\n",
    "\n",
    "    for var_name in globals():\n",
    "        if var_name.lower().startswith(\"covariates_cat_\") and isinstance(globals()[var_name], list):\n",
    "            group_name = var_name.replace(\"covariates_\", \"\")\n",
    "            group_name = group_name.replace(\"_\", \" \").title().replace(\" \", \"_\")  # e.g., cat_z_drugs → Cat_Z_Drugs\n",
    "            group_name = group_name.replace(\"Cat_\", \"CAT_\")  # force prefix to uppercase\n",
    "\n",
    "            covariates = globals()[var_name]\n",
    "            output_dir = f\"outputs/{group_name}\"\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "            print(f\"\\n Processing {group_name}...\")\n",
    "\n",
    "            for k, df_imp in enumerate(imputed_dfs):\n",
    "                print(f\"  → Using imputation {k+1}\")\n",
    "\n",
    "                # Define X and Y\n",
    "                X = df_imp[covariates]\n",
    "                Y = df_imp[\"caps5_change_baseline\"]\n",
    "\n",
    "                # === Save X and Y as placeholder (replace with modeling later)\n",
    "                X.to_csv(f\"{output_dir}/X_imp{k+1}.csv\", index=False)\n",
    "                Y.to_frame(name=\"Y\").to_csv(f\"{output_dir}/Y_imp{k+1}.csv\", index=False)\n",
    "\n",
    "            print(f\" Done: {group_name}\")\n",
    "\n",
    "    print(\"\\n All CAT group analyses complete.\")\n",
    "\n",
    "# ========= STEP 4: Execute ========= #\n",
    "run_all_CAT_group_models(imputed_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "aa157356-6578-40bc-a6c3-3f9664d73f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " CAT_ADHD\n",
      "  Imp 1: Treated = 56, Control = 3585, Missing = 0\n",
      "  Imp 2: Treated = 56, Control = 3585, Missing = 0\n",
      "  Imp 3: Treated = 56, Control = 3585, Missing = 0\n",
      "  Imp 4: Treated = 56, Control = 3585, Missing = 0\n",
      "  Imp 5: Treated = 56, Control = 3585, Missing = 0\n",
      "\n",
      " CAT_Aceetanilidederivaten\n",
      "  Imp 1: Treated = 50, Control = 3591, Missing = 0\n",
      "  Imp 2: Treated = 50, Control = 3591, Missing = 0\n",
      "  Imp 3: Treated = 50, Control = 3591, Missing = 0\n",
      "  Imp 4: Treated = 50, Control = 3591, Missing = 0\n",
      "  Imp 5: Treated = 50, Control = 3591, Missing = 0\n",
      "\n",
      " CAT_Z_drugs\n",
      "  Imp 1: Treated = 57, Control = 3584, Missing = 0\n",
      "  Imp 2: Treated = 57, Control = 3584, Missing = 0\n",
      "  Imp 3: Treated = 57, Control = 3584, Missing = 0\n",
      "  Imp 4: Treated = 57, Control = 3584, Missing = 0\n",
      "  Imp 5: Treated = 57, Control = 3584, Missing = 0\n",
      "\n",
      " CAT_Opioden\n",
      "  Imp 1: Treated = 54, Control = 3587, Missing = 0\n",
      "  Imp 2: Treated = 54, Control = 3587, Missing = 0\n",
      "  Imp 3: Treated = 54, Control = 3587, Missing = 0\n",
      "  Imp 4: Treated = 54, Control = 3587, Missing = 0\n",
      "  Imp 5: Treated = 54, Control = 3587, Missing = 0\n",
      "\n",
      " CAT_NSAIDs\n",
      "  Imp 1: Treated = 37, Control = 3604, Missing = 0\n",
      "  Imp 2: Treated = 37, Control = 3604, Missing = 0\n",
      "  Imp 3: Treated = 37, Control = 3604, Missing = 0\n",
      "  Imp 4: Treated = 37, Control = 3604, Missing = 0\n",
      "  Imp 5: Treated = 37, Control = 3604, Missing = 0\n",
      "\n",
      " CAT_Benzodiazepine\n",
      "  Imp 1: Treated = 396, Control = 3245, Missing = 0\n",
      "  Imp 2: Treated = 396, Control = 3245, Missing = 0\n",
      "  Imp 3: Treated = 396, Control = 3245, Missing = 0\n",
      "  Imp 4: Treated = 396, Control = 3245, Missing = 0\n",
      "  Imp 5: Treated = 396, Control = 3245, Missing = 0\n",
      "\n",
      " CAT_Antihypertensiva\n",
      "  Imp 1: Treated = 45, Control = 3596, Missing = 0\n",
      "  Imp 2: Treated = 45, Control = 3596, Missing = 0\n",
      "  Imp 3: Treated = 45, Control = 3596, Missing = 0\n",
      "  Imp 4: Treated = 45, Control = 3596, Missing = 0\n",
      "  Imp 5: Treated = 45, Control = 3596, Missing = 0\n",
      "\n",
      " CAT_Antihistaminica\n",
      "  Imp 1: Treated = 56, Control = 3585, Missing = 0\n",
      "  Imp 2: Treated = 56, Control = 3585, Missing = 0\n",
      "  Imp 3: Treated = 56, Control = 3585, Missing = 0\n",
      "  Imp 4: Treated = 56, Control = 3585, Missing = 0\n",
      "  Imp 5: Treated = 56, Control = 3585, Missing = 0\n",
      "\n",
      " CAT_Anti_epileptica\n",
      "  Imp 1: Treated = 84, Control = 3557, Missing = 0\n",
      "  Imp 2: Treated = 84, Control = 3557, Missing = 0\n",
      "  Imp 3: Treated = 84, Control = 3557, Missing = 0\n",
      "  Imp 4: Treated = 84, Control = 3557, Missing = 0\n",
      "  Imp 5: Treated = 84, Control = 3557, Missing = 0\n",
      "\n",
      " CAT_Antidepressiva\n",
      "  Imp 1: Treated = 636, Control = 3005, Missing = 0\n",
      "  Imp 2: Treated = 636, Control = 3005, Missing = 0\n",
      "  Imp 3: Treated = 636, Control = 3005, Missing = 0\n",
      "  Imp 4: Treated = 636, Control = 3005, Missing = 0\n",
      "  Imp 5: Treated = 636, Control = 3005, Missing = 0\n",
      "\n",
      " CAT_Antipsychotica\n",
      "  Imp 1: Treated = 268, Control = 3373, Missing = 0\n",
      "  Imp 2: Treated = 268, Control = 3373, Missing = 0\n",
      "  Imp 3: Treated = 268, Control = 3373, Missing = 0\n",
      "  Imp 4: Treated = 268, Control = 3373, Missing = 0\n",
      "  Imp 5: Treated = 268, Control = 3373, Missing = 0\n",
      "\n",
      " CAT_ALL_PSYCHOTROPICS_EXCL_BENZO\n",
      "  Imp 1: Treated = 869, Control = 2772, Missing = 0\n",
      "  Imp 2: Treated = 869, Control = 2772, Missing = 0\n",
      "  Imp 3: Treated = 869, Control = 2772, Missing = 0\n",
      "  Imp 4: Treated = 869, Control = 2772, Missing = 0\n",
      "  Imp 5: Treated = 869, Control = 2772, Missing = 0\n",
      "\n",
      " CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS\n",
      "  Imp 1: Treated = 846, Control = 2795, Missing = 0\n",
      "  Imp 2: Treated = 846, Control = 2795, Missing = 0\n",
      "  Imp 3: Treated = 846, Control = 2795, Missing = 0\n",
      "  Imp 4: Treated = 846, Control = 2795, Missing = 0\n",
      "  Imp 5: Treated = 846, Control = 2795, Missing = 0\n",
      "\n",
      " CAT_ALL_PSYCHOTROPICS\n",
      "  Imp 1: Treated = 1031, Control = 2610, Missing = 0\n",
      "  Imp 2: Treated = 1031, Control = 2610, Missing = 0\n",
      "  Imp 3: Treated = 1031, Control = 2610, Missing = 0\n",
      "  Imp 4: Treated = 1031, Control = 2610, Missing = 0\n",
      "  Imp 5: Treated = 1031, Control = 2610, Missing = 0\n",
      "\n",
      " CAT_ALL\n",
      "  Imp 1: Treated = 1072, Control = 2569, Missing = 0\n",
      "  Imp 2: Treated = 1072, Control = 2569, Missing = 0\n",
      "  Imp 3: Treated = 1072, Control = 2569, Missing = 0\n",
      "  Imp 4: Treated = 1072, Control = 2569, Missing = 0\n",
      "  Imp 5: Treated = 1072, Control = 2569, Missing = 0\n"
     ]
    }
   ],
   "source": [
    "for treatment_var in medication_groups:\n",
    "    print(f\"\\n {treatment_var}\")\n",
    "    \n",
    "    for i, df in enumerate(imputed_dfs):\n",
    "        if treatment_var not in df.columns:\n",
    "            print(f\"  Imp {i+1}:  Not found in columns.\")\n",
    "            continue\n",
    "\n",
    "        treated = (df[treatment_var] == 1).sum()\n",
    "        control = (df[treatment_var] == 0).sum()\n",
    "        missing = df[treatment_var].isna().sum()\n",
    "\n",
    "        print(f\"  Imp {i+1}: Treated = {treated}, Control = {control}, Missing = {missing}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "45518bb5-2213-4061-a9f4-d9dc5a771895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Processing VIF for CAT_ADHD\n",
      " ✅ Saved: outputs\\CAT_ADHD/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for CAT_Aceetanilidederivaten\n",
      " ✅ Saved: outputs\\CAT_Aceetanilidederivaten/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for CAT_Z_drugs\n",
      " ✅ Saved: outputs\\CAT_Z_drugs/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for CAT_Opioden\n",
      " ✅ Saved: outputs\\CAT_Opioden/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for CAT_NSAIDs\n",
      " ✅ Saved: outputs\\CAT_NSAIDs/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for CAT_Benzodiazepine\n",
      " ✅ Saved: outputs\\CAT_Benzodiazepine/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for CAT_Antihypertensiva\n",
      " ✅ Saved: outputs\\CAT_Antihypertensiva/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for CAT_Antihistaminica\n",
      " ✅ Saved: outputs\\CAT_Antihistaminica/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for CAT_Anti_epileptica\n",
      " ✅ Saved: outputs\\CAT_Anti_epileptica/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for CAT_Antidepressiva\n",
      " ✅ Saved: outputs\\CAT_Antidepressiva/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for CAT_Antipsychotica\n",
      " ✅ Saved: outputs\\CAT_Antipsychotica/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for CAT_ALL_PSYCHOTROPICS_EXCL_BENZO\n",
      " ✅ Saved: outputs\\CAT_ALL_PSYCHOTROPICS_EXCL_BENZO/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS\n",
      " ✅ Saved: outputs\\CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for CAT_ALL_PSYCHOTROPICS\n",
      " ✅ Saved: outputs\\CAT_ALL_PSYCHOTROPICS/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for CAT_ALL\n",
      " ✅ Saved: outputs\\CAT_ALL/pooled_vif.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from collections import defaultdict\n",
    "\n",
    "# ✅ VIF computation function\n",
    "def compute_vif(X):\n",
    "    X = sm.add_constant(X, has_constant='add')\n",
    "    vif_df = pd.DataFrame()\n",
    "    vif_df[\"variable\"] = X.columns\n",
    "    vif_df[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "    return vif_df\n",
    "\n",
    "# ✅ Process each group\n",
    "for group in medication_groups:\n",
    "    print(f\"\\n🔍 Processing VIF for {group}\")\n",
    "\n",
    "    if group not in final_covariates_map:\n",
    "        print(f\" ⚠️ No covariates found for {group}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    covariates = final_covariates_map[group]\n",
    "    vif_list = []\n",
    "\n",
    "    for i, df_imp in enumerate(imputed_dfs):\n",
    "        try:\n",
    "            X = df_imp[covariates].copy()\n",
    "            vif_df = compute_vif(X)\n",
    "            vif_df[\"imputation\"] = i + 1\n",
    "            vif_list.append(vif_df)\n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ Failed on imputation {i+1} for {group}: {e}\")\n",
    "\n",
    "    if vif_list:\n",
    "        all_vif = pd.concat(vif_list)\n",
    "        pooled_vif = all_vif.groupby(\"variable\")[\"VIF\"].mean().reset_index()\n",
    "        pooled_vif = pooled_vif.sort_values(by=\"VIF\", ascending=False)\n",
    "\n",
    "        output_folder = os.path.join(\"outputs\", group)\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        pooled_vif.to_csv(os.path.join(output_folder, \"pooled_vif.csv\"), index=False)\n",
    "\n",
    "        print(f\" ✅ Saved: {output_folder}/pooled_vif.csv\")\n",
    "    else:\n",
    "        print(f\" ⚠️ Skipped {group}: No valid imputations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d0a75c56-8246-4cf6-87ef-07269bd1ce01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Running PS estimation for CAT_ADHD\n",
      "   Imp 1: AUC = 0.673, ROC saved.\n",
      "   Imp 2: AUC = 0.674, ROC saved.\n",
      "   Imp 3: AUC = 0.656, ROC saved.\n",
      "   Imp 4: AUC = 0.725, ROC saved.\n",
      "   Imp 5: AUC = 0.638, ROC saved.\n",
      " Composite PS + AUC saved for CAT_ADHD\n",
      " Running PS estimation for CAT_Aceetanilidederivaten\n",
      "   Imp 1: AUC = 0.726, ROC saved.\n",
      "   Imp 2: AUC = 0.778, ROC saved.\n",
      "   Imp 3: AUC = 0.743, ROC saved.\n",
      "   Imp 4: AUC = 0.800, ROC saved.\n",
      "   Imp 5: AUC = 0.791, ROC saved.\n",
      " Composite PS + AUC saved for CAT_Aceetanilidederivaten\n",
      " Running PS estimation for CAT_Z_drugs\n",
      "   Imp 1: AUC = 0.717, ROC saved.\n",
      "   Imp 2: AUC = 0.717, ROC saved.\n",
      "   Imp 3: AUC = 0.705, ROC saved.\n",
      "   Imp 4: AUC = 0.695, ROC saved.\n",
      "   Imp 5: AUC = 0.690, ROC saved.\n",
      " Composite PS + AUC saved for CAT_Z_drugs\n",
      " Running PS estimation for CAT_Opioden\n",
      "   Imp 1: AUC = 0.796, ROC saved.\n",
      "   Imp 2: AUC = 0.804, ROC saved.\n",
      "   Imp 3: AUC = 0.814, ROC saved.\n",
      "   Imp 4: AUC = 0.789, ROC saved.\n",
      "   Imp 5: AUC = 0.812, ROC saved.\n",
      " Composite PS + AUC saved for CAT_Opioden\n",
      " Running PS estimation for CAT_NSAIDs\n",
      "   Imp 1: AUC = 0.687, ROC saved.\n",
      "   Imp 2: AUC = 0.712, ROC saved.\n",
      "   Imp 3: AUC = 0.711, ROC saved.\n",
      "   Imp 4: AUC = 0.681, ROC saved.\n",
      "   Imp 5: AUC = 0.692, ROC saved.\n",
      " Composite PS + AUC saved for CAT_NSAIDs\n",
      " Running PS estimation for CAT_Benzodiazepine\n",
      "   Imp 1: AUC = 0.757, ROC saved.\n",
      "   Imp 2: AUC = 0.750, ROC saved.\n",
      "   Imp 3: AUC = 0.748, ROC saved.\n",
      "   Imp 4: AUC = 0.755, ROC saved.\n",
      "   Imp 5: AUC = 0.762, ROC saved.\n",
      " Composite PS + AUC saved for CAT_Benzodiazepine\n",
      " Running PS estimation for CAT_Antihypertensiva\n",
      "   Imp 1: AUC = 0.768, ROC saved.\n",
      "   Imp 2: AUC = 0.751, ROC saved.\n",
      "   Imp 3: AUC = 0.790, ROC saved.\n",
      "   Imp 4: AUC = 0.768, ROC saved.\n",
      "   Imp 5: AUC = 0.756, ROC saved.\n",
      " Composite PS + AUC saved for CAT_Antihypertensiva\n",
      " Running PS estimation for CAT_Antihistaminica\n",
      "   Imp 1: AUC = 0.798, ROC saved.\n",
      "   Imp 2: AUC = 0.790, ROC saved.\n",
      "   Imp 3: AUC = 0.795, ROC saved.\n",
      "   Imp 4: AUC = 0.770, ROC saved.\n",
      "   Imp 5: AUC = 0.761, ROC saved.\n",
      " Composite PS + AUC saved for CAT_Antihistaminica\n",
      " Running PS estimation for CAT_Anti_epileptica\n",
      "   Imp 1: AUC = 0.731, ROC saved.\n",
      "   Imp 2: AUC = 0.773, ROC saved.\n",
      "   Imp 3: AUC = 0.751, ROC saved.\n",
      "   Imp 4: AUC = 0.763, ROC saved.\n",
      "   Imp 5: AUC = 0.760, ROC saved.\n",
      " Composite PS + AUC saved for CAT_Anti_epileptica\n",
      " Running PS estimation for CAT_Antidepressiva\n",
      "   Imp 1: AUC = 0.787, ROC saved.\n",
      "   Imp 2: AUC = 0.780, ROC saved.\n",
      "   Imp 3: AUC = 0.782, ROC saved.\n",
      "   Imp 4: AUC = 0.772, ROC saved.\n",
      "   Imp 5: AUC = 0.779, ROC saved.\n",
      " Composite PS + AUC saved for CAT_Antidepressiva\n",
      " Running PS estimation for CAT_Antipsychotica\n",
      "   Imp 1: AUC = 0.812, ROC saved.\n",
      "   Imp 2: AUC = 0.802, ROC saved.\n",
      "   Imp 3: AUC = 0.824, ROC saved.\n",
      "   Imp 4: AUC = 0.795, ROC saved.\n",
      "   Imp 5: AUC = 0.813, ROC saved.\n",
      " Composite PS + AUC saved for CAT_Antipsychotica\n",
      " Running PS estimation for CAT_ALL_PSYCHOTROPICS_EXCL_BENZO\n",
      "   Imp 1: AUC = 0.774, ROC saved.\n",
      "   Imp 2: AUC = 0.768, ROC saved.\n",
      "   Imp 3: AUC = 0.770, ROC saved.\n",
      "   Imp 4: AUC = 0.764, ROC saved.\n",
      "   Imp 5: AUC = 0.764, ROC saved.\n",
      " Composite PS + AUC saved for CAT_ALL_PSYCHOTROPICS_EXCL_BENZO\n",
      " Running PS estimation for CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS\n",
      "   Imp 1: AUC = 0.786, ROC saved.\n",
      "   Imp 2: AUC = 0.775, ROC saved.\n",
      "   Imp 3: AUC = 0.769, ROC saved.\n",
      "   Imp 4: AUC = 0.771, ROC saved.\n",
      "   Imp 5: AUC = 0.776, ROC saved.\n",
      " Composite PS + AUC saved for CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS\n",
      " Running PS estimation for CAT_ALL_PSYCHOTROPICS\n",
      "   Imp 1: AUC = 0.773, ROC saved.\n",
      "   Imp 2: AUC = 0.782, ROC saved.\n",
      "   Imp 3: AUC = 0.776, ROC saved.\n",
      "   Imp 4: AUC = 0.761, ROC saved.\n",
      "   Imp 5: AUC = 0.780, ROC saved.\n",
      " Composite PS + AUC saved for CAT_ALL_PSYCHOTROPICS\n",
      " Running PS estimation for CAT_ALL\n",
      "   Imp 1: AUC = 0.778, ROC saved.\n",
      "   Imp 2: AUC = 0.778, ROC saved.\n",
      "   Imp 3: AUC = 0.777, ROC saved.\n",
      "   Imp 4: AUC = 0.774, ROC saved.\n",
      "   Imp 5: AUC = 0.787, ROC saved.\n",
      " Composite PS + AUC saved for CAT_ALL\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ---------- PS Estimation Function ----------\n",
    "def run_xgboost_ps_modeling(imputed_dfs, medication_groups, final_covariates_map):\n",
    "    for group in medication_groups:\n",
    "        print(f\" Running PS estimation for {group}\")\n",
    "\n",
    "        if group not in final_covariates_map:\n",
    "            print(f\" No covariates found for {group}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        output_folder = os.path.join(\"outputs\", group)\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "        covariates = final_covariates_map[group]\n",
    "        ps_matrix = pd.DataFrame()\n",
    "        auc_list = []\n",
    "\n",
    "        for i, df_imp in enumerate(imputed_dfs):\n",
    "            if group not in df_imp.columns:\n",
    "                print(f\" {group} not found in imputed dataset {i+1}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            X = df_imp[covariates].copy()\n",
    "            T = df_imp[group]\n",
    "\n",
    "            # Drop missing treatment rows\n",
    "            valid_idx = T.dropna().index\n",
    "            X = X.loc[valid_idx]\n",
    "            T = T.loc[valid_idx]\n",
    "\n",
    "            # Train-test split for ROC\n",
    "            X_train, X_test, T_train, T_test = train_test_split(\n",
    "                X, T, stratify=T, test_size=0.3, random_state=42\n",
    "            )\n",
    "\n",
    "            try:\n",
    "                model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "                model.fit(X_train, T_train)\n",
    "\n",
    "                ps_scores = model.predict_proba(X)[:, 1]\n",
    "                ps_matrix[f\"ps_imp{i+1}\"] = pd.Series(ps_scores, index=valid_idx)\n",
    "\n",
    "                # ROC & AUC\n",
    "                auc = roc_auc_score(T_test, model.predict_proba(X_test)[:, 1])\n",
    "                auc_list.append(auc)\n",
    "\n",
    "                fpr, tpr, _ = roc_curve(T_test, model.predict_proba(X_test)[:, 1])\n",
    "                plt.figure()\n",
    "                plt.plot(fpr, tpr, label=f\"AUC = {auc:.3f}\")\n",
    "                plt.plot([0, 1], [0, 1], 'k--')\n",
    "                plt.xlabel(\"False Positive Rate\")\n",
    "                plt.ylabel(\"True Positive Rate\")\n",
    "                plt.title(f\"ROC Curve - {group} (Imp {i+1})\")\n",
    "                plt.legend()\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(os.path.join(output_folder, f\"roc_curve_imp{i+1}.png\"))\n",
    "                plt.close()\n",
    "                print(f\"   Imp {i+1}: AUC = {auc:.3f}, ROC saved.\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"   Error in {group} (imp {i+1}): {e}\")\n",
    "\n",
    "        # Save AUCs and Composite PS\n",
    "        if not ps_matrix.empty:\n",
    "            # Fill NaN rows (from dropped subjects in some imputations) with mean\n",
    "            ps_matrix[\"composite_ps\"] = ps_matrix.mean(axis=1)\n",
    "            ps_matrix.to_excel(os.path.join(output_folder, \"propensity_scores.xlsx\"))\n",
    "\n",
    "            auc_df = pd.DataFrame({\n",
    "                \"imputation\": [f\"imp{i+1}\" for i in range(len(auc_list))],\n",
    "                \"AUC\": auc_list\n",
    "            })\n",
    "            auc_df.loc[len(auc_df.index)] = [\"mean\", np.mean(auc_list) if auc_list else np.nan]\n",
    "            auc_df.to_excel(os.path.join(output_folder, \"auc_scores.xlsx\"), index=False)\n",
    "\n",
    "            print(f\" Composite PS + AUC saved for {group}\")\n",
    "        else:\n",
    "            print(f\" No valid PS scores generated for {group}\")\n",
    "\n",
    "# ---------- Run ----------\n",
    "run_xgboost_ps_modeling(imputed_dfs, medication_groups, final_covariates_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "9a181c2a-5bec-4510-9d28-a7637b4615e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Computing feature importance for CAT_ADHD\n",
      " Saved feature importance plot and CSV for CAT_ADHD\n",
      "\n",
      " Computing feature importance for CAT_Aceetanilidederivaten\n",
      " Saved feature importance plot and CSV for CAT_Aceetanilidederivaten\n",
      "\n",
      " Computing feature importance for CAT_Z_drugs\n",
      " Saved feature importance plot and CSV for CAT_Z_drugs\n",
      "\n",
      " Computing feature importance for CAT_Opioden\n",
      " Saved feature importance plot and CSV for CAT_Opioden\n",
      "\n",
      " Computing feature importance for CAT_NSAIDs\n",
      " Saved feature importance plot and CSV for CAT_NSAIDs\n",
      "\n",
      " Computing feature importance for CAT_Benzodiazepine\n",
      " Saved feature importance plot and CSV for CAT_Benzodiazepine\n",
      "\n",
      " Computing feature importance for CAT_Antihypertensiva\n",
      " Saved feature importance plot and CSV for CAT_Antihypertensiva\n",
      "\n",
      " Computing feature importance for CAT_Antihistaminica\n",
      " Saved feature importance plot and CSV for CAT_Antihistaminica\n",
      "\n",
      " Computing feature importance for CAT_Anti_epileptica\n",
      " Saved feature importance plot and CSV for CAT_Anti_epileptica\n",
      "\n",
      " Computing feature importance for CAT_Antidepressiva\n",
      " Saved feature importance plot and CSV for CAT_Antidepressiva\n",
      "\n",
      " Computing feature importance for CAT_Antipsychotica\n",
      " Saved feature importance plot and CSV for CAT_Antipsychotica\n",
      "\n",
      " Computing feature importance for CAT_ALL_PSYCHOTROPICS_EXCL_BENZO\n",
      " Saved feature importance plot and CSV for CAT_ALL_PSYCHOTROPICS_EXCL_BENZO\n",
      "\n",
      " Computing feature importance for CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS\n",
      " Saved feature importance plot and CSV for CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS\n",
      "\n",
      " Computing feature importance for CAT_ALL_PSYCHOTROPICS\n",
      " Saved feature importance plot and CSV for CAT_ALL_PSYCHOTROPICS\n",
      "\n",
      " Computing feature importance for CAT_ALL\n",
      " Saved feature importance plot and CSV for CAT_ALL\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "def compute_feature_importance(imputed_dfs, medication_groups, final_covariates_map):\n",
    "    for group in medication_groups:\n",
    "        print(f\"\\n Computing feature importance for {group}\")\n",
    "\n",
    "        if group not in final_covariates_map:\n",
    "            print(f\" No covariates found for {group}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        covariates = final_covariates_map[group]\n",
    "        output_folder = os.path.join(\"outputs\", group)\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "        importance_df_list = []\n",
    "\n",
    "        for i, df_imp in enumerate(imputed_dfs):\n",
    "            if group not in df_imp.columns:\n",
    "                print(f\" {group} not in imputed dataset {i+1}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            X = df_imp[covariates].copy()\n",
    "            T = df_imp[group]\n",
    "\n",
    "            # Drop NaNs in treatment\n",
    "            valid_idx = T.dropna().index\n",
    "            X = X.loc[valid_idx]\n",
    "            T = T.loc[valid_idx]\n",
    "\n",
    "            try:\n",
    "                model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "                model.fit(X, T)\n",
    "\n",
    "                # Get feature importance\n",
    "                importances = model.get_booster().get_score(importance_type='gain')\n",
    "                df_feat = pd.DataFrame.from_dict(importances, orient='index', columns=[f\"imp{i+1}\"])\n",
    "                df_feat.index.name = 'feature'\n",
    "                importance_df_list.append(df_feat)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"   Error during modeling: {e}\")\n",
    "\n",
    "        if importance_df_list:\n",
    "            # Combine and average\n",
    "            all_feat = pd.concat(importance_df_list, axis=1).fillna(0)\n",
    "            all_feat[\"mean_importance\"] = all_feat.mean(axis=1)\n",
    "\n",
    "            # Filter top 30 non-zero\n",
    "            non_zero = all_feat[all_feat[\"mean_importance\"] > 0]\n",
    "            top30 = non_zero.sort_values(by=\"mean_importance\", ascending=False).head(30)\n",
    "\n",
    "            # Save to CSV\n",
    "            top30.to_csv(os.path.join(output_folder, \"feature_importance.csv\"))\n",
    "\n",
    "            # Plot\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            plt.barh(top30.index[::-1], top30[\"mean_importance\"][::-1])  # plot top → bottom\n",
    "            plt.xlabel(\"Mean Gain Importance\")\n",
    "            plt.title(f\"Top 30 Feature Importance - {group}\")\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(output_folder, \"feature_importance_top30.png\"))\n",
    "            plt.close()\n",
    "\n",
    "            print(f\" Saved feature importance plot and CSV for {group}\")\n",
    "        else:\n",
    "            print(f\" No valid models for {group}\")\n",
    "\n",
    "#  Run\n",
    "compute_feature_importance(imputed_dfs, medication_groups, final_covariates_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "df86de76-a391-45d6-a5e2-06d6390c6a1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Processing IPTW + trimming + clipping for CAT_ADHD\n",
      "✅ Saved IPTW weights for CAT_ADHD\n",
      "    ℹ️ Retained 111/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_ADHD/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 103/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_ADHD/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 110/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_ADHD/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 108/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_ADHD/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 104/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_ADHD/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for CAT_Aceetanilidederivaten\n",
      "✅ Saved IPTW weights for CAT_Aceetanilidederivaten\n",
      "    ℹ️ Retained 75/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Aceetanilidederivaten/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 68/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Aceetanilidederivaten/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 67/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Aceetanilidederivaten/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 75/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Aceetanilidederivaten/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 68/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Aceetanilidederivaten/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for CAT_Z_drugs\n",
      "✅ Saved IPTW weights for CAT_Z_drugs\n",
      "    ℹ️ Retained 99/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Z_drugs/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 96/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Z_drugs/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 101/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Z_drugs/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 100/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Z_drugs/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 101/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Z_drugs/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for CAT_Opioden\n",
      "✅ Saved IPTW weights for CAT_Opioden\n",
      "    ℹ️ Retained 98/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Opioden/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 92/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Opioden/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 95/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Opioden/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 98/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Opioden/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 90/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Opioden/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for CAT_NSAIDs\n",
      "✅ Saved IPTW weights for CAT_NSAIDs\n",
      "    ℹ️ Retained 65/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_NSAIDs/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 62/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_NSAIDs/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 67/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_NSAIDs/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 69/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_NSAIDs/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 62/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_NSAIDs/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for CAT_Benzodiazepine\n",
      "✅ Saved IPTW weights for CAT_Benzodiazepine\n",
      "    ℹ️ Retained 991/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Benzodiazepine/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 1028/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Benzodiazepine/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 977/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Benzodiazepine/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 1052/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Benzodiazepine/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 1030/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Benzodiazepine/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for CAT_Antihypertensiva\n",
      "✅ Saved IPTW weights for CAT_Antihypertensiva\n",
      "    ℹ️ Retained 84/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Antihypertensiva/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 82/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Antihypertensiva/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 79/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Antihypertensiva/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 90/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Antihypertensiva/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 86/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Antihypertensiva/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for CAT_Antihistaminica\n",
      "✅ Saved IPTW weights for CAT_Antihistaminica\n",
      "    ℹ️ Retained 96/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Antihistaminica/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 96/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Antihistaminica/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 96/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Antihistaminica/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 96/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Antihistaminica/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 92/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Antihistaminica/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for CAT_Anti_epileptica\n",
      "✅ Saved IPTW weights for CAT_Anti_epileptica\n",
      "    ℹ️ Retained 135/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Anti_epileptica/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 145/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Anti_epileptica/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 140/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Anti_epileptica/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 147/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Anti_epileptica/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 148/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Anti_epileptica/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for CAT_Antidepressiva\n",
      "✅ Saved IPTW weights for CAT_Antidepressiva\n",
      "    ℹ️ Retained 1622/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Antidepressiva/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 1554/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Antidepressiva/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 1587/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Antidepressiva/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 1610/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Antidepressiva/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 1590/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Antidepressiva/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for CAT_Antipsychotica\n",
      "✅ Saved IPTW weights for CAT_Antipsychotica\n",
      "    ℹ️ Retained 637/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Antipsychotica/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 623/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Antipsychotica/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 604/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Antipsychotica/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 598/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Antipsychotica/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 587/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Antipsychotica/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for CAT_ALL_PSYCHOTROPICS_EXCL_BENZO\n",
      "✅ Saved IPTW weights for CAT_ALL_PSYCHOTROPICS_EXCL_BENZO\n",
      "    ℹ️ Retained 1938/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_ALL_PSYCHOTROPICS_EXCL_BENZO/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 1899/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_ALL_PSYCHOTROPICS_EXCL_BENZO/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 1992/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_ALL_PSYCHOTROPICS_EXCL_BENZO/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 1948/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_ALL_PSYCHOTROPICS_EXCL_BENZO/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 1929/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_ALL_PSYCHOTROPICS_EXCL_BENZO/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS\n",
      "✅ Saved IPTW weights for CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS\n",
      "    ℹ️ Retained 1973/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 1925/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 1945/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 1910/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 1940/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for CAT_ALL_PSYCHOTROPICS\n",
      "✅ Saved IPTW weights for CAT_ALL_PSYCHOTROPICS\n",
      "    ℹ️ Retained 2321/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_ALL_PSYCHOTROPICS/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 2238/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_ALL_PSYCHOTROPICS/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 2298/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_ALL_PSYCHOTROPICS/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 2277/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_ALL_PSYCHOTROPICS/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 2271/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_ALL_PSYCHOTROPICS/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for CAT_ALL\n",
      "✅ Saved IPTW weights for CAT_ALL\n",
      "    ℹ️ Retained 2300/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_ALL/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 2203/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_ALL/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 2295/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_ALL/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 2284/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_ALL/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 2282/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_ALL/trimmed_data_imp5.*\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_trimmed_clipped_iptw(ps_df, treatment, lower=0.05, upper=0.95, clip_max=10):\n",
    "    weights = []\n",
    "    keep_mask = (ps_df > lower) & (ps_df < upper)\n",
    "\n",
    "    for i in range(ps_df.shape[1]):\n",
    "        ps = ps_df.iloc[:, i].clip(lower=1e-6, upper=1 - 1e-6)  # avoid div by zero\n",
    "        mask = keep_mask.iloc[:, i]\n",
    "        w = pd.Series(np.nan, index=ps.index)\n",
    "\n",
    "        w[mask & (treatment == 1)] = 1 / ps[mask & (treatment == 1)]\n",
    "        w[mask & (treatment == 0)] = 1 / (1 - ps[mask & (treatment == 0)])\n",
    "        w = w.clip(upper=clip_max)\n",
    "        weights.append(w)\n",
    "\n",
    "    return pd.concat(weights, axis=1)\n",
    "\n",
    "\n",
    "def apply_rubins_rule_to_iptw(iptw_matrix):\n",
    "    \"\"\"\n",
    "    Given an IPTW matrix (n rows × M imputations), return Rubin’s rule pooled mean, SD, SE.\n",
    "    \"\"\"\n",
    "    M = iptw_matrix.shape[1]\n",
    "    q_bar = iptw_matrix.mean(axis=1)\n",
    "    u_bar = iptw_matrix.var(axis=1, ddof=1)\n",
    "    B = iptw_matrix.apply(lambda x: x.mean(), axis=1).var(ddof=1)\n",
    "    total_var = u_bar + (1 + 1/M) * B\n",
    "    total_se = np.sqrt(total_var)\n",
    "    return q_bar, u_bar.pow(0.5), total_se\n",
    "\n",
    "\n",
    "def run_trim_clip_save_all(imputed_dfs, medication_groups, final_covariates_map):\n",
    "    for group in medication_groups:\n",
    "        print(f\"\\n🔍 Processing IPTW + trimming + clipping for {group}\")\n",
    "        output_folder = os.path.join(\"outputs\", group)\n",
    "        ps_path = os.path.join(output_folder, \"propensity_scores.xlsx\")\n",
    "\n",
    "        if not os.path.exists(ps_path):\n",
    "            print(f\"⚠️ Missing PS file: {ps_path}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            ps_all = pd.read_excel(ps_path, index_col=0)\n",
    "            ps_cols = [col for col in ps_all.columns if col.startswith(\"ps_imp\")]\n",
    "            composite_index = ps_all.index\n",
    "\n",
    "            # Get treatment from one imputed dataset\n",
    "            T_full = None\n",
    "            for df in imputed_dfs:\n",
    "                if group in df.columns:\n",
    "                    T_full = df.loc[composite_index, group]\n",
    "                    break\n",
    "\n",
    "            if T_full is None:\n",
    "                print(f\"❌ Treatment column {group} not found in any imputed dataset.\")\n",
    "                continue\n",
    "\n",
    "            # Compute IPTW matrix (shape: n × M)\n",
    "            iptw_matrix = compute_trimmed_clipped_iptw(ps_all[ps_cols], T_full)\n",
    "            iptw_matrix.columns = [f\"iptw_imp{i+1}\" for i in range(iptw_matrix.shape[1])]\n",
    "\n",
    "            # Apply Rubin’s Rule for mean, SD, SE\n",
    "            iptw_matrix[\"iptw_mean\"], iptw_matrix[\"iptw_sd\"], iptw_matrix[\"iptw_se\"] = apply_rubins_rule_to_iptw(\n",
    "                iptw_matrix[[f\"iptw_imp{i+1}\" for i in range(iptw_matrix.shape[1])]]\n",
    "            )\n",
    "\n",
    "            # Save IPTW matrix separately\n",
    "            iptw_matrix.to_excel(os.path.join(output_folder, \"iptw_weights.xlsx\"))\n",
    "            print(f\"✅ Saved IPTW weights for {group}\")\n",
    "\n",
    "            # Save trimmed & clipped imputed datasets with IPTW\n",
    "            for i in range(5):\n",
    "                df = imputed_dfs[i].copy()\n",
    "                if group not in df.columns:\n",
    "                    continue\n",
    "\n",
    "                trimmed_idx = iptw_matrix.index.intersection(df.index)\n",
    "                needed_cols = final_covariates_map[group] + [group, \"caps5_change_baseline\"]\n",
    "\n",
    "                # Select only necessary columns\n",
    "                df_trimmed = df.loc[trimmed_idx, needed_cols].copy()\n",
    "                df_trimmed[\"iptw\"] = iptw_matrix[f\"iptw_imp{i+1}\"].loc[trimmed_idx]\n",
    "\n",
    "                # ✅ DROP rows with missing IPTW values\n",
    "                before = len(df_trimmed)\n",
    "                df_trimmed = df_trimmed.dropna(subset=[\"iptw\"])\n",
    "                after = len(df_trimmed)\n",
    "                print(f\"    ℹ️ Retained {after}/{before} rows after IPTW NaN drop.\")\n",
    "\n",
    "                # Save to .pkl\n",
    "                df_trimmed.to_pickle(os.path.join(output_folder, f\"trimmed_data_imp{i+1}.pkl\"))\n",
    "                print(f\"  💾 Saved trimmed dataset: {output_folder}/trimmed_data_imp{i+1}.*\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error in {group}: {e}\")\n",
    "\n",
    "\n",
    "run_trim_clip_save_all(imputed_dfs, medication_groups, final_covariates_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "9ed308b6-fe68-43f9-aa75-565caf5adf0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Plotting PS overlap for CAT_ADHD\n",
      "✅ Saved unweighted and weighted PS plots for CAT_ADHD\n",
      "\n",
      "📊 Plotting PS overlap for CAT_Aceetanilidederivaten\n",
      "✅ Saved unweighted and weighted PS plots for CAT_Aceetanilidederivaten\n",
      "\n",
      "📊 Plotting PS overlap for CAT_Z_drugs\n",
      "✅ Saved unweighted and weighted PS plots for CAT_Z_drugs\n",
      "\n",
      "📊 Plotting PS overlap for CAT_Opioden\n",
      "✅ Saved unweighted and weighted PS plots for CAT_Opioden\n",
      "\n",
      "📊 Plotting PS overlap for CAT_NSAIDs\n",
      "✅ Saved unweighted and weighted PS plots for CAT_NSAIDs\n",
      "\n",
      "📊 Plotting PS overlap for CAT_Benzodiazepine\n",
      "✅ Saved unweighted and weighted PS plots for CAT_Benzodiazepine\n",
      "\n",
      "📊 Plotting PS overlap for CAT_Antihypertensiva\n",
      "✅ Saved unweighted and weighted PS plots for CAT_Antihypertensiva\n",
      "\n",
      "📊 Plotting PS overlap for CAT_Antihistaminica\n",
      "✅ Saved unweighted and weighted PS plots for CAT_Antihistaminica\n",
      "\n",
      "📊 Plotting PS overlap for CAT_Anti_epileptica\n",
      "✅ Saved unweighted and weighted PS plots for CAT_Anti_epileptica\n",
      "\n",
      "📊 Plotting PS overlap for CAT_Antidepressiva\n",
      "✅ Saved unweighted and weighted PS plots for CAT_Antidepressiva\n",
      "\n",
      "📊 Plotting PS overlap for CAT_Antipsychotica\n",
      "✅ Saved unweighted and weighted PS plots for CAT_Antipsychotica\n",
      "\n",
      "📊 Plotting PS overlap for CAT_ALL_PSYCHOTROPICS_EXCL_BENZO\n",
      "✅ Saved unweighted and weighted PS plots for CAT_ALL_PSYCHOTROPICS_EXCL_BENZO\n",
      "\n",
      "📊 Plotting PS overlap for CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS\n",
      "✅ Saved unweighted and weighted PS plots for CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS\n",
      "\n",
      "📊 Plotting PS overlap for CAT_ALL_PSYCHOTROPICS\n",
      "✅ Saved unweighted and weighted PS plots for CAT_ALL_PSYCHOTROPICS\n",
      "\n",
      "📊 Plotting PS overlap for CAT_ALL\n",
      "✅ Saved unweighted and weighted PS plots for CAT_ALL\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_ps_overlap_all_groups(medication_groups):\n",
    "    for group in medication_groups:\n",
    "        print(f\"\\n📊 Plotting PS overlap for {group}\")\n",
    "\n",
    "        folder = os.path.join(\"outputs\", group)\n",
    "        ps_file = os.path.join(folder, \"propensity_scores.xlsx\")\n",
    "        iptw_file = os.path.join(folder, \"iptw_weights.xlsx\")\n",
    "        trimmed_file = os.path.join(folder, \"trimmed_data_imp1.pkl\")\n",
    "\n",
    "        if not all(os.path.exists(f) for f in [ps_file, iptw_file, trimmed_file]):\n",
    "            print(f\"⚠️ Missing required files for {group}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            ps_df = pd.read_excel(ps_file, index_col=0)\n",
    "            iptw_df = pd.read_excel(iptw_file, index_col=0)\n",
    "            trimmed_df = pd.read_pickle(trimmed_file)\n",
    "\n",
    "            # Extract\n",
    "            ps = ps_df[\"composite_ps\"].reindex(trimmed_df.index)\n",
    "            w = iptw_df[\"iptw_mean\"].reindex(trimmed_df.index)\n",
    "            T = trimmed_df[group]\n",
    "\n",
    "            # Masks to remove NaNs\n",
    "            treated_mask = (T == 1) & ps.notna() & w.notna()\n",
    "            control_mask = (T == 0) & ps.notna() & w.notna()\n",
    "\n",
    "            treated = ps[treated_mask]\n",
    "            treated_w = w[treated_mask]\n",
    "\n",
    "            control = ps[control_mask]\n",
    "            control_w = w[control_mask]\n",
    "\n",
    "            # === Unweighted Plot ===\n",
    "            plt.figure(figsize=(8, 5))\n",
    "            plt.hist([treated, control], bins=25, label=[\"Treated\", \"Control\"], alpha=0.6)\n",
    "            plt.title(f\"Unweighted PS Overlap - {group}\")\n",
    "            plt.xlabel(\"Composite Propensity Score\")\n",
    "            plt.ylabel(\"Count\")\n",
    "            plt.legend()\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(folder, \"ps_overlap_unweighted.png\"))\n",
    "            plt.close()\n",
    "\n",
    "            # === Weighted Plot ===\n",
    "            plt.figure(figsize=(8, 5))\n",
    "            plt.hist([treated, control], bins=25, weights=[treated_w, control_w], label=[\"Treated\", \"Control\"], alpha=0.6)\n",
    "            plt.title(f\"Weighted PS Overlap - {group}\")\n",
    "            plt.xlabel(\"Composite Propensity Score\")\n",
    "            plt.ylabel(\"Weighted Count\")\n",
    "            plt.legend()\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(folder, \"ps_overlap_weighted.png\"))\n",
    "            plt.close()\n",
    "\n",
    "            print(f\"✅ Saved unweighted and weighted PS plots for {group}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error processing {group}: {e}\")\n",
    "\n",
    "# 🔁 Run\n",
    "plot_ps_overlap_all_groups(medication_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "29ea4dea-63df-45a3-96a0-4fa1500801cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ✅ Saved: outputs\\CAT_ADHD\\four_panel_overlap_CAT_ADHD.png\n",
      " ✅ Saved: outputs\\CAT_Aceetanilidederivaten\\four_panel_overlap_CAT_Aceetanilidederivaten.png\n",
      " ✅ Saved: outputs\\CAT_Z_drugs\\four_panel_overlap_CAT_Z_drugs.png\n",
      " ✅ Saved: outputs\\CAT_Opioden\\four_panel_overlap_CAT_Opioden.png\n",
      " ✅ Saved: outputs\\CAT_NSAIDs\\four_panel_overlap_CAT_NSAIDs.png\n",
      " ✅ Saved: outputs\\CAT_Benzodiazepine\\four_panel_overlap_CAT_Benzodiazepine.png\n",
      " ✅ Saved: outputs\\CAT_Antihypertensiva\\four_panel_overlap_CAT_Antihypertensiva.png\n",
      " ✅ Saved: outputs\\CAT_Antihistaminica\\four_panel_overlap_CAT_Antihistaminica.png\n",
      " ✅ Saved: outputs\\CAT_Anti_epileptica\\four_panel_overlap_CAT_Anti_epileptica.png\n",
      " ✅ Saved: outputs\\CAT_Antidepressiva\\four_panel_overlap_CAT_Antidepressiva.png\n",
      " ✅ Saved: outputs\\CAT_Antipsychotica\\four_panel_overlap_CAT_Antipsychotica.png\n",
      " ✅ Saved: outputs\\CAT_ALL_PSYCHOTROPICS_EXCL_BENZO\\four_panel_overlap_CAT_ALL_PSYCHOTROPICS_EXCL_BENZO.png\n",
      " ✅ Saved: outputs\\CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS\\four_panel_overlap_CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS.png\n",
      " ✅ Saved: outputs\\CAT_ALL_PSYCHOTROPICS\\four_panel_overlap_CAT_ALL_PSYCHOTROPICS.png\n",
      " ✅ Saved: outputs\\CAT_ALL\\four_panel_overlap_CAT_ALL.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set up base output folder\n",
    "output_base = \"outputs\"\n",
    "ps_file = \"propensity_scores.xlsx\"\n",
    "iptw_file = \"iptw_weights.xlsx\"\n",
    "trimmed_data_file = \"trimmed_data_imp1.pkl\"\n",
    "\n",
    "# Collect all treatment group folders\n",
    "groups = [g for g in medication_groups if os.path.isdir(os.path.join(output_base, g))]\n",
    "\n",
    "# Generate 4-panel overlap plots\n",
    "for group in groups:\n",
    "    group_path = os.path.join(output_base, group)\n",
    "    try:\n",
    "        # Load trimmed treatment info\n",
    "        trimmed_df = pd.read_pickle(os.path.join(group_path, trimmed_data_file))\n",
    "        index = trimmed_df.index\n",
    "\n",
    "        # Fix: case-insensitive match for treatment variable\n",
    "        possible_cols = [col for col in trimmed_df.columns if col.upper() == group.upper()]\n",
    "        if not possible_cols:\n",
    "            print(f\" Treatment variable {group} not found in {group}, skipping.\")\n",
    "            continue\n",
    "        treatment_var = possible_cols[0]\n",
    "        T = trimmed_df[treatment_var]\n",
    "\n",
    "        # Load composite PS (aligned to trimmed_df index)\n",
    "        ps_df = pd.read_excel(os.path.join(group_path, ps_file), index_col=0)\n",
    "        if 'composite_ps' not in ps_df.columns:\n",
    "            print(f\" Composite column missing in {ps_file}, skipping {group}.\")\n",
    "            continue\n",
    "        ps = ps_df.loc[index, 'composite_ps']\n",
    "\n",
    "        # Load IPTW weights (aligned to trimmed_df index)\n",
    "        weights_df = pd.read_excel(os.path.join(group_path, iptw_file), index_col=0)\n",
    "        if 'iptw_mean' not in weights_df.columns:\n",
    "            print(f\" IPTW weight column missing in {iptw_file}, skipping {group}.\")\n",
    "            continue\n",
    "        weights = weights_df.loc[index, 'iptw_mean']\n",
    "\n",
    "        # Prepare 4 datasets\n",
    "        raw_treated = ps[T == 1]\n",
    "        raw_control = ps[T == 0]\n",
    "        weighted_treated = (ps[T == 1], weights[T == 1])\n",
    "        weighted_control = (ps[T == 0], weights[T == 0])\n",
    "\n",
    "        # Create plot\n",
    "        fig, axs = plt.subplots(2, 2, figsize=(12, 8))\n",
    "        fig.suptitle(f\"Propensity Score Distribution - {group}\", fontsize=14)\n",
    "\n",
    "        axs[0, 0].hist(raw_treated, bins=20, alpha=0.7, color='blue')\n",
    "        axs[0, 0].set_title(\"Raw Treated\")\n",
    "\n",
    "        axs[0, 1].hist(raw_control, bins=20, alpha=0.7, color='green')\n",
    "        axs[0, 1].set_title(\"Raw Control\")\n",
    "\n",
    "        axs[1, 0].hist(weighted_treated[0], bins=20, weights=weighted_treated[1], alpha=0.7, color='blue')\n",
    "        axs[1, 0].set_title(\"Weighted Treated\")\n",
    "\n",
    "        axs[1, 1].hist(weighted_control[0], bins=20, weights=weighted_control[1], alpha=0.7, color='green')\n",
    "        axs[1, 1].set_title(\"Weighted Control\")\n",
    "\n",
    "        for ax in axs.flat:\n",
    "            ax.set_xlim(0, 1)\n",
    "            ax.set_xlabel(\"Propensity Score\")\n",
    "            ax.set_ylabel(\"Count\")\n",
    "\n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "\n",
    "        # Save figure\n",
    "        plot_path = os.path.join(group_path, f\"four_panel_overlap_{group}.png\")\n",
    "        plt.savefig(plot_path)\n",
    "        plt.close()\n",
    "        print(f\" ✅ Saved: {plot_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\" ❌ Error in {group}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "84753833-c355-4cd9-91f1-f0d0f66b7705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ATT calculation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "8ac32062-ff51-4b7d-9ac8-94e71a1e7534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weighted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "9be14728-16ba-4ae3-8077-ec1c895d8b10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Running XGBoost for CAT_ADHD\n",
      "✅ CAT_ADHD | Seed 1: ATT = 0.6398, SE = 1.8546, p = 0.73313\n",
      "✅ CAT_ADHD | Seed 2: ATT = 0.8262, SE = 1.4715, p = 0.57969\n",
      "✅ CAT_ADHD | Seed 3: ATT = 0.6040, SE = 1.6900, p = 0.72390\n",
      "✅ CAT_ADHD | Seed 4: ATT = 0.4602, SE = 1.7659, p = 0.79662\n",
      "✅ CAT_ADHD | Seed 5: ATT = 0.4471, SE = 1.4554, p = 0.76135\n",
      "✅ CAT_ADHD | Seed 6: ATT = 0.6564, SE = 1.5766, p = 0.68086\n",
      "✅ CAT_ADHD | Seed 7: ATT = 0.6471, SE = 1.5556, p = 0.68113\n",
      "✅ CAT_ADHD | Seed 8: ATT = 0.4790, SE = 1.5862, p = 0.76528\n",
      "✅ CAT_ADHD | Seed 9: ATT = 0.4780, SE = 1.4343, p = 0.74182\n",
      "✅ CAT_ADHD | Seed 10: ATT = 0.6919, SE = 1.7242, p = 0.69175\n",
      "📊 Diagnostic plots saved for CAT_ADHD\n",
      "🏆 Best result for CAT_ADHD → Seed 9 | SE = 1.4343\n",
      "\n",
      "🚀 Running XGBoost for CAT_Aceetanilidederivaten\n",
      "✅ CAT_Aceetanilidederivaten | Seed 1: ATT = 0.2975, SE = 2.8691, p = 0.91828\n",
      "✅ CAT_Aceetanilidederivaten | Seed 2: ATT = 0.4510, SE = 3.1244, p = 0.88644\n",
      "✅ CAT_Aceetanilidederivaten | Seed 3: ATT = 0.4654, SE = 3.0902, p = 0.88154\n",
      "✅ CAT_Aceetanilidederivaten | Seed 4: ATT = 0.4088, SE = 2.9916, p = 0.89244\n",
      "✅ CAT_Aceetanilidederivaten | Seed 5: ATT = 0.2789, SE = 3.1691, p = 0.93061\n",
      "✅ CAT_Aceetanilidederivaten | Seed 6: ATT = 0.1762, SE = 2.6640, p = 0.94780\n",
      "✅ CAT_Aceetanilidederivaten | Seed 7: ATT = 0.2876, SE = 3.1560, p = 0.92815\n",
      "✅ CAT_Aceetanilidederivaten | Seed 8: ATT = -0.0931, SE = 3.4733, p = 0.97884\n",
      "✅ CAT_Aceetanilidederivaten | Seed 9: ATT = 0.4887, SE = 2.6818, p = 0.85694\n",
      "✅ CAT_Aceetanilidederivaten | Seed 10: ATT = 0.3615, SE = 3.1816, p = 0.91048\n",
      "📊 Diagnostic plots saved for CAT_Aceetanilidederivaten\n",
      "🏆 Best result for CAT_Aceetanilidederivaten → Seed 6 | SE = 2.6640\n",
      "\n",
      "🚀 Running XGBoost for CAT_Z_drugs\n",
      "✅ CAT_Z_drugs | Seed 1: ATT = 1.6543, SE = 2.2972, p = 0.47840\n",
      "✅ CAT_Z_drugs | Seed 2: ATT = 1.8005, SE = 2.5655, p = 0.48955\n",
      "✅ CAT_Z_drugs | Seed 3: ATT = 1.8726, SE = 2.4232, p = 0.44721\n",
      "✅ CAT_Z_drugs | Seed 4: ATT = 2.0002, SE = 2.7489, p = 0.47387\n",
      "✅ CAT_Z_drugs | Seed 5: ATT = 1.9562, SE = 2.9419, p = 0.51243\n",
      "✅ CAT_Z_drugs | Seed 6: ATT = 1.7947, SE = 2.2633, p = 0.43557\n",
      "✅ CAT_Z_drugs | Seed 7: ATT = 1.9174, SE = 2.5665, p = 0.46229\n",
      "✅ CAT_Z_drugs | Seed 8: ATT = 1.8006, SE = 2.5342, p = 0.48422\n",
      "✅ CAT_Z_drugs | Seed 9: ATT = 1.9565, SE = 2.8335, p = 0.49650\n",
      "✅ CAT_Z_drugs | Seed 10: ATT = 1.9022, SE = 2.7553, p = 0.49658\n",
      "📊 Diagnostic plots saved for CAT_Z_drugs\n",
      "🏆 Best result for CAT_Z_drugs → Seed 6 | SE = 2.2633\n",
      "\n",
      "🚀 Running XGBoost for CAT_Opioden\n",
      "✅ CAT_Opioden | Seed 1: ATT = 1.3282, SE = 1.3960, p = 0.35085\n",
      "✅ CAT_Opioden | Seed 2: ATT = 1.0273, SE = 1.3282, p = 0.44681\n",
      "✅ CAT_Opioden | Seed 3: ATT = 1.0416, SE = 1.4482, p = 0.47893\n",
      "✅ CAT_Opioden | Seed 4: ATT = 1.3028, SE = 1.9832, p = 0.51749\n",
      "✅ CAT_Opioden | Seed 5: ATT = 1.1067, SE = 1.3827, p = 0.43135\n",
      "✅ CAT_Opioden | Seed 6: ATT = 1.1278, SE = 1.1617, p = 0.34135\n",
      "✅ CAT_Opioden | Seed 7: ATT = 1.4468, SE = 1.3851, p = 0.30664\n",
      "✅ CAT_Opioden | Seed 8: ATT = 1.1480, SE = 1.3143, p = 0.39107\n",
      "✅ CAT_Opioden | Seed 9: ATT = 1.0798, SE = 1.6741, p = 0.52502\n",
      "✅ CAT_Opioden | Seed 10: ATT = 1.0983, SE = 1.3885, p = 0.43668\n",
      "📊 Diagnostic plots saved for CAT_Opioden\n",
      "🏆 Best result for CAT_Opioden → Seed 6 | SE = 1.1617\n",
      "\n",
      "🚀 Running XGBoost for CAT_NSAIDs\n",
      "✅ CAT_NSAIDs | Seed 1: ATT = 1.0605, SE = 2.1695, p = 0.62940\n",
      "✅ CAT_NSAIDs | Seed 2: ATT = 0.9690, SE = 2.2269, p = 0.66737\n",
      "✅ CAT_NSAIDs | Seed 3: ATT = 1.0056, SE = 2.3311, p = 0.67006\n",
      "✅ CAT_NSAIDs | Seed 4: ATT = 0.7983, SE = 2.2999, p = 0.73153\n",
      "✅ CAT_NSAIDs | Seed 5: ATT = 0.8897, SE = 2.1683, p = 0.68522\n",
      "✅ CAT_NSAIDs | Seed 6: ATT = 0.9899, SE = 2.3087, p = 0.67193\n",
      "✅ CAT_NSAIDs | Seed 7: ATT = 0.6264, SE = 1.4557, p = 0.67081\n",
      "✅ CAT_NSAIDs | Seed 8: ATT = 0.8327, SE = 2.0021, p = 0.68116\n",
      "✅ CAT_NSAIDs | Seed 9: ATT = 0.8049, SE = 2.2322, p = 0.72155\n",
      "✅ CAT_NSAIDs | Seed 10: ATT = 1.1998, SE = 2.3251, p = 0.61055\n",
      "📊 Diagnostic plots saved for CAT_NSAIDs\n",
      "🏆 Best result for CAT_NSAIDs → Seed 7 | SE = 1.4557\n",
      "\n",
      "🚀 Running XGBoost for CAT_Benzodiazepine\n",
      "✅ CAT_Benzodiazepine | Seed 1: ATT = -0.0377, SE = 0.6840, p = 0.95653\n",
      "✅ CAT_Benzodiazepine | Seed 2: ATT = 0.0419, SE = 0.6450, p = 0.94870\n",
      "✅ CAT_Benzodiazepine | Seed 3: ATT = 0.0019, SE = 0.6712, p = 0.99772\n",
      "✅ CAT_Benzodiazepine | Seed 4: ATT = -0.0132, SE = 0.6206, p = 0.98320\n",
      "✅ CAT_Benzodiazepine | Seed 5: ATT = -0.0392, SE = 0.5512, p = 0.94383\n",
      "✅ CAT_Benzodiazepine | Seed 6: ATT = 0.0827, SE = 0.5254, p = 0.87625\n",
      "✅ CAT_Benzodiazepine | Seed 7: ATT = -0.0102, SE = 0.6545, p = 0.98772\n",
      "✅ CAT_Benzodiazepine | Seed 8: ATT = 0.0005, SE = 0.4966, p = 0.99924\n",
      "✅ CAT_Benzodiazepine | Seed 9: ATT = 0.0411, SE = 0.5405, p = 0.94007\n",
      "✅ CAT_Benzodiazepine | Seed 10: ATT = 0.0331, SE = 0.5492, p = 0.95238\n",
      "📊 Diagnostic plots saved for CAT_Benzodiazepine\n",
      "🏆 Best result for CAT_Benzodiazepine → Seed 8 | SE = 0.4966\n",
      "\n",
      "🚀 Running XGBoost for CAT_Antihypertensiva\n",
      "✅ CAT_Antihypertensiva | Seed 1: ATT = -0.4511, SE = 1.1467, p = 0.69751\n",
      "✅ CAT_Antihypertensiva | Seed 2: ATT = -0.3866, SE = 0.9317, p = 0.68185\n",
      "✅ CAT_Antihypertensiva | Seed 3: ATT = -0.4618, SE = 1.5558, p = 0.76914\n",
      "✅ CAT_Antihypertensiva | Seed 4: ATT = -0.3840, SE = 1.3588, p = 0.77989\n",
      "✅ CAT_Antihypertensiva | Seed 5: ATT = -0.3672, SE = 1.2783, p = 0.77641\n",
      "✅ CAT_Antihypertensiva | Seed 6: ATT = -0.3128, SE = 1.2583, p = 0.80577\n",
      "✅ CAT_Antihypertensiva | Seed 7: ATT = -0.2706, SE = 1.0630, p = 0.80123\n",
      "✅ CAT_Antihypertensiva | Seed 8: ATT = -0.3240, SE = 1.6639, p = 0.84725\n",
      "✅ CAT_Antihypertensiva | Seed 9: ATT = -0.3159, SE = 1.3086, p = 0.81127\n",
      "✅ CAT_Antihypertensiva | Seed 10: ATT = -0.3633, SE = 0.9161, p = 0.69518\n",
      "📊 Diagnostic plots saved for CAT_Antihypertensiva\n",
      "🏆 Best result for CAT_Antihypertensiva → Seed 10 | SE = 0.9161\n",
      "\n",
      "🚀 Running XGBoost for CAT_Antihistaminica\n",
      "✅ CAT_Antihistaminica | Seed 1: ATT = 1.3301, SE = 1.4132, p = 0.35599\n",
      "✅ CAT_Antihistaminica | Seed 2: ATT = 1.2875, SE = 1.3585, p = 0.35269\n",
      "✅ CAT_Antihistaminica | Seed 3: ATT = 1.3465, SE = 1.4438, p = 0.36030\n",
      "✅ CAT_Antihistaminica | Seed 4: ATT = 1.2185, SE = 1.2393, p = 0.33528\n",
      "✅ CAT_Antihistaminica | Seed 5: ATT = 1.3082, SE = 1.1263, p = 0.25683\n",
      "✅ CAT_Antihistaminica | Seed 6: ATT = 1.2464, SE = 1.3835, p = 0.37656\n",
      "✅ CAT_Antihistaminica | Seed 7: ATT = 1.2627, SE = 1.7062, p = 0.46644\n",
      "✅ CAT_Antihistaminica | Seed 8: ATT = 1.2095, SE = 1.3552, p = 0.38100\n",
      "✅ CAT_Antihistaminica | Seed 9: ATT = 1.3573, SE = 1.2520, p = 0.28908\n",
      "✅ CAT_Antihistaminica | Seed 10: ATT = 1.3719, SE = 1.3274, p = 0.31166\n",
      "📊 Diagnostic plots saved for CAT_Antihistaminica\n",
      "🏆 Best result for CAT_Antihistaminica → Seed 5 | SE = 1.1263\n",
      "\n",
      "🚀 Running XGBoost for CAT_Anti_epileptica\n",
      "✅ CAT_Anti_epileptica | Seed 1: ATT = 1.7975, SE = 2.1851, p = 0.41880\n",
      "✅ CAT_Anti_epileptica | Seed 2: ATT = 1.8566, SE = 2.2290, p = 0.41309\n",
      "✅ CAT_Anti_epileptica | Seed 3: ATT = 1.8823, SE = 2.2779, p = 0.41675\n",
      "✅ CAT_Anti_epileptica | Seed 4: ATT = 1.6111, SE = 1.8124, p = 0.38289\n",
      "✅ CAT_Anti_epileptica | Seed 5: ATT = 1.6519, SE = 1.7482, p = 0.35411\n",
      "✅ CAT_Anti_epileptica | Seed 6: ATT = 1.6680, SE = 1.7649, p = 0.35402\n",
      "✅ CAT_Anti_epileptica | Seed 7: ATT = 2.1125, SE = 2.4046, p = 0.38837\n",
      "✅ CAT_Anti_epileptica | Seed 8: ATT = 1.8988, SE = 2.0831, p = 0.37109\n",
      "✅ CAT_Anti_epileptica | Seed 9: ATT = 1.8877, SE = 2.0817, p = 0.37351\n",
      "✅ CAT_Anti_epileptica | Seed 10: ATT = 1.8031, SE = 2.2805, p = 0.43688\n",
      "📊 Diagnostic plots saved for CAT_Anti_epileptica\n",
      "🏆 Best result for CAT_Anti_epileptica → Seed 5 | SE = 1.7482\n",
      "\n",
      "🚀 Running XGBoost for CAT_Antidepressiva\n",
      "✅ CAT_Antidepressiva | Seed 1: ATT = 0.7347, SE = 0.3626, p = 0.05398\n",
      "✅ CAT_Antidepressiva | Seed 2: ATT = 0.7006, SE = 0.3374, p = 0.04875\n",
      "✅ CAT_Antidepressiva | Seed 3: ATT = 0.7026, SE = 0.3835, p = 0.07938\n",
      "✅ CAT_Antidepressiva | Seed 4: ATT = 0.7111, SE = 0.3441, p = 0.04971\n",
      "✅ CAT_Antidepressiva | Seed 5: ATT = 0.6671, SE = 0.3238, p = 0.05036\n",
      "✅ CAT_Antidepressiva | Seed 6: ATT = 0.7090, SE = 0.3583, p = 0.05946\n",
      "✅ CAT_Antidepressiva | Seed 7: ATT = 0.7067, SE = 0.3977, p = 0.08823\n",
      "✅ CAT_Antidepressiva | Seed 8: ATT = 0.6586, SE = 0.3446, p = 0.06802\n",
      "✅ CAT_Antidepressiva | Seed 9: ATT = 0.7155, SE = 0.4433, p = 0.11961\n",
      "✅ CAT_Antidepressiva | Seed 10: ATT = 0.7449, SE = 0.4894, p = 0.14103\n",
      "📊 Diagnostic plots saved for CAT_Antidepressiva\n",
      "🏆 Best result for CAT_Antidepressiva → Seed 5 | SE = 0.3238\n",
      "\n",
      "🚀 Running XGBoost for CAT_Antipsychotica\n",
      "✅ CAT_Antipsychotica | Seed 1: ATT = 0.7601, SE = 0.8005, p = 0.35185\n",
      "✅ CAT_Antipsychotica | Seed 2: ATT = 0.6547, SE = 0.8229, p = 0.43407\n",
      "✅ CAT_Antipsychotica | Seed 3: ATT = 0.6411, SE = 0.7460, p = 0.39859\n",
      "✅ CAT_Antipsychotica | Seed 4: ATT = 0.7443, SE = 0.8971, p = 0.41493\n",
      "✅ CAT_Antipsychotica | Seed 5: ATT = 0.7025, SE = 0.6613, p = 0.29869\n",
      "✅ CAT_Antipsychotica | Seed 6: ATT = 0.5721, SE = 0.6462, p = 0.38477\n",
      "✅ CAT_Antipsychotica | Seed 7: ATT = 0.7636, SE = 0.6694, p = 0.26522\n",
      "✅ CAT_Antipsychotica | Seed 8: ATT = 0.6330, SE = 0.7932, p = 0.43265\n",
      "✅ CAT_Antipsychotica | Seed 9: ATT = 0.6966, SE = 0.7450, p = 0.35906\n",
      "✅ CAT_Antipsychotica | Seed 10: ATT = 0.6938, SE = 0.6799, p = 0.31766\n",
      "📊 Diagnostic plots saved for CAT_Antipsychotica\n",
      "🏆 Best result for CAT_Antipsychotica → Seed 6 | SE = 0.6462\n",
      "\n",
      "🚀 Running XGBoost for CAT_ALL_PSYCHOTROPICS_EXCL_BENZO\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_BENZO | Seed 1: ATT = 1.5821, SE = 0.5541, p = 0.00872\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_BENZO | Seed 2: ATT = 1.5745, SE = 0.5953, p = 0.01418\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_BENZO | Seed 3: ATT = 1.5571, SE = 0.6117, p = 0.01776\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_BENZO | Seed 4: ATT = 1.5741, SE = 0.5149, p = 0.00541\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_BENZO | Seed 5: ATT = 1.6148, SE = 0.6360, p = 0.01802\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_BENZO | Seed 6: ATT = 1.5842, SE = 0.6865, p = 0.02996\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_BENZO | Seed 7: ATT = 1.5890, SE = 0.5302, p = 0.00625\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_BENZO | Seed 8: ATT = 1.5755, SE = 0.5737, p = 0.01124\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_BENZO | Seed 9: ATT = 1.5728, SE = 0.5917, p = 0.01376\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_BENZO | Seed 10: ATT = 1.5336, SE = 0.6769, p = 0.03279\n",
      "📊 Diagnostic plots saved for CAT_ALL_PSYCHOTROPICS_EXCL_BENZO\n",
      "🏆 Best result for CAT_ALL_PSYCHOTROPICS_EXCL_BENZO → Seed 4 | SE = 0.5149\n",
      "\n",
      "🚀 Running XGBoost for CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS | Seed 1: ATT = 1.1345, SE = 0.4274, p = 0.01388\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS | Seed 2: ATT = 1.1671, SE = 0.4374, p = 0.01344\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS | Seed 3: ATT = 1.1542, SE = 0.3947, p = 0.00742\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS | Seed 4: ATT = 1.1347, SE = 0.4744, p = 0.02494\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS | Seed 5: ATT = 1.1553, SE = 0.3937, p = 0.00724\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS | Seed 6: ATT = 1.1656, SE = 0.4372, p = 0.01352\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS | Seed 7: ATT = 1.1599, SE = 0.4442, p = 0.01531\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS | Seed 8: ATT = 1.1665, SE = 0.4750, p = 0.02169\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS | Seed 9: ATT = 1.1394, SE = 0.5141, p = 0.03641\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS | Seed 10: ATT = 1.1719, SE = 0.4336, p = 0.01243\n",
      "📊 Diagnostic plots saved for CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS\n",
      "🏆 Best result for CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS → Seed 5 | SE = 0.3937\n",
      "\n",
      "🚀 Running XGBoost for CAT_ALL_PSYCHOTROPICS\n",
      "✅ CAT_ALL_PSYCHOTROPICS | Seed 1: ATT = 1.6451, SE = 0.4732, p = 0.00195\n",
      "✅ CAT_ALL_PSYCHOTROPICS | Seed 2: ATT = 1.6850, SE = 0.3958, p = 0.00027\n",
      "✅ CAT_ALL_PSYCHOTROPICS | Seed 3: ATT = 1.6624, SE = 0.4036, p = 0.00039\n",
      "✅ CAT_ALL_PSYCHOTROPICS | Seed 4: ATT = 1.6103, SE = 0.4209, p = 0.00082\n",
      "✅ CAT_ALL_PSYCHOTROPICS | Seed 5: ATT = 1.6379, SE = 0.4155, p = 0.00061\n",
      "✅ CAT_ALL_PSYCHOTROPICS | Seed 6: ATT = 1.6301, SE = 0.4206, p = 0.00072\n",
      "✅ CAT_ALL_PSYCHOTROPICS | Seed 7: ATT = 1.6533, SE = 0.4208, p = 0.00063\n",
      "✅ CAT_ALL_PSYCHOTROPICS | Seed 8: ATT = 1.6500, SE = 0.3803, p = 0.00022\n",
      "✅ CAT_ALL_PSYCHOTROPICS | Seed 9: ATT = 1.6783, SE = 0.4239, p = 0.00058\n",
      "✅ CAT_ALL_PSYCHOTROPICS | Seed 10: ATT = 1.6640, SE = 0.4890, p = 0.00234\n",
      "📊 Diagnostic plots saved for CAT_ALL_PSYCHOTROPICS\n",
      "🏆 Best result for CAT_ALL_PSYCHOTROPICS → Seed 8 | SE = 0.3803\n",
      "\n",
      "🚀 Running XGBoost for CAT_ALL\n",
      "✅ CAT_ALL | Seed 1: ATT = 2.0939, SE = 0.3808, p = < 0.00001\n",
      "✅ CAT_ALL | Seed 2: ATT = 2.0753, SE = 0.4938, p = 0.00032\n",
      "✅ CAT_ALL | Seed 3: ATT = 2.0863, SE = 0.5517, p = 0.00091\n",
      "✅ CAT_ALL | Seed 4: ATT = 2.0797, SE = 0.4805, p = 0.00023\n",
      "✅ CAT_ALL | Seed 5: ATT = 2.0804, SE = 0.4467, p = 0.00010\n",
      "✅ CAT_ALL | Seed 6: ATT = 2.0702, SE = 0.5665, p = 0.00126\n",
      "✅ CAT_ALL | Seed 7: ATT = 2.0836, SE = 0.5123, p = 0.00044\n",
      "✅ CAT_ALL | Seed 8: ATT = 2.0713, SE = 0.4302, p = 0.00007\n",
      "✅ CAT_ALL | Seed 9: ATT = 2.0930, SE = 0.5186, p = 0.00048\n",
      "✅ CAT_ALL | Seed 10: ATT = 2.0448, SE = 0.4792, p = 0.00027\n",
      "📊 Diagnostic plots saved for CAT_ALL\n",
      "🏆 Best result for CAT_ALL → Seed 1 | SE = 0.3808\n",
      "\n",
      "🎯 All summary files saved.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy.stats import t, probplot\n",
    "import xgboost as xgb\n",
    "\n",
    "# -----------------------------\n",
    "# Configuration\n",
    "# -----------------------------\n",
    "n_repeats = 1\n",
    "seeds = list(range(1, 11))\n",
    "imputations = 5\n",
    "output_folder = \"outputs\"\n",
    "\n",
    "# -----------------------------\n",
    "# Diagnostic Plotting Function\n",
    "# -----------------------------\n",
    "def create_diagnostic_plots(residuals_data, fitted_data, group_name):\n",
    "    \"\"\"Create 4 diagnostic plots for model validation\"\"\"\n",
    "    plots_dir = os.path.join(output_folder, \"plots\")\n",
    "    os.makedirs(plots_dir, exist_ok=True)\n",
    "    \n",
    "    # Flatten the collected data\n",
    "    all_residuals = np.concatenate(residuals_data)\n",
    "    all_fitted = np.concatenate(fitted_data)\n",
    "    \n",
    "    # Create figure with 2x2 subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    fig.suptitle(f'Diagnostic Plots - {group_name}', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. Residuals vs Fitted\n",
    "    axes[0,0].scatter(all_fitted, all_residuals, alpha=0.6, s=20)\n",
    "    axes[0,0].axhline(y=0, color='red', linestyle='--', alpha=0.8)\n",
    "    axes[0,0].set_xlabel('Fitted Values')\n",
    "    axes[0,0].set_ylabel('Residuals')\n",
    "    axes[0,0].set_title('Residuals vs Fitted')\n",
    "    axes[0,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. QQ Plot\n",
    "    probplot(all_residuals, dist=\"norm\", plot=axes[0,1])\n",
    "    axes[0,1].set_title('Q-Q Plot (Normal)')\n",
    "    axes[0,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Residual Histogram\n",
    "    axes[1,0].hist(all_residuals, bins=30, density=True, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    axes[1,0].set_xlabel('Residuals')\n",
    "    axes[1,0].set_ylabel('Density')\n",
    "    axes[1,0].set_title('Residual Distribution')\n",
    "    axes[1,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Scale-Location Plot\n",
    "    sqrt_abs_residuals = np.sqrt(np.abs(all_residuals))\n",
    "    axes[1,1].scatter(all_fitted, sqrt_abs_residuals, alpha=0.6, s=20)\n",
    "    axes[1,1].set_xlabel('Fitted Values')\n",
    "    axes[1,1].set_ylabel('√|Residuals|')\n",
    "    axes[1,1].set_title('Scale-Location Plot')\n",
    "    axes[1,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save plot\n",
    "    plot_filename = os.path.join(plots_dir, f'{group_name}.png')\n",
    "    plt.savefig(plot_filename, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"📊 Diagnostic plots saved for {group_name}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Rubin's Rule\n",
    "# -----------------------------\n",
    "def rubins_pool(estimates, ses):\n",
    "    m = len(estimates)\n",
    "    q_bar = np.mean(estimates)\n",
    "    u_bar = np.mean(np.square(ses))\n",
    "    b_m = np.var(estimates, ddof=1)\n",
    "    total_var = u_bar + ((1 + 1/m) * b_m)\n",
    "    total_se = np.sqrt(total_var)\n",
    "    ci_lower = q_bar - 1.96 * total_se\n",
    "    ci_upper = q_bar + 1.96 * total_se\n",
    "    p_value = 2 * (1 - t.cdf(np.abs(q_bar / total_se), df=m-1))\n",
    "    rounded_p = round(p_value, 5)\n",
    "    formatted_p = \"< 0.00001\" if rounded_p <= 0.00001 else f\"{rounded_p:.5f}\"\n",
    "    return q_bar, total_se, ci_lower, ci_upper, formatted_p\n",
    "\n",
    "# -----------------------------\n",
    "# SMD + Variance Ratio\n",
    "# -----------------------------\n",
    "def calculate_smd_vr(X, T, weights):\n",
    "    treated = X[T == 1]\n",
    "    control = X[T == 0]\n",
    "    w_treated = weights[T == 1]\n",
    "    w_control = weights[T == 0]\n",
    "    smd, vr = [], []\n",
    "    for col in X.columns:\n",
    "        try:\n",
    "            m1, m0 = np.average(treated[col], weights=w_treated), np.average(control[col], weights=w_control)\n",
    "            s1 = np.sqrt(np.average((treated[col] - m1) ** 2, weights=w_treated))\n",
    "            s0 = np.sqrt(np.average((control[col] - m0) ** 2, weights=w_control))\n",
    "            pooled_sd = np.sqrt((s1 ** 2 + s0 ** 2) / 2)\n",
    "            smd.append((m1 - m0) / pooled_sd if pooled_sd > 0 else 0)\n",
    "            vr.append(s1**2 / s0**2 if s0**2 > 0 else 0)\n",
    "        except Exception:\n",
    "            smd.append(np.nan)\n",
    "            vr.append(np.nan)\n",
    "    return np.nanmean(smd), np.nanmean(vr)\n",
    "\n",
    "# -----------------------------\n",
    "# XGBoost Main Loop (No DML)\n",
    "# -----------------------------\n",
    "def run_xgboost_with_trimmed_data(final_covariates_map):\n",
    "    att_results = []\n",
    "    balance_results = []\n",
    "\n",
    "    for group, covariates in final_covariates_map.items():\n",
    "        print(f\"\\n🚀 Running XGBoost for {group}\")\n",
    "        group_dir = os.path.join(output_folder, group)\n",
    "        os.makedirs(group_dir, exist_ok=True)\n",
    "\n",
    "        best_result = None\n",
    "        best_se = float(\"inf\")\n",
    "        \n",
    "        # Initialize lists to collect residuals and fitted values for diagnostic plots\n",
    "        group_residuals = []\n",
    "        group_fitted = []\n",
    "\n",
    "        for seed in seeds:\n",
    "            att_list, se_list, r2_list, rmse_list, smd_list, vr_list = [], [], [], [], [], []\n",
    "\n",
    "            for imp in range(1, imputations + 1):\n",
    "                file_path = os.path.join(group_dir, f\"trimmed_data_imp{imp}.pkl\")\n",
    "                if not os.path.exists(file_path):\n",
    "                    continue\n",
    "\n",
    "                df = pd.read_pickle(file_path)\n",
    "                if group not in df.columns or \"iptw\" not in df.columns:\n",
    "                    continue\n",
    "\n",
    "                X = df[covariates].copy()\n",
    "                T = df[group]\n",
    "                Y = df[\"caps5_change_baseline\"]\n",
    "                W = df[\"iptw\"]\n",
    "\n",
    "                for repeat in range(n_repeats):\n",
    "                    kf = KFold(n_splits=5, shuffle=True, random_state=seed + repeat)\n",
    "                    for train_idx, test_idx in kf.split(X):\n",
    "                        try:\n",
    "                            X_train, T_train, Y_train, W_train = (\n",
    "                                X.iloc[train_idx],\n",
    "                                T.iloc[train_idx],\n",
    "                                Y.iloc[train_idx],\n",
    "                                W.iloc[train_idx],\n",
    "                            )\n",
    "\n",
    "                            # XGBoost regression model\n",
    "                            model = xgb.XGBRegressor(n_estimators=100, max_depth=3, learning_rate=0.1, n_jobs=1, random_state=seed)\n",
    "                            \n",
    "                            # Add treatment variable to features\n",
    "                            X_train_with_T = X_train.copy()\n",
    "                            X_train_with_T[group] = T_train\n",
    "                            \n",
    "                            # Fit model\n",
    "                            model.fit(X_train_with_T, Y_train, sample_weight=W_train)\n",
    "                            \n",
    "                            # Predict outcomes for treated and control groups\n",
    "                            X_treated = X_train.copy()\n",
    "                            X_treated[group] = 1\n",
    "                            X_control = X_train.copy()\n",
    "                            X_control[group] = 0\n",
    "                            \n",
    "                            Y_pred_treated = model.predict(X_treated)\n",
    "                            Y_pred_control = model.predict(X_control)\n",
    "                            \n",
    "                            # Calculate ATT (Average Treatment Effect on Treated)\n",
    "                            treated_mask = T_train == 1\n",
    "                            if np.any(treated_mask):\n",
    "                                att = np.average(Y_pred_treated[treated_mask] - Y_pred_control[treated_mask], \n",
    "                                               weights=W_train[treated_mask])\n",
    "                                \n",
    "                                # Calculate standard error (approximate)\n",
    "                                treatment_effects = Y_pred_treated[treated_mask] - Y_pred_control[treated_mask]\n",
    "                                residual = treatment_effects - att\n",
    "                                se = np.sqrt(np.sum((W_train[treated_mask] * residual) ** 2)) / np.sum(W_train[treated_mask])\n",
    "\n",
    "                                \n",
    "                                att_list.append(att)\n",
    "                                se_list.append(se)\n",
    "\n",
    "                            # Model performance metrics\n",
    "                            Y_pred = model.predict(X_train_with_T)\n",
    "                            residuals = Y_train - Y_pred\n",
    "                            rmse = mean_squared_error(Y_train, Y_pred, squared=False)\n",
    "                            r2 = r2_score(Y_train, Y_pred)\n",
    "                            r2_list.append(r2)\n",
    "                            rmse_list.append(rmse)\n",
    "                            \n",
    "                            # Collect residuals and fitted values for diagnostic plots\n",
    "                            group_residuals.append(residuals.values)\n",
    "                            group_fitted.append(Y_pred)\n",
    "\n",
    "                            smd, vr = calculate_smd_vr(X_train, T_train, W_train)\n",
    "                            smd_list.append(smd)\n",
    "                            vr_list.append(vr)\n",
    "                        except Exception as e:\n",
    "                            print(f\"⚠️ Error in {group}, seed {seed}, imp {imp}, rep {repeat}: {e}\")\n",
    "\n",
    "            if att_list:\n",
    "                att, se, ci_l, ci_u, p_val = rubins_pool(att_list, se_list)\n",
    "                avg_r2 = np.mean(r2_list)\n",
    "                avg_rmse = np.mean(rmse_list)\n",
    "                avg_smd = np.mean(smd_list)\n",
    "                avg_vr = np.mean(vr_list)\n",
    "\n",
    "                balance_results.append({\n",
    "                    \"group\": group, \"seed\": seed, \"smd\": avg_smd, \"vr\": avg_vr\n",
    "                })\n",
    "\n",
    "                if se < best_se:\n",
    "                    best_se = se\n",
    "                    best_result = {\n",
    "                        \"group\": group, \"seed\": seed, \"att\": att, \"se\": se,\n",
    "                        \"ci_lower\": ci_l, \"ci_upper\": ci_u, \"p_value\": p_val,\n",
    "                        \"r2\": avg_r2, \"rmse\": avg_rmse\n",
    "                    }\n",
    "\n",
    "                print(f\"✅ {group} | Seed {seed}: ATT = {att:.4f}, SE = {se:.4f}, p = {p_val}\")\n",
    "            else:\n",
    "                print(f\"⚠️ No valid results for {group} | Seed {seed}\")\n",
    "\n",
    "        # Create diagnostic plots for this group\n",
    "        if group_residuals and group_fitted:\n",
    "            create_diagnostic_plots(group_residuals, group_fitted, group)\n",
    "\n",
    "        if best_result:\n",
    "            att_results.append(best_result)\n",
    "            print(f\"🏆 Best result for {group} → Seed {best_result['seed']} | SE = {best_result['se']:.4f}\")\n",
    "\n",
    "    # Save final output\n",
    "    pd.DataFrame(att_results).to_excel(\"xgb_rubin_summary_cats.xlsx\", index=False)\n",
    "    pd.DataFrame(balance_results).to_excel(\"smd_vr_summary_cats.xlsx\", index=False)\n",
    "    print(\"\\n🎯 All summary files saved.\")\n",
    "\n",
    "run_xgboost_with_trimmed_data(final_covariates_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "accbc7d0-83ff-4a42-a304-f9cd50f5031b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unweighted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "2031c63f-4f0b-4ead-acae-9a083dbea569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Running XGBoost for CAT_ADHD\n",
      "✅ CAT_ADHD | Seed 1: ATT = 0.3917, SE = 1.8300, p = 0.83234\n",
      "✅ CAT_ADHD | Seed 2: ATT = 0.6429, SE = 1.6017, p = 0.69171\n",
      "✅ CAT_ADHD | Seed 3: ATT = 0.4355, SE = 1.4527, p = 0.76695\n",
      "✅ CAT_ADHD | Seed 4: ATT = 0.3375, SE = 1.6151, p = 0.83624\n",
      "✅ CAT_ADHD | Seed 5: ATT = 0.3827, SE = 1.4431, p = 0.79312\n",
      "✅ CAT_ADHD | Seed 6: ATT = 0.5450, SE = 1.3486, p = 0.68972\n",
      "✅ CAT_ADHD | Seed 7: ATT = 0.4745, SE = 1.5034, p = 0.75505\n",
      "✅ CAT_ADHD | Seed 8: ATT = 0.4960, SE = 1.4371, p = 0.73298\n",
      "✅ CAT_ADHD | Seed 9: ATT = 0.4193, SE = 1.2929, p = 0.74853\n",
      "✅ CAT_ADHD | Seed 10: ATT = 0.4049, SE = 1.5725, p = 0.79901\n",
      "📊 Diagnostic plots saved for CAT_ADHD\n",
      "🏆 Best result for CAT_ADHD → Seed 9 | SE = 1.2929\n",
      "\n",
      "🚀 Running XGBoost for CAT_Aceetanilidederivaten\n",
      "✅ CAT_Aceetanilidederivaten | Seed 1: ATT = 0.5079, SE = 2.4989, p = 0.84064\n",
      "✅ CAT_Aceetanilidederivaten | Seed 2: ATT = 0.5197, SE = 2.7070, p = 0.84938\n",
      "✅ CAT_Aceetanilidederivaten | Seed 3: ATT = 0.1977, SE = 2.5870, p = 0.93973\n",
      "✅ CAT_Aceetanilidederivaten | Seed 4: ATT = 0.2976, SE = 2.8787, p = 0.91853\n",
      "✅ CAT_Aceetanilidederivaten | Seed 5: ATT = 0.2865, SE = 2.2633, p = 0.90032\n",
      "✅ CAT_Aceetanilidederivaten | Seed 6: ATT = 0.3165, SE = 2.3146, p = 0.89236\n",
      "✅ CAT_Aceetanilidederivaten | Seed 7: ATT = 0.5245, SE = 2.8020, p = 0.85308\n",
      "✅ CAT_Aceetanilidederivaten | Seed 8: ATT = -0.0815, SE = 3.1562, p = 0.97961\n",
      "✅ CAT_Aceetanilidederivaten | Seed 9: ATT = 0.6130, SE = 2.5515, p = 0.81217\n",
      "✅ CAT_Aceetanilidederivaten | Seed 10: ATT = 0.3675, SE = 2.7211, p = 0.89368\n",
      "📊 Diagnostic plots saved for CAT_Aceetanilidederivaten\n",
      "🏆 Best result for CAT_Aceetanilidederivaten → Seed 5 | SE = 2.2633\n",
      "\n",
      "🚀 Running XGBoost for CAT_Z_drugs\n",
      "✅ CAT_Z_drugs | Seed 1: ATT = 1.7026, SE = 2.2622, p = 0.45898\n",
      "✅ CAT_Z_drugs | Seed 2: ATT = 1.6228, SE = 2.4578, p = 0.51536\n",
      "✅ CAT_Z_drugs | Seed 3: ATT = 1.6112, SE = 2.0481, p = 0.43917\n",
      "✅ CAT_Z_drugs | Seed 4: ATT = 1.8127, SE = 2.4403, p = 0.46481\n",
      "✅ CAT_Z_drugs | Seed 5: ATT = 1.7725, SE = 2.3572, p = 0.45939\n",
      "✅ CAT_Z_drugs | Seed 6: ATT = 1.8918, SE = 2.1084, p = 0.37848\n",
      "✅ CAT_Z_drugs | Seed 7: ATT = 1.7999, SE = 2.2659, p = 0.43476\n",
      "✅ CAT_Z_drugs | Seed 8: ATT = 1.6591, SE = 2.1059, p = 0.43851\n",
      "✅ CAT_Z_drugs | Seed 9: ATT = 1.8434, SE = 2.3393, p = 0.43839\n",
      "✅ CAT_Z_drugs | Seed 10: ATT = 1.8718, SE = 2.3672, p = 0.43686\n",
      "📊 Diagnostic plots saved for CAT_Z_drugs\n",
      "🏆 Best result for CAT_Z_drugs → Seed 3 | SE = 2.0481\n",
      "\n",
      "🚀 Running XGBoost for CAT_Opioden\n",
      "✅ CAT_Opioden | Seed 1: ATT = 1.2481, SE = 1.3933, p = 0.37927\n",
      "✅ CAT_Opioden | Seed 2: ATT = 1.1118, SE = 1.2019, p = 0.36416\n",
      "✅ CAT_Opioden | Seed 3: ATT = 0.8531, SE = 1.2050, p = 0.48575\n",
      "✅ CAT_Opioden | Seed 4: ATT = 1.3476, SE = 2.0414, p = 0.51546\n",
      "✅ CAT_Opioden | Seed 5: ATT = 1.2285, SE = 1.4606, p = 0.40859\n",
      "✅ CAT_Opioden | Seed 6: ATT = 1.0796, SE = 1.2987, p = 0.41400\n",
      "✅ CAT_Opioden | Seed 7: ATT = 1.3679, SE = 1.4907, p = 0.36794\n",
      "✅ CAT_Opioden | Seed 8: ATT = 1.0536, SE = 1.6159, p = 0.52060\n",
      "✅ CAT_Opioden | Seed 9: ATT = 0.9430, SE = 1.3802, p = 0.50101\n",
      "✅ CAT_Opioden | Seed 10: ATT = 1.2302, SE = 1.5568, p = 0.43715\n",
      "📊 Diagnostic plots saved for CAT_Opioden\n",
      "🏆 Best result for CAT_Opioden → Seed 2 | SE = 1.2019\n",
      "\n",
      "🚀 Running XGBoost for CAT_NSAIDs\n",
      "✅ CAT_NSAIDs | Seed 1: ATT = 1.1089, SE = 2.2675, p = 0.62926\n",
      "✅ CAT_NSAIDs | Seed 2: ATT = 1.0503, SE = 2.2178, p = 0.64009\n",
      "✅ CAT_NSAIDs | Seed 3: ATT = 0.9823, SE = 2.4492, p = 0.69194\n",
      "✅ CAT_NSAIDs | Seed 4: ATT = 1.1218, SE = 2.2172, p = 0.61750\n",
      "✅ CAT_NSAIDs | Seed 5: ATT = 0.9849, SE = 2.2420, p = 0.66440\n",
      "✅ CAT_NSAIDs | Seed 6: ATT = 1.1108, SE = 2.4764, p = 0.65779\n",
      "✅ CAT_NSAIDs | Seed 7: ATT = 0.8450, SE = 1.7732, p = 0.63802\n",
      "✅ CAT_NSAIDs | Seed 8: ATT = 1.0164, SE = 2.0788, p = 0.62931\n",
      "✅ CAT_NSAIDs | Seed 9: ATT = 0.9091, SE = 2.3862, p = 0.70656\n",
      "✅ CAT_NSAIDs | Seed 10: ATT = 1.1424, SE = 2.3609, p = 0.63284\n",
      "📊 Diagnostic plots saved for CAT_NSAIDs\n",
      "🏆 Best result for CAT_NSAIDs → Seed 7 | SE = 1.7732\n",
      "\n",
      "🚀 Running XGBoost for CAT_Benzodiazepine\n",
      "✅ CAT_Benzodiazepine | Seed 1: ATT = 0.2874, SE = 0.4001, p = 0.47960\n",
      "✅ CAT_Benzodiazepine | Seed 2: ATT = 0.3413, SE = 0.3859, p = 0.38523\n",
      "✅ CAT_Benzodiazepine | Seed 3: ATT = 0.2947, SE = 0.3020, p = 0.33879\n",
      "✅ CAT_Benzodiazepine | Seed 4: ATT = 0.2725, SE = 0.4353, p = 0.53723\n",
      "✅ CAT_Benzodiazepine | Seed 5: ATT = 0.2924, SE = 0.3228, p = 0.37405\n",
      "✅ CAT_Benzodiazepine | Seed 6: ATT = 0.3149, SE = 0.3626, p = 0.39386\n",
      "✅ CAT_Benzodiazepine | Seed 7: ATT = 0.2418, SE = 0.3579, p = 0.50577\n",
      "✅ CAT_Benzodiazepine | Seed 8: ATT = 0.3192, SE = 0.3472, p = 0.36702\n",
      "✅ CAT_Benzodiazepine | Seed 9: ATT = 0.2812, SE = 0.3176, p = 0.38478\n",
      "✅ CAT_Benzodiazepine | Seed 10: ATT = 0.2873, SE = 0.3197, p = 0.37784\n",
      "📊 Diagnostic plots saved for CAT_Benzodiazepine\n",
      "🏆 Best result for CAT_Benzodiazepine → Seed 3 | SE = 0.3020\n",
      "\n",
      "🚀 Running XGBoost for CAT_Antihypertensiva\n",
      "✅ CAT_Antihypertensiva | Seed 1: ATT = -0.4378, SE = 1.0469, p = 0.67950\n",
      "✅ CAT_Antihypertensiva | Seed 2: ATT = -0.3604, SE = 0.9420, p = 0.70539\n",
      "✅ CAT_Antihypertensiva | Seed 3: ATT = -0.4735, SE = 1.3834, p = 0.73512\n",
      "✅ CAT_Antihypertensiva | Seed 4: ATT = -0.2201, SE = 1.3770, p = 0.87436\n",
      "✅ CAT_Antihypertensiva | Seed 5: ATT = -0.1620, SE = 1.3015, p = 0.90199\n",
      "✅ CAT_Antihypertensiva | Seed 6: ATT = -0.2753, SE = 1.0425, p = 0.79399\n",
      "✅ CAT_Antihypertensiva | Seed 7: ATT = -0.1325, SE = 1.1126, p = 0.90621\n",
      "✅ CAT_Antihypertensiva | Seed 8: ATT = -0.2809, SE = 1.6194, p = 0.86376\n",
      "✅ CAT_Antihypertensiva | Seed 9: ATT = -0.2064, SE = 1.2223, p = 0.86730\n",
      "✅ CAT_Antihypertensiva | Seed 10: ATT = -0.3280, SE = 1.0503, p = 0.75754\n",
      "📊 Diagnostic plots saved for CAT_Antihypertensiva\n",
      "🏆 Best result for CAT_Antihypertensiva → Seed 2 | SE = 0.9420\n",
      "\n",
      "🚀 Running XGBoost for CAT_Antihistaminica\n",
      "✅ CAT_Antihistaminica | Seed 1: ATT = 1.4831, SE = 1.0287, p = 0.16231\n",
      "✅ CAT_Antihistaminica | Seed 2: ATT = 1.4511, SE = 1.4784, p = 0.33610\n",
      "✅ CAT_Antihistaminica | Seed 3: ATT = 1.3902, SE = 1.3364, p = 0.30860\n",
      "✅ CAT_Antihistaminica | Seed 4: ATT = 1.4573, SE = 1.2330, p = 0.24883\n",
      "✅ CAT_Antihistaminica | Seed 5: ATT = 1.3652, SE = 1.2001, p = 0.26651\n",
      "✅ CAT_Antihistaminica | Seed 6: ATT = 1.4958, SE = 1.4863, p = 0.32427\n",
      "✅ CAT_Antihistaminica | Seed 7: ATT = 1.4814, SE = 1.6825, p = 0.38734\n",
      "✅ CAT_Antihistaminica | Seed 8: ATT = 1.3965, SE = 1.3559, p = 0.31331\n",
      "✅ CAT_Antihistaminica | Seed 9: ATT = 1.5152, SE = 1.2253, p = 0.22821\n",
      "✅ CAT_Antihistaminica | Seed 10: ATT = 1.4705, SE = 1.4614, p = 0.32435\n",
      "📊 Diagnostic plots saved for CAT_Antihistaminica\n",
      "🏆 Best result for CAT_Antihistaminica → Seed 1 | SE = 1.0287\n",
      "\n",
      "🚀 Running XGBoost for CAT_Anti_epileptica\n",
      "✅ CAT_Anti_epileptica | Seed 1: ATT = 1.6849, SE = 1.9045, p = 0.38510\n",
      "✅ CAT_Anti_epileptica | Seed 2: ATT = 1.7863, SE = 1.8199, p = 0.33612\n",
      "✅ CAT_Anti_epileptica | Seed 3: ATT = 1.7945, SE = 1.8073, p = 0.33067\n",
      "✅ CAT_Anti_epileptica | Seed 4: ATT = 1.6692, SE = 1.7199, p = 0.34147\n",
      "✅ CAT_Anti_epileptica | Seed 5: ATT = 1.7242, SE = 1.7980, p = 0.34716\n",
      "✅ CAT_Anti_epileptica | Seed 6: ATT = 1.8372, SE = 1.6760, p = 0.28387\n",
      "✅ CAT_Anti_epileptica | Seed 7: ATT = 1.9840, SE = 2.0670, p = 0.34671\n",
      "✅ CAT_Anti_epileptica | Seed 8: ATT = 1.7428, SE = 1.7737, p = 0.33560\n",
      "✅ CAT_Anti_epileptica | Seed 9: ATT = 1.9905, SE = 1.8378, p = 0.28953\n",
      "✅ CAT_Anti_epileptica | Seed 10: ATT = 1.7232, SE = 1.8876, p = 0.37037\n",
      "📊 Diagnostic plots saved for CAT_Anti_epileptica\n",
      "🏆 Best result for CAT_Anti_epileptica → Seed 6 | SE = 1.6760\n",
      "\n",
      "🚀 Running XGBoost for CAT_Antidepressiva\n",
      "✅ CAT_Antidepressiva | Seed 1: ATT = 0.7568, SE = 0.3792, p = 0.05745\n",
      "✅ CAT_Antidepressiva | Seed 2: ATT = 0.7308, SE = 0.3272, p = 0.03512\n",
      "✅ CAT_Antidepressiva | Seed 3: ATT = 0.7725, SE = 0.4167, p = 0.07608\n",
      "✅ CAT_Antidepressiva | Seed 4: ATT = 0.7389, SE = 0.3549, p = 0.04815\n",
      "✅ CAT_Antidepressiva | Seed 5: ATT = 0.7625, SE = 0.3006, p = 0.01813\n",
      "✅ CAT_Antidepressiva | Seed 6: ATT = 0.7398, SE = 0.3271, p = 0.03307\n",
      "✅ CAT_Antidepressiva | Seed 7: ATT = 0.7272, SE = 0.3529, p = 0.05038\n",
      "✅ CAT_Antidepressiva | Seed 8: ATT = 0.6963, SE = 0.2607, p = 0.01337\n",
      "✅ CAT_Antidepressiva | Seed 9: ATT = 0.7450, SE = 0.3754, p = 0.05876\n",
      "✅ CAT_Antidepressiva | Seed 10: ATT = 0.7477, SE = 0.3748, p = 0.05754\n",
      "📊 Diagnostic plots saved for CAT_Antidepressiva\n",
      "🏆 Best result for CAT_Antidepressiva → Seed 8 | SE = 0.2607\n",
      "\n",
      "🚀 Running XGBoost for CAT_Antipsychotica\n",
      "✅ CAT_Antipsychotica | Seed 1: ATT = 1.2444, SE = 0.7484, p = 0.10938\n",
      "✅ CAT_Antipsychotica | Seed 2: ATT = 1.2182, SE = 0.6761, p = 0.08414\n",
      "✅ CAT_Antipsychotica | Seed 3: ATT = 1.2274, SE = 0.5713, p = 0.04199\n",
      "✅ CAT_Antipsychotica | Seed 4: ATT = 1.2174, SE = 0.9075, p = 0.19231\n",
      "✅ CAT_Antipsychotica | Seed 5: ATT = 1.2026, SE = 0.5683, p = 0.04489\n",
      "✅ CAT_Antipsychotica | Seed 6: ATT = 1.0961, SE = 0.4211, p = 0.01560\n",
      "✅ CAT_Antipsychotica | Seed 7: ATT = 1.1863, SE = 0.6015, p = 0.06023\n",
      "✅ CAT_Antipsychotica | Seed 8: ATT = 1.2331, SE = 0.5813, p = 0.04441\n",
      "✅ CAT_Antipsychotica | Seed 9: ATT = 1.1750, SE = 0.6405, p = 0.07902\n",
      "✅ CAT_Antipsychotica | Seed 10: ATT = 1.1732, SE = 0.5268, p = 0.03559\n",
      "📊 Diagnostic plots saved for CAT_Antipsychotica\n",
      "🏆 Best result for CAT_Antipsychotica → Seed 6 | SE = 0.4211\n",
      "\n",
      "🚀 Running XGBoost for CAT_ALL_PSYCHOTROPICS_EXCL_BENZO\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_BENZO | Seed 1: ATT = 1.0629, SE = 0.3872, p = 0.01128\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_BENZO | Seed 2: ATT = 1.0278, SE = 0.3735, p = 0.01110\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_BENZO | Seed 3: ATT = 1.0330, SE = 0.3892, p = 0.01389\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_BENZO | Seed 4: ATT = 1.0671, SE = 0.4124, p = 0.01616\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_BENZO | Seed 5: ATT = 1.0459, SE = 0.3690, p = 0.00916\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_BENZO | Seed 6: ATT = 1.0315, SE = 0.4380, p = 0.02705\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_BENZO | Seed 7: ATT = 1.0519, SE = 0.3404, p = 0.00500\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_BENZO | Seed 8: ATT = 1.0356, SE = 0.4173, p = 0.02048\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_BENZO | Seed 9: ATT = 1.0792, SE = 0.4222, p = 0.01734\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_BENZO | Seed 10: ATT = 1.0720, SE = 0.4035, p = 0.01380\n",
      "📊 Diagnostic plots saved for CAT_ALL_PSYCHOTROPICS_EXCL_BENZO\n",
      "🏆 Best result for CAT_ALL_PSYCHOTROPICS_EXCL_BENZO → Seed 7 | SE = 0.3404\n",
      "\n",
      "🚀 Running XGBoost for CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS | Seed 1: ATT = 0.8251, SE = 0.3131, p = 0.01449\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS | Seed 2: ATT = 0.8714, SE = 0.3872, p = 0.03383\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS | Seed 3: ATT = 0.8360, SE = 0.3444, p = 0.02307\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS | Seed 4: ATT = 0.8316, SE = 0.2252, p = 0.00114\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS | Seed 5: ATT = 0.8457, SE = 0.3758, p = 0.03388\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS | Seed 6: ATT = 0.8528, SE = 0.3710, p = 0.03055\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS | Seed 7: ATT = 0.8364, SE = 0.2987, p = 0.00992\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS | Seed 8: ATT = 0.8347, SE = 0.2482, p = 0.00258\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS | Seed 9: ATT = 0.8368, SE = 0.3680, p = 0.03221\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS | Seed 10: ATT = 0.8658, SE = 0.3816, p = 0.03255\n",
      "📊 Diagnostic plots saved for CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS\n",
      "🏆 Best result for CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS → Seed 4 | SE = 0.2252\n",
      "\n",
      "🚀 Running XGBoost for CAT_ALL_PSYCHOTROPICS\n",
      "✅ CAT_ALL_PSYCHOTROPICS | Seed 1: ATT = 1.5842, SE = 0.3769, p = 0.00031\n",
      "✅ CAT_ALL_PSYCHOTROPICS | Seed 2: ATT = 1.5893, SE = 0.4113, p = 0.00074\n",
      "✅ CAT_ALL_PSYCHOTROPICS | Seed 3: ATT = 1.6036, SE = 0.4042, p = 0.00057\n",
      "✅ CAT_ALL_PSYCHOTROPICS | Seed 4: ATT = 1.5857, SE = 0.3313, p = 0.00007\n",
      "✅ CAT_ALL_PSYCHOTROPICS | Seed 5: ATT = 1.6003, SE = 0.4233, p = 0.00092\n",
      "✅ CAT_ALL_PSYCHOTROPICS | Seed 6: ATT = 1.5562, SE = 0.3206, p = 0.00006\n",
      "✅ CAT_ALL_PSYCHOTROPICS | Seed 7: ATT = 1.5912, SE = 0.3861, p = 0.00039\n",
      "✅ CAT_ALL_PSYCHOTROPICS | Seed 8: ATT = 1.6229, SE = 0.3508, p = 0.00011\n",
      "✅ CAT_ALL_PSYCHOTROPICS | Seed 9: ATT = 1.5746, SE = 0.3534, p = 0.00017\n",
      "✅ CAT_ALL_PSYCHOTROPICS | Seed 10: ATT = 1.6034, SE = 0.3459, p = 0.00010\n",
      "📊 Diagnostic plots saved for CAT_ALL_PSYCHOTROPICS\n",
      "🏆 Best result for CAT_ALL_PSYCHOTROPICS → Seed 6 | SE = 0.3206\n",
      "\n",
      "🚀 Running XGBoost for CAT_ALL\n",
      "✅ CAT_ALL | Seed 1: ATT = 2.0414, SE = 0.2589, p = < 0.00001\n",
      "✅ CAT_ALL | Seed 2: ATT = 2.0530, SE = 0.3257, p = < 0.00001\n",
      "✅ CAT_ALL | Seed 3: ATT = 2.0554, SE = 0.3898, p = 0.00002\n",
      "✅ CAT_ALL | Seed 4: ATT = 2.0605, SE = 0.4100, p = 0.00004\n",
      "✅ CAT_ALL | Seed 5: ATT = 2.0588, SE = 0.2623, p = < 0.00001\n",
      "✅ CAT_ALL | Seed 6: ATT = 2.0694, SE = 0.4013, p = 0.00003\n",
      "✅ CAT_ALL | Seed 7: ATT = 2.0709, SE = 0.3551, p = < 0.00001\n",
      "✅ CAT_ALL | Seed 8: ATT = 2.0459, SE = 0.3626, p = < 0.00001\n",
      "✅ CAT_ALL | Seed 9: ATT = 2.0890, SE = 0.3036, p = < 0.00001\n",
      "✅ CAT_ALL | Seed 10: ATT = 2.0531, SE = 0.2924, p = < 0.00001\n",
      "📊 Diagnostic plots saved for CAT_ALL\n",
      "🏆 Best result for CAT_ALL → Seed 1 | SE = 0.2589\n",
      "\n",
      "🎯 All summary files saved.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy.stats import t, probplot\n",
    "import xgboost as xgb\n",
    "\n",
    "# -----------------------------\n",
    "# Configuration\n",
    "# -----------------------------\n",
    "n_repeats = 1\n",
    "seeds = list(range(1, 11))\n",
    "imputations = 5\n",
    "output_folder = \"outputs\"\n",
    "\n",
    "# -----------------------------\n",
    "# Diagnostic Plotting Function\n",
    "# -----------------------------\n",
    "def create_diagnostic_plots(residuals_data, fitted_data, group_name):\n",
    "    \"\"\"Create 4 diagnostic plots for model validation\"\"\"\n",
    "    plots_dir = os.path.join(output_folder, \"plots\")\n",
    "    os.makedirs(plots_dir, exist_ok=True)\n",
    "    \n",
    "    # Flatten the collected data\n",
    "    all_residuals = np.concatenate(residuals_data)\n",
    "    all_fitted = np.concatenate(fitted_data)\n",
    "    \n",
    "    # Create figure with 2x2 subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    fig.suptitle(f'Diagnostic Plots - {group_name}', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. Residuals vs Fitted\n",
    "    axes[0,0].scatter(all_fitted, all_residuals, alpha=0.6, s=20)\n",
    "    axes[0,0].axhline(y=0, color='red', linestyle='--', alpha=0.8)\n",
    "    axes[0,0].set_xlabel('Fitted Values')\n",
    "    axes[0,0].set_ylabel('Residuals')\n",
    "    axes[0,0].set_title('Residuals vs Fitted')\n",
    "    axes[0,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. QQ Plot\n",
    "    probplot(all_residuals, dist=\"norm\", plot=axes[0,1])\n",
    "    axes[0,1].set_title('Q-Q Plot (Normal)')\n",
    "    axes[0,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Residual Histogram\n",
    "    axes[1,0].hist(all_residuals, bins=30, density=True, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    axes[1,0].set_xlabel('Residuals')\n",
    "    axes[1,0].set_ylabel('Density')\n",
    "    axes[1,0].set_title('Residual Distribution')\n",
    "    axes[1,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Scale-Location Plot\n",
    "    sqrt_abs_residuals = np.sqrt(np.abs(all_residuals))\n",
    "    axes[1,1].scatter(all_fitted, sqrt_abs_residuals, alpha=0.6, s=20)\n",
    "    axes[1,1].set_xlabel('Fitted Values')\n",
    "    axes[1,1].set_ylabel('√|Residuals|')\n",
    "    axes[1,1].set_title('Scale-Location Plot')\n",
    "    axes[1,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save plot\n",
    "    plot_filename = os.path.join(plots_dir, f'{group_name}_unweighted.png')\n",
    "    plt.savefig(plot_filename, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"📊 Diagnostic plots saved for {group_name}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Rubin's Rule\n",
    "# -----------------------------\n",
    "def rubins_pool(estimates, ses):\n",
    "    m = len(estimates)\n",
    "    q_bar = np.mean(estimates)\n",
    "    u_bar = np.mean(np.square(ses))\n",
    "    b_m = np.var(estimates, ddof=1)\n",
    "    total_var = u_bar + ((1 + 1/m) * b_m)\n",
    "    total_se = np.sqrt(total_var)\n",
    "    ci_lower = q_bar - 1.96 * total_se\n",
    "    ci_upper = q_bar + 1.96 * total_se\n",
    "    p_value = 2 * (1 - t.cdf(np.abs(q_bar / total_se), df=m-1))\n",
    "    rounded_p = round(p_value, 5)\n",
    "    formatted_p = \"< 0.00001\" if rounded_p <= 0.00001 else f\"{rounded_p:.5f}\"\n",
    "    return q_bar, total_se, ci_lower, ci_upper, formatted_p\n",
    "\n",
    "# -----------------------------\n",
    "# SMD + Variance Ratio\n",
    "# -----------------------------\n",
    "def calculate_smd_vr(X, T):\n",
    "    treated = X[T == 1]\n",
    "    control = X[T == 0]\n",
    "    smd, vr = [], []\n",
    "    for col in X.columns:\n",
    "        try:\n",
    "            m1, m0 = np.mean(treated[col]), np.mean(control[col])\n",
    "            s1 = np.std(treated[col])\n",
    "            s0 = np.std(control[col])\n",
    "            pooled_sd = np.sqrt((s1 ** 2 + s0 ** 2) / 2)\n",
    "            smd.append((m1 - m0) / pooled_sd if pooled_sd > 0 else 0)\n",
    "            vr.append(s1**2 / s0**2 if s0**2 > 0 else 0)\n",
    "        except Exception:\n",
    "            smd.append(np.nan)\n",
    "            vr.append(np.nan)\n",
    "    return np.nanmean(smd), np.nanmean(vr)\n",
    "\n",
    "# -----------------------------\n",
    "# XGBoost Main Loop (No DML)\n",
    "# -----------------------------\n",
    "def run_xgboost_with_trimmed_data(final_covariates_map):\n",
    "    att_results = []\n",
    "    balance_results = []\n",
    "\n",
    "    for group, covariates in final_covariates_map.items():\n",
    "        print(f\"\\n🚀 Running XGBoost for {group}\")\n",
    "        group_dir = os.path.join(output_folder, group)\n",
    "        os.makedirs(group_dir, exist_ok=True)\n",
    "\n",
    "        best_result = None\n",
    "        best_se = float(\"inf\")\n",
    "        \n",
    "        # Initialize lists to collect residuals and fitted values for diagnostic plots\n",
    "        group_residuals = []\n",
    "        group_fitted = []\n",
    "\n",
    "        for seed in seeds:\n",
    "            att_list, se_list, r2_list, rmse_list, smd_list, vr_list = [], [], [], [], [], []\n",
    "\n",
    "            for imp in range(1, imputations + 1):\n",
    "                file_path = os.path.join(group_dir, f\"trimmed_data_imp{imp}.pkl\")\n",
    "                if not os.path.exists(file_path):\n",
    "                    continue\n",
    "\n",
    "                df = pd.read_pickle(file_path)\n",
    "                if group not in df.columns or \"iptw\" not in df.columns:\n",
    "                    continue\n",
    "\n",
    "                X = df[covariates].copy()\n",
    "                T = df[group]\n",
    "                Y = df[\"caps5_change_baseline\"]\n",
    "                #W = df[\"iptw\"]\n",
    "\n",
    "                for repeat in range(n_repeats):\n",
    "                    kf = KFold(n_splits=5, shuffle=True, random_state=seed + repeat)\n",
    "                    for train_idx, test_idx in kf.split(X):\n",
    "                        try:\n",
    "                            X_train = X.iloc[train_idx]\n",
    "                            T_train = T.iloc[train_idx]\n",
    "                            Y_train = Y.iloc[train_idx]\n",
    "                        \n",
    "\n",
    "                            # XGBoost regression model\n",
    "                            model = xgb.XGBRegressor(n_estimators=100, max_depth=3, learning_rate=0.1, n_jobs=1, random_state=seed)\n",
    "                            \n",
    "                            # Add treatment variable to features\n",
    "                            X_train_with_T = X_train.copy()\n",
    "                            X_train_with_T[group] = T_train\n",
    "                            \n",
    "                            # Fit model\n",
    "                            model.fit(X_train_with_T, Y_train)\n",
    "                            \n",
    "                            # Predict outcomes for treated and control groups\n",
    "                            X_treated = X_train.copy()\n",
    "                            X_treated[group] = 1\n",
    "                            X_control = X_train.copy()\n",
    "                            X_control[group] = 0\n",
    "                            \n",
    "                            Y_pred_treated = model.predict(X_treated)\n",
    "                            Y_pred_control = model.predict(X_control)\n",
    "                            \n",
    "                            # Calculate ATT (Average Treatment Effect on Treated)\n",
    "                            treated_mask = T_train == 1\n",
    "                            if np.any(treated_mask):\n",
    "                                att = np.mean(Y_pred_treated[treated_mask] - Y_pred_control[treated_mask])\n",
    "                                \n",
    "                                # Calculate standard error (approximate)\n",
    "                                treatment_effects = Y_pred_treated[treated_mask] - Y_pred_control[treated_mask]\n",
    "                                residual = treatment_effects - att\n",
    "                                se = np.sqrt(np.sum((residual) ** 2)) / np.sum(treated_mask)\n",
    "                                att_list.append(att)\n",
    "                                se_list.append(se)\n",
    "\n",
    "                            # Model performance metrics\n",
    "                            Y_pred = model.predict(X_train_with_T)\n",
    "                            residuals = Y_train - Y_pred\n",
    "                            rmse = mean_squared_error(Y_train, Y_pred, squared=False)\n",
    "                            r2 = r2_score(Y_train, Y_pred)\n",
    "                            r2_list.append(r2)\n",
    "                            rmse_list.append(rmse)\n",
    "                            \n",
    "                            # Collect residuals and fitted values for diagnostic plots\n",
    "                            group_residuals.append(residuals.values)\n",
    "                            group_fitted.append(Y_pred)\n",
    "\n",
    "                            smd, vr = calculate_smd_vr(X_train, T_train)\n",
    "                            smd_list.append(smd)\n",
    "                            vr_list.append(vr)\n",
    "                        except Exception as e:\n",
    "                            print(f\"⚠️ Error in {group}, seed {seed}, imp {imp}, rep {repeat}: {e}\")\n",
    "\n",
    "            if att_list:\n",
    "                att, se, ci_l, ci_u, p_val = rubins_pool(att_list, se_list)\n",
    "                avg_r2 = np.mean(r2_list)\n",
    "                avg_rmse = np.mean(rmse_list)\n",
    "                avg_smd = np.mean(smd_list)\n",
    "                avg_vr = np.mean(vr_list)\n",
    "\n",
    "                balance_results.append({\n",
    "                    \"group\": group, \"seed\": seed, \"smd\": avg_smd, \"vr\": avg_vr\n",
    "                })\n",
    "\n",
    "                if se < best_se:\n",
    "                    best_se = se\n",
    "                    best_result = {\n",
    "                        \"group\": group, \"seed\": seed, \"att\": att, \"se\": se,\n",
    "                        \"ci_lower\": ci_l, \"ci_upper\": ci_u, \"p_value\": p_val,\n",
    "                        \"r2\": avg_r2, \"rmse\": avg_rmse\n",
    "                    }\n",
    "\n",
    "                print(f\"✅ {group} | Seed {seed}: ATT = {att:.4f}, SE = {se:.4f}, p = {p_val}\")\n",
    "            else:\n",
    "                print(f\"⚠️ No valid results for {group} | Seed {seed}\")\n",
    "\n",
    "        # Create diagnostic plots for this group\n",
    "        if group_residuals and group_fitted:\n",
    "            create_diagnostic_plots(group_residuals, group_fitted, group)\n",
    "\n",
    "        if best_result:\n",
    "            att_results.append(best_result)\n",
    "            print(f\"🏆 Best result for {group} → Seed {best_result['seed']} | SE = {best_result['se']:.4f}\")\n",
    "\n",
    "    # Save final output\n",
    "    pd.DataFrame(att_results).to_excel(\"xgb_rubin_summary_cats_unweighted.xlsx\", index=False)\n",
    "    pd.DataFrame(balance_results).to_excel(\"smd_vr_summary_cats_unweighted.xlsx\", index=False)\n",
    "    print(\"\\n🎯 All summary files saved.\")\n",
    "\n",
    "run_xgboost_with_trimmed_data(final_covariates_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "09f4c13c-ac14-4dfc-aa7a-e7ec6d3a5f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Final_ATT_Summary_Cat saved\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import sem, ttest_ind\n",
    "\n",
    "# ----------------------------------\n",
    "# File paths\n",
    "# ----------------------------------\n",
    "output_base = \"outputs\"\n",
    "att_file = \"xgb_rubin_summary_cats.xlsx\"\n",
    "trimmed_file = \"trimmed_data_imp1.pkl\"\n",
    "auc_file = \"auc_scores.xlsx\"  # NEW\n",
    "\n",
    "# ----------------------------------\n",
    "# Load ATT Summary\n",
    "# ----------------------------------\n",
    "if os.path.exists(att_file):\n",
    "    att_df = pd.read_excel(att_file)\n",
    "else:\n",
    "    raise FileNotFoundError(\"❌ ATT summary file not found: xgb_rubin_summary_cats.xlsx\")\n",
    "\n",
    "summary_rows = []\n",
    "\n",
    "# ----------------------------------\n",
    "# Loop over medication groups\n",
    "# ----------------------------------\n",
    "groups = [g for g in medication_groups if os.path.isdir(os.path.join(output_base, g))]\n",
    "\n",
    "for med in groups:\n",
    "    try:\n",
    "        group_path = os.path.join(output_base, med)\n",
    "\n",
    "        # Load trimmed data\n",
    "        df = pd.read_pickle(os.path.join(group_path, trimmed_file))\n",
    "\n",
    "        # Detect treatment column\n",
    "        treatment_cols = [col for col in df.columns if col.upper() == med.upper()]\n",
    "        if not treatment_cols:\n",
    "            print(f\"⚠️ Treatment column {med} not found in trimmed data. Skipping.\")\n",
    "            continue\n",
    "        treatment_var = treatment_cols[0]\n",
    "\n",
    "        # Extract treatment and outcome\n",
    "        T = df[treatment_var]\n",
    "        Y = df[\"caps5_change_baseline\"]\n",
    "\n",
    "        # Treated and control stats\n",
    "        treated = Y[T == 1]\n",
    "        control = Y[T == 0]\n",
    "\n",
    "        mean_treat = treated.mean()\n",
    "        se_treat = sem(treated) if len(treated) > 1 else np.nan\n",
    "\n",
    "        mean_ctrl = control.mean()\n",
    "        se_ctrl = sem(control) if len(control) > 1 else np.nan\n",
    "\n",
    "        # Cohen's d (unadjusted)\n",
    "        pooled_sd = np.sqrt(((treated.std() ** 2) + (control.std() ** 2)) / 2)\n",
    "        cohen_d = (mean_treat - mean_ctrl) / pooled_sd if pooled_sd > 0 else np.nan\n",
    "\n",
    "        # E-value (unadjusted)\n",
    "        delta = mean_treat - mean_ctrl\n",
    "        E = delta / abs(mean_ctrl) * 100 if mean_ctrl != 0 else np.nan\n",
    "\n",
    "        # Unadjusted p-value\n",
    "        try:\n",
    "            t_stat, p_val = ttest_ind(treated, control, equal_var=False, nan_policy=\"omit\")\n",
    "            rounded_p = round(p_val, 5)\n",
    "            formatted_p = \"< 0.00001\" if rounded_p < 0.00001 else rounded_p\n",
    "        except Exception:\n",
    "            formatted_p = np.nan\n",
    "\n",
    "        # AUC from new auc_scores.xlsx file\n",
    "        auc_val = np.nan\n",
    "        auc_path = os.path.join(group_path, auc_file)\n",
    "        if os.path.exists(auc_path):\n",
    "            auc_df = pd.read_excel(auc_path)\n",
    "            if \"AUC\" in auc_df.columns:\n",
    "                auc_val = auc_df[\"AUC\"].dropna().mean()\n",
    "\n",
    "        # Adjusted stats from Rubin summary\n",
    "        att_row = att_df[att_df[\"group\"].str.strip().str.upper() == med.strip().upper()]\n",
    "        if not att_row.empty:\n",
    "            att = att_row.iloc[0][\"att\"]\n",
    "            att_se = att_row.iloc[0][\"se\"]\n",
    "            att_p_val = att_row.iloc[0][\"p_value\"]\n",
    "            r2 = att_row.iloc[0][\"r2\"]\n",
    "            rmse = att_row.iloc[0][\"rmse\"]\n",
    "\n",
    "            try:\n",
    "                rounded_att_p = round(float(att_p_val), 5)\n",
    "                formatted_att_p = \"< 0.00001\" if rounded_att_p < 0.00001 else rounded_att_p\n",
    "            except:\n",
    "                formatted_att_p = att_p_val\n",
    "        else:\n",
    "            att, att_se, formatted_att_p, r2, rmse = np.nan, np.nan, np.nan, np.nan, np.nan\n",
    "\n",
    "        # Append full row\n",
    "        summary_rows.append({\n",
    "            'Medication Group': med,\n",
    "            'Mean Treated': mean_treat,\n",
    "            'SE Treated': se_treat,\n",
    "            'Mean Control': mean_ctrl,\n",
    "            'SE Control': se_ctrl,\n",
    "            'Cohen d': cohen_d,\n",
    "            'E (Unadjusted)': E,\n",
    "            'n Treated': len(treated),\n",
    "            'n Control': len(control),\n",
    "            #'Unadjusted p-value': formatted_p,\n",
    "            'ATT Estimate': att,\n",
    "            'ATT SE (Robust)': att_se,\n",
    "            'ATT p-value': formatted_att_p,\n",
    "            'R²': r2,\n",
    "            'RMSE': rmse,\n",
    "            'AUC': auc_val\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error in {med}: {e}\")\n",
    "\n",
    "# ----------------------------------\n",
    "# Save final summary\n",
    "# ----------------------------------\n",
    "summary_df = pd.DataFrame(summary_rows)\n",
    "summary_df = summary_df.sort_values(\"Medication Group\")\n",
    "summary_df.to_excel(\"Final_ATT_Summary_Cat.xlsx\", index=False)\n",
    "print(\"✅ Final_ATT_Summary_Cat saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "2add3f46-01e8-4fac-b63c-cb913efd7755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ xgb_att_barplot_cat saved\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "# ✅ Load the final summary table\n",
    "final_df = pd.read_excel(\"Final_ATT_Summary_Cat.xlsx\")\n",
    "\n",
    "# ✅ Parse DML p-values (handle \"< 0.00001\")\n",
    "def parse_pval(p):\n",
    "    try:\n",
    "        if isinstance(p, str) and \"<\" in p:\n",
    "            return 0.000001\n",
    "        return float(p)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "final_df['ATT p-value'] = final_df['ATT p-value'].apply(parse_pval)\n",
    "\n",
    "# ✅ Plot settings\n",
    "width = 0.35\n",
    "\n",
    "# ✅ Plotting function for a single medication group\n",
    "def plot_single_group(row):\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    bars1 = ax.bar(-width/2, row['Mean Control'], width, \n",
    "                   yerr=row['SE Control'], label='Control', hatch='//', color='gray', capsize=5)\n",
    "    bars2 = ax.bar(+width/2, row['Mean Treated'], width, \n",
    "                   yerr=row['SE Treated'], label='Treated', color='steelblue', capsize=5)\n",
    "\n",
    "    label = (\n",
    "        f\"ATT = {row['ATT Estimate']:.2f}\\n\"\n",
    "        f\"d = {row['Cohen d']:.2f}, p = {row['ATT p-value']:.3f}\\n\"\n",
    "        f\"nT = {row['n Treated']}, nC = {row['n Control']}\\n\"\n",
    "        f\"E = {row['E (Unadjusted)']:.1f}%\"\n",
    "    )\n",
    "    max_y = max(row['Mean Control'], row['Mean Treated']) + 1.5\n",
    "    ax.text(0, max_y, label, ha='center', va='bottom', fontsize=9, color='#FFD700')\n",
    "\n",
    "    ax.axhline(0, color='black', linewidth=0.8)\n",
    "    ax.set_xticks([-width/2, +width/2])\n",
    "    ax.set_xticklabels(['Control', 'Treated'])\n",
    "    ax.set_title(f\"Group: {row['Medication Group']}\", fontsize=12, weight='bold')\n",
    "    ax.set_ylabel(\"CAPS5 Change Score\")\n",
    "    ax.set_ylim(bottom=0, top=max_y + 2)\n",
    "    ax.legend()\n",
    "    fig.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# ✅ Generate and save all plots into a multi-page PDF\n",
    "with PdfPages(\"xgb_att_barplot_cat.pdf\") as pdf:\n",
    "    for idx, row in final_df.iterrows():\n",
    "        fig = plot_single_group(row)\n",
    "        pdf.savefig(fig, dpi=300, bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "print(\"✅ xgb_att_barplot_cat saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "7c7dd2a6-210a-47e3-adc8-15a9d93cfd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Love plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "bd5ab6a2-6ea7-4e7c-bb94-cf40cd9c330d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Processing CAT_Aceetanilidederivaten...\n",
      "📊 Exported numeric summary to: outputs\\CAT_Aceetanilidederivaten\\covariate_balance_table_CAT_Aceetanilidederivaten.xlsx\n",
      "✅ Saved love plot: outputs\\CAT_Aceetanilidederivaten\\love_plot_CAT_Aceetanilidederivaten.pdf\n",
      "📏 Max weighted SMD for CAT_Aceetanilidederivaten: 0.478\n",
      "\n",
      "🔍 Processing CAT_Adhd...\n",
      "📊 Exported numeric summary to: outputs\\CAT_Adhd\\covariate_balance_table_CAT_Adhd.xlsx\n",
      "✅ Saved love plot: outputs\\CAT_Adhd\\love_plot_CAT_Adhd.pdf\n",
      "📏 Max weighted SMD for CAT_Adhd: 0.390\n",
      "\n",
      "🔍 Processing CAT_All...\n",
      "📊 Exported numeric summary to: outputs\\CAT_All\\covariate_balance_table_CAT_All.xlsx\n",
      "✅ Saved love plot: outputs\\CAT_All\\love_plot_CAT_All.pdf\n",
      "📏 Max weighted SMD for CAT_All: 0.235\n",
      "\n",
      "🔍 Processing CAT_All_Psychotropics...\n",
      "📊 Exported numeric summary to: outputs\\CAT_All_Psychotropics\\covariate_balance_table_CAT_All_Psychotropics.xlsx\n",
      "✅ Saved love plot: outputs\\CAT_All_Psychotropics\\love_plot_CAT_All_Psychotropics.pdf\n",
      "📏 Max weighted SMD for CAT_All_Psychotropics: 0.207\n",
      "\n",
      "🔍 Processing CAT_All_Psychotropics_Excl_Benzo...\n",
      "📊 Exported numeric summary to: outputs\\CAT_All_Psychotropics_Excl_Benzo\\covariate_balance_table_CAT_All_Psychotropics_Excl_Benzo.xlsx\n",
      "✅ Saved love plot: outputs\\CAT_All_Psychotropics_Excl_Benzo\\love_plot_CAT_All_Psychotropics_Excl_Benzo.pdf\n",
      "📏 Max weighted SMD for CAT_All_Psychotropics_Excl_Benzo: 0.194\n",
      "\n",
      "🔍 Processing CAT_All_Psychotropics_Excl_Sedatives_Hypnotics...\n",
      "📊 Exported numeric summary to: outputs\\CAT_All_Psychotropics_Excl_Sedatives_Hypnotics\\covariate_balance_table_CAT_All_Psychotropics_Excl_Sedatives_Hypnotics.xlsx\n",
      "✅ Saved love plot: outputs\\CAT_All_Psychotropics_Excl_Sedatives_Hypnotics\\love_plot_CAT_All_Psychotropics_Excl_Sedatives_Hypnotics.pdf\n",
      "📏 Max weighted SMD for CAT_All_Psychotropics_Excl_Sedatives_Hypnotics: 0.207\n",
      "\n",
      "🔍 Processing CAT_Antidepressiva...\n",
      "📊 Exported numeric summary to: outputs\\CAT_Antidepressiva\\covariate_balance_table_CAT_Antidepressiva.xlsx\n",
      "✅ Saved love plot: outputs\\CAT_Antidepressiva\\love_plot_CAT_Antidepressiva.pdf\n",
      "📏 Max weighted SMD for CAT_Antidepressiva: 0.131\n",
      "\n",
      "🔍 Processing CAT_Antihistaminica...\n",
      "📊 Exported numeric summary to: outputs\\CAT_Antihistaminica\\covariate_balance_table_CAT_Antihistaminica.xlsx\n",
      "✅ Saved love plot: outputs\\CAT_Antihistaminica\\love_plot_CAT_Antihistaminica.pdf\n",
      "📏 Max weighted SMD for CAT_Antihistaminica: 0.385\n",
      "\n",
      "🔍 Processing CAT_Antihypertensiva...\n",
      "📊 Exported numeric summary to: outputs\\CAT_Antihypertensiva\\covariate_balance_table_CAT_Antihypertensiva.xlsx\n",
      "✅ Saved love plot: outputs\\CAT_Antihypertensiva\\love_plot_CAT_Antihypertensiva.pdf\n",
      "📏 Max weighted SMD for CAT_Antihypertensiva: 0.325\n",
      "\n",
      "🔍 Processing CAT_Antipsychotica...\n",
      "📊 Exported numeric summary to: outputs\\CAT_Antipsychotica\\covariate_balance_table_CAT_Antipsychotica.xlsx\n",
      "✅ Saved love plot: outputs\\CAT_Antipsychotica\\love_plot_CAT_Antipsychotica.pdf\n",
      "📏 Max weighted SMD for CAT_Antipsychotica: 0.237\n",
      "\n",
      "🔍 Processing CAT_Anti_Epileptica...\n",
      "📊 Exported numeric summary to: outputs\\CAT_Anti_Epileptica\\covariate_balance_table_CAT_Anti_Epileptica.xlsx\n",
      "✅ Saved love plot: outputs\\CAT_Anti_Epileptica\\love_plot_CAT_Anti_Epileptica.pdf\n",
      "📏 Max weighted SMD for CAT_Anti_Epileptica: 0.382\n",
      "\n",
      "🔍 Processing CAT_Benzodiazepine...\n",
      "📊 Exported numeric summary to: outputs\\CAT_Benzodiazepine\\covariate_balance_table_CAT_Benzodiazepine.xlsx\n",
      "✅ Saved love plot: outputs\\CAT_Benzodiazepine\\love_plot_CAT_Benzodiazepine.pdf\n",
      "📏 Max weighted SMD for CAT_Benzodiazepine: 0.185\n",
      "\n",
      "🔍 Processing CAT_Nsaids...\n",
      "📊 Exported numeric summary to: outputs\\CAT_Nsaids\\covariate_balance_table_CAT_Nsaids.xlsx\n",
      "✅ Saved love plot: outputs\\CAT_Nsaids\\love_plot_CAT_Nsaids.pdf\n",
      "📏 Max weighted SMD for CAT_Nsaids: 0.351\n",
      "\n",
      "🔍 Processing CAT_Opioden...\n",
      "📊 Exported numeric summary to: outputs\\CAT_Opioden\\covariate_balance_table_CAT_Opioden.xlsx\n",
      "✅ Saved love plot: outputs\\CAT_Opioden\\love_plot_CAT_Opioden.pdf\n",
      "📏 Max weighted SMD for CAT_Opioden: 0.325\n",
      "\n",
      "🔍 Processing CAT_Z_Drugs...\n",
      "📊 Exported numeric summary to: outputs\\CAT_Z_Drugs\\covariate_balance_table_CAT_Z_Drugs.xlsx\n",
      "✅ Saved love plot: outputs\\CAT_Z_Drugs\\love_plot_CAT_Z_Drugs.pdf\n",
      "📏 Max weighted SMD for CAT_Z_Drugs: 0.376\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "# ----------------------------------------\n",
    "# Functions to calculate balance\n",
    "# ----------------------------------------\n",
    "def calculate_smd(x1, x2, w1=None, w2=None):\n",
    "    def weighted_mean(x, w): return np.average(x, weights=w)\n",
    "    def weighted_var(x, w):\n",
    "        m = np.average(x, weights=w)\n",
    "        return np.average((x - m) ** 2, weights=w)\n",
    "    \n",
    "    m1 = weighted_mean(x1, w1) if w1 is not None else np.mean(x1)\n",
    "    m2 = weighted_mean(x2, w2) if w2 is not None else np.mean(x2)\n",
    "    v1 = weighted_var(x1, w1) if w1 is not None else np.var(x1, ddof=1)\n",
    "    v2 = weighted_var(x2, w2) if w2 is not None else np.var(x2, ddof=1)\n",
    "    \n",
    "    pooled_sd = np.sqrt((v1 + v2) / 2)\n",
    "    return np.abs(m1 - m2) / pooled_sd if pooled_sd > 0 else 0\n",
    "\n",
    "def variance_ratio(x1, x2, w1=None, w2=None):\n",
    "    def weighted_var(x, w):\n",
    "        m = np.average(x, weights=w)\n",
    "        return np.average((x - m) ** 2, weights=w)\n",
    "    \n",
    "    v1 = weighted_var(x1, w1) if w1 is not None else np.var(x1, ddof=1)\n",
    "    v2 = weighted_var(x2, w2) if w2 is not None else np.var(x2, ddof=1)\n",
    "    \n",
    "    return max(v1 / v2, v2 / v1) if v1 > 0 and v2 > 0 else 1\n",
    "\n",
    "# ----------------------------------------\n",
    "# Setup\n",
    "# ----------------------------------------\n",
    "output_base = \"outputs\"\n",
    "groups = [g for g in os.listdir(output_base) if os.path.isdir(os.path.join(output_base, g))]\n",
    "\n",
    "# Create a case-insensitive mapping\n",
    "final_covariates_map_lower = {k.lower(): v for k, v in final_covariates_map.items()}\n",
    "\n",
    "# ----------------------------------------\n",
    "# Main Loop\n",
    "# ----------------------------------------\n",
    "for group in groups:\n",
    "    if group.lower() not in final_covariates_map_lower:\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n🔍 Processing {group}...\")\n",
    "\n",
    "    try:\n",
    "        group_path = os.path.join(output_base, group)\n",
    "        covariates = final_covariates_map_lower[group.lower()]\n",
    "        \n",
    "        column_name = None\n",
    "        for col in pd.read_pickle(os.path.join(group_path, \"trimmed_data_imp1.pkl\")).columns:\n",
    "            if col.lower() == group.lower():\n",
    "                column_name = col\n",
    "                break\n",
    "        if column_name is None:\n",
    "            print(f\"⚠️ Column not found for {group}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        smd_unw_all, smd_w_all = [], []\n",
    "        vr_unw_all, vr_w_all = [], []\n",
    "\n",
    "        for i in range(1, 6):\n",
    "            df_path = os.path.join(group_path, f\"trimmed_data_imp{i}.pkl\")\n",
    "            iptw_path = os.path.join(group_path, \"iptw_weights.xlsx\")\n",
    "\n",
    "            if not os.path.exists(df_path) or not os.path.exists(iptw_path):\n",
    "                print(f\"⚠️ Missing data for {group} imp{i}, skipping.\")\n",
    "                continue\n",
    "\n",
    "            df = pd.read_pickle(df_path)\n",
    "            iptw_df = pd.read_excel(iptw_path, index_col=0)\n",
    "            T = df[column_name]\n",
    "            W = iptw_df.loc[df.index, \"iptw_mean\"]\n",
    "\n",
    "            smd_unw_i, smd_w_i, vr_unw_i, vr_w_i = [], [], [], []\n",
    "\n",
    "            for cov in covariates:\n",
    "                x1, x0 = df.loc[T == 1, cov], df.loc[T == 0, cov]\n",
    "                w1, w0 = W[T == 1], W[T == 0]\n",
    "\n",
    "                su = calculate_smd(x1, x0)\n",
    "                sw = calculate_smd(x1, x0, w1, w0)\n",
    "\n",
    "                vu = variance_ratio(x1, x0) if cov in ['treatmentdurationdays', 'CAPS5score_baseline', 'age'] else np.nan\n",
    "                vw = variance_ratio(x1, x0, w1, w0) if cov in ['treatmentdurationdays', 'CAPS5score_baseline', 'age'] else np.nan\n",
    "\n",
    "                smd_unw_i.append(su)\n",
    "                smd_w_i.append(sw)\n",
    "                vr_unw_i.append(vu)\n",
    "                vr_w_i.append(vw)\n",
    "\n",
    "            smd_unw_all.append(smd_unw_i)\n",
    "            smd_w_all.append(smd_w_i)\n",
    "            vr_unw_all.append(vr_unw_i)\n",
    "            vr_w_all.append(vr_w_i)\n",
    "\n",
    "        smd_unw = np.mean(smd_unw_all, axis=0)\n",
    "        smd_w = np.mean(smd_w_all, axis=0)\n",
    "        vr_unw = np.nanmean(vr_unw_all, axis=0)\n",
    "        vr_w = np.nanmean(vr_w_all, axis=0)\n",
    "\n",
    "        severity = []\n",
    "        for sw in smd_w:\n",
    "            if sw <= 0.1:\n",
    "                severity.append(\"Good\")\n",
    "            elif sw <= 0.2:\n",
    "                severity.append(\"Moderate\")\n",
    "            else:\n",
    "                severity.append(\"Poor\")\n",
    "\n",
    "        covariate_names = covariates\n",
    "        numeric_df = pd.DataFrame({\n",
    "            \"Covariate\": covariate_names,\n",
    "            \"SMD_Unweighted\": smd_unw,\n",
    "            \"SMD_Weighted\": smd_w,\n",
    "            \"Imbalance_Severity\": severity,\n",
    "            \"VR_Unweighted\": vr_unw,\n",
    "            \"VR_Weighted\": vr_w\n",
    "        })\n",
    "\n",
    "        numeric_path = os.path.join(group_path, f\"covariate_balance_table_{group}.xlsx\")\n",
    "        numeric_df.to_excel(numeric_path, index=False)\n",
    "        print(f\"📊 Exported numeric summary to: {numeric_path}\")\n",
    "\n",
    "        # -------------------------\n",
    "        # Plot\n",
    "        # -------------------------\n",
    "        labels = covariates\n",
    "        y_pos = np.arange(len(labels))\n",
    "\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(18, len(labels) * 0.45))\n",
    "\n",
    "        axes[0].scatter(smd_unw, y_pos, color='red', label=\"Unweighted\")\n",
    "        axes[0].scatter(smd_w, y_pos, color='blue', label=\"Weighted\")\n",
    "        axes[0].axvline(0.1, color='gray', linestyle='--', label=\"Threshold 0.1\")\n",
    "        axes[0].axvline(0.2, color='black', linestyle='--', label=\"Threshold 0.2\")\n",
    "        axes[0].set_xlim(0, max(max(smd_unw), max(smd_w), 0.25) + 0.05)\n",
    "        axes[0].set_yticks(y_pos)\n",
    "        axes[0].set_yticklabels(labels)\n",
    "        axes[0].invert_yaxis()\n",
    "        axes[0].set_title(\"Standardized Mean Differences (SMD)\")\n",
    "        axes[0].legend(loc=\"upper right\")\n",
    "        axes[0].grid(True)\n",
    "\n",
    "        vr_mask = [cov in ['treatmentdurationdays', 'CAPS5score_baseline', 'age'] for cov in covariates]\n",
    "        filtered_y = [i for i, b in enumerate(vr_mask) if b]\n",
    "        filtered_labels = [labels[i] for i in filtered_y]\n",
    "        filtered_vr_unw = [vr_unw[i] for i in filtered_y]\n",
    "        filtered_vr_w = [vr_w[i] for i in filtered_y]\n",
    "\n",
    "        axes[1].scatter(filtered_vr_unw, filtered_y, color='blue', marker='o', label=\"Unweighted\")\n",
    "        axes[1].scatter(filtered_vr_w, filtered_y, color='red', marker='x', label=\"Weighted\")\n",
    "        axes[1].axvline(2, color='gray', linestyle='--')\n",
    "        axes[1].axvline(0.5, color='gray', linestyle='--')\n",
    "        axes[1].set_xlim(0, max(filtered_vr_unw + filtered_vr_w + [2.5]) + 0.5)\n",
    "        axes[1].set_yticks(filtered_y)\n",
    "        axes[1].set_yticklabels(filtered_labels)\n",
    "        axes[1].invert_yaxis()\n",
    "        axes[1].set_title(\"Variance Ratio (VR)\")\n",
    "        axes[1].legend()\n",
    "        axes[1].grid(True)\n",
    "\n",
    "        fig.suptitle(f\"Covariate Balance for {group.replace('CAT_', '')}\", fontsize=14, weight='bold')\n",
    "        fig.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "        plot_path = os.path.join(group_path, f\"love_plot_{group}.pdf\")\n",
    "        fig.savefig(plot_path, dpi=300)\n",
    "        plt.close()\n",
    "        print(f\"✅ Saved love plot: {plot_path}\")\n",
    "        print(f\"📏 Max weighted SMD for {group}: {np.max(smd_w):.3f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error in {group}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "1cedeed7-7c10-422b-b58e-81e03e632ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "99056fbb-3bd6-44b0-beed-753f79181a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Creating Heatmap for CAT_ADHD ==========\n",
      "✅ Heatmap saved: outputs\\CAT_ADHD\\heatmap_smd_CAT_ADHD.png\n",
      "\n",
      "========== Creating Heatmap for CAT_Aceetanilidederivaten ==========\n",
      "✅ Heatmap saved: outputs\\CAT_Aceetanilidederivaten\\heatmap_smd_CAT_Aceetanilidederivaten.png\n",
      "\n",
      "========== Creating Heatmap for CAT_Z_drugs ==========\n",
      "✅ Heatmap saved: outputs\\CAT_Z_drugs\\heatmap_smd_CAT_Z_drugs.png\n",
      "\n",
      "========== Creating Heatmap for CAT_Opioden ==========\n",
      "✅ Heatmap saved: outputs\\CAT_Opioden\\heatmap_smd_CAT_Opioden.png\n",
      "\n",
      "========== Creating Heatmap for CAT_NSAIDs ==========\n",
      "✅ Heatmap saved: outputs\\CAT_NSAIDs\\heatmap_smd_CAT_NSAIDs.png\n",
      "\n",
      "========== Creating Heatmap for CAT_Benzodiazepine ==========\n",
      "✅ Heatmap saved: outputs\\CAT_Benzodiazepine\\heatmap_smd_CAT_Benzodiazepine.png\n",
      "\n",
      "========== Creating Heatmap for CAT_Antihypertensiva ==========\n",
      "✅ Heatmap saved: outputs\\CAT_Antihypertensiva\\heatmap_smd_CAT_Antihypertensiva.png\n",
      "\n",
      "========== Creating Heatmap for CAT_Antihistaminica ==========\n",
      "✅ Heatmap saved: outputs\\CAT_Antihistaminica\\heatmap_smd_CAT_Antihistaminica.png\n",
      "\n",
      "========== Creating Heatmap for CAT_Anti_epileptica ==========\n",
      "✅ Heatmap saved: outputs\\CAT_Anti_epileptica\\heatmap_smd_CAT_Anti_epileptica.png\n",
      "\n",
      "========== Creating Heatmap for CAT_Antidepressiva ==========\n",
      "✅ Heatmap saved: outputs\\CAT_Antidepressiva\\heatmap_smd_CAT_Antidepressiva.png\n",
      "\n",
      "========== Creating Heatmap for CAT_Antipsychotica ==========\n",
      "✅ Heatmap saved: outputs\\CAT_Antipsychotica\\heatmap_smd_CAT_Antipsychotica.png\n",
      "\n",
      "========== Creating Heatmap for CAT_ALL_PSYCHOTROPICS_EXCL_BENZO ==========\n",
      "✅ Heatmap saved: outputs\\CAT_ALL_PSYCHOTROPICS_EXCL_BENZO\\heatmap_smd_CAT_ALL_PSYCHOTROPICS_EXCL_BENZO.png\n",
      "\n",
      "========== Creating Heatmap for CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS ==========\n",
      "✅ Heatmap saved: outputs\\CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS\\heatmap_smd_CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS.png\n",
      "\n",
      "========== Creating Heatmap for CAT_ALL_PSYCHOTROPICS ==========\n",
      "✅ Heatmap saved: outputs\\CAT_ALL_PSYCHOTROPICS\\heatmap_smd_CAT_ALL_PSYCHOTROPICS.png\n",
      "\n",
      "========== Creating Heatmap for CAT_ALL ==========\n",
      "✅ Heatmap saved: outputs\\CAT_ALL\\heatmap_smd_CAT_ALL.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "#-----------------------------\n",
    "# Generate heatmaps\n",
    "# -------------------------------\n",
    "for treatment_var in medication_groups:\n",
    "    print(f\"\\n========== Creating Heatmap for {treatment_var} ==========\")\n",
    "\n",
    "    try:\n",
    "        output_folder = os.path.join('outputs', treatment_var)\n",
    "        balance_path = os.path.join(output_folder, f'covariate_balance_table_{treatment_var}.xlsx')\n",
    "\n",
    "        if not os.path.exists(balance_path):\n",
    "            print(f\"❌ Balance file not found: {balance_path}\")\n",
    "            continue\n",
    "\n",
    "        balance_df = pd.read_excel(balance_path)\n",
    "\n",
    "        # ✅ Use finalized covariates + 'Propensity Score'\n",
    "        covariates = final_covariates_map[treatment_var] + ['Propensity Score']\n",
    "        balance_df = balance_df[balance_df['Covariate'].isin(covariates)]\n",
    "\n",
    "        # ✅ Check for CAPS5score_baseline\n",
    "        highlight_caps = 'CAPS5score_baseline' in balance_df['Covariate'].values\n",
    "\n",
    "        # ✅ Format for heatmap\n",
    "        heatmap_df = balance_df[['Covariate', 'SMD_Unweighted', 'SMD_Weighted']].copy()\n",
    "        heatmap_df.columns = ['Covariate', 'Unweighted', 'Weighted']\n",
    "        heatmap_df = heatmap_df.set_index('Covariate')\n",
    "        heatmap_df = heatmap_df.sort_values(by='Unweighted', ascending=False)\n",
    "\n",
    "        # ✅ Plot\n",
    "        plt.figure(figsize=(12, max(10, len(heatmap_df) * 0.35)))\n",
    "        ax = sns.heatmap(\n",
    "            heatmap_df,\n",
    "            cmap=\"coolwarm\",\n",
    "            annot=True,\n",
    "            fmt=\".2f\",\n",
    "            linewidths=0.6,\n",
    "            linecolor='gray',\n",
    "            cbar_kws={\"label\": \"Standardized Mean Difference\"}\n",
    "        )\n",
    "\n",
    "        plt.title(f\"Covariate Balance Heatmap (Rubin IPTW)\\n{treatment_var}\", fontsize=15, weight='bold')\n",
    "        plt.xlabel(\"Condition\")\n",
    "        plt.ylabel(\"Covariate\")\n",
    "\n",
    "        # ✅ Bold CAPS5score_baseline if present\n",
    "        if highlight_caps:\n",
    "            ylabels = [label.get_text() for label in ax.get_yticklabels()]\n",
    "            ax.set_yticklabels([\n",
    "                f\"{label} ←\" if label == 'CAPS5score_baseline' else label for label in ylabels\n",
    "            ])\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # ✅ Save image\n",
    "        save_path = os.path.join(output_folder, f'heatmap_smd_{treatment_var}.png')\n",
    "        plt.savefig(save_path, dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "        print(f\"✅ Heatmap saved: {save_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error processing {treatment_var}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ecb610-b6bb-4639-9b1b-ff658d37153c",
   "metadata": {},
   "source": [
    "## Subcat analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "71e55b3a-f46c-4df7-bc09-7d346c53e2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "covariates_SUBCAT_Antipsychotica_atypisch = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antidepressiva', 'CAT_Antipsychotica',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "covariates_SUBCAT_TCA = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antipsychotica',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "covariates_SUBCAT_SSRI = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antipsychotica',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "covariates_SUBCAT_SNRI = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antipsychotica',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "\n",
    "covariates_SUBCAT_Tetracyclische_antidepressiva = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antipsychotica',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "covariates_SUBCAT_Antidepressiva_overige = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antipsychotica',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "covariates_SUBCAT_Systemische_antihistaminica = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antidepressiva', 'CAT_Antipsychotica',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "\n",
    "covariates_SUBCAT_anxiolytica_Benzodiazepine = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antidepressiva',\n",
    "    'CAT_Antipsychotica',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "covariates_SUBCAT_hypnotica_Benzodiazepine = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antidepressiva',\n",
    "    'CAT_Antipsychotica',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "\n",
    "covariates_SUBCAT_Amfetaminen = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline', 'CAT_Antidepressiva', 'CAT_Antipsychotica',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD',\n",
    "    'DIAGNOSIS_SEXUAL_TRAUMA', 'DIAGNOSIS_SUICIDALITY',\n",
    "    'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "\n",
    "covariates_SUBCAT_Paracetamol_mono = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antidepressiva', 'CAT_Antipsychotica',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "\n",
    "covariates_SUBCAT_Anti_epileptica_stemmingsstabilisatoren = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antidepressiva',\n",
    "    'CAT_Antipsychotica',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age', \n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "covariates_SUBCAT_Opioden = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antidepressiva',\n",
    "    'CAT_Antipsychotica',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "covariates_SUBCAT_Z_drugs = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antidepressiva', 'CAT_Antipsychotica',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "covariates_SUBCAT_NSAIDs = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antidepressiva',\n",
    "    'CAT_Antipsychotica',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "9a3ef609-2a60-4e10-8983-dadb6790f337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groups found: ['SUBCAT_Antipsychotica_atypisch', 'SUBCAT_TCA', 'SUBCAT_SSRI', 'SUBCAT_SNRI', 'SUBCAT_Tetracyclische_antidepressiva', 'SUBCAT_Antidepressiva_overige', 'SUBCAT_Systemische_antihistaminica', 'SUBCAT_anxiolytica_Benzodiazepine', 'SUBCAT_hypnotica_Benzodiazepine', 'SUBCAT_Amfetaminen', 'SUBCAT_Paracetamol_mono', 'SUBCAT_Anti_epileptica_stemmingsstabilisatoren', 'SUBCAT_Opioden', 'SUBCAT_Z_drugs', 'SUBCAT_NSAIDs']\n",
      "['SUBCAT_Antipsychotica_atypisch', 'SUBCAT_TCA', 'SUBCAT_SSRI', 'SUBCAT_SNRI', 'SUBCAT_Tetracyclische_antidepressiva', 'SUBCAT_Antidepressiva_overige', 'SUBCAT_Systemische_antihistaminica', 'SUBCAT_anxiolytica_Benzodiazepine', 'SUBCAT_hypnotica_Benzodiazepine', 'SUBCAT_Amfetaminen', 'SUBCAT_Paracetamol_mono', 'SUBCAT_Anti_epileptica_stemmingsstabilisatoren', 'SUBCAT_Opioden', 'SUBCAT_Z_drugs', 'SUBCAT_NSAIDs']\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# This finds all variables that start with covariates_SUBCAT_\n",
    "final_covariates_map = defaultdict(list)\n",
    "final_covariates_map.update({\n",
    "    var.replace(\"covariates_\", \"\"): val\n",
    "    for var, val in globals().items()\n",
    "    if var.lower().startswith(\"covariates_subcat_\") and isinstance(val, list)\n",
    "})\n",
    "\n",
    "# Show detected group names\n",
    "print(\"Groups found:\", list(final_covariates_map.keys()))\n",
    "medication_groups = list(final_covariates_map.keys())\n",
    "print(medication_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "e8784a01-10be-41b1-aa30-a516788adbaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Starting analysis for all SUBCAT groups\n",
      "\n",
      " Processing SUBCAT_Antipsychotica_Atypisch...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBCAT_Antipsychotica_Atypisch\n",
      "\n",
      " Processing SUBCAT_Tca...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBCAT_Tca\n",
      "\n",
      " Processing SUBCAT_Ssri...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBCAT_Ssri\n",
      "\n",
      " Processing SUBCAT_Snri...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBCAT_Snri\n",
      "\n",
      " Processing SUBCAT_Tetracyclische_Antidepressiva...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBCAT_Tetracyclische_Antidepressiva\n",
      "\n",
      " Processing SUBCAT_Antidepressiva_Overige...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBCAT_Antidepressiva_Overige\n",
      "\n",
      " Processing SUBCAT_Systemische_Antihistaminica...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBCAT_Systemische_Antihistaminica\n",
      "\n",
      " Processing SUBCAT_Anxiolytica_Benzodiazepine...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBCAT_Anxiolytica_Benzodiazepine\n",
      "\n",
      " Processing SUBCAT_Hypnotica_Benzodiazepine...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBCAT_Hypnotica_Benzodiazepine\n",
      "\n",
      " Processing SUBCAT_Amfetaminen...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBCAT_Amfetaminen\n",
      "\n",
      " Processing SUBCAT_Paracetamol_Mono...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBCAT_Paracetamol_Mono\n",
      "\n",
      " Processing SUBCAT_Anti_Epileptica_Stemmingsstabilisatoren...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBCAT_Anti_Epileptica_Stemmingsstabilisatoren\n",
      "\n",
      " Processing SUBCAT_Opioden...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBCAT_Opioden\n",
      "\n",
      " Processing SUBCAT_Z_Drugs...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBCAT_Z_Drugs\n",
      "\n",
      " Processing SUBCAT_Nsaids...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBCAT_Nsaids\n",
      "\n",
      " All SUBCAT group analyses complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def run_all_SUBCAT_group_models(imputed_dfs):\n",
    "    \"\"\"\n",
    "    Runs downstream analysis for each SUBCAT medisubcation group using imputed datasets.\n",
    "\n",
    "    Parameters:\n",
    "    - imputed_dfs: list of 5 imputed DataFrames (from df_imputed_final_imp1.pkl ... imp5.pkl)\n",
    "    \n",
    "    Notes:\n",
    "    - Covariate lists must be defined as global variables: covariates_subcat_<group>\n",
    "    - Outputs are saved in: outputs/SUBCAT_<GROUP>/\n",
    "    \"\"\"\n",
    "\n",
    "    print(\" Starting analysis for all SUBCAT groups\")\n",
    "\n",
    "    for var_name in globals():\n",
    "        if var_name.lower().startswith(\"covariates_subcat_\") and isinstance(globals()[var_name], list):\n",
    "            group_name = var_name.replace(\"covariates_\", \"\")\n",
    "            group_name = group_name.replace(\"_\", \" \").title().replace(\" \", \"_\")  # e.g., subcat_z_drugs → Subcat_Z_Drugs\n",
    "            group_name = group_name.replace(\"Subcat_\", \"SUBCAT_\")  # force prefix to uppercase\n",
    "\n",
    "            covariates = globals()[var_name]\n",
    "            output_dir = f\"outputs/{group_name}\"\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "            print(f\"\\n Processing {group_name}...\")\n",
    "\n",
    "            for k, df_imp in enumerate(imputed_dfs):\n",
    "                print(f\"  → Using imputation {k+1}\")\n",
    "\n",
    "                # Define X and Y\n",
    "                X = df_imp[covariates]\n",
    "                Y = df_imp[\"caps5_change_baseline\"]\n",
    "\n",
    "                # === Save X and Y as placeholder (replace with modeling later)\n",
    "                X.to_csv(f\"{output_dir}/X_imp{k+1}.csv\", index=False)\n",
    "                Y.to_frame(name=\"Y\").to_csv(f\"{output_dir}/Y_imp{k+1}.csv\", index=False)\n",
    "\n",
    "            print(f\" Done: {group_name}\")\n",
    "\n",
    "    print(\"\\n All SUBCAT group analyses complete.\")\n",
    "\n",
    "# ========= STEP 4: Execute ========= #\n",
    "run_all_SUBCAT_group_models(imputed_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "e6669c45-1195-4268-9001-4ddc425cc580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " SUBCAT_Antipsychotica_atypisch\n",
      "  Imp 1: Treated = 256, Control = 3385, Missing = 0\n",
      "  Imp 2: Treated = 256, Control = 3385, Missing = 0\n",
      "  Imp 3: Treated = 256, Control = 3385, Missing = 0\n",
      "  Imp 4: Treated = 256, Control = 3385, Missing = 0\n",
      "  Imp 5: Treated = 256, Control = 3385, Missing = 0\n",
      "\n",
      " SUBCAT_TCA\n",
      "  Imp 1: Treated = 86, Control = 3555, Missing = 0\n",
      "  Imp 2: Treated = 86, Control = 3555, Missing = 0\n",
      "  Imp 3: Treated = 86, Control = 3555, Missing = 0\n",
      "  Imp 4: Treated = 86, Control = 3555, Missing = 0\n",
      "  Imp 5: Treated = 86, Control = 3555, Missing = 0\n",
      "\n",
      " SUBCAT_SSRI\n",
      "  Imp 1: Treated = 396, Control = 3245, Missing = 0\n",
      "  Imp 2: Treated = 396, Control = 3245, Missing = 0\n",
      "  Imp 3: Treated = 396, Control = 3245, Missing = 0\n",
      "  Imp 4: Treated = 396, Control = 3245, Missing = 0\n",
      "  Imp 5: Treated = 396, Control = 3245, Missing = 0\n",
      "\n",
      " SUBCAT_SNRI\n",
      "  Imp 1: Treated = 82, Control = 3559, Missing = 0\n",
      "  Imp 2: Treated = 82, Control = 3559, Missing = 0\n",
      "  Imp 3: Treated = 82, Control = 3559, Missing = 0\n",
      "  Imp 4: Treated = 82, Control = 3559, Missing = 0\n",
      "  Imp 5: Treated = 82, Control = 3559, Missing = 0\n",
      "\n",
      " SUBCAT_Tetracyclische_antidepressiva\n",
      "  Imp 1: Treated = 87, Control = 3554, Missing = 0\n",
      "  Imp 2: Treated = 87, Control = 3554, Missing = 0\n",
      "  Imp 3: Treated = 87, Control = 3554, Missing = 0\n",
      "  Imp 4: Treated = 87, Control = 3554, Missing = 0\n",
      "  Imp 5: Treated = 87, Control = 3554, Missing = 0\n",
      "\n",
      " SUBCAT_Antidepressiva_overige\n",
      "  Imp 1: Treated = 42, Control = 3599, Missing = 0\n",
      "  Imp 2: Treated = 42, Control = 3599, Missing = 0\n",
      "  Imp 3: Treated = 42, Control = 3599, Missing = 0\n",
      "  Imp 4: Treated = 42, Control = 3599, Missing = 0\n",
      "  Imp 5: Treated = 42, Control = 3599, Missing = 0\n",
      "\n",
      " SUBCAT_Systemische_antihistaminica\n",
      "  Imp 1: Treated = 56, Control = 3585, Missing = 0\n",
      "  Imp 2: Treated = 56, Control = 3585, Missing = 0\n",
      "  Imp 3: Treated = 56, Control = 3585, Missing = 0\n",
      "  Imp 4: Treated = 56, Control = 3585, Missing = 0\n",
      "  Imp 5: Treated = 56, Control = 3585, Missing = 0\n",
      "\n",
      " SUBCAT_anxiolytica_Benzodiazepine\n",
      "  Imp 1: Treated = 311, Control = 3330, Missing = 0\n",
      "  Imp 2: Treated = 311, Control = 3330, Missing = 0\n",
      "  Imp 3: Treated = 311, Control = 3330, Missing = 0\n",
      "  Imp 4: Treated = 311, Control = 3330, Missing = 0\n",
      "  Imp 5: Treated = 311, Control = 3330, Missing = 0\n",
      "\n",
      " SUBCAT_hypnotica_Benzodiazepine\n",
      "  Imp 1: Treated = 132, Control = 3509, Missing = 0\n",
      "  Imp 2: Treated = 132, Control = 3509, Missing = 0\n",
      "  Imp 3: Treated = 132, Control = 3509, Missing = 0\n",
      "  Imp 4: Treated = 132, Control = 3509, Missing = 0\n",
      "  Imp 5: Treated = 132, Control = 3509, Missing = 0\n",
      "\n",
      " SUBCAT_Amfetaminen\n",
      "  Imp 1: Treated = 52, Control = 3589, Missing = 0\n",
      "  Imp 2: Treated = 52, Control = 3589, Missing = 0\n",
      "  Imp 3: Treated = 52, Control = 3589, Missing = 0\n",
      "  Imp 4: Treated = 52, Control = 3589, Missing = 0\n",
      "  Imp 5: Treated = 52, Control = 3589, Missing = 0\n",
      "\n",
      " SUBCAT_Paracetamol_mono\n",
      "  Imp 1: Treated = 43, Control = 3598, Missing = 0\n",
      "  Imp 2: Treated = 43, Control = 3598, Missing = 0\n",
      "  Imp 3: Treated = 43, Control = 3598, Missing = 0\n",
      "  Imp 4: Treated = 43, Control = 3598, Missing = 0\n",
      "  Imp 5: Treated = 43, Control = 3598, Missing = 0\n",
      "\n",
      " SUBCAT_Anti_epileptica_stemmingsstabilisatoren\n",
      "  Imp 1: Treated = 57, Control = 3584, Missing = 0\n",
      "  Imp 2: Treated = 57, Control = 3584, Missing = 0\n",
      "  Imp 3: Treated = 57, Control = 3584, Missing = 0\n",
      "  Imp 4: Treated = 57, Control = 3584, Missing = 0\n",
      "  Imp 5: Treated = 57, Control = 3584, Missing = 0\n",
      "\n",
      " SUBCAT_Opioden\n",
      "  Imp 1: Treated = 54, Control = 3587, Missing = 0\n",
      "  Imp 2: Treated = 54, Control = 3587, Missing = 0\n",
      "  Imp 3: Treated = 54, Control = 3587, Missing = 0\n",
      "  Imp 4: Treated = 54, Control = 3587, Missing = 0\n",
      "  Imp 5: Treated = 54, Control = 3587, Missing = 0\n",
      "\n",
      " SUBCAT_Z_drugs\n",
      "  Imp 1: Treated = 57, Control = 3584, Missing = 0\n",
      "  Imp 2: Treated = 57, Control = 3584, Missing = 0\n",
      "  Imp 3: Treated = 57, Control = 3584, Missing = 0\n",
      "  Imp 4: Treated = 57, Control = 3584, Missing = 0\n",
      "  Imp 5: Treated = 57, Control = 3584, Missing = 0\n",
      "\n",
      " SUBCAT_NSAIDs\n",
      "  Imp 1: Treated = 37, Control = 3604, Missing = 0\n",
      "  Imp 2: Treated = 37, Control = 3604, Missing = 0\n",
      "  Imp 3: Treated = 37, Control = 3604, Missing = 0\n",
      "  Imp 4: Treated = 37, Control = 3604, Missing = 0\n",
      "  Imp 5: Treated = 37, Control = 3604, Missing = 0\n"
     ]
    }
   ],
   "source": [
    "for treatment_var in medication_groups:\n",
    "    print(f\"\\n {treatment_var}\")\n",
    "    \n",
    "    for i, df in enumerate(imputed_dfs):\n",
    "        if treatment_var not in df.columns:\n",
    "            print(f\"  Imp {i+1}:  Not found in columns.\")\n",
    "            continue\n",
    "\n",
    "        treated = (df[treatment_var] == 1).sum()\n",
    "        control = (df[treatment_var] == 0).sum()\n",
    "        missing = df[treatment_var].isna().sum()\n",
    "\n",
    "        print(f\"  Imp {i+1}: Treated = {treated}, Control = {control}, Missing = {missing}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "62728b25-f7b4-4303-b783-3813f0bc25f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Processing VIF for SUBCAT_Antipsychotica_atypisch\n",
      " ✅ Saved: outputs\\SUBCAT_Antipsychotica_atypisch/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SUBCAT_TCA\n",
      " ✅ Saved: outputs\\SUBCAT_TCA/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SUBCAT_SSRI\n",
      " ✅ Saved: outputs\\SUBCAT_SSRI/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SUBCAT_SNRI\n",
      " ✅ Saved: outputs\\SUBCAT_SNRI/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SUBCAT_Tetracyclische_antidepressiva\n",
      " ✅ Saved: outputs\\SUBCAT_Tetracyclische_antidepressiva/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SUBCAT_Antidepressiva_overige\n",
      " ✅ Saved: outputs\\SUBCAT_Antidepressiva_overige/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SUBCAT_Systemische_antihistaminica\n",
      " ✅ Saved: outputs\\SUBCAT_Systemische_antihistaminica/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SUBCAT_anxiolytica_Benzodiazepine\n",
      " ✅ Saved: outputs\\SUBCAT_anxiolytica_Benzodiazepine/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SUBCAT_hypnotica_Benzodiazepine\n",
      " ✅ Saved: outputs\\SUBCAT_hypnotica_Benzodiazepine/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SUBCAT_Amfetaminen\n",
      " ✅ Saved: outputs\\SUBCAT_Amfetaminen/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SUBCAT_Paracetamol_mono\n",
      " ✅ Saved: outputs\\SUBCAT_Paracetamol_mono/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SUBCAT_Anti_epileptica_stemmingsstabilisatoren\n",
      " ✅ Saved: outputs\\SUBCAT_Anti_epileptica_stemmingsstabilisatoren/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SUBCAT_Opioden\n",
      " ✅ Saved: outputs\\SUBCAT_Opioden/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SUBCAT_Z_drugs\n",
      " ✅ Saved: outputs\\SUBCAT_Z_drugs/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SUBCAT_NSAIDs\n",
      " ✅ Saved: outputs\\SUBCAT_NSAIDs/pooled_vif.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from collections import defaultdict\n",
    "\n",
    "# ✅ VIF computation function\n",
    "def compute_vif(X):\n",
    "    X = sm.add_constant(X, has_constant='add')\n",
    "    vif_df = pd.DataFrame()\n",
    "    vif_df[\"variable\"] = X.columns\n",
    "    vif_df[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "    return vif_df\n",
    "\n",
    "# ✅ Process each group\n",
    "for group in medication_groups:\n",
    "    print(f\"\\n🔍 Processing VIF for {group}\")\n",
    "\n",
    "    if group not in final_covariates_map:\n",
    "        print(f\" ⚠️ No covariates found for {group}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    covariates = final_covariates_map[group]\n",
    "    vif_list = []\n",
    "\n",
    "    for i, df_imp in enumerate(imputed_dfs):\n",
    "        try:\n",
    "            X = df_imp[covariates].copy()\n",
    "            vif_df = compute_vif(X)\n",
    "            vif_df[\"imputation\"] = i + 1\n",
    "            vif_list.append(vif_df)\n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ Failed on imputation {i+1} for {group}: {e}\")\n",
    "\n",
    "    if vif_list:\n",
    "        all_vif = pd.concat(vif_list)\n",
    "        pooled_vif = all_vif.groupby(\"variable\")[\"VIF\"].mean().reset_index()\n",
    "        pooled_vif = pooled_vif.sort_values(by=\"VIF\", ascending=False)\n",
    "\n",
    "        output_folder = os.path.join(\"outputs\", group)\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        pooled_vif.to_csv(os.path.join(output_folder, \"pooled_vif.csv\"), index=False)\n",
    "\n",
    "        print(f\" ✅ Saved: {output_folder}/pooled_vif.csv\")\n",
    "    else:\n",
    "        print(f\" ⚠️ Skipped {group}: No valid imputations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "00a3aec7-90b0-4160-b2eb-4e97e633bfb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Running PS estimation for SUBCAT_Antipsychotica_atypisch\n",
      "   Imp 1: AUC = 0.998, ROC saved.\n",
      "   Imp 2: AUC = 0.998, ROC saved.\n",
      "   Imp 3: AUC = 0.998, ROC saved.\n",
      "   Imp 4: AUC = 0.998, ROC saved.\n",
      "   Imp 5: AUC = 0.998, ROC saved.\n",
      " Composite PS + AUC saved for SUBCAT_Antipsychotica_atypisch\n",
      " Running PS estimation for SUBCAT_TCA\n",
      "   Imp 1: AUC = 0.575, ROC saved.\n",
      "   Imp 2: AUC = 0.579, ROC saved.\n",
      "   Imp 3: AUC = 0.579, ROC saved.\n",
      "   Imp 4: AUC = 0.608, ROC saved.\n",
      "   Imp 5: AUC = 0.571, ROC saved.\n",
      " Composite PS + AUC saved for SUBCAT_TCA\n",
      " Running PS estimation for SUBCAT_SSRI\n",
      "   Imp 1: AUC = 0.641, ROC saved.\n",
      "   Imp 2: AUC = 0.658, ROC saved.\n",
      "   Imp 3: AUC = 0.644, ROC saved.\n",
      "   Imp 4: AUC = 0.631, ROC saved.\n",
      "   Imp 5: AUC = 0.653, ROC saved.\n",
      " Composite PS + AUC saved for SUBCAT_SSRI\n",
      " Running PS estimation for SUBCAT_SNRI\n",
      "   Imp 1: AUC = 0.689, ROC saved.\n",
      "   Imp 2: AUC = 0.638, ROC saved.\n",
      "   Imp 3: AUC = 0.640, ROC saved.\n",
      "   Imp 4: AUC = 0.655, ROC saved.\n",
      "   Imp 5: AUC = 0.641, ROC saved.\n",
      " Composite PS + AUC saved for SUBCAT_SNRI\n",
      " Running PS estimation for SUBCAT_Tetracyclische_antidepressiva\n",
      "   Imp 1: AUC = 0.581, ROC saved.\n",
      "   Imp 2: AUC = 0.538, ROC saved.\n",
      "   Imp 3: AUC = 0.569, ROC saved.\n",
      "   Imp 4: AUC = 0.577, ROC saved.\n",
      "   Imp 5: AUC = 0.623, ROC saved.\n",
      " Composite PS + AUC saved for SUBCAT_Tetracyclische_antidepressiva\n",
      " Running PS estimation for SUBCAT_Antidepressiva_overige\n",
      "   Imp 1: AUC = 0.439, ROC saved.\n",
      "   Imp 2: AUC = 0.438, ROC saved.\n",
      "   Imp 3: AUC = 0.503, ROC saved.\n",
      "   Imp 4: AUC = 0.523, ROC saved.\n",
      "   Imp 5: AUC = 0.487, ROC saved.\n",
      " Composite PS + AUC saved for SUBCAT_Antidepressiva_overige\n",
      " Running PS estimation for SUBCAT_Systemische_antihistaminica\n",
      "   Imp 1: AUC = 0.637, ROC saved.\n",
      "   Imp 2: AUC = 0.646, ROC saved.\n",
      "   Imp 3: AUC = 0.614, ROC saved.\n",
      "   Imp 4: AUC = 0.639, ROC saved.\n",
      "   Imp 5: AUC = 0.647, ROC saved.\n",
      " Composite PS + AUC saved for SUBCAT_Systemische_antihistaminica\n",
      " Running PS estimation for SUBCAT_anxiolytica_Benzodiazepine\n",
      "   Imp 1: AUC = 0.708, ROC saved.\n",
      "   Imp 2: AUC = 0.708, ROC saved.\n",
      "   Imp 3: AUC = 0.708, ROC saved.\n",
      "   Imp 4: AUC = 0.705, ROC saved.\n",
      "   Imp 5: AUC = 0.703, ROC saved.\n",
      " Composite PS + AUC saved for SUBCAT_anxiolytica_Benzodiazepine\n",
      " Running PS estimation for SUBCAT_hypnotica_Benzodiazepine\n",
      "   Imp 1: AUC = 0.603, ROC saved.\n",
      "   Imp 2: AUC = 0.577, ROC saved.\n",
      "   Imp 3: AUC = 0.604, ROC saved.\n",
      "   Imp 4: AUC = 0.583, ROC saved.\n",
      "   Imp 5: AUC = 0.634, ROC saved.\n",
      " Composite PS + AUC saved for SUBCAT_hypnotica_Benzodiazepine\n",
      " Running PS estimation for SUBCAT_Amfetaminen\n",
      "   Imp 1: AUC = 0.530, ROC saved.\n",
      "   Imp 2: AUC = 0.554, ROC saved.\n",
      "   Imp 3: AUC = 0.556, ROC saved.\n",
      "   Imp 4: AUC = 0.562, ROC saved.\n",
      "   Imp 5: AUC = 0.488, ROC saved.\n",
      " Composite PS + AUC saved for SUBCAT_Amfetaminen\n",
      " Running PS estimation for SUBCAT_Paracetamol_mono\n",
      "   Imp 1: AUC = 0.599, ROC saved.\n",
      "   Imp 2: AUC = 0.609, ROC saved.\n",
      "   Imp 3: AUC = 0.625, ROC saved.\n",
      "   Imp 4: AUC = 0.658, ROC saved.\n",
      "   Imp 5: AUC = 0.664, ROC saved.\n",
      " Composite PS + AUC saved for SUBCAT_Paracetamol_mono\n",
      " Running PS estimation for SUBCAT_Anti_epileptica_stemmingsstabilisatoren\n",
      "   Imp 1: AUC = 0.687, ROC saved.\n",
      "   Imp 2: AUC = 0.683, ROC saved.\n",
      "   Imp 3: AUC = 0.697, ROC saved.\n",
      "   Imp 4: AUC = 0.686, ROC saved.\n",
      "   Imp 5: AUC = 0.688, ROC saved.\n",
      " Composite PS + AUC saved for SUBCAT_Anti_epileptica_stemmingsstabilisatoren\n",
      " Running PS estimation for SUBCAT_Opioden\n",
      "   Imp 1: AUC = 0.660, ROC saved.\n",
      "   Imp 2: AUC = 0.676, ROC saved.\n",
      "   Imp 3: AUC = 0.694, ROC saved.\n",
      "   Imp 4: AUC = 0.665, ROC saved.\n",
      "   Imp 5: AUC = 0.635, ROC saved.\n",
      " Composite PS + AUC saved for SUBCAT_Opioden\n",
      " Running PS estimation for SUBCAT_Z_drugs\n",
      "   Imp 1: AUC = 0.599, ROC saved.\n",
      "   Imp 2: AUC = 0.651, ROC saved.\n",
      "   Imp 3: AUC = 0.591, ROC saved.\n",
      "   Imp 4: AUC = 0.573, ROC saved.\n",
      "   Imp 5: AUC = 0.588, ROC saved.\n",
      " Composite PS + AUC saved for SUBCAT_Z_drugs\n",
      " Running PS estimation for SUBCAT_NSAIDs\n",
      "   Imp 1: AUC = 0.537, ROC saved.\n",
      "   Imp 2: AUC = 0.554, ROC saved.\n",
      "   Imp 3: AUC = 0.615, ROC saved.\n",
      "   Imp 4: AUC = 0.612, ROC saved.\n",
      "   Imp 5: AUC = 0.608, ROC saved.\n",
      " Composite PS + AUC saved for SUBCAT_NSAIDs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ---------- PS Estimation Function ----------\n",
    "def run_xgboost_ps_modeling(imputed_dfs, medication_groups, final_covariates_map):\n",
    "    for group in medication_groups:\n",
    "        print(f\" Running PS estimation for {group}\")\n",
    "\n",
    "        if group not in final_covariates_map:\n",
    "            print(f\" No covariates found for {group}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        output_folder = os.path.join(\"outputs\", group)\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "        covariates = final_covariates_map[group]\n",
    "        ps_matrix = pd.DataFrame()\n",
    "        auc_list = []\n",
    "\n",
    "        for i, df_imp in enumerate(imputed_dfs):\n",
    "            if group not in df_imp.columns:\n",
    "                print(f\" {group} not found in imputed dataset {i+1}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            X = df_imp[covariates].copy()\n",
    "            T = df_imp[group]\n",
    "\n",
    "            # Drop missing treatment rows\n",
    "            valid_idx = T.dropna().index\n",
    "            X = X.loc[valid_idx]\n",
    "            T = T.loc[valid_idx]\n",
    "\n",
    "            # Train-test split for ROC\n",
    "            X_train, X_test, T_train, T_test = train_test_split(\n",
    "                X, T, stratify=T, test_size=0.3, random_state=42\n",
    "            )\n",
    "\n",
    "            try:\n",
    "                model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "                model.fit(X_train, T_train)\n",
    "\n",
    "                ps_scores = model.predict_proba(X)[:, 1]\n",
    "                ps_matrix[f\"ps_imp{i+1}\"] = pd.Series(ps_scores, index=valid_idx)\n",
    "\n",
    "                # ROC & AUC\n",
    "                auc = roc_auc_score(T_test, model.predict_proba(X_test)[:, 1])\n",
    "                auc_list.append(auc)\n",
    "\n",
    "                fpr, tpr, _ = roc_curve(T_test, model.predict_proba(X_test)[:, 1])\n",
    "                plt.figure()\n",
    "                plt.plot(fpr, tpr, label=f\"AUC = {auc:.3f}\")\n",
    "                plt.plot([0, 1], [0, 1], 'k--')\n",
    "                plt.xlabel(\"False Positive Rate\")\n",
    "                plt.ylabel(\"True Positive Rate\")\n",
    "                plt.title(f\"ROC Curve - {group} (Imp {i+1})\")\n",
    "                plt.legend()\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(os.path.join(output_folder, f\"roc_curve_imp{i+1}.png\"))\n",
    "                plt.close()\n",
    "                print(f\"   Imp {i+1}: AUC = {auc:.3f}, ROC saved.\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"   Error in {group} (imp {i+1}): {e}\")\n",
    "\n",
    "        # Save AUCs and Composite PS\n",
    "        if not ps_matrix.empty:\n",
    "            # Fill NaN rows (from dropped subjects in some imputations) with mean\n",
    "            ps_matrix[\"composite_ps\"] = ps_matrix.mean(axis=1)\n",
    "            ps_matrix.to_excel(os.path.join(output_folder, \"propensity_scores.xlsx\"))\n",
    "\n",
    "            auc_df = pd.DataFrame({\n",
    "                \"imputation\": [f\"imp{i+1}\" for i in range(len(auc_list))],\n",
    "                \"AUC\": auc_list\n",
    "            })\n",
    "            auc_df.loc[len(auc_df.index)] = [\"mean\", np.mean(auc_list) if auc_list else np.nan]\n",
    "            auc_df.to_excel(os.path.join(output_folder, \"auc_scores.xlsx\"), index=False)\n",
    "\n",
    "            print(f\" Composite PS + AUC saved for {group}\")\n",
    "        else:\n",
    "            print(f\" No valid PS scores generated for {group}\")\n",
    "\n",
    "# ---------- Run ----------\n",
    "run_xgboost_ps_modeling(imputed_dfs, medication_groups, final_covariates_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "6c350b8e-70f1-4c4d-bfa4-8963d6f2e7f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Computing feature importance for SUBCAT_Antipsychotica_atypisch\n",
      " Saved feature importance plot and CSV for SUBCAT_Antipsychotica_atypisch\n",
      "\n",
      " Computing feature importance for SUBCAT_TCA\n",
      " Saved feature importance plot and CSV for SUBCAT_TCA\n",
      "\n",
      " Computing feature importance for SUBCAT_SSRI\n",
      " Saved feature importance plot and CSV for SUBCAT_SSRI\n",
      "\n",
      " Computing feature importance for SUBCAT_SNRI\n",
      " Saved feature importance plot and CSV for SUBCAT_SNRI\n",
      "\n",
      " Computing feature importance for SUBCAT_Tetracyclische_antidepressiva\n",
      " Saved feature importance plot and CSV for SUBCAT_Tetracyclische_antidepressiva\n",
      "\n",
      " Computing feature importance for SUBCAT_Antidepressiva_overige\n",
      " Saved feature importance plot and CSV for SUBCAT_Antidepressiva_overige\n",
      "\n",
      " Computing feature importance for SUBCAT_Systemische_antihistaminica\n",
      " Saved feature importance plot and CSV for SUBCAT_Systemische_antihistaminica\n",
      "\n",
      " Computing feature importance for SUBCAT_anxiolytica_Benzodiazepine\n",
      " Saved feature importance plot and CSV for SUBCAT_anxiolytica_Benzodiazepine\n",
      "\n",
      " Computing feature importance for SUBCAT_hypnotica_Benzodiazepine\n",
      " Saved feature importance plot and CSV for SUBCAT_hypnotica_Benzodiazepine\n",
      "\n",
      " Computing feature importance for SUBCAT_Amfetaminen\n",
      " Saved feature importance plot and CSV for SUBCAT_Amfetaminen\n",
      "\n",
      " Computing feature importance for SUBCAT_Paracetamol_mono\n",
      " Saved feature importance plot and CSV for SUBCAT_Paracetamol_mono\n",
      "\n",
      " Computing feature importance for SUBCAT_Anti_epileptica_stemmingsstabilisatoren\n",
      " Saved feature importance plot and CSV for SUBCAT_Anti_epileptica_stemmingsstabilisatoren\n",
      "\n",
      " Computing feature importance for SUBCAT_Opioden\n",
      " Saved feature importance plot and CSV for SUBCAT_Opioden\n",
      "\n",
      " Computing feature importance for SUBCAT_Z_drugs\n",
      " Saved feature importance plot and CSV for SUBCAT_Z_drugs\n",
      "\n",
      " Computing feature importance for SUBCAT_NSAIDs\n",
      " Saved feature importance plot and CSV for SUBCAT_NSAIDs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "def compute_feature_importance(imputed_dfs, medication_groups, final_covariates_map):\n",
    "    for group in medication_groups:\n",
    "        print(f\"\\n Computing feature importance for {group}\")\n",
    "\n",
    "        if group not in final_covariates_map:\n",
    "            print(f\" No covariates found for {group}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        covariates = final_covariates_map[group]\n",
    "        output_folder = os.path.join(\"outputs\", group)\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "        importance_df_list = []\n",
    "\n",
    "        for i, df_imp in enumerate(imputed_dfs):\n",
    "            if group not in df_imp.columns:\n",
    "                print(f\" {group} not in imputed dataset {i+1}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            X = df_imp[covariates].copy()\n",
    "            T = df_imp[group]\n",
    "\n",
    "            # Drop NaNs in treatment\n",
    "            valid_idx = T.dropna().index\n",
    "            X = X.loc[valid_idx]\n",
    "            T = T.loc[valid_idx]\n",
    "\n",
    "            try:\n",
    "                model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "                model.fit(X, T)\n",
    "\n",
    "                # Get feature importance\n",
    "                importances = model.get_booster().get_score(importance_type='gain')\n",
    "                df_feat = pd.DataFrame.from_dict(importances, orient='index', columns=[f\"imp{i+1}\"])\n",
    "                df_feat.index.name = 'feature'\n",
    "                importance_df_list.append(df_feat)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"   Error during modeling: {e}\")\n",
    "\n",
    "        if importance_df_list:\n",
    "            # Combine and average\n",
    "            all_feat = pd.concat(importance_df_list, axis=1).fillna(0)\n",
    "            all_feat[\"mean_importance\"] = all_feat.mean(axis=1)\n",
    "\n",
    "            # Filter top 30 non-zero\n",
    "            non_zero = all_feat[all_feat[\"mean_importance\"] > 0]\n",
    "            top30 = non_zero.sort_values(by=\"mean_importance\", ascending=False).head(30)\n",
    "\n",
    "            # Save to CSV\n",
    "            top30.to_csv(os.path.join(output_folder, \"feature_importance.csv\"))\n",
    "\n",
    "            # Plot\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            plt.barh(top30.index[::-1], top30[\"mean_importance\"][::-1])  # plot top → bottom\n",
    "            plt.xlabel(\"Mean Gain Importance\")\n",
    "            plt.title(f\"Top 30 Feature Importance - {group}\")\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(output_folder, \"feature_importance_top30.png\"))\n",
    "            plt.close()\n",
    "\n",
    "            print(f\" Saved feature importance plot and CSV for {group}\")\n",
    "        else:\n",
    "            print(f\" No valid models for {group}\")\n",
    "\n",
    "#  Run\n",
    "compute_feature_importance(imputed_dfs, medication_groups, final_covariates_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "03b8ab3d-0e32-41f1-8ac1-e8c308947d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SUBCAT_Antipsychotica_atypisch\n",
      "✅ Saved IPTW weights for SUBCAT_Antipsychotica_atypisch\n",
      "    ℹ️ Retained 35/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Antipsychotica_atypisch/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 38/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Antipsychotica_atypisch/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 34/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Antipsychotica_atypisch/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 33/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Antipsychotica_atypisch/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 35/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Antipsychotica_atypisch/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SUBCAT_TCA\n",
      "✅ Saved IPTW weights for SUBCAT_TCA\n",
      "    ℹ️ Retained 174/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_TCA/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 179/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_TCA/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 192/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_TCA/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 178/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_TCA/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 182/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_TCA/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SUBCAT_SSRI\n",
      "✅ Saved IPTW weights for SUBCAT_SSRI\n",
      "    ℹ️ Retained 1206/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_SSRI/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 1195/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_SSRI/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 1266/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_SSRI/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 1231/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_SSRI/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 1227/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_SSRI/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SUBCAT_SNRI\n",
      "✅ Saved IPTW weights for SUBCAT_SNRI\n",
      "    ℹ️ Retained 168/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_SNRI/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 159/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_SNRI/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 169/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_SNRI/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 155/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_SNRI/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 183/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_SNRI/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SUBCAT_Tetracyclische_antidepressiva\n",
      "✅ Saved IPTW weights for SUBCAT_Tetracyclische_antidepressiva\n",
      "    ℹ️ Retained 193/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Tetracyclische_antidepressiva/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 185/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Tetracyclische_antidepressiva/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 196/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Tetracyclische_antidepressiva/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 181/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Tetracyclische_antidepressiva/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 181/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Tetracyclische_antidepressiva/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SUBCAT_Antidepressiva_overige\n",
      "✅ Saved IPTW weights for SUBCAT_Antidepressiva_overige\n",
      "    ℹ️ Retained 81/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Antidepressiva_overige/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 75/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Antidepressiva_overige/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 69/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Antidepressiva_overige/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 75/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Antidepressiva_overige/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 73/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Antidepressiva_overige/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SUBCAT_Systemische_antihistaminica\n",
      "✅ Saved IPTW weights for SUBCAT_Systemische_antihistaminica\n",
      "    ℹ️ Retained 123/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Systemische_antihistaminica/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 118/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Systemische_antihistaminica/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 128/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Systemische_antihistaminica/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 118/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Systemische_antihistaminica/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 115/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Systemische_antihistaminica/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SUBCAT_anxiolytica_Benzodiazepine\n",
      "✅ Saved IPTW weights for SUBCAT_anxiolytica_Benzodiazepine\n",
      "    ℹ️ Retained 885/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_anxiolytica_Benzodiazepine/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 938/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_anxiolytica_Benzodiazepine/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 895/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_anxiolytica_Benzodiazepine/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 945/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_anxiolytica_Benzodiazepine/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 828/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_anxiolytica_Benzodiazepine/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SUBCAT_hypnotica_Benzodiazepine\n",
      "✅ Saved IPTW weights for SUBCAT_hypnotica_Benzodiazepine\n",
      "    ℹ️ Retained 327/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_hypnotica_Benzodiazepine/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 324/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_hypnotica_Benzodiazepine/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 324/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_hypnotica_Benzodiazepine/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 326/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_hypnotica_Benzodiazepine/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 322/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_hypnotica_Benzodiazepine/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SUBCAT_Amfetaminen\n",
      "✅ Saved IPTW weights for SUBCAT_Amfetaminen\n",
      "    ℹ️ Retained 103/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Amfetaminen/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 105/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Amfetaminen/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 102/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Amfetaminen/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 96/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Amfetaminen/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 110/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Amfetaminen/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SUBCAT_Paracetamol_mono\n",
      "✅ Saved IPTW weights for SUBCAT_Paracetamol_mono\n",
      "    ℹ️ Retained 64/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Paracetamol_mono/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 76/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Paracetamol_mono/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 64/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Paracetamol_mono/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 55/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Paracetamol_mono/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 69/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Paracetamol_mono/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SUBCAT_Anti_epileptica_stemmingsstabilisatoren\n",
      "✅ Saved IPTW weights for SUBCAT_Anti_epileptica_stemmingsstabilisatoren\n",
      "    ℹ️ Retained 92/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Anti_epileptica_stemmingsstabilisatoren/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 98/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Anti_epileptica_stemmingsstabilisatoren/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 96/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Anti_epileptica_stemmingsstabilisatoren/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 105/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Anti_epileptica_stemmingsstabilisatoren/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 95/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Anti_epileptica_stemmingsstabilisatoren/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SUBCAT_Opioden\n",
      "✅ Saved IPTW weights for SUBCAT_Opioden\n",
      "    ℹ️ Retained 106/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Opioden/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 115/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Opioden/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 106/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Opioden/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 117/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Opioden/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 116/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Opioden/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SUBCAT_Z_drugs\n",
      "✅ Saved IPTW weights for SUBCAT_Z_drugs\n",
      "    ℹ️ Retained 119/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Z_drugs/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 124/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Z_drugs/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 126/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Z_drugs/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 118/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Z_drugs/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 114/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Z_drugs/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SUBCAT_NSAIDs\n",
      "✅ Saved IPTW weights for SUBCAT_NSAIDs\n",
      "    ℹ️ Retained 83/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_NSAIDs/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 86/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_NSAIDs/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 67/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_NSAIDs/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 77/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_NSAIDs/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 77/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_NSAIDs/trimmed_data_imp5.*\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_trimmed_clipped_iptw(ps_df, treatment, lower=0.05, upper=0.95, clip_max=10):\n",
    "    weights = []\n",
    "    keep_mask = (ps_df > lower) & (ps_df < upper)\n",
    "\n",
    "    for i in range(ps_df.shape[1]):\n",
    "        ps = ps_df.iloc[:, i].clip(lower=1e-6, upper=1 - 1e-6)  # avoid div by zero\n",
    "        mask = keep_mask.iloc[:, i]\n",
    "        w = pd.Series(np.nan, index=ps.index)\n",
    "\n",
    "        w[mask & (treatment == 1)] = 1 / ps[mask & (treatment == 1)]\n",
    "        w[mask & (treatment == 0)] = 1 / (1 - ps[mask & (treatment == 0)])\n",
    "        w = w.clip(upper=clip_max)\n",
    "        weights.append(w)\n",
    "\n",
    "    return pd.concat(weights, axis=1)\n",
    "\n",
    "\n",
    "def apply_rubins_rule_to_iptw(iptw_matrix):\n",
    "    \"\"\"\n",
    "    Given an IPTW matrix (n rows × M imputations), return Rubin’s rule pooled mean, SD, SE.\n",
    "    \"\"\"\n",
    "    M = iptw_matrix.shape[1]\n",
    "    q_bar = iptw_matrix.mean(axis=1)\n",
    "    u_bar = iptw_matrix.var(axis=1, ddof=1)\n",
    "    B = iptw_matrix.apply(lambda x: x.mean(), axis=1).var(ddof=1)\n",
    "    total_var = u_bar + (1 + 1/M) * B\n",
    "    total_se = np.sqrt(total_var)\n",
    "    return q_bar, u_bar.pow(0.5), total_se\n",
    "\n",
    "\n",
    "def run_trim_clip_save_all(imputed_dfs, medication_groups, final_covariates_map):\n",
    "    for group in medication_groups:\n",
    "        print(f\"\\n🔍 Processing IPTW + trimming + clipping for {group}\")\n",
    "        output_folder = os.path.join(\"outputs\", group)\n",
    "        ps_path = os.path.join(output_folder, \"propensity_scores.xlsx\")\n",
    "\n",
    "        if not os.path.exists(ps_path):\n",
    "            print(f\"⚠️ Missing PS file: {ps_path}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            ps_all = pd.read_excel(ps_path, index_col=0)\n",
    "            ps_cols = [col for col in ps_all.columns if col.startswith(\"ps_imp\")]\n",
    "            composite_index = ps_all.index\n",
    "\n",
    "            # Get treatment from one imputed dataset\n",
    "            T_full = None\n",
    "            for df in imputed_dfs:\n",
    "                if group in df.columns:\n",
    "                    T_full = df.loc[composite_index, group]\n",
    "                    break\n",
    "\n",
    "            if T_full is None:\n",
    "                print(f\"❌ Treatment column {group} not found in any imputed dataset.\")\n",
    "                continue\n",
    "\n",
    "            # Compute IPTW matrix (shape: n × M)\n",
    "            iptw_matrix = compute_trimmed_clipped_iptw(ps_all[ps_cols], T_full)\n",
    "            iptw_matrix.columns = [f\"iptw_imp{i+1}\" for i in range(iptw_matrix.shape[1])]\n",
    "\n",
    "            # Apply Rubin’s Rule for mean, SD, SE\n",
    "            iptw_matrix[\"iptw_mean\"], iptw_matrix[\"iptw_sd\"], iptw_matrix[\"iptw_se\"] = apply_rubins_rule_to_iptw(\n",
    "                iptw_matrix[[f\"iptw_imp{i+1}\" for i in range(iptw_matrix.shape[1])]]\n",
    "            )\n",
    "\n",
    "            # Save IPTW matrix separately\n",
    "            iptw_matrix.to_excel(os.path.join(output_folder, \"iptw_weights.xlsx\"))\n",
    "            print(f\"✅ Saved IPTW weights for {group}\")\n",
    "\n",
    "            # Save trimmed & clipped imputed datasets with IPTW\n",
    "            for i in range(5):\n",
    "                df = imputed_dfs[i].copy()\n",
    "                if group not in df.columns:\n",
    "                    continue\n",
    "\n",
    "                trimmed_idx = iptw_matrix.index.intersection(df.index)\n",
    "                needed_cols = final_covariates_map[group] + [group, \"caps5_change_baseline\"]\n",
    "\n",
    "                # Select only necessary columns\n",
    "                df_trimmed = df.loc[trimmed_idx, needed_cols].copy()\n",
    "                df_trimmed[\"iptw\"] = iptw_matrix[f\"iptw_imp{i+1}\"].loc[trimmed_idx]\n",
    "\n",
    "                # ✅ DROP rows with missing IPTW values\n",
    "                before = len(df_trimmed)\n",
    "                df_trimmed = df_trimmed.dropna(subset=[\"iptw\"])\n",
    "                after = len(df_trimmed)\n",
    "                print(f\"    ℹ️ Retained {after}/{before} rows after IPTW NaN drop.\")\n",
    "\n",
    "                # Save to .pkl\n",
    "                df_trimmed.to_pickle(os.path.join(output_folder, f\"trimmed_data_imp{i+1}.pkl\"))\n",
    "                print(f\"  💾 Saved trimmed dataset: {output_folder}/trimmed_data_imp{i+1}.*\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error in {group}: {e}\")\n",
    "\n",
    "\n",
    "run_trim_clip_save_all(imputed_dfs, medication_groups, final_covariates_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "36c885c8-0ce8-4666-83e8-5926e92c2ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Plotting PS overlap for SUBCAT_Antipsychotica_atypisch\n",
      "✅ Saved unweighted and weighted PS plots for SUBCAT_Antipsychotica_atypisch\n",
      "\n",
      "📊 Plotting PS overlap for SUBCAT_TCA\n",
      "✅ Saved unweighted and weighted PS plots for SUBCAT_TCA\n",
      "\n",
      "📊 Plotting PS overlap for SUBCAT_SSRI\n",
      "✅ Saved unweighted and weighted PS plots for SUBCAT_SSRI\n",
      "\n",
      "📊 Plotting PS overlap for SUBCAT_SNRI\n",
      "✅ Saved unweighted and weighted PS plots for SUBCAT_SNRI\n",
      "\n",
      "📊 Plotting PS overlap for SUBCAT_Tetracyclische_antidepressiva\n",
      "✅ Saved unweighted and weighted PS plots for SUBCAT_Tetracyclische_antidepressiva\n",
      "\n",
      "📊 Plotting PS overlap for SUBCAT_Antidepressiva_overige\n",
      "✅ Saved unweighted and weighted PS plots for SUBCAT_Antidepressiva_overige\n",
      "\n",
      "📊 Plotting PS overlap for SUBCAT_Systemische_antihistaminica\n",
      "✅ Saved unweighted and weighted PS plots for SUBCAT_Systemische_antihistaminica\n",
      "\n",
      "📊 Plotting PS overlap for SUBCAT_anxiolytica_Benzodiazepine\n",
      "✅ Saved unweighted and weighted PS plots for SUBCAT_anxiolytica_Benzodiazepine\n",
      "\n",
      "📊 Plotting PS overlap for SUBCAT_hypnotica_Benzodiazepine\n",
      "✅ Saved unweighted and weighted PS plots for SUBCAT_hypnotica_Benzodiazepine\n",
      "\n",
      "📊 Plotting PS overlap for SUBCAT_Amfetaminen\n",
      "✅ Saved unweighted and weighted PS plots for SUBCAT_Amfetaminen\n",
      "\n",
      "📊 Plotting PS overlap for SUBCAT_Paracetamol_mono\n",
      "✅ Saved unweighted and weighted PS plots for SUBCAT_Paracetamol_mono\n",
      "\n",
      "📊 Plotting PS overlap for SUBCAT_Anti_epileptica_stemmingsstabilisatoren\n",
      "✅ Saved unweighted and weighted PS plots for SUBCAT_Anti_epileptica_stemmingsstabilisatoren\n",
      "\n",
      "📊 Plotting PS overlap for SUBCAT_Opioden\n",
      "✅ Saved unweighted and weighted PS plots for SUBCAT_Opioden\n",
      "\n",
      "📊 Plotting PS overlap for SUBCAT_Z_drugs\n",
      "✅ Saved unweighted and weighted PS plots for SUBCAT_Z_drugs\n",
      "\n",
      "📊 Plotting PS overlap for SUBCAT_NSAIDs\n",
      "✅ Saved unweighted and weighted PS plots for SUBCAT_NSAIDs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_ps_overlap_all_groups(medication_groups):\n",
    "    for group in medication_groups:\n",
    "        print(f\"\\n📊 Plotting PS overlap for {group}\")\n",
    "\n",
    "        folder = os.path.join(\"outputs\", group)\n",
    "        ps_file = os.path.join(folder, \"propensity_scores.xlsx\")\n",
    "        iptw_file = os.path.join(folder, \"iptw_weights.xlsx\")\n",
    "        trimmed_file = os.path.join(folder, \"trimmed_data_imp1.pkl\")\n",
    "\n",
    "        if not all(os.path.exists(f) for f in [ps_file, iptw_file, trimmed_file]):\n",
    "            print(f\"⚠️ Missing required files for {group}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            ps_df = pd.read_excel(ps_file, index_col=0)\n",
    "            iptw_df = pd.read_excel(iptw_file, index_col=0)\n",
    "            trimmed_df = pd.read_pickle(trimmed_file)\n",
    "\n",
    "            # Extract\n",
    "            ps = ps_df[\"composite_ps\"].reindex(trimmed_df.index)\n",
    "            w = iptw_df[\"iptw_mean\"].reindex(trimmed_df.index)\n",
    "            T = trimmed_df[group]\n",
    "\n",
    "            # Masks to remove NaNs\n",
    "            treated_mask = (T == 1) & ps.notna() & w.notna()\n",
    "            control_mask = (T == 0) & ps.notna() & w.notna()\n",
    "\n",
    "            treated = ps[treated_mask]\n",
    "            treated_w = w[treated_mask]\n",
    "\n",
    "            control = ps[control_mask]\n",
    "            control_w = w[control_mask]\n",
    "\n",
    "            # === Unweighted Plot ===\n",
    "            plt.figure(figsize=(8, 5))\n",
    "            plt.hist([treated, control], bins=25, label=[\"Treated\", \"Control\"], alpha=0.6)\n",
    "            plt.title(f\"Unweighted PS Overlap - {group}\")\n",
    "            plt.xlabel(\"Composite Propensity Score\")\n",
    "            plt.ylabel(\"Count\")\n",
    "            plt.legend()\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(folder, \"ps_overlap_unweighted.png\"))\n",
    "            plt.close()\n",
    "\n",
    "            # === Weighted Plot ===\n",
    "            plt.figure(figsize=(8, 5))\n",
    "            plt.hist([treated, control], bins=25, weights=[treated_w, control_w], label=[\"Treated\", \"Control\"], alpha=0.6)\n",
    "            plt.title(f\"Weighted PS Overlap - {group}\")\n",
    "            plt.xlabel(\"Composite Propensity Score\")\n",
    "            plt.ylabel(\"Weighted Count\")\n",
    "            plt.legend()\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(folder, \"ps_overlap_weighted.png\"))\n",
    "            plt.close()\n",
    "\n",
    "            print(f\"✅ Saved unweighted and weighted PS plots for {group}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error processing {group}: {e}\")\n",
    "\n",
    "# 🔁 Run\n",
    "plot_ps_overlap_all_groups(medication_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "9416ccc5-be17-41b6-b800-1388807f0170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ✅ Saved: outputs\\SUBCAT_Antipsychotica_atypisch\\four_panel_overlap_SUBCAT_Antipsychotica_atypisch.png\n",
      " ✅ Saved: outputs\\SUBCAT_TCA\\four_panel_overlap_SUBCAT_TCA.png\n",
      " ✅ Saved: outputs\\SUBCAT_SSRI\\four_panel_overlap_SUBCAT_SSRI.png\n",
      " ✅ Saved: outputs\\SUBCAT_SNRI\\four_panel_overlap_SUBCAT_SNRI.png\n",
      " ✅ Saved: outputs\\SUBCAT_Tetracyclische_antidepressiva\\four_panel_overlap_SUBCAT_Tetracyclische_antidepressiva.png\n",
      " ✅ Saved: outputs\\SUBCAT_Antidepressiva_overige\\four_panel_overlap_SUBCAT_Antidepressiva_overige.png\n",
      " ✅ Saved: outputs\\SUBCAT_Systemische_antihistaminica\\four_panel_overlap_SUBCAT_Systemische_antihistaminica.png\n",
      " ✅ Saved: outputs\\SUBCAT_anxiolytica_Benzodiazepine\\four_panel_overlap_SUBCAT_anxiolytica_Benzodiazepine.png\n",
      " ✅ Saved: outputs\\SUBCAT_hypnotica_Benzodiazepine\\four_panel_overlap_SUBCAT_hypnotica_Benzodiazepine.png\n",
      " ✅ Saved: outputs\\SUBCAT_Amfetaminen\\four_panel_overlap_SUBCAT_Amfetaminen.png\n",
      " ✅ Saved: outputs\\SUBCAT_Paracetamol_mono\\four_panel_overlap_SUBCAT_Paracetamol_mono.png\n",
      " ✅ Saved: outputs\\SUBCAT_Anti_epileptica_stemmingsstabilisatoren\\four_panel_overlap_SUBCAT_Anti_epileptica_stemmingsstabilisatoren.png\n",
      " ✅ Saved: outputs\\SUBCAT_Opioden\\four_panel_overlap_SUBCAT_Opioden.png\n",
      " ✅ Saved: outputs\\SUBCAT_Z_drugs\\four_panel_overlap_SUBCAT_Z_drugs.png\n",
      " ✅ Saved: outputs\\SUBCAT_NSAIDs\\four_panel_overlap_SUBCAT_NSAIDs.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set up base output folder\n",
    "output_base = \"outputs\"\n",
    "ps_file = \"propensity_scores.xlsx\"\n",
    "iptw_file = \"iptw_weights.xlsx\"\n",
    "trimmed_data_file = \"trimmed_data_imp1.pkl\"\n",
    "\n",
    "# Collect all treatment group folders\n",
    "groups = [g for g in medication_groups if os.path.isdir(os.path.join(output_base, g))]\n",
    "\n",
    "\n",
    "# Generate 4-panel overlap plots\n",
    "for group in groups:\n",
    "    group_path = os.path.join(output_base, group)\n",
    "    try:\n",
    "        # Load trimmed treatment info\n",
    "        trimmed_df = pd.read_pickle(os.path.join(group_path, trimmed_data_file))\n",
    "        index = trimmed_df.index\n",
    "\n",
    "        # Fix: case-insensitive match for treatment variable\n",
    "        possible_cols = [col for col in trimmed_df.columns if col.upper() == group.upper()]\n",
    "        if not possible_cols:\n",
    "            print(f\" Treatment variable {group} not found in {group}, skipping.\")\n",
    "            continue\n",
    "        treatment_var = possible_cols[0]\n",
    "        T = trimmed_df[treatment_var]\n",
    "\n",
    "        # Load composite PS (aligned to trimmed_df index)\n",
    "        ps_df = pd.read_excel(os.path.join(group_path, ps_file), index_col=0)\n",
    "        if 'composite_ps' not in ps_df.columns:\n",
    "            print(f\" Composite column missing in {ps_file}, skipping {group}.\")\n",
    "            continue\n",
    "        ps = ps_df.loc[index, 'composite_ps']\n",
    "\n",
    "        # Load IPTW weights (aligned to trimmed_df index)\n",
    "        weights_df = pd.read_excel(os.path.join(group_path, iptw_file), index_col=0)\n",
    "        if 'iptw_mean' not in weights_df.columns:\n",
    "            print(f\" IPTW weight column missing in {iptw_file}, skipping {group}.\")\n",
    "            continue\n",
    "        weights = weights_df.loc[index, 'iptw_mean']\n",
    "\n",
    "        # Prepare 4 datasets\n",
    "        raw_treated = ps[T == 1]\n",
    "        raw_control = ps[T == 0]\n",
    "        weighted_treated = (ps[T == 1], weights[T == 1])\n",
    "        weighted_control = (ps[T == 0], weights[T == 0])\n",
    "\n",
    "        # Create plot\n",
    "        fig, axs = plt.subplots(2, 2, figsize=(12, 8))\n",
    "        fig.suptitle(f\"Propensity Score Distribution - {group}\", fontsize=14)\n",
    "\n",
    "        axs[0, 0].hist(raw_treated, bins=20, alpha=0.7, color='blue')\n",
    "        axs[0, 0].set_title(\"Raw Treated\")\n",
    "\n",
    "        axs[0, 1].hist(raw_control, bins=20, alpha=0.7, color='green')\n",
    "        axs[0, 1].set_title(\"Raw Control\")\n",
    "\n",
    "        axs[1, 0].hist(weighted_treated[0], bins=20, weights=weighted_treated[1], alpha=0.7, color='blue')\n",
    "        axs[1, 0].set_title(\"Weighted Treated\")\n",
    "\n",
    "        axs[1, 1].hist(weighted_control[0], bins=20, weights=weighted_control[1], alpha=0.7, color='green')\n",
    "        axs[1, 1].set_title(\"Weighted Control\")\n",
    "\n",
    "        for ax in axs.flat:\n",
    "            ax.set_xlim(0, 1)\n",
    "            ax.set_xlabel(\"Propensity Score\")\n",
    "            ax.set_ylabel(\"Count\")\n",
    "\n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "\n",
    "        # Save figure\n",
    "        plot_path = os.path.join(group_path, f\"four_panel_overlap_{group}.png\")\n",
    "        plt.savefig(plot_path)\n",
    "        plt.close()\n",
    "        print(f\" ✅ Saved: {plot_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\" ❌ Error in {group}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "a5ffe0fe-e79d-49bb-9f2b-7e652c1e72ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ATT calculation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "37018865-e063-4f96-a285-b905dc33fabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weighted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "96f04f14-2d87-4c64-ace6-45cb7c97414e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Running XGBoost for SUBCAT_Antipsychotica_atypisch\n",
      "✅ SUBCAT_Antipsychotica_atypisch | Seed 1: ATT = -0.7985, SE = 2.1885, p = 0.71841\n",
      "✅ SUBCAT_Antipsychotica_atypisch | Seed 2: ATT = -0.9127, SE = 1.9794, p = 0.64886\n",
      "✅ SUBCAT_Antipsychotica_atypisch | Seed 3: ATT = -0.6022, SE = 1.5906, p = 0.70829\n",
      "✅ SUBCAT_Antipsychotica_atypisch | Seed 4: ATT = -0.8361, SE = 1.9341, p = 0.66938\n",
      "✅ SUBCAT_Antipsychotica_atypisch | Seed 5: ATT = -0.9879, SE = 2.1822, p = 0.65483\n",
      "✅ SUBCAT_Antipsychotica_atypisch | Seed 6: ATT = -1.2858, SE = 2.3160, p = 0.58390\n",
      "✅ SUBCAT_Antipsychotica_atypisch | Seed 7: ATT = -0.6123, SE = 2.2906, p = 0.79153\n",
      "✅ SUBCAT_Antipsychotica_atypisch | Seed 8: ATT = -0.9784, SE = 1.9259, p = 0.61608\n",
      "✅ SUBCAT_Antipsychotica_atypisch | Seed 9: ATT = -0.8381, SE = 2.1425, p = 0.69912\n",
      "✅ SUBCAT_Antipsychotica_atypisch | Seed 10: ATT = -1.1909, SE = 1.8273, p = 0.52076\n",
      "📊 Diagnostic plots saved for SUBCAT_Antipsychotica_atypisch\n",
      "🏆 Best result for SUBCAT_Antipsychotica_atypisch → Seed 3 | SE = 1.5906\n",
      "\n",
      "🚀 Running XGBoost for SUBCAT_TCA\n",
      "✅ SUBCAT_TCA | Seed 1: ATT = 4.0786, SE = 1.8896, p = 0.04111\n",
      "✅ SUBCAT_TCA | Seed 2: ATT = 3.8987, SE = 1.9588, p = 0.05807\n",
      "✅ SUBCAT_TCA | Seed 3: ATT = 4.0471, SE = 1.8504, p = 0.03871\n",
      "✅ SUBCAT_TCA | Seed 4: ATT = 3.8287, SE = 2.0184, p = 0.06993\n",
      "✅ SUBCAT_TCA | Seed 5: ATT = 4.1543, SE = 1.6271, p = 0.01745\n",
      "✅ SUBCAT_TCA | Seed 6: ATT = 4.1536, SE = 2.1056, p = 0.06017\n",
      "✅ SUBCAT_TCA | Seed 7: ATT = 3.8999, SE = 1.6159, p = 0.02379\n",
      "✅ SUBCAT_TCA | Seed 8: ATT = 3.9887, SE = 2.1346, p = 0.07394\n",
      "✅ SUBCAT_TCA | Seed 9: ATT = 3.9705, SE = 1.9272, p = 0.05038\n",
      "✅ SUBCAT_TCA | Seed 10: ATT = 3.9388, SE = 1.9252, p = 0.05187\n",
      "📊 Diagnostic plots saved for SUBCAT_TCA\n",
      "🏆 Best result for SUBCAT_TCA → Seed 7 | SE = 1.6159\n",
      "\n",
      "🚀 Running XGBoost for SUBCAT_SSRI\n",
      "✅ SUBCAT_SSRI | Seed 1: ATT = -0.0051, SE = 0.4202, p = 0.99042\n",
      "✅ SUBCAT_SSRI | Seed 2: ATT = -0.0493, SE = 0.4349, p = 0.91069\n",
      "✅ SUBCAT_SSRI | Seed 3: ATT = -0.0001, SE = 0.5001, p = 0.99983\n",
      "✅ SUBCAT_SSRI | Seed 4: ATT = -0.0848, SE = 0.5310, p = 0.87446\n",
      "✅ SUBCAT_SSRI | Seed 5: ATT = -0.0589, SE = 0.4640, p = 0.90007\n",
      "✅ SUBCAT_SSRI | Seed 6: ATT = -0.0433, SE = 0.4570, p = 0.92521\n",
      "✅ SUBCAT_SSRI | Seed 7: ATT = -0.0493, SE = 0.4352, p = 0.91073\n",
      "✅ SUBCAT_SSRI | Seed 8: ATT = -0.0347, SE = 0.3724, p = 0.92664\n",
      "✅ SUBCAT_SSRI | Seed 9: ATT = -0.0351, SE = 0.4587, p = 0.93966\n",
      "✅ SUBCAT_SSRI | Seed 10: ATT = -0.0637, SE = 0.4234, p = 0.88168\n",
      "📊 Diagnostic plots saved for SUBCAT_SSRI\n",
      "🏆 Best result for SUBCAT_SSRI → Seed 8 | SE = 0.3724\n",
      "\n",
      "🚀 Running XGBoost for SUBCAT_SNRI\n",
      "✅ SUBCAT_SNRI | Seed 1: ATT = 2.5961, SE = 1.8332, p = 0.16958\n",
      "✅ SUBCAT_SNRI | Seed 2: ATT = 2.6194, SE = 1.4069, p = 0.07491\n",
      "✅ SUBCAT_SNRI | Seed 3: ATT = 2.6223, SE = 1.6670, p = 0.12879\n",
      "✅ SUBCAT_SNRI | Seed 4: ATT = 2.5993, SE = 1.5531, p = 0.10718\n",
      "✅ SUBCAT_SNRI | Seed 5: ATT = 2.5317, SE = 1.3426, p = 0.07149\n",
      "✅ SUBCAT_SNRI | Seed 6: ATT = 2.3457, SE = 1.3412, p = 0.09308\n",
      "✅ SUBCAT_SNRI | Seed 7: ATT = 2.5235, SE = 1.5223, p = 0.11038\n",
      "✅ SUBCAT_SNRI | Seed 8: ATT = 2.4054, SE = 1.3102, p = 0.07878\n",
      "✅ SUBCAT_SNRI | Seed 9: ATT = 2.6288, SE = 1.3651, p = 0.06608\n",
      "✅ SUBCAT_SNRI | Seed 10: ATT = 2.6318, SE = 1.4052, p = 0.07330\n",
      "📊 Diagnostic plots saved for SUBCAT_SNRI\n",
      "🏆 Best result for SUBCAT_SNRI → Seed 8 | SE = 1.3102\n",
      "\n",
      "🚀 Running XGBoost for SUBCAT_Tetracyclische_antidepressiva\n",
      "✅ SUBCAT_Tetracyclische_antidepressiva | Seed 1: ATT = 6.6345, SE = 2.6139, p = 0.01805\n",
      "✅ SUBCAT_Tetracyclische_antidepressiva | Seed 2: ATT = 6.6273, SE = 2.6463, p = 0.01946\n",
      "✅ SUBCAT_Tetracyclische_antidepressiva | Seed 3: ATT = 6.5832, SE = 2.5837, p = 0.01766\n",
      "✅ SUBCAT_Tetracyclische_antidepressiva | Seed 4: ATT = 6.5959, SE = 2.1612, p = 0.00548\n",
      "✅ SUBCAT_Tetracyclische_antidepressiva | Seed 5: ATT = 6.7347, SE = 2.4721, p = 0.01183\n",
      "✅ SUBCAT_Tetracyclische_antidepressiva | Seed 6: ATT = 6.6746, SE = 2.3943, p = 0.01022\n",
      "✅ SUBCAT_Tetracyclische_antidepressiva | Seed 7: ATT = 6.6459, SE = 2.4576, p = 0.01239\n",
      "✅ SUBCAT_Tetracyclische_antidepressiva | Seed 8: ATT = 6.5744, SE = 2.9128, p = 0.03338\n",
      "✅ SUBCAT_Tetracyclische_antidepressiva | Seed 9: ATT = 6.3731, SE = 2.3476, p = 0.01209\n",
      "✅ SUBCAT_Tetracyclische_antidepressiva | Seed 10: ATT = 6.4235, SE = 2.4629, p = 0.01542\n",
      "📊 Diagnostic plots saved for SUBCAT_Tetracyclische_antidepressiva\n",
      "🏆 Best result for SUBCAT_Tetracyclische_antidepressiva → Seed 4 | SE = 2.1612\n",
      "\n",
      "🚀 Running XGBoost for SUBCAT_Antidepressiva_overige\n",
      "✅ SUBCAT_Antidepressiva_overige | Seed 1: ATT = 2.1925, SE = 1.6217, p = 0.18899\n",
      "✅ SUBCAT_Antidepressiva_overige | Seed 2: ATT = 2.3841, SE = 2.2118, p = 0.29178\n",
      "✅ SUBCAT_Antidepressiva_overige | Seed 3: ATT = 2.2070, SE = 2.0157, p = 0.28444\n",
      "✅ SUBCAT_Antidepressiva_overige | Seed 4: ATT = 2.1234, SE = 2.3645, p = 0.37809\n",
      "✅ SUBCAT_Antidepressiva_overige | Seed 5: ATT = 2.2061, SE = 2.0192, p = 0.28544\n",
      "✅ SUBCAT_Antidepressiva_overige | Seed 6: ATT = 2.1143, SE = 2.1108, p = 0.32650\n",
      "✅ SUBCAT_Antidepressiva_overige | Seed 7: ATT = 2.2430, SE = 1.7498, p = 0.21213\n",
      "✅ SUBCAT_Antidepressiva_overige | Seed 8: ATT = 2.2101, SE = 1.9341, p = 0.26442\n",
      "✅ SUBCAT_Antidepressiva_overige | Seed 9: ATT = 2.2909, SE = 2.1870, p = 0.30529\n",
      "✅ SUBCAT_Antidepressiva_overige | Seed 10: ATT = 2.0978, SE = 1.7722, p = 0.24809\n",
      "📊 Diagnostic plots saved for SUBCAT_Antidepressiva_overige\n",
      "🏆 Best result for SUBCAT_Antidepressiva_overige → Seed 1 | SE = 1.6217\n",
      "\n",
      "🚀 Running XGBoost for SUBCAT_Systemische_antihistaminica\n",
      "✅ SUBCAT_Systemische_antihistaminica | Seed 1: ATT = 0.7615, SE = 2.0489, p = 0.71340\n",
      "✅ SUBCAT_Systemische_antihistaminica | Seed 2: ATT = 0.7586, SE = 1.3301, p = 0.57374\n",
      "✅ SUBCAT_Systemische_antihistaminica | Seed 3: ATT = 0.8844, SE = 1.3225, p = 0.51008\n",
      "✅ SUBCAT_Systemische_antihistaminica | Seed 4: ATT = 0.6090, SE = 1.4631, p = 0.68094\n",
      "✅ SUBCAT_Systemische_antihistaminica | Seed 5: ATT = 0.7006, SE = 1.3674, p = 0.61306\n",
      "✅ SUBCAT_Systemische_antihistaminica | Seed 6: ATT = 0.8417, SE = 1.3444, p = 0.53718\n",
      "✅ SUBCAT_Systemische_antihistaminica | Seed 7: ATT = 0.7604, SE = 1.3913, p = 0.58976\n",
      "✅ SUBCAT_Systemische_antihistaminica | Seed 8: ATT = 0.8257, SE = 1.5255, p = 0.59330\n",
      "✅ SUBCAT_Systemische_antihistaminica | Seed 9: ATT = 0.4784, SE = 1.1326, p = 0.67653\n",
      "✅ SUBCAT_Systemische_antihistaminica | Seed 10: ATT = 0.5472, SE = 1.7676, p = 0.75954\n",
      "📊 Diagnostic plots saved for SUBCAT_Systemische_antihistaminica\n",
      "🏆 Best result for SUBCAT_Systemische_antihistaminica → Seed 9 | SE = 1.1326\n",
      "\n",
      "🚀 Running XGBoost for SUBCAT_anxiolytica_Benzodiazepine\n",
      "✅ SUBCAT_anxiolytica_Benzodiazepine | Seed 1: ATT = 0.5913, SE = 0.7964, p = 0.46502\n",
      "✅ SUBCAT_anxiolytica_Benzodiazepine | Seed 2: ATT = 0.5444, SE = 0.7987, p = 0.50201\n",
      "✅ SUBCAT_anxiolytica_Benzodiazepine | Seed 3: ATT = 0.6334, SE = 0.7986, p = 0.43551\n",
      "✅ SUBCAT_anxiolytica_Benzodiazepine | Seed 4: ATT = 0.6370, SE = 0.7372, p = 0.39610\n",
      "✅ SUBCAT_anxiolytica_Benzodiazepine | Seed 5: ATT = 0.5873, SE = 0.7461, p = 0.43891\n",
      "✅ SUBCAT_anxiolytica_Benzodiazepine | Seed 6: ATT = 0.5816, SE = 0.7493, p = 0.44527\n",
      "✅ SUBCAT_anxiolytica_Benzodiazepine | Seed 7: ATT = 0.5995, SE = 0.7226, p = 0.41490\n",
      "✅ SUBCAT_anxiolytica_Benzodiazepine | Seed 8: ATT = 0.6345, SE = 0.7373, p = 0.39802\n",
      "✅ SUBCAT_anxiolytica_Benzodiazepine | Seed 9: ATT = 0.6145, SE = 0.7440, p = 0.41696\n",
      "✅ SUBCAT_anxiolytica_Benzodiazepine | Seed 10: ATT = 0.6114, SE = 0.7675, p = 0.43351\n",
      "📊 Diagnostic plots saved for SUBCAT_anxiolytica_Benzodiazepine\n",
      "🏆 Best result for SUBCAT_anxiolytica_Benzodiazepine → Seed 7 | SE = 0.7226\n",
      "\n",
      "🚀 Running XGBoost for SUBCAT_hypnotica_Benzodiazepine\n",
      "✅ SUBCAT_hypnotica_Benzodiazepine | Seed 1: ATT = -0.5967, SE = 1.1729, p = 0.61555\n",
      "✅ SUBCAT_hypnotica_Benzodiazepine | Seed 2: ATT = -0.5229, SE = 1.2645, p = 0.68292\n",
      "✅ SUBCAT_hypnotica_Benzodiazepine | Seed 3: ATT = -0.5680, SE = 0.9964, p = 0.57395\n",
      "✅ SUBCAT_hypnotica_Benzodiazepine | Seed 4: ATT = -0.5468, SE = 1.1616, p = 0.64210\n",
      "✅ SUBCAT_hypnotica_Benzodiazepine | Seed 5: ATT = -0.6749, SE = 1.1510, p = 0.56312\n",
      "✅ SUBCAT_hypnotica_Benzodiazepine | Seed 6: ATT = -0.6709, SE = 1.2511, p = 0.59671\n",
      "✅ SUBCAT_hypnotica_Benzodiazepine | Seed 7: ATT = -0.5701, SE = 1.2313, p = 0.64752\n",
      "✅ SUBCAT_hypnotica_Benzodiazepine | Seed 8: ATT = -0.5809, SE = 1.1719, p = 0.62463\n",
      "✅ SUBCAT_hypnotica_Benzodiazepine | Seed 9: ATT = -0.6017, SE = 1.1448, p = 0.60397\n",
      "✅ SUBCAT_hypnotica_Benzodiazepine | Seed 10: ATT = -0.6602, SE = 1.3247, p = 0.62275\n",
      "📊 Diagnostic plots saved for SUBCAT_hypnotica_Benzodiazepine\n",
      "🏆 Best result for SUBCAT_hypnotica_Benzodiazepine → Seed 3 | SE = 0.9964\n",
      "\n",
      "🚀 Running XGBoost for SUBCAT_Amfetaminen\n",
      "✅ SUBCAT_Amfetaminen | Seed 1: ATT = 2.8473, SE = 1.9825, p = 0.16386\n",
      "✅ SUBCAT_Amfetaminen | Seed 2: ATT = 3.0475, SE = 1.9651, p = 0.13403\n",
      "✅ SUBCAT_Amfetaminen | Seed 3: ATT = 2.9085, SE = 2.3980, p = 0.23697\n",
      "✅ SUBCAT_Amfetaminen | Seed 4: ATT = 2.9915, SE = 2.2834, p = 0.20255\n",
      "✅ SUBCAT_Amfetaminen | Seed 5: ATT = 2.8083, SE = 1.9725, p = 0.16740\n",
      "✅ SUBCAT_Amfetaminen | Seed 6: ATT = 2.9731, SE = 2.2494, p = 0.19873\n",
      "✅ SUBCAT_Amfetaminen | Seed 7: ATT = 3.0606, SE = 2.1569, p = 0.16876\n",
      "✅ SUBCAT_Amfetaminen | Seed 8: ATT = 2.8773, SE = 2.3521, p = 0.23310\n",
      "✅ SUBCAT_Amfetaminen | Seed 9: ATT = 2.9991, SE = 2.0723, p = 0.16077\n",
      "✅ SUBCAT_Amfetaminen | Seed 10: ATT = 2.9529, SE = 1.7397, p = 0.10257\n",
      "📊 Diagnostic plots saved for SUBCAT_Amfetaminen\n",
      "🏆 Best result for SUBCAT_Amfetaminen → Seed 10 | SE = 1.7397\n",
      "\n",
      "🚀 Running XGBoost for SUBCAT_Paracetamol_mono\n",
      "✅ SUBCAT_Paracetamol_mono | Seed 1: ATT = 1.3167, SE = 2.2934, p = 0.57121\n",
      "✅ SUBCAT_Paracetamol_mono | Seed 2: ATT = 1.5294, SE = 2.7448, p = 0.58254\n",
      "✅ SUBCAT_Paracetamol_mono | Seed 3: ATT = 1.2618, SE = 2.5283, p = 0.62227\n",
      "✅ SUBCAT_Paracetamol_mono | Seed 4: ATT = 1.4966, SE = 2.3570, p = 0.53146\n",
      "✅ SUBCAT_Paracetamol_mono | Seed 5: ATT = 1.4246, SE = 2.4743, p = 0.57014\n",
      "✅ SUBCAT_Paracetamol_mono | Seed 6: ATT = 1.1908, SE = 2.2429, p = 0.60035\n",
      "✅ SUBCAT_Paracetamol_mono | Seed 7: ATT = 1.3765, SE = 2.2047, p = 0.53830\n",
      "✅ SUBCAT_Paracetamol_mono | Seed 8: ATT = 1.3630, SE = 2.5052, p = 0.59140\n",
      "✅ SUBCAT_Paracetamol_mono | Seed 9: ATT = 1.6804, SE = 2.6162, p = 0.52677\n",
      "✅ SUBCAT_Paracetamol_mono | Seed 10: ATT = 1.2644, SE = 2.2738, p = 0.58333\n",
      "📊 Diagnostic plots saved for SUBCAT_Paracetamol_mono\n",
      "🏆 Best result for SUBCAT_Paracetamol_mono → Seed 7 | SE = 2.2047\n",
      "\n",
      "🚀 Running XGBoost for SUBCAT_Anti_epileptica_stemmingsstabilisatoren\n",
      "✅ SUBCAT_Anti_epileptica_stemmingsstabilisatoren | Seed 1: ATT = 3.1349, SE = 2.0671, p = 0.14244\n",
      "✅ SUBCAT_Anti_epileptica_stemmingsstabilisatoren | Seed 2: ATT = 3.4130, SE = 2.3589, p = 0.16087\n",
      "✅ SUBCAT_Anti_epileptica_stemmingsstabilisatoren | Seed 3: ATT = 3.4091, SE = 2.3698, p = 0.16320\n",
      "✅ SUBCAT_Anti_epileptica_stemmingsstabilisatoren | Seed 4: ATT = 3.4183, SE = 2.1390, p = 0.12311\n",
      "✅ SUBCAT_Anti_epileptica_stemmingsstabilisatoren | Seed 5: ATT = 3.5255, SE = 2.0879, p = 0.10426\n",
      "✅ SUBCAT_Anti_epileptica_stemmingsstabilisatoren | Seed 6: ATT = 3.2613, SE = 2.8732, p = 0.26754\n",
      "✅ SUBCAT_Anti_epileptica_stemmingsstabilisatoren | Seed 7: ATT = 3.1568, SE = 2.1620, p = 0.15721\n",
      "✅ SUBCAT_Anti_epileptica_stemmingsstabilisatoren | Seed 8: ATT = 3.2859, SE = 2.3924, p = 0.18229\n",
      "✅ SUBCAT_Anti_epileptica_stemmingsstabilisatoren | Seed 9: ATT = 3.3504, SE = 2.5942, p = 0.20884\n",
      "✅ SUBCAT_Anti_epileptica_stemmingsstabilisatoren | Seed 10: ATT = 3.3486, SE = 2.8053, p = 0.24428\n",
      "📊 Diagnostic plots saved for SUBCAT_Anti_epileptica_stemmingsstabilisatoren\n",
      "🏆 Best result for SUBCAT_Anti_epileptica_stemmingsstabilisatoren → Seed 1 | SE = 2.0671\n",
      "\n",
      "🚀 Running XGBoost for SUBCAT_Opioden\n",
      "✅ SUBCAT_Opioden | Seed 1: ATT = 1.6252, SE = 2.4072, p = 0.50603\n",
      "✅ SUBCAT_Opioden | Seed 2: ATT = 1.6932, SE = 1.8996, p = 0.38161\n",
      "✅ SUBCAT_Opioden | Seed 3: ATT = 1.6778, SE = 1.8693, p = 0.37834\n",
      "✅ SUBCAT_Opioden | Seed 4: ATT = 1.8805, SE = 1.7173, p = 0.28436\n",
      "✅ SUBCAT_Opioden | Seed 5: ATT = 1.6580, SE = 1.5364, p = 0.29125\n",
      "✅ SUBCAT_Opioden | Seed 6: ATT = 1.6938, SE = 1.9012, p = 0.38182\n",
      "✅ SUBCAT_Opioden | Seed 7: ATT = 1.8555, SE = 1.9502, p = 0.35084\n",
      "✅ SUBCAT_Opioden | Seed 8: ATT = 1.4915, SE = 1.9542, p = 0.45277\n",
      "✅ SUBCAT_Opioden | Seed 9: ATT = 1.5180, SE = 1.5607, p = 0.34043\n",
      "✅ SUBCAT_Opioden | Seed 10: ATT = 1.4408, SE = 1.7056, p = 0.40659\n",
      "📊 Diagnostic plots saved for SUBCAT_Opioden\n",
      "🏆 Best result for SUBCAT_Opioden → Seed 5 | SE = 1.5364\n",
      "\n",
      "🚀 Running XGBoost for SUBCAT_Z_drugs\n",
      "✅ SUBCAT_Z_drugs | Seed 1: ATT = 4.4883, SE = 1.7254, p = 0.01566\n",
      "✅ SUBCAT_Z_drugs | Seed 2: ATT = 4.6155, SE = 2.0635, p = 0.03486\n",
      "✅ SUBCAT_Z_drugs | Seed 3: ATT = 4.6152, SE = 2.0963, p = 0.03755\n",
      "✅ SUBCAT_Z_drugs | Seed 4: ATT = 4.9237, SE = 1.8979, p = 0.01591\n",
      "✅ SUBCAT_Z_drugs | Seed 5: ATT = 4.4150, SE = 2.0102, p = 0.03798\n",
      "✅ SUBCAT_Z_drugs | Seed 6: ATT = 4.4812, SE = 2.1615, p = 0.04906\n",
      "✅ SUBCAT_Z_drugs | Seed 7: ATT = 4.7137, SE = 1.8468, p = 0.01748\n",
      "✅ SUBCAT_Z_drugs | Seed 8: ATT = 4.6923, SE = 2.0958, p = 0.03470\n",
      "✅ SUBCAT_Z_drugs | Seed 9: ATT = 4.4653, SE = 2.0358, p = 0.03821\n",
      "✅ SUBCAT_Z_drugs | Seed 10: ATT = 4.7464, SE = 2.1316, p = 0.03561\n",
      "📊 Diagnostic plots saved for SUBCAT_Z_drugs\n",
      "🏆 Best result for SUBCAT_Z_drugs → Seed 1 | SE = 1.7254\n",
      "\n",
      "🚀 Running XGBoost for SUBCAT_NSAIDs\n",
      "✅ SUBCAT_NSAIDs | Seed 1: ATT = 0.1779, SE = 1.7289, p = 0.91889\n",
      "✅ SUBCAT_NSAIDs | Seed 2: ATT = 0.3865, SE = 1.5601, p = 0.80646\n",
      "✅ SUBCAT_NSAIDs | Seed 3: ATT = 0.2973, SE = 2.0921, p = 0.88819\n",
      "✅ SUBCAT_NSAIDs | Seed 4: ATT = 0.2822, SE = 1.5494, p = 0.85701\n",
      "✅ SUBCAT_NSAIDs | Seed 5: ATT = 0.1655, SE = 1.6655, p = 0.92167\n",
      "✅ SUBCAT_NSAIDs | Seed 6: ATT = 0.4503, SE = 1.8941, p = 0.81410\n",
      "✅ SUBCAT_NSAIDs | Seed 7: ATT = 0.0548, SE = 2.0731, p = 0.97915\n",
      "✅ SUBCAT_NSAIDs | Seed 8: ATT = 0.0384, SE = 1.6661, p = 0.98180\n",
      "✅ SUBCAT_NSAIDs | Seed 9: ATT = 0.0449, SE = 1.4769, p = 0.97600\n",
      "✅ SUBCAT_NSAIDs | Seed 10: ATT = 0.2776, SE = 1.4993, p = 0.85466\n",
      "📊 Diagnostic plots saved for SUBCAT_NSAIDs\n",
      "🏆 Best result for SUBCAT_NSAIDs → Seed 9 | SE = 1.4769\n",
      "\n",
      "🎯 All summary files saved.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy.stats import t, probplot\n",
    "import xgboost as xgb\n",
    "\n",
    "# -----------------------------\n",
    "# Configuration\n",
    "# -----------------------------\n",
    "n_repeats = 1\n",
    "seeds = list(range(1, 11))\n",
    "imputations = 5\n",
    "output_folder = \"outputs\"\n",
    "\n",
    "# -----------------------------\n",
    "# Diagnostic Plotting Function\n",
    "# -----------------------------\n",
    "def create_diagnostic_plots(residuals_data, fitted_data, group_name):\n",
    "    \"\"\"Create 4 diagnostic plots for model validation\"\"\"\n",
    "    plots_dir = os.path.join(output_folder, \"plots\")\n",
    "    os.makedirs(plots_dir, exist_ok=True)\n",
    "    \n",
    "    # Flatten the collected data\n",
    "    all_residuals = np.concatenate(residuals_data)\n",
    "    all_fitted = np.concatenate(fitted_data)\n",
    "    \n",
    "    # Create figure with 2x2 subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    fig.suptitle(f'Diagnostic Plots - {group_name}', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. Residuals vs Fitted\n",
    "    axes[0,0].scatter(all_fitted, all_residuals, alpha=0.6, s=20)\n",
    "    axes[0,0].axhline(y=0, color='red', linestyle='--', alpha=0.8)\n",
    "    axes[0,0].set_xlabel('Fitted Values')\n",
    "    axes[0,0].set_ylabel('Residuals')\n",
    "    axes[0,0].set_title('Residuals vs Fitted')\n",
    "    axes[0,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. QQ Plot\n",
    "    probplot(all_residuals, dist=\"norm\", plot=axes[0,1])\n",
    "    axes[0,1].set_title('Q-Q Plot (Normal)')\n",
    "    axes[0,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Residual Histogram\n",
    "    axes[1,0].hist(all_residuals, bins=30, density=True, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    axes[1,0].set_xlabel('Residuals')\n",
    "    axes[1,0].set_ylabel('Density')\n",
    "    axes[1,0].set_title('Residual Distribution')\n",
    "    axes[1,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Scale-Location Plot\n",
    "    sqrt_abs_residuals = np.sqrt(np.abs(all_residuals))\n",
    "    axes[1,1].scatter(all_fitted, sqrt_abs_residuals, alpha=0.6, s=20)\n",
    "    axes[1,1].set_xlabel('Fitted Values')\n",
    "    axes[1,1].set_ylabel('√|Residuals|')\n",
    "    axes[1,1].set_title('Scale-Location Plot')\n",
    "    axes[1,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save plot\n",
    "    plot_filename = os.path.join(plots_dir, f'{group_name}.png')\n",
    "    plt.savefig(plot_filename, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"📊 Diagnostic plots saved for {group_name}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Rubin's Rule\n",
    "# -----------------------------\n",
    "def rubins_pool(estimates, ses):\n",
    "    m = len(estimates)\n",
    "    q_bar = np.mean(estimates)\n",
    "    u_bar = np.mean(np.square(ses))\n",
    "    b_m = np.var(estimates, ddof=1)\n",
    "    total_var = u_bar + ((1 + 1/m) * b_m)\n",
    "    total_se = np.sqrt(total_var)\n",
    "    ci_lower = q_bar - 1.96 * total_se\n",
    "    ci_upper = q_bar + 1.96 * total_se\n",
    "    p_value = 2 * (1 - t.cdf(np.abs(q_bar / total_se), df=m-1))\n",
    "    rounded_p = round(p_value, 5)\n",
    "    formatted_p = \"< 0.00001\" if rounded_p <= 0.00001 else f\"{rounded_p:.5f}\"\n",
    "    return q_bar, total_se, ci_lower, ci_upper, formatted_p\n",
    "\n",
    "# -----------------------------\n",
    "# SMD + Variance Ratio\n",
    "# -----------------------------\n",
    "def calculate_smd_vr(X, T, weights):\n",
    "    treated = X[T == 1]\n",
    "    control = X[T == 0]\n",
    "    w_treated = weights[T == 1]\n",
    "    w_control = weights[T == 0]\n",
    "    smd, vr = [], []\n",
    "    for col in X.columns:\n",
    "        try:\n",
    "            m1, m0 = np.average(treated[col], weights=w_treated), np.average(control[col], weights=w_control)\n",
    "            s1 = np.sqrt(np.average((treated[col] - m1) ** 2, weights=w_treated))\n",
    "            s0 = np.sqrt(np.average((control[col] - m0) ** 2, weights=w_control))\n",
    "            pooled_sd = np.sqrt((s1 ** 2 + s0 ** 2) / 2)\n",
    "            smd.append((m1 - m0) / pooled_sd if pooled_sd > 0 else 0)\n",
    "            vr.append(s1**2 / s0**2 if s0**2 > 0 else 0)\n",
    "        except Exception:\n",
    "            smd.append(np.nan)\n",
    "            vr.append(np.nan)\n",
    "    return np.nanmean(smd), np.nanmean(vr)\n",
    "\n",
    "# -----------------------------\n",
    "# XGBoost Main Loop (No DML)\n",
    "# -----------------------------\n",
    "def run_xgboost_with_trimmed_data(final_covariates_map):\n",
    "    att_results = []\n",
    "    balance_results = []\n",
    "\n",
    "    for group, covariates in final_covariates_map.items():\n",
    "        print(f\"\\n🚀 Running XGBoost for {group}\")\n",
    "        group_dir = os.path.join(output_folder, group)\n",
    "        os.makedirs(group_dir, exist_ok=True)\n",
    "\n",
    "        best_result = None\n",
    "        best_se = float(\"inf\")\n",
    "        \n",
    "        # Initialize lists to collect residuals and fitted values for diagnostic plots\n",
    "        group_residuals = []\n",
    "        group_fitted = []\n",
    "\n",
    "        for seed in seeds:\n",
    "            att_list, se_list, r2_list, rmse_list, smd_list, vr_list = [], [], [], [], [], []\n",
    "\n",
    "            for imp in range(1, imputations + 1):\n",
    "                file_path = os.path.join(group_dir, f\"trimmed_data_imp{imp}.pkl\")\n",
    "                if not os.path.exists(file_path):\n",
    "                    continue\n",
    "\n",
    "                df = pd.read_pickle(file_path)\n",
    "                if group not in df.columns or \"iptw\" not in df.columns:\n",
    "                    continue\n",
    "\n",
    "                X = df[covariates].copy()\n",
    "                T = df[group]\n",
    "                Y = df[\"caps5_change_baseline\"]\n",
    "                W = df[\"iptw\"]\n",
    "\n",
    "                for repeat in range(n_repeats):\n",
    "                    kf = KFold(n_splits=5, shuffle=True, random_state=seed + repeat)\n",
    "                    for train_idx, test_idx in kf.split(X):\n",
    "                        try:\n",
    "                            X_train, T_train, Y_train, W_train = (\n",
    "                                X.iloc[train_idx],\n",
    "                                T.iloc[train_idx],\n",
    "                                Y.iloc[train_idx],\n",
    "                                W.iloc[train_idx],\n",
    "                            )\n",
    "\n",
    "                            # XGBoost regression model\n",
    "                            model = xgb.XGBRegressor(n_estimators=100, max_depth=3, learning_rate=0.1, n_jobs=1, random_state=seed)\n",
    "                            \n",
    "                            # Add treatment variable to features\n",
    "                            X_train_with_T = X_train.copy()\n",
    "                            X_train_with_T[group] = T_train\n",
    "                            \n",
    "                            # Fit model\n",
    "                            model.fit(X_train_with_T, Y_train, sample_weight=W_train)\n",
    "                            \n",
    "                            # Predict outcomes for treated and control groups\n",
    "                            X_treated = X_train.copy()\n",
    "                            X_treated[group] = 1\n",
    "                            X_control = X_train.copy()\n",
    "                            X_control[group] = 0\n",
    "                            \n",
    "                            Y_pred_treated = model.predict(X_treated)\n",
    "                            Y_pred_control = model.predict(X_control)\n",
    "                            \n",
    "                            # Calculate ATT (Average Treatment Effect on Treated)\n",
    "                            treated_mask = T_train == 1\n",
    "                            if np.any(treated_mask):\n",
    "                                att = np.average(Y_pred_treated[treated_mask] - Y_pred_control[treated_mask], \n",
    "                                               weights=W_train[treated_mask])\n",
    "                                \n",
    "                                # Calculate standard error (approximate)\n",
    "                                treatment_effects = Y_pred_treated[treated_mask] - Y_pred_control[treated_mask]\n",
    "                                residual = treatment_effects - att\n",
    "                                se = np.sqrt(np.sum((W_train[treated_mask] * residual) ** 2)) / np.sum(W_train[treated_mask])\n",
    "\n",
    "                                \n",
    "                                att_list.append(att)\n",
    "                                se_list.append(se)\n",
    "\n",
    "                            # Model performance metrics\n",
    "                            Y_pred = model.predict(X_train_with_T)\n",
    "                            residuals = Y_train - Y_pred\n",
    "                            rmse = mean_squared_error(Y_train, Y_pred, squared=False)\n",
    "                            r2 = r2_score(Y_train, Y_pred)\n",
    "                            r2_list.append(r2)\n",
    "                            rmse_list.append(rmse)\n",
    "                            \n",
    "                            # Collect residuals and fitted values for diagnostic plots\n",
    "                            group_residuals.append(residuals.values)\n",
    "                            group_fitted.append(Y_pred)\n",
    "\n",
    "                            smd, vr = calculate_smd_vr(X_train, T_train, W_train)\n",
    "                            smd_list.append(smd)\n",
    "                            vr_list.append(vr)\n",
    "                        except Exception as e:\n",
    "                            print(f\"⚠️ Error in {group}, seed {seed}, imp {imp}, rep {repeat}: {e}\")\n",
    "\n",
    "            if att_list:\n",
    "                att, se, ci_l, ci_u, p_val = rubins_pool(att_list, se_list)\n",
    "                avg_r2 = np.mean(r2_list)\n",
    "                avg_rmse = np.mean(rmse_list)\n",
    "                avg_smd = np.mean(smd_list)\n",
    "                avg_vr = np.mean(vr_list)\n",
    "\n",
    "                balance_results.append({\n",
    "                    \"group\": group, \"seed\": seed, \"smd\": avg_smd, \"vr\": avg_vr\n",
    "                })\n",
    "\n",
    "                if se < best_se:\n",
    "                    best_se = se\n",
    "                    best_result = {\n",
    "                        \"group\": group, \"seed\": seed, \"att\": att, \"se\": se,\n",
    "                        \"ci_lower\": ci_l, \"ci_upper\": ci_u, \"p_value\": p_val,\n",
    "                        \"r2\": avg_r2, \"rmse\": avg_rmse\n",
    "                    }\n",
    "\n",
    "                print(f\"✅ {group} | Seed {seed}: ATT = {att:.4f}, SE = {se:.4f}, p = {p_val}\")\n",
    "            else:\n",
    "                print(f\"⚠️ No valid results for {group} | Seed {seed}\")\n",
    "\n",
    "        # Create diagnostic plots for this group\n",
    "        if group_residuals and group_fitted:\n",
    "            create_diagnostic_plots(group_residuals, group_fitted, group)\n",
    "\n",
    "        if best_result:\n",
    "            att_results.append(best_result)\n",
    "            print(f\"🏆 Best result for {group} → Seed {best_result['seed']} | SE = {best_result['se']:.4f}\")\n",
    "\n",
    "    # Save final output\n",
    "    pd.DataFrame(att_results).to_excel(\"xgb_rubin_summary_subcats.xlsx\", index=False)\n",
    "    pd.DataFrame(balance_results).to_excel(\"smd_vr_summary_subcats.xlsx\", index=False)\n",
    "    print(\"\\n🎯 All summary files saved.\")\n",
    "\n",
    "run_xgboost_with_trimmed_data(final_covariates_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "7e354a90-c1e2-491d-9a6a-28dc4ac2cf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unweighted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "3e72bfe5-59ae-4ce7-bda2-80909a87b90f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Running XGBoost for SUBCAT_Antipsychotica_atypisch\n",
      "✅ SUBCAT_Antipsychotica_atypisch | Seed 1: ATT = -0.6518, SE = 2.0419, p = 0.75232\n",
      "✅ SUBCAT_Antipsychotica_atypisch | Seed 2: ATT = -0.9624, SE = 1.4914, p = 0.52486\n",
      "✅ SUBCAT_Antipsychotica_atypisch | Seed 3: ATT = -0.6041, SE = 1.5713, p = 0.70403\n",
      "✅ SUBCAT_Antipsychotica_atypisch | Seed 4: ATT = -0.8957, SE = 2.0290, p = 0.66285\n",
      "✅ SUBCAT_Antipsychotica_atypisch | Seed 5: ATT = -0.8422, SE = 1.9465, p = 0.66911\n",
      "✅ SUBCAT_Antipsychotica_atypisch | Seed 6: ATT = -1.1004, SE = 2.2366, p = 0.62720\n",
      "✅ SUBCAT_Antipsychotica_atypisch | Seed 7: ATT = -0.7453, SE = 1.8420, p = 0.68934\n",
      "✅ SUBCAT_Antipsychotica_atypisch | Seed 8: ATT = -0.7859, SE = 1.7412, p = 0.65580\n",
      "✅ SUBCAT_Antipsychotica_atypisch | Seed 9: ATT = -0.8629, SE = 2.6222, p = 0.74497\n",
      "✅ SUBCAT_Antipsychotica_atypisch | Seed 10: ATT = -1.1860, SE = 2.1617, p = 0.58832\n",
      "📊 Diagnostic plots saved for SUBCAT_Antipsychotica_atypisch\n",
      "🏆 Best result for SUBCAT_Antipsychotica_atypisch → Seed 2 | SE = 1.4914\n",
      "\n",
      "🚀 Running XGBoost for SUBCAT_TCA\n",
      "✅ SUBCAT_TCA | Seed 1: ATT = 2.2467, SE = 1.1176, p = 0.05576\n",
      "✅ SUBCAT_TCA | Seed 2: ATT = 2.3489, SE = 1.2469, p = 0.07177\n",
      "✅ SUBCAT_TCA | Seed 3: ATT = 2.3164, SE = 1.0688, p = 0.04037\n",
      "✅ SUBCAT_TCA | Seed 4: ATT = 2.2354, SE = 1.1845, p = 0.07128\n",
      "✅ SUBCAT_TCA | Seed 5: ATT = 2.4270, SE = 1.0046, p = 0.02367\n",
      "✅ SUBCAT_TCA | Seed 6: ATT = 2.3668, SE = 1.2427, p = 0.06890\n",
      "✅ SUBCAT_TCA | Seed 7: ATT = 2.3150, SE = 1.2119, p = 0.06813\n",
      "✅ SUBCAT_TCA | Seed 8: ATT = 2.2655, SE = 1.3358, p = 0.10283\n",
      "✅ SUBCAT_TCA | Seed 9: ATT = 2.2495, SE = 1.2531, p = 0.08523\n",
      "✅ SUBCAT_TCA | Seed 10: ATT = 2.3283, SE = 0.9758, p = 0.02527\n",
      "📊 Diagnostic plots saved for SUBCAT_TCA\n",
      "🏆 Best result for SUBCAT_TCA → Seed 10 | SE = 0.9758\n",
      "\n",
      "🚀 Running XGBoost for SUBCAT_SSRI\n",
      "✅ SUBCAT_SSRI | Seed 1: ATT = 0.2086, SE = 0.2459, p = 0.40479\n",
      "✅ SUBCAT_SSRI | Seed 2: ATT = 0.2325, SE = 0.3244, p = 0.48046\n",
      "✅ SUBCAT_SSRI | Seed 3: ATT = 0.2274, SE = 0.3878, p = 0.56298\n",
      "✅ SUBCAT_SSRI | Seed 4: ATT = 0.1996, SE = 0.3767, p = 0.60098\n",
      "✅ SUBCAT_SSRI | Seed 5: ATT = 0.1342, SE = 0.3468, p = 0.70213\n",
      "✅ SUBCAT_SSRI | Seed 6: ATT = 0.2276, SE = 0.2774, p = 0.42018\n",
      "✅ SUBCAT_SSRI | Seed 7: ATT = 0.2187, SE = 0.3280, p = 0.51122\n",
      "✅ SUBCAT_SSRI | Seed 8: ATT = 0.2076, SE = 0.3151, p = 0.51635\n",
      "✅ SUBCAT_SSRI | Seed 9: ATT = 0.2793, SE = 0.3963, p = 0.48770\n",
      "✅ SUBCAT_SSRI | Seed 10: ATT = 0.2153, SE = 0.3407, p = 0.53343\n",
      "📊 Diagnostic plots saved for SUBCAT_SSRI\n",
      "🏆 Best result for SUBCAT_SSRI → Seed 1 | SE = 0.2459\n",
      "\n",
      "🚀 Running XGBoost for SUBCAT_SNRI\n",
      "✅ SUBCAT_SNRI | Seed 1: ATT = 3.0641, SE = 1.8645, p = 0.11334\n",
      "✅ SUBCAT_SNRI | Seed 2: ATT = 3.2252, SE = 1.6305, p = 0.05952\n",
      "✅ SUBCAT_SNRI | Seed 3: ATT = 3.1145, SE = 1.7076, p = 0.08065\n",
      "✅ SUBCAT_SNRI | Seed 4: ATT = 3.0608, SE = 1.5839, p = 0.06519\n",
      "✅ SUBCAT_SNRI | Seed 5: ATT = 3.0239, SE = 1.3367, p = 0.03301\n",
      "✅ SUBCAT_SNRI | Seed 6: ATT = 3.0128, SE = 1.5395, p = 0.06208\n",
      "✅ SUBCAT_SNRI | Seed 7: ATT = 3.1160, SE = 1.7684, p = 0.09079\n",
      "✅ SUBCAT_SNRI | Seed 8: ATT = 3.1702, SE = 1.5708, p = 0.05488\n",
      "✅ SUBCAT_SNRI | Seed 9: ATT = 3.0567, SE = 1.5388, p = 0.05852\n",
      "✅ SUBCAT_SNRI | Seed 10: ATT = 3.1382, SE = 1.4952, p = 0.04654\n",
      "📊 Diagnostic plots saved for SUBCAT_SNRI\n",
      "🏆 Best result for SUBCAT_SNRI → Seed 5 | SE = 1.3367\n",
      "\n",
      "🚀 Running XGBoost for SUBCAT_Tetracyclische_antidepressiva\n",
      "✅ SUBCAT_Tetracyclische_antidepressiva | Seed 1: ATT = 5.7911, SE = 1.8495, p = 0.00453\n",
      "✅ SUBCAT_Tetracyclische_antidepressiva | Seed 2: ATT = 5.8245, SE = 2.0462, p = 0.00891\n",
      "✅ SUBCAT_Tetracyclische_antidepressiva | Seed 3: ATT = 5.8673, SE = 1.8981, p = 0.00499\n",
      "✅ SUBCAT_Tetracyclische_antidepressiva | Seed 4: ATT = 5.9391, SE = 1.5627, p = 0.00087\n",
      "✅ SUBCAT_Tetracyclische_antidepressiva | Seed 5: ATT = 5.9885, SE = 1.5675, p = 0.00083\n",
      "✅ SUBCAT_Tetracyclische_antidepressiva | Seed 6: ATT = 5.8928, SE = 1.8661, p = 0.00425\n",
      "✅ SUBCAT_Tetracyclische_antidepressiva | Seed 7: ATT = 5.9749, SE = 1.4899, p = 0.00051\n",
      "✅ SUBCAT_Tetracyclische_antidepressiva | Seed 8: ATT = 5.7346, SE = 2.0138, p = 0.00889\n",
      "✅ SUBCAT_Tetracyclische_antidepressiva | Seed 9: ATT = 5.6834, SE = 1.8340, p = 0.00490\n",
      "✅ SUBCAT_Tetracyclische_antidepressiva | Seed 10: ATT = 5.6171, SE = 1.5726, p = 0.00154\n",
      "📊 Diagnostic plots saved for SUBCAT_Tetracyclische_antidepressiva\n",
      "🏆 Best result for SUBCAT_Tetracyclische_antidepressiva → Seed 7 | SE = 1.4899\n",
      "\n",
      "🚀 Running XGBoost for SUBCAT_Antidepressiva_overige\n",
      "✅ SUBCAT_Antidepressiva_overige | Seed 1: ATT = 2.4530, SE = 1.9900, p = 0.22963\n",
      "✅ SUBCAT_Antidepressiva_overige | Seed 2: ATT = 2.7042, SE = 2.2681, p = 0.24482\n",
      "✅ SUBCAT_Antidepressiva_overige | Seed 3: ATT = 2.4556, SE = 2.3474, p = 0.30595\n",
      "✅ SUBCAT_Antidepressiva_overige | Seed 4: ATT = 2.4178, SE = 2.6751, p = 0.37508\n",
      "✅ SUBCAT_Antidepressiva_overige | Seed 5: ATT = 2.4640, SE = 2.3812, p = 0.31108\n",
      "✅ SUBCAT_Antidepressiva_overige | Seed 6: ATT = 2.5173, SE = 2.3867, p = 0.30206\n",
      "✅ SUBCAT_Antidepressiva_overige | Seed 7: ATT = 2.6255, SE = 2.0543, p = 0.21345\n",
      "✅ SUBCAT_Antidepressiva_overige | Seed 8: ATT = 2.5815, SE = 2.2186, p = 0.25604\n",
      "✅ SUBCAT_Antidepressiva_overige | Seed 9: ATT = 2.6589, SE = 2.2969, p = 0.25841\n",
      "✅ SUBCAT_Antidepressiva_overige | Seed 10: ATT = 2.5367, SE = 2.0578, p = 0.22963\n",
      "📊 Diagnostic plots saved for SUBCAT_Antidepressiva_overige\n",
      "🏆 Best result for SUBCAT_Antidepressiva_overige → Seed 1 | SE = 1.9900\n",
      "\n",
      "🚀 Running XGBoost for SUBCAT_Systemische_antihistaminica\n",
      "✅ SUBCAT_Systemische_antihistaminica | Seed 1: ATT = 1.6965, SE = 2.1834, p = 0.44475\n",
      "✅ SUBCAT_Systemische_antihistaminica | Seed 2: ATT = 1.7117, SE = 1.4376, p = 0.24541\n",
      "✅ SUBCAT_Systemische_antihistaminica | Seed 3: ATT = 1.8448, SE = 1.5703, p = 0.25162\n",
      "✅ SUBCAT_Systemische_antihistaminica | Seed 4: ATT = 1.4946, SE = 1.5597, p = 0.34747\n",
      "✅ SUBCAT_Systemische_antihistaminica | Seed 5: ATT = 1.8345, SE = 1.7118, p = 0.29450\n",
      "✅ SUBCAT_Systemische_antihistaminica | Seed 6: ATT = 1.8217, SE = 1.5812, p = 0.26061\n",
      "✅ SUBCAT_Systemische_antihistaminica | Seed 7: ATT = 1.5769, SE = 1.9483, p = 0.42624\n",
      "✅ SUBCAT_Systemische_antihistaminica | Seed 8: ATT = 1.7147, SE = 1.6061, p = 0.29634\n",
      "✅ SUBCAT_Systemische_antihistaminica | Seed 9: ATT = 1.5616, SE = 1.4644, p = 0.29686\n",
      "✅ SUBCAT_Systemische_antihistaminica | Seed 10: ATT = 1.4696, SE = 1.7345, p = 0.40520\n",
      "📊 Diagnostic plots saved for SUBCAT_Systemische_antihistaminica\n",
      "🏆 Best result for SUBCAT_Systemische_antihistaminica → Seed 2 | SE = 1.4376\n",
      "\n",
      "🚀 Running XGBoost for SUBCAT_anxiolytica_Benzodiazepine\n",
      "✅ SUBCAT_anxiolytica_Benzodiazepine | Seed 1: ATT = 0.7005, SE = 0.6283, p = 0.27594\n",
      "✅ SUBCAT_anxiolytica_Benzodiazepine | Seed 2: ATT = 0.7351, SE = 0.6055, p = 0.23653\n",
      "✅ SUBCAT_anxiolytica_Benzodiazepine | Seed 3: ATT = 0.7039, SE = 0.5338, p = 0.19977\n",
      "✅ SUBCAT_anxiolytica_Benzodiazepine | Seed 4: ATT = 0.7284, SE = 0.5930, p = 0.23121\n",
      "✅ SUBCAT_anxiolytica_Benzodiazepine | Seed 5: ATT = 0.6644, SE = 0.5388, p = 0.22948\n",
      "✅ SUBCAT_anxiolytica_Benzodiazepine | Seed 6: ATT = 0.6857, SE = 0.5696, p = 0.24044\n",
      "✅ SUBCAT_anxiolytica_Benzodiazepine | Seed 7: ATT = 0.7265, SE = 0.5810, p = 0.22322\n",
      "✅ SUBCAT_anxiolytica_Benzodiazepine | Seed 8: ATT = 0.7630, SE = 0.6264, p = 0.23503\n",
      "✅ SUBCAT_anxiolytica_Benzodiazepine | Seed 9: ATT = 0.7143, SE = 0.5533, p = 0.20900\n",
      "✅ SUBCAT_anxiolytica_Benzodiazepine | Seed 10: ATT = 0.6989, SE = 0.5544, p = 0.21953\n",
      "📊 Diagnostic plots saved for SUBCAT_anxiolytica_Benzodiazepine\n",
      "🏆 Best result for SUBCAT_anxiolytica_Benzodiazepine → Seed 3 | SE = 0.5338\n",
      "\n",
      "🚀 Running XGBoost for SUBCAT_hypnotica_Benzodiazepine\n",
      "✅ SUBCAT_hypnotica_Benzodiazepine | Seed 1: ATT = -0.8012, SE = 0.8022, p = 0.32784\n",
      "✅ SUBCAT_hypnotica_Benzodiazepine | Seed 2: ATT = -0.7322, SE = 0.8935, p = 0.42058\n",
      "✅ SUBCAT_hypnotica_Benzodiazepine | Seed 3: ATT = -0.7089, SE = 0.7035, p = 0.32369\n",
      "✅ SUBCAT_hypnotica_Benzodiazepine | Seed 4: ATT = -0.8092, SE = 0.7407, p = 0.28551\n",
      "✅ SUBCAT_hypnotica_Benzodiazepine | Seed 5: ATT = -0.7849, SE = 0.9199, p = 0.40199\n",
      "✅ SUBCAT_hypnotica_Benzodiazepine | Seed 6: ATT = -0.8834, SE = 0.8900, p = 0.33081\n",
      "✅ SUBCAT_hypnotica_Benzodiazepine | Seed 7: ATT = -0.8046, SE = 0.9423, p = 0.40159\n",
      "✅ SUBCAT_hypnotica_Benzodiazepine | Seed 8: ATT = -0.7121, SE = 0.7698, p = 0.36416\n",
      "✅ SUBCAT_hypnotica_Benzodiazepine | Seed 9: ATT = -0.7136, SE = 0.8456, p = 0.40704\n",
      "✅ SUBCAT_hypnotica_Benzodiazepine | Seed 10: ATT = -0.8317, SE = 0.9739, p = 0.40157\n",
      "📊 Diagnostic plots saved for SUBCAT_hypnotica_Benzodiazepine\n",
      "🏆 Best result for SUBCAT_hypnotica_Benzodiazepine → Seed 3 | SE = 0.7035\n",
      "\n",
      "🚀 Running XGBoost for SUBCAT_Amfetaminen\n",
      "✅ SUBCAT_Amfetaminen | Seed 1: ATT = 0.7753, SE = 1.7732, p = 0.66587\n",
      "✅ SUBCAT_Amfetaminen | Seed 2: ATT = 0.7822, SE = 1.7182, p = 0.65303\n",
      "✅ SUBCAT_Amfetaminen | Seed 3: ATT = 0.8043, SE = 1.9774, p = 0.68780\n",
      "✅ SUBCAT_Amfetaminen | Seed 4: ATT = 0.8033, SE = 1.7301, p = 0.64661\n",
      "✅ SUBCAT_Amfetaminen | Seed 5: ATT = 0.6545, SE = 1.5259, p = 0.67181\n",
      "✅ SUBCAT_Amfetaminen | Seed 6: ATT = 0.5794, SE = 1.5451, p = 0.71093\n",
      "✅ SUBCAT_Amfetaminen | Seed 7: ATT = 0.7809, SE = 1.7725, p = 0.66348\n",
      "✅ SUBCAT_Amfetaminen | Seed 8: ATT = 0.6817, SE = 1.7847, p = 0.70585\n",
      "✅ SUBCAT_Amfetaminen | Seed 9: ATT = 0.7250, SE = 1.8724, p = 0.70204\n",
      "✅ SUBCAT_Amfetaminen | Seed 10: ATT = 0.8364, SE = 1.5052, p = 0.58360\n",
      "📊 Diagnostic plots saved for SUBCAT_Amfetaminen\n",
      "🏆 Best result for SUBCAT_Amfetaminen → Seed 10 | SE = 1.5052\n",
      "\n",
      "🚀 Running XGBoost for SUBCAT_Paracetamol_mono\n",
      "✅ SUBCAT_Paracetamol_mono | Seed 1: ATT = 1.1099, SE = 2.3321, p = 0.63843\n",
      "✅ SUBCAT_Paracetamol_mono | Seed 2: ATT = 1.5200, SE = 2.5011, p = 0.54908\n",
      "✅ SUBCAT_Paracetamol_mono | Seed 3: ATT = 1.1555, SE = 2.4523, p = 0.64177\n",
      "✅ SUBCAT_Paracetamol_mono | Seed 4: ATT = 1.2644, SE = 2.1225, p = 0.55694\n",
      "✅ SUBCAT_Paracetamol_mono | Seed 5: ATT = 1.3599, SE = 2.4224, p = 0.57975\n",
      "✅ SUBCAT_Paracetamol_mono | Seed 6: ATT = 1.1734, SE = 2.0125, p = 0.56527\n",
      "✅ SUBCAT_Paracetamol_mono | Seed 7: ATT = 1.2068, SE = 2.2296, p = 0.59333\n",
      "✅ SUBCAT_Paracetamol_mono | Seed 8: ATT = 1.2402, SE = 2.4402, p = 0.61592\n",
      "✅ SUBCAT_Paracetamol_mono | Seed 9: ATT = 1.4779, SE = 2.6630, p = 0.58406\n",
      "✅ SUBCAT_Paracetamol_mono | Seed 10: ATT = 1.1612, SE = 2.2465, p = 0.60997\n",
      "📊 Diagnostic plots saved for SUBCAT_Paracetamol_mono\n",
      "🏆 Best result for SUBCAT_Paracetamol_mono → Seed 6 | SE = 2.0125\n",
      "\n",
      "🚀 Running XGBoost for SUBCAT_Anti_epileptica_stemmingsstabilisatoren\n",
      "✅ SUBCAT_Anti_epileptica_stemmingsstabilisatoren | Seed 1: ATT = 3.6564, SE = 2.0168, p = 0.08236\n",
      "✅ SUBCAT_Anti_epileptica_stemmingsstabilisatoren | Seed 2: ATT = 4.1219, SE = 2.2363, p = 0.07769\n",
      "✅ SUBCAT_Anti_epileptica_stemmingsstabilisatoren | Seed 3: ATT = 4.0547, SE = 2.4483, p = 0.11071\n",
      "✅ SUBCAT_Anti_epileptica_stemmingsstabilisatoren | Seed 4: ATT = 4.0751, SE = 2.0793, p = 0.06173\n",
      "✅ SUBCAT_Anti_epileptica_stemmingsstabilisatoren | Seed 5: ATT = 4.0854, SE = 1.9793, p = 0.04998\n",
      "✅ SUBCAT_Anti_epileptica_stemmingsstabilisatoren | Seed 6: ATT = 3.8769, SE = 2.9122, p = 0.19560\n",
      "✅ SUBCAT_Anti_epileptica_stemmingsstabilisatoren | Seed 7: ATT = 4.1256, SE = 2.2520, p = 0.07939\n",
      "✅ SUBCAT_Anti_epileptica_stemmingsstabilisatoren | Seed 8: ATT = 3.9695, SE = 2.4810, p = 0.12269\n",
      "✅ SUBCAT_Anti_epileptica_stemmingsstabilisatoren | Seed 9: ATT = 3.9356, SE = 2.6844, p = 0.15560\n",
      "✅ SUBCAT_Anti_epileptica_stemmingsstabilisatoren | Seed 10: ATT = 3.9852, SE = 2.3052, p = 0.09669\n",
      "📊 Diagnostic plots saved for SUBCAT_Anti_epileptica_stemmingsstabilisatoren\n",
      "🏆 Best result for SUBCAT_Anti_epileptica_stemmingsstabilisatoren → Seed 5 | SE = 1.9793\n",
      "\n",
      "🚀 Running XGBoost for SUBCAT_Opioden\n",
      "✅ SUBCAT_Opioden | Seed 1: ATT = 1.5236, SE = 2.3956, p = 0.53080\n",
      "✅ SUBCAT_Opioden | Seed 2: ATT = 1.7836, SE = 1.7372, p = 0.31478\n",
      "✅ SUBCAT_Opioden | Seed 3: ATT = 1.8287, SE = 1.8094, p = 0.32227\n",
      "✅ SUBCAT_Opioden | Seed 4: ATT = 1.9864, SE = 1.7733, p = 0.27372\n",
      "✅ SUBCAT_Opioden | Seed 5: ATT = 1.8329, SE = 1.6387, p = 0.27444\n",
      "✅ SUBCAT_Opioden | Seed 6: ATT = 1.8095, SE = 1.7259, p = 0.30488\n",
      "✅ SUBCAT_Opioden | Seed 7: ATT = 1.9543, SE = 1.9692, p = 0.33089\n",
      "✅ SUBCAT_Opioden | Seed 8: ATT = 1.5198, SE = 1.7480, p = 0.39320\n",
      "✅ SUBCAT_Opioden | Seed 9: ATT = 1.6666, SE = 1.4266, p = 0.25418\n",
      "✅ SUBCAT_Opioden | Seed 10: ATT = 1.4959, SE = 1.7143, p = 0.39153\n",
      "📊 Diagnostic plots saved for SUBCAT_Opioden\n",
      "🏆 Best result for SUBCAT_Opioden → Seed 9 | SE = 1.4266\n",
      "\n",
      "🚀 Running XGBoost for SUBCAT_Z_drugs\n",
      "✅ SUBCAT_Z_drugs | Seed 1: ATT = 4.9974, SE = 1.8740, p = 0.01350\n",
      "✅ SUBCAT_Z_drugs | Seed 2: ATT = 5.1104, SE = 2.0622, p = 0.02064\n",
      "✅ SUBCAT_Z_drugs | Seed 3: ATT = 5.0258, SE = 2.0727, p = 0.02321\n",
      "✅ SUBCAT_Z_drugs | Seed 4: ATT = 5.0790, SE = 2.0066, p = 0.01833\n",
      "✅ SUBCAT_Z_drugs | Seed 5: ATT = 4.7027, SE = 2.1530, p = 0.03894\n",
      "✅ SUBCAT_Z_drugs | Seed 6: ATT = 4.9990, SE = 2.2162, p = 0.03348\n",
      "✅ SUBCAT_Z_drugs | Seed 7: ATT = 5.0100, SE = 1.8101, p = 0.01070\n",
      "✅ SUBCAT_Z_drugs | Seed 8: ATT = 5.0717, SE = 1.9902, p = 0.01764\n",
      "✅ SUBCAT_Z_drugs | Seed 9: ATT = 5.0630, SE = 2.1446, p = 0.02670\n",
      "✅ SUBCAT_Z_drugs | Seed 10: ATT = 5.2677, SE = 2.2110, p = 0.02547\n",
      "📊 Diagnostic plots saved for SUBCAT_Z_drugs\n",
      "🏆 Best result for SUBCAT_Z_drugs → Seed 7 | SE = 1.8101\n",
      "\n",
      "🚀 Running XGBoost for SUBCAT_NSAIDs\n",
      "✅ SUBCAT_NSAIDs | Seed 1: ATT = 0.1120, SE = 1.9030, p = 0.95357\n",
      "✅ SUBCAT_NSAIDs | Seed 2: ATT = 0.2923, SE = 1.7992, p = 0.87229\n",
      "✅ SUBCAT_NSAIDs | Seed 3: ATT = 0.0139, SE = 2.3326, p = 0.99529\n",
      "✅ SUBCAT_NSAIDs | Seed 4: ATT = 0.1627, SE = 1.6165, p = 0.92066\n",
      "✅ SUBCAT_NSAIDs | Seed 5: ATT = 0.1832, SE = 1.7698, p = 0.91843\n",
      "✅ SUBCAT_NSAIDs | Seed 6: ATT = 0.2289, SE = 1.8184, p = 0.90087\n",
      "✅ SUBCAT_NSAIDs | Seed 7: ATT = -0.2260, SE = 1.9387, p = 0.90815\n",
      "✅ SUBCAT_NSAIDs | Seed 8: ATT = 0.0403, SE = 1.6141, p = 0.98028\n",
      "✅ SUBCAT_NSAIDs | Seed 9: ATT = 0.0269, SE = 1.4591, p = 0.98543\n",
      "✅ SUBCAT_NSAIDs | Seed 10: ATT = 0.1598, SE = 1.6946, p = 0.92564\n",
      "📊 Diagnostic plots saved for SUBCAT_NSAIDs\n",
      "🏆 Best result for SUBCAT_NSAIDs → Seed 9 | SE = 1.4591\n",
      "\n",
      "🎯 All summary files saved.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy.stats import t, probplot\n",
    "import xgboost as xgb\n",
    "\n",
    "# -----------------------------\n",
    "# Configuration\n",
    "# -----------------------------\n",
    "n_repeats = 1\n",
    "seeds = list(range(1, 11))\n",
    "imputations = 5\n",
    "output_folder = \"outputs\"\n",
    "\n",
    "# -----------------------------\n",
    "# Diagnostic Plotting Function\n",
    "# -----------------------------\n",
    "def create_diagnostic_plots(residuals_data, fitted_data, group_name):\n",
    "    \"\"\"Create 4 diagnostic plots for model validation\"\"\"\n",
    "    plots_dir = os.path.join(output_folder, \"plots\")\n",
    "    os.makedirs(plots_dir, exist_ok=True)\n",
    "    \n",
    "    # Flatten the collected data\n",
    "    all_residuals = np.concatenate(residuals_data)\n",
    "    all_fitted = np.concatenate(fitted_data)\n",
    "    \n",
    "    # Create figure with 2x2 subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    fig.suptitle(f'Diagnostic Plots - {group_name}', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. Residuals vs Fitted\n",
    "    axes[0,0].scatter(all_fitted, all_residuals, alpha=0.6, s=20)\n",
    "    axes[0,0].axhline(y=0, color='red', linestyle='--', alpha=0.8)\n",
    "    axes[0,0].set_xlabel('Fitted Values')\n",
    "    axes[0,0].set_ylabel('Residuals')\n",
    "    axes[0,0].set_title('Residuals vs Fitted')\n",
    "    axes[0,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. QQ Plot\n",
    "    probplot(all_residuals, dist=\"norm\", plot=axes[0,1])\n",
    "    axes[0,1].set_title('Q-Q Plot (Normal)')\n",
    "    axes[0,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Residual Histogram\n",
    "    axes[1,0].hist(all_residuals, bins=30, density=True, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    axes[1,0].set_xlabel('Residuals')\n",
    "    axes[1,0].set_ylabel('Density')\n",
    "    axes[1,0].set_title('Residual Distribution')\n",
    "    axes[1,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Scale-Location Plot\n",
    "    sqrt_abs_residuals = np.sqrt(np.abs(all_residuals))\n",
    "    axes[1,1].scatter(all_fitted, sqrt_abs_residuals, alpha=0.6, s=20)\n",
    "    axes[1,1].set_xlabel('Fitted Values')\n",
    "    axes[1,1].set_ylabel('√|Residuals|')\n",
    "    axes[1,1].set_title('Scale-Location Plot')\n",
    "    axes[1,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save plot\n",
    "    plot_filename = os.path.join(plots_dir, f'{group_name}_unweighted.png')\n",
    "    plt.savefig(plot_filename, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"📊 Diagnostic plots saved for {group_name}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Rubin's Rule\n",
    "# -----------------------------\n",
    "def rubins_pool(estimates, ses):\n",
    "    m = len(estimates)\n",
    "    q_bar = np.mean(estimates)\n",
    "    u_bar = np.mean(np.square(ses))\n",
    "    b_m = np.var(estimates, ddof=1)\n",
    "    total_var = u_bar + ((1 + 1/m) * b_m)\n",
    "    total_se = np.sqrt(total_var)\n",
    "    ci_lower = q_bar - 1.96 * total_se\n",
    "    ci_upper = q_bar + 1.96 * total_se\n",
    "    p_value = 2 * (1 - t.cdf(np.abs(q_bar / total_se), df=m-1))\n",
    "    rounded_p = round(p_value, 5)\n",
    "    formatted_p = \"< 0.00001\" if rounded_p <= 0.00001 else f\"{rounded_p:.5f}\"\n",
    "    return q_bar, total_se, ci_lower, ci_upper, formatted_p\n",
    "\n",
    "# -----------------------------\n",
    "# SMD + Variance Ratio\n",
    "# -----------------------------\n",
    "def calculate_smd_vr(X, T):\n",
    "    treated = X[T == 1]\n",
    "    control = X[T == 0]\n",
    "    smd, vr = [], []\n",
    "    for col in X.columns:\n",
    "        try:\n",
    "            m1, m0 = np.mean(treated[col]), np.mean(control[col])\n",
    "            s1 = np.std(treated[col])\n",
    "            s0 = np.std(control[col])\n",
    "            pooled_sd = np.sqrt((s1 ** 2 + s0 ** 2) / 2)\n",
    "            smd.append((m1 - m0) / pooled_sd if pooled_sd > 0 else 0)\n",
    "            vr.append(s1**2 / s0**2 if s0**2 > 0 else 0)\n",
    "        except Exception:\n",
    "            smd.append(np.nan)\n",
    "            vr.append(np.nan)\n",
    "    return np.nanmean(smd), np.nanmean(vr)\n",
    "\n",
    "# -----------------------------\n",
    "# XGBoost Main Loop (No DML)\n",
    "# -----------------------------\n",
    "def run_xgboost_with_trimmed_data(final_covariates_map):\n",
    "    att_results = []\n",
    "    balance_results = []\n",
    "\n",
    "    for group, covariates in final_covariates_map.items():\n",
    "        print(f\"\\n🚀 Running XGBoost for {group}\")\n",
    "        group_dir = os.path.join(output_folder, group)\n",
    "        os.makedirs(group_dir, exist_ok=True)\n",
    "\n",
    "        best_result = None\n",
    "        best_se = float(\"inf\")\n",
    "        \n",
    "        # Initialize lists to collect residuals and fitted values for diagnostic plots\n",
    "        group_residuals = []\n",
    "        group_fitted = []\n",
    "\n",
    "        for seed in seeds:\n",
    "            att_list, se_list, r2_list, rmse_list, smd_list, vr_list = [], [], [], [], [], []\n",
    "\n",
    "            for imp in range(1, imputations + 1):\n",
    "                file_path = os.path.join(group_dir, f\"trimmed_data_imp{imp}.pkl\")\n",
    "                if not os.path.exists(file_path):\n",
    "                    continue\n",
    "\n",
    "                df = pd.read_pickle(file_path)\n",
    "                if group not in df.columns or \"iptw\" not in df.columns:\n",
    "                    continue\n",
    "\n",
    "                X = df[covariates].copy()\n",
    "                T = df[group]\n",
    "                Y = df[\"caps5_change_baseline\"]\n",
    "                #W = df[\"iptw\"]\n",
    "\n",
    "                for repeat in range(n_repeats):\n",
    "                    kf = KFold(n_splits=5, shuffle=True, random_state=seed + repeat)\n",
    "                    for train_idx, test_idx in kf.split(X):\n",
    "                        try:\n",
    "                            X_train = X.iloc[train_idx]\n",
    "                            T_train = T.iloc[train_idx]\n",
    "                            Y_train = Y.iloc[train_idx]\n",
    "                            \n",
    "\n",
    "                            # XGBoost regression model\n",
    "                            model = xgb.XGBRegressor(n_estimators=100, max_depth=3, learning_rate=0.1, n_jobs=1, random_state=seed)\n",
    "                            \n",
    "                            # Add treatment variable to features\n",
    "                            X_train_with_T = X_train.copy()\n",
    "                            X_train_with_T[group] = T_train\n",
    "                            \n",
    "                            # Fit model\n",
    "                            model.fit(X_train_with_T, Y_train)\n",
    "                            \n",
    "                            # Predict outcomes for treated and control groups\n",
    "                            X_treated = X_train.copy()\n",
    "                            X_treated[group] = 1\n",
    "                            X_control = X_train.copy()\n",
    "                            X_control[group] = 0\n",
    "                            \n",
    "                            Y_pred_treated = model.predict(X_treated)\n",
    "                            Y_pred_control = model.predict(X_control)\n",
    "                            \n",
    "                            # Calculate ATT (Average Treatment Effect on Treated)\n",
    "                            treated_mask = T_train == 1\n",
    "                            if np.any(treated_mask):\n",
    "                                att = np.mean(Y_pred_treated[treated_mask] - Y_pred_control[treated_mask])\n",
    "                                \n",
    "                                # Calculate standard error (approximate)\n",
    "                                treatment_effects = Y_pred_treated[treated_mask] - Y_pred_control[treated_mask]\n",
    "                                residual = treatment_effects - att\n",
    "                                se = np.sqrt(np.sum((residual) ** 2)) / np.sum(treated_mask)\n",
    "                                att_list.append(att)\n",
    "                                se_list.append(se)\n",
    "\n",
    "                            # Model performance metrics\n",
    "                            Y_pred = model.predict(X_train_with_T)\n",
    "                            residuals = Y_train - Y_pred\n",
    "                            rmse = mean_squared_error(Y_train, Y_pred, squared=False)\n",
    "                            r2 = r2_score(Y_train, Y_pred)\n",
    "                            r2_list.append(r2)\n",
    "                            rmse_list.append(rmse)\n",
    "                            \n",
    "                            # Collect residuals and fitted values for diagnostic plots\n",
    "                            group_residuals.append(residuals.values)\n",
    "                            group_fitted.append(Y_pred)\n",
    "\n",
    "                            smd, vr = calculate_smd_vr(X_train, T_train)\n",
    "                            smd_list.append(smd)\n",
    "                            vr_list.append(vr)\n",
    "                        except Exception as e:\n",
    "                            print(f\"⚠️ Error in {group}, seed {seed}, imp {imp}, rep {repeat}: {e}\")\n",
    "\n",
    "            if att_list:\n",
    "                att, se, ci_l, ci_u, p_val = rubins_pool(att_list, se_list)\n",
    "                avg_r2 = np.mean(r2_list)\n",
    "                avg_rmse = np.mean(rmse_list)\n",
    "                avg_smd = np.mean(smd_list)\n",
    "                avg_vr = np.mean(vr_list)\n",
    "\n",
    "                balance_results.append({\n",
    "                    \"group\": group, \"seed\": seed, \"smd\": avg_smd, \"vr\": avg_vr\n",
    "                })\n",
    "\n",
    "                if se < best_se:\n",
    "                    best_se = se\n",
    "                    best_result = {\n",
    "                        \"group\": group, \"seed\": seed, \"att\": att, \"se\": se,\n",
    "                        \"ci_lower\": ci_l, \"ci_upper\": ci_u, \"p_value\": p_val,\n",
    "                        \"r2\": avg_r2, \"rmse\": avg_rmse\n",
    "                    }\n",
    "\n",
    "                print(f\"✅ {group} | Seed {seed}: ATT = {att:.4f}, SE = {se:.4f}, p = {p_val}\")\n",
    "            else:\n",
    "                print(f\"⚠️ No valid results for {group} | Seed {seed}\")\n",
    "\n",
    "        # Create diagnostic plots for this group\n",
    "        if group_residuals and group_fitted:\n",
    "            create_diagnostic_plots(group_residuals, group_fitted, group)\n",
    "\n",
    "        if best_result:\n",
    "            att_results.append(best_result)\n",
    "            print(f\"🏆 Best result for {group} → Seed {best_result['seed']} | SE = {best_result['se']:.4f}\")\n",
    "\n",
    "    # Save final output\n",
    "    pd.DataFrame(att_results).to_excel(\"xgb_rubin_summary_subcats_unweighted.xlsx\", index=False)\n",
    "    pd.DataFrame(balance_results).to_excel(\"smd_vr_summary_subcats_unweighted.xlsx\", index=False)\n",
    "    print(\"\\n🎯 All summary files saved.\")\n",
    "\n",
    "run_xgboost_with_trimmed_data(final_covariates_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "6d115ca6-36c5-48a5-b13c-4147a3a01119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Final_ATT_Summary_SubCat saved\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import sem, ttest_ind\n",
    "\n",
    "# ----------------------------------\n",
    "# File paths\n",
    "# ----------------------------------\n",
    "output_base = \"outputs\"\n",
    "att_file = \"xgb_rubin_summary_subcats.xlsx\"\n",
    "trimmed_file = \"trimmed_data_imp1.pkl\"\n",
    "auc_file = \"auc_scores.xlsx\"  \n",
    "\n",
    "# ----------------------------------\n",
    "# Load ATT Summary\n",
    "# ----------------------------------\n",
    "if os.path.exists(att_file):\n",
    "    att_df = pd.read_excel(att_file)\n",
    "else:\n",
    "    raise FileNotFoundError(\"❌ ATT summary file not found: xgb_rubin_summary_subcats.xlsx\")\n",
    "\n",
    "summary_rows = []\n",
    "\n",
    "# ----------------------------------\n",
    "# Loop over medication groups\n",
    "# ----------------------------------\n",
    "groups = [g for g in medication_groups if os.path.isdir(os.path.join(output_base, g))]\n",
    "\n",
    "for med in groups:\n",
    "    try:\n",
    "        group_path = os.path.join(output_base, med)\n",
    "\n",
    "        # Load trimmed data\n",
    "        df = pd.read_pickle(os.path.join(group_path, trimmed_file))\n",
    "\n",
    "        # Detect treatment column\n",
    "        treatment_cols = [col for col in df.columns if col.upper() == med.upper()]\n",
    "        if not treatment_cols:\n",
    "            print(f\"⚠️ Treatment column {med} not found in trimmed data. Skipping.\")\n",
    "            continue\n",
    "        treatment_var = treatment_cols[0]\n",
    "\n",
    "        # Extract treatment and outcome\n",
    "        T = df[treatment_var]\n",
    "        Y = df[\"caps5_change_baseline\"]\n",
    "\n",
    "        # Treated and control stats\n",
    "        treated = Y[T == 1]\n",
    "        control = Y[T == 0]\n",
    "\n",
    "        mean_treat = treated.mean()\n",
    "        se_treat = sem(treated) if len(treated) > 1 else np.nan\n",
    "\n",
    "        mean_ctrl = control.mean()\n",
    "        se_ctrl = sem(control) if len(control) > 1 else np.nan\n",
    "\n",
    "        # Cohen's d (unadjusted)\n",
    "        pooled_sd = np.sqrt(((treated.std() ** 2) + (control.std() ** 2)) / 2)\n",
    "        cohen_d = (mean_treat - mean_ctrl) / pooled_sd if pooled_sd > 0 else np.nan\n",
    "\n",
    "        # E-value (unadjusted)\n",
    "        delta = mean_treat - mean_ctrl\n",
    "        E = delta / abs(mean_ctrl) * 100 if mean_ctrl != 0 else np.nan\n",
    "\n",
    "        # Unadjusted p-value\n",
    "        try:\n",
    "            t_stat, p_val = ttest_ind(treated, control, equal_var=False, nan_policy=\"omit\")\n",
    "            rounded_p = round(p_val, 5)\n",
    "            formatted_p = \"< 0.00001\" if rounded_p < 0.00001 else rounded_p\n",
    "        except Exception:\n",
    "            formatted_p = np.nan\n",
    "\n",
    "        # AUC from new auc_scores.xlsx file\n",
    "        auc_val = np.nan\n",
    "        auc_path = os.path.join(group_path, auc_file)\n",
    "        if os.path.exists(auc_path):\n",
    "            auc_df = pd.read_excel(auc_path)\n",
    "            if \"AUC\" in auc_df.columns:\n",
    "                auc_val = auc_df[\"AUC\"].dropna().mean()\n",
    "\n",
    "        # Adjusted stats from Rubin summary\n",
    "        att_row = att_df[att_df[\"group\"].str.strip().str.upper() == med.strip().upper()]\n",
    "        if not att_row.empty:\n",
    "            att = att_row.iloc[0][\"att\"]\n",
    "            att_se = att_row.iloc[0][\"se\"]\n",
    "            att_p_val = att_row.iloc[0][\"p_value\"]\n",
    "            r2 = att_row.iloc[0][\"r2\"]\n",
    "            rmse = att_row.iloc[0][\"rmse\"]\n",
    "\n",
    "            try:\n",
    "                rounded_att_p = round(float(att_p_val), 5)\n",
    "                formatted_att_p = \"< 0.00001\" if rounded_att_p < 0.00001 else rounded_att_p\n",
    "            except:\n",
    "                formatted_att_p = att_p_val\n",
    "        else:\n",
    "            att, att_se, formatted_att_p, r2, rmse = np.nan, np.nan, np.nan, np.nan, np.nan\n",
    "\n",
    "        # Append full row\n",
    "        summary_rows.append({\n",
    "            'Medication Group': med,\n",
    "            'Mean Treated': mean_treat,\n",
    "            'SE Treated': se_treat,\n",
    "            'Mean Control': mean_ctrl,\n",
    "            'SE Control': se_ctrl,\n",
    "            'Cohen d': cohen_d,\n",
    "            'E (Unadjusted)': E,\n",
    "            'n Treated': len(treated),\n",
    "            'n Control': len(control),\n",
    "            #'Unadjusted p-value': formatted_p,\n",
    "            'ATT Estimate': att,\n",
    "            'ATT SE (Robust)': att_se,\n",
    "            'ATT p-value': formatted_att_p,\n",
    "            'R²': r2,\n",
    "            'RMSE': rmse,\n",
    "            'AUC': auc_val\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error in {med}: {e}\")\n",
    "\n",
    "# ----------------------------------\n",
    "# Save final summary\n",
    "# ----------------------------------\n",
    "summary_df = pd.DataFrame(summary_rows)\n",
    "summary_df = summary_df.sort_values(\"Medication Group\")\n",
    "summary_df.to_excel(\"Final_ATT_Summary_SubCat.xlsx\", index=False)\n",
    "print(\"✅ Final_ATT_Summary_SubCat saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "630929b1-b3f8-4767-8b90-68918d6543ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ xgb_att_barplot_subcat saved\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "# ✅ Load the final summary table\n",
    "final_df = pd.read_excel(\"Final_ATT_Summary_SubCat.xlsx\")\n",
    "\n",
    "# ✅ Parse DML p-values (handle \"< 0.00001\")\n",
    "def parse_pval(p):\n",
    "    try:\n",
    "        if isinstance(p, str) and \"<\" in p:\n",
    "            return 0.000001\n",
    "        return float(p)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "final_df['ATT p-value'] = final_df['ATT p-value'].apply(parse_pval)\n",
    "\n",
    "# ✅ Plot settings\n",
    "width = 0.35\n",
    "\n",
    "# ✅ Plotting function for a single medication group\n",
    "def plot_single_group(row):\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    bars1 = ax.bar(-width/2, row['Mean Control'], width, \n",
    "                   yerr=row['SE Control'], label='Control', hatch='//', color='gray', capsize=5)\n",
    "    bars2 = ax.bar(+width/2, row['Mean Treated'], width, \n",
    "                   yerr=row['SE Treated'], label='Treated', color='steelblue', capsize=5)\n",
    "\n",
    "    label = (\n",
    "        f\"ATT = {row['ATT Estimate']:.2f}\\n\"\n",
    "        f\"d = {row['Cohen d']:.2f}, p = {row['ATT p-value']:.3f}\\n\"\n",
    "        f\"nT = {row['n Treated']}, nC = {row['n Control']}\\n\"\n",
    "        f\"E = {row['E (Unadjusted)']:.1f}%\"\n",
    "    )\n",
    "    max_y = max(row['Mean Control'], row['Mean Treated']) + 1.5\n",
    "    ax.text(0, max_y, label, ha='center', va='bottom', fontsize=9, color='#FFD700')\n",
    "\n",
    "    ax.axhline(0, color='black', linewidth=0.8)\n",
    "    ax.set_xticks([-width/2, +width/2])\n",
    "    ax.set_xticklabels(['Control', 'Treated'])\n",
    "    ax.set_title(f\"Group: {row['Medication Group']}\", fontsize=12, weight='bold')\n",
    "    ax.set_ylabel(\"CAPS5 Change Score\")\n",
    "    ax.set_ylim(bottom=0, top=max_y + 2)\n",
    "    ax.legend()\n",
    "    fig.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# ✅ Generate and save all plots into a multi-page PDF\n",
    "with PdfPages(\"xgb_att_barplot_subcat.pdf\") as pdf:\n",
    "    for idx, row in final_df.iterrows():\n",
    "        fig = plot_single_group(row)\n",
    "        pdf.savefig(fig, dpi=300, bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "print(\"✅ xgb_att_barplot_subcat saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "2cccc7ca-28e3-40b5-a9ea-17419902df6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Love plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "d0812ab6-4512-4742-9f4d-26503f46c4ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Processing SUBCAT_Amfetaminen...\n",
      "📊 Exported numeric summary to: outputs\\SUBCAT_Amfetaminen\\covariate_balance_table_SUBCAT_Amfetaminen.xlsx\n",
      "✅ Saved love plot: outputs\\SUBCAT_Amfetaminen\\love_plot_SUBCAT_Amfetaminen.pdf\n",
      "📏 Max weighted SMD for SUBCAT_Amfetaminen: 0.339\n",
      "\n",
      "🔍 Processing SUBCAT_Antidepressiva_Overige...\n",
      "📊 Exported numeric summary to: outputs\\SUBCAT_Antidepressiva_Overige\\covariate_balance_table_SUBCAT_Antidepressiva_Overige.xlsx\n",
      "✅ Saved love plot: outputs\\SUBCAT_Antidepressiva_Overige\\love_plot_SUBCAT_Antidepressiva_Overige.pdf\n",
      "📏 Max weighted SMD for SUBCAT_Antidepressiva_Overige: 0.277\n",
      "\n",
      "🔍 Processing SUBCAT_Antipsychotica_Atypisch...\n",
      "📊 Exported numeric summary to: outputs\\SUBCAT_Antipsychotica_Atypisch\\covariate_balance_table_SUBCAT_Antipsychotica_Atypisch.xlsx\n",
      "✅ Saved love plot: outputs\\SUBCAT_Antipsychotica_Atypisch\\love_plot_SUBCAT_Antipsychotica_Atypisch.pdf\n",
      "📏 Max weighted SMD for SUBCAT_Antipsychotica_Atypisch: 0.579\n",
      "\n",
      "🔍 Processing SUBCAT_Anti_Epileptica_Stemmingsstabilisatoren...\n",
      "📊 Exported numeric summary to: outputs\\SUBCAT_Anti_Epileptica_Stemmingsstabilisatoren\\covariate_balance_table_SUBCAT_Anti_Epileptica_Stemmingsstabilisatoren.xlsx\n",
      "✅ Saved love plot: outputs\\SUBCAT_Anti_Epileptica_Stemmingsstabilisatoren\\love_plot_SUBCAT_Anti_Epileptica_Stemmingsstabilisatoren.pdf\n",
      "📏 Max weighted SMD for SUBCAT_Anti_Epileptica_Stemmingsstabilisatoren: 0.233\n",
      "\n",
      "🔍 Processing SUBCAT_Anxiolytica_Benzodiazepine...\n",
      "📊 Exported numeric summary to: outputs\\SUBCAT_Anxiolytica_Benzodiazepine\\covariate_balance_table_SUBCAT_Anxiolytica_Benzodiazepine.xlsx\n",
      "✅ Saved love plot: outputs\\SUBCAT_Anxiolytica_Benzodiazepine\\love_plot_SUBCAT_Anxiolytica_Benzodiazepine.pdf\n",
      "📏 Max weighted SMD for SUBCAT_Anxiolytica_Benzodiazepine: 0.145\n",
      "\n",
      "🔍 Processing SUBCAT_Hypnotica_Benzodiazepine...\n",
      "📊 Exported numeric summary to: outputs\\SUBCAT_Hypnotica_Benzodiazepine\\covariate_balance_table_SUBCAT_Hypnotica_Benzodiazepine.xlsx\n",
      "✅ Saved love plot: outputs\\SUBCAT_Hypnotica_Benzodiazepine\\love_plot_SUBCAT_Hypnotica_Benzodiazepine.pdf\n",
      "📏 Max weighted SMD for SUBCAT_Hypnotica_Benzodiazepine: 0.188\n",
      "\n",
      "🔍 Processing SUBCAT_Nsaids...\n",
      "📊 Exported numeric summary to: outputs\\SUBCAT_Nsaids\\covariate_balance_table_SUBCAT_Nsaids.xlsx\n",
      "✅ Saved love plot: outputs\\SUBCAT_Nsaids\\love_plot_SUBCAT_Nsaids.pdf\n",
      "📏 Max weighted SMD for SUBCAT_Nsaids: 0.238\n",
      "\n",
      "🔍 Processing SUBCAT_Opioden...\n",
      "📊 Exported numeric summary to: outputs\\SUBCAT_Opioden\\covariate_balance_table_SUBCAT_Opioden.xlsx\n",
      "✅ Saved love plot: outputs\\SUBCAT_Opioden\\love_plot_SUBCAT_Opioden.pdf\n",
      "📏 Max weighted SMD for SUBCAT_Opioden: 0.442\n",
      "\n",
      "🔍 Processing SUBCAT_Paracetamol_Mono...\n",
      "📊 Exported numeric summary to: outputs\\SUBCAT_Paracetamol_Mono\\covariate_balance_table_SUBCAT_Paracetamol_Mono.xlsx\n",
      "✅ Saved love plot: outputs\\SUBCAT_Paracetamol_Mono\\love_plot_SUBCAT_Paracetamol_Mono.pdf\n",
      "📏 Max weighted SMD for SUBCAT_Paracetamol_Mono: 0.267\n",
      "\n",
      "🔍 Processing SUBCAT_Snri...\n",
      "📊 Exported numeric summary to: outputs\\SUBCAT_Snri\\covariate_balance_table_SUBCAT_Snri.xlsx\n",
      "✅ Saved love plot: outputs\\SUBCAT_Snri\\love_plot_SUBCAT_Snri.pdf\n",
      "📏 Max weighted SMD for SUBCAT_Snri: 0.325\n",
      "\n",
      "🔍 Processing SUBCAT_Ssri...\n",
      "📊 Exported numeric summary to: outputs\\SUBCAT_Ssri\\covariate_balance_table_SUBCAT_Ssri.xlsx\n",
      "✅ Saved love plot: outputs\\SUBCAT_Ssri\\love_plot_SUBCAT_Ssri.pdf\n",
      "📏 Max weighted SMD for SUBCAT_Ssri: 0.186\n",
      "\n",
      "🔍 Processing SUBCAT_Systemische_Antihistaminica...\n",
      "📊 Exported numeric summary to: outputs\\SUBCAT_Systemische_Antihistaminica\\covariate_balance_table_SUBCAT_Systemische_Antihistaminica.xlsx\n",
      "✅ Saved love plot: outputs\\SUBCAT_Systemische_Antihistaminica\\love_plot_SUBCAT_Systemische_Antihistaminica.pdf\n",
      "📏 Max weighted SMD for SUBCAT_Systemische_Antihistaminica: 0.316\n",
      "\n",
      "🔍 Processing SUBCAT_Tca...\n",
      "📊 Exported numeric summary to: outputs\\SUBCAT_Tca\\covariate_balance_table_SUBCAT_Tca.xlsx\n",
      "✅ Saved love plot: outputs\\SUBCAT_Tca\\love_plot_SUBCAT_Tca.pdf\n",
      "📏 Max weighted SMD for SUBCAT_Tca: 0.336\n",
      "\n",
      "🔍 Processing SUBCAT_Tetracyclische_Antidepressiva...\n",
      "📊 Exported numeric summary to: outputs\\SUBCAT_Tetracyclische_Antidepressiva\\covariate_balance_table_SUBCAT_Tetracyclische_Antidepressiva.xlsx\n",
      "✅ Saved love plot: outputs\\SUBCAT_Tetracyclische_Antidepressiva\\love_plot_SUBCAT_Tetracyclische_Antidepressiva.pdf\n",
      "📏 Max weighted SMD for SUBCAT_Tetracyclische_Antidepressiva: 0.255\n",
      "\n",
      "🔍 Processing SUBCAT_Z_Drugs...\n",
      "📊 Exported numeric summary to: outputs\\SUBCAT_Z_Drugs\\covariate_balance_table_SUBCAT_Z_Drugs.xlsx\n",
      "✅ Saved love plot: outputs\\SUBCAT_Z_Drugs\\love_plot_SUBCAT_Z_Drugs.pdf\n",
      "📏 Max weighted SMD for SUBCAT_Z_Drugs: 0.179\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "# ----------------------------------------\n",
    "# Functions to calculate balance\n",
    "# ----------------------------------------\n",
    "def calculate_smd(x1, x2, w1=None, w2=None):\n",
    "    def weighted_mean(x, w): return np.average(x, weights=w)\n",
    "    def weighted_var(x, w):\n",
    "        m = np.average(x, weights=w)\n",
    "        return np.average((x - m) ** 2, weights=w)\n",
    "    \n",
    "    m1 = weighted_mean(x1, w1) if w1 is not None else np.mean(x1)\n",
    "    m2 = weighted_mean(x2, w2) if w2 is not None else np.mean(x2)\n",
    "    v1 = weighted_var(x1, w1) if w1 is not None else np.var(x1, ddof=1)\n",
    "    v2 = weighted_var(x2, w2) if w2 is not None else np.var(x2, ddof=1)\n",
    "    \n",
    "    pooled_sd = np.sqrt((v1 + v2) / 2)\n",
    "    return np.abs(m1 - m2) / pooled_sd if pooled_sd > 0 else 0\n",
    "\n",
    "def variance_ratio(x1, x2, w1=None, w2=None):\n",
    "    def weighted_var(x, w):\n",
    "        m = np.average(x, weights=w)\n",
    "        return np.average((x - m) ** 2, weights=w)\n",
    "    \n",
    "    v1 = weighted_var(x1, w1) if w1 is not None else np.var(x1, ddof=1)\n",
    "    v2 = weighted_var(x2, w2) if w2 is not None else np.var(x2, ddof=1)\n",
    "    \n",
    "    return max(v1 / v2, v2 / v1) if v1 > 0 and v2 > 0 else 1\n",
    "\n",
    "# ----------------------------------------\n",
    "# Setup\n",
    "# ----------------------------------------\n",
    "output_base = \"outputs\"\n",
    "groups = [g for g in os.listdir(output_base) if os.path.isdir(os.path.join(output_base, g))]\n",
    "\n",
    "# Create a case-insensitive mapping\n",
    "final_covariates_map_lower = {k.lower(): v for k, v in final_covariates_map.items()}\n",
    "\n",
    "# ----------------------------------------\n",
    "# Main Loop\n",
    "# ----------------------------------------\n",
    "for group in groups:\n",
    "    if group.lower() not in final_covariates_map_lower:\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n🔍 Processing {group}...\")\n",
    "\n",
    "    try:\n",
    "        group_path = os.path.join(output_base, group)\n",
    "        covariates = final_covariates_map_lower[group.lower()]\n",
    "        \n",
    "        column_name = None\n",
    "        for col in pd.read_pickle(os.path.join(group_path, \"trimmed_data_imp1.pkl\")).columns:\n",
    "            if col.lower() == group.lower():\n",
    "                column_name = col\n",
    "                break\n",
    "        if column_name is None:\n",
    "            print(f\"⚠️ Column not found for {group}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        smd_unw_all, smd_w_all = [], []\n",
    "        vr_unw_all, vr_w_all = [], []\n",
    "\n",
    "        for i in range(1, 6):\n",
    "            df_path = os.path.join(group_path, f\"trimmed_data_imp{i}.pkl\")\n",
    "            iptw_path = os.path.join(group_path, \"iptw_weights.xlsx\")\n",
    "\n",
    "            if not os.path.exists(df_path) or not os.path.exists(iptw_path):\n",
    "                print(f\"⚠️ Missing data for {group} imp{i}, skipping.\")\n",
    "                continue\n",
    "\n",
    "            df = pd.read_pickle(df_path)\n",
    "            iptw_df = pd.read_excel(iptw_path, index_col=0)\n",
    "            T = df[column_name]\n",
    "            W = iptw_df.loc[df.index, \"iptw_mean\"]\n",
    "\n",
    "            smd_unw_i, smd_w_i, vr_unw_i, vr_w_i = [], [], [], []\n",
    "\n",
    "            for cov in covariates:\n",
    "                x1, x0 = df.loc[T == 1, cov], df.loc[T == 0, cov]\n",
    "                w1, w0 = W[T == 1], W[T == 0]\n",
    "\n",
    "                su = calculate_smd(x1, x0)\n",
    "                sw = calculate_smd(x1, x0, w1, w0)\n",
    "\n",
    "                vu = variance_ratio(x1, x0) if cov in ['treatmentdurationdays', 'CAPS5score_baseline', 'age'] else np.nan\n",
    "                vw = variance_ratio(x1, x0, w1, w0) if cov in ['treatmentdurationdays', 'CAPS5score_baseline', 'age'] else np.nan\n",
    "\n",
    "                smd_unw_i.append(su)\n",
    "                smd_w_i.append(sw)\n",
    "                vr_unw_i.append(vu)\n",
    "                vr_w_i.append(vw)\n",
    "\n",
    "            smd_unw_all.append(smd_unw_i)\n",
    "            smd_w_all.append(smd_w_i)\n",
    "            vr_unw_all.append(vr_unw_i)\n",
    "            vr_w_all.append(vr_w_i)\n",
    "\n",
    "        smd_unw = np.mean(smd_unw_all, axis=0)\n",
    "        smd_w = np.mean(smd_w_all, axis=0)\n",
    "        vr_unw = np.nanmean(vr_unw_all, axis=0)\n",
    "        vr_w = np.nanmean(vr_w_all, axis=0)\n",
    "\n",
    "        severity = []\n",
    "        for sw in smd_w:\n",
    "            if sw <= 0.1:\n",
    "                severity.append(\"Good\")\n",
    "            elif sw <= 0.2:\n",
    "                severity.append(\"Moderate\")\n",
    "            else:\n",
    "                severity.append(\"Poor\")\n",
    "\n",
    "        covariate_names = covariates\n",
    "        numeric_df = pd.DataFrame({\n",
    "            \"Covariate\": covariate_names,\n",
    "            \"SMD_Unweighted\": smd_unw,\n",
    "            \"SMD_Weighted\": smd_w,\n",
    "            \"Imbalance_Severity\": severity,\n",
    "            \"VR_Unweighted\": vr_unw,\n",
    "            \"VR_Weighted\": vr_w\n",
    "        })\n",
    "\n",
    "        numeric_path = os.path.join(group_path, f\"covariate_balance_table_{group}.xlsx\")\n",
    "        numeric_df.to_excel(numeric_path, index=False)\n",
    "        print(f\"📊 Exported numeric summary to: {numeric_path}\")\n",
    "\n",
    "        # -------------------------\n",
    "        # Plot\n",
    "        # -------------------------\n",
    "        labels = covariates\n",
    "        y_pos = np.arange(len(labels))\n",
    "\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(18, len(labels) * 0.45))\n",
    "\n",
    "        axes[0].scatter(smd_unw, y_pos, color='red', label=\"Unweighted\")\n",
    "        axes[0].scatter(smd_w, y_pos, color='blue', label=\"Weighted\")\n",
    "        axes[0].axvline(0.1, color='gray', linestyle='--', label=\"Threshold 0.1\")\n",
    "        axes[0].axvline(0.2, color='black', linestyle='--', label=\"Threshold 0.2\")\n",
    "        axes[0].set_xlim(0, max(max(smd_unw), max(smd_w), 0.25) + 0.05)\n",
    "        axes[0].set_yticks(y_pos)\n",
    "        axes[0].set_yticklabels(labels)\n",
    "        axes[0].invert_yaxis()\n",
    "        axes[0].set_title(\"Standardized Mean Differences (SMD)\")\n",
    "        axes[0].legend(loc=\"upper right\")\n",
    "        axes[0].grid(True)\n",
    "\n",
    "        vr_mask = [cov in ['treatmentdurationdays', 'CAPS5score_baseline', 'age'] for cov in covariates]\n",
    "        filtered_y = [i for i, b in enumerate(vr_mask) if b]\n",
    "        filtered_labels = [labels[i] for i in filtered_y]\n",
    "        filtered_vr_unw = [vr_unw[i] for i in filtered_y]\n",
    "        filtered_vr_w = [vr_w[i] for i in filtered_y]\n",
    "\n",
    "        axes[1].scatter(filtered_vr_unw, filtered_y, color='blue', marker='o', label=\"Unweighted\")\n",
    "        axes[1].scatter(filtered_vr_w, filtered_y, color='red', marker='x', label=\"Weighted\")\n",
    "        axes[1].axvline(2, color='gray', linestyle='--')\n",
    "        axes[1].axvline(0.5, color='gray', linestyle='--')\n",
    "        axes[1].set_xlim(0, max(filtered_vr_unw + filtered_vr_w + [2.5]) + 0.5)\n",
    "        axes[1].set_yticks(filtered_y)\n",
    "        axes[1].set_yticklabels(filtered_labels)\n",
    "        axes[1].invert_yaxis()\n",
    "        axes[1].set_title(\"Variance Ratio (VR)\")\n",
    "        axes[1].legend()\n",
    "        axes[1].grid(True)\n",
    "\n",
    "        fig.suptitle(f\"Covariate Balance for {group.replace('CAT_', '')}\", fontsize=14, weight='bold')\n",
    "        fig.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "        plot_path = os.path.join(group_path, f\"love_plot_{group}.pdf\")\n",
    "        fig.savefig(plot_path, dpi=300)\n",
    "        plt.close()\n",
    "        print(f\"✅ Saved love plot: {plot_path}\")\n",
    "        print(f\"📏 Max weighted SMD for {group}: {np.max(smd_w):.3f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error in {group}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "ae62a1bf-fc01-4e72-b029-43d68b098e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "29d944cd-c180-4252-8adb-fef061de0ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Creating Heatmap for SUBCAT_Antipsychotica_atypisch ==========\n",
      "✅ Heatmap saved: outputs\\SUBCAT_Antipsychotica_atypisch\\heatmap_smd_SUBCAT_Antipsychotica_atypisch.png\n",
      "\n",
      "========== Creating Heatmap for SUBCAT_TCA ==========\n",
      "✅ Heatmap saved: outputs\\SUBCAT_TCA\\heatmap_smd_SUBCAT_TCA.png\n",
      "\n",
      "========== Creating Heatmap for SUBCAT_SSRI ==========\n",
      "✅ Heatmap saved: outputs\\SUBCAT_SSRI\\heatmap_smd_SUBCAT_SSRI.png\n",
      "\n",
      "========== Creating Heatmap for SUBCAT_SNRI ==========\n",
      "✅ Heatmap saved: outputs\\SUBCAT_SNRI\\heatmap_smd_SUBCAT_SNRI.png\n",
      "\n",
      "========== Creating Heatmap for SUBCAT_Tetracyclische_antidepressiva ==========\n",
      "✅ Heatmap saved: outputs\\SUBCAT_Tetracyclische_antidepressiva\\heatmap_smd_SUBCAT_Tetracyclische_antidepressiva.png\n",
      "\n",
      "========== Creating Heatmap for SUBCAT_Antidepressiva_overige ==========\n",
      "✅ Heatmap saved: outputs\\SUBCAT_Antidepressiva_overige\\heatmap_smd_SUBCAT_Antidepressiva_overige.png\n",
      "\n",
      "========== Creating Heatmap for SUBCAT_Systemische_antihistaminica ==========\n",
      "✅ Heatmap saved: outputs\\SUBCAT_Systemische_antihistaminica\\heatmap_smd_SUBCAT_Systemische_antihistaminica.png\n",
      "\n",
      "========== Creating Heatmap for SUBCAT_anxiolytica_Benzodiazepine ==========\n",
      "✅ Heatmap saved: outputs\\SUBCAT_anxiolytica_Benzodiazepine\\heatmap_smd_SUBCAT_anxiolytica_Benzodiazepine.png\n",
      "\n",
      "========== Creating Heatmap for SUBCAT_hypnotica_Benzodiazepine ==========\n",
      "✅ Heatmap saved: outputs\\SUBCAT_hypnotica_Benzodiazepine\\heatmap_smd_SUBCAT_hypnotica_Benzodiazepine.png\n",
      "\n",
      "========== Creating Heatmap for SUBCAT_Amfetaminen ==========\n",
      "✅ Heatmap saved: outputs\\SUBCAT_Amfetaminen\\heatmap_smd_SUBCAT_Amfetaminen.png\n",
      "\n",
      "========== Creating Heatmap for SUBCAT_Paracetamol_mono ==========\n",
      "✅ Heatmap saved: outputs\\SUBCAT_Paracetamol_mono\\heatmap_smd_SUBCAT_Paracetamol_mono.png\n",
      "\n",
      "========== Creating Heatmap for SUBCAT_Anti_epileptica_stemmingsstabilisatoren ==========\n",
      "✅ Heatmap saved: outputs\\SUBCAT_Anti_epileptica_stemmingsstabilisatoren\\heatmap_smd_SUBCAT_Anti_epileptica_stemmingsstabilisatoren.png\n",
      "\n",
      "========== Creating Heatmap for SUBCAT_Opioden ==========\n",
      "✅ Heatmap saved: outputs\\SUBCAT_Opioden\\heatmap_smd_SUBCAT_Opioden.png\n",
      "\n",
      "========== Creating Heatmap for SUBCAT_Z_drugs ==========\n",
      "✅ Heatmap saved: outputs\\SUBCAT_Z_drugs\\heatmap_smd_SUBCAT_Z_drugs.png\n",
      "\n",
      "========== Creating Heatmap for SUBCAT_NSAIDs ==========\n",
      "✅ Heatmap saved: outputs\\SUBCAT_NSAIDs\\heatmap_smd_SUBCAT_NSAIDs.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "#-----------------------------\n",
    "# Generate heatmaps\n",
    "# -------------------------------\n",
    "for treatment_var in medication_groups:\n",
    "    print(f\"\\n========== Creating Heatmap for {treatment_var} ==========\")\n",
    "\n",
    "    try:\n",
    "        output_folder = os.path.join('outputs', treatment_var)\n",
    "        balance_path = os.path.join(output_folder, f'covariate_balance_table_{treatment_var}.xlsx')\n",
    "\n",
    "        if not os.path.exists(balance_path):\n",
    "            print(f\"❌ Balance file not found: {balance_path}\")\n",
    "            continue\n",
    "\n",
    "        balance_df = pd.read_excel(balance_path)\n",
    "\n",
    "        # ✅ Use finalized covariates + 'Propensity Score'\n",
    "        covariates = final_covariates_map[treatment_var] + ['Propensity Score']\n",
    "        balance_df = balance_df[balance_df['Covariate'].isin(covariates)]\n",
    "\n",
    "        # ✅ Check for CAPS5score_baseline\n",
    "        highlight_caps = 'CAPS5score_baseline' in balance_df['Covariate'].values\n",
    "\n",
    "        # ✅ Format for heatmap\n",
    "        heatmap_df = balance_df[['Covariate', 'SMD_Unweighted', 'SMD_Weighted']].copy()\n",
    "        heatmap_df.columns = ['Covariate', 'Unweighted', 'Weighted']\n",
    "        heatmap_df = heatmap_df.set_index('Covariate')\n",
    "        heatmap_df = heatmap_df.sort_values(by='Unweighted', ascending=False)\n",
    "\n",
    "        # ✅ Plot\n",
    "        plt.figure(figsize=(12, max(10, len(heatmap_df) * 0.35)))\n",
    "        ax = sns.heatmap(\n",
    "            heatmap_df,\n",
    "            cmap=\"coolwarm\",\n",
    "            annot=True,\n",
    "            fmt=\".2f\",\n",
    "            linewidths=0.6,\n",
    "            linecolor='gray',\n",
    "            cbar_kws={\"label\": \"Standardized Mean Difference\"}\n",
    "        )\n",
    "\n",
    "        plt.title(f\"Covariate Balance Heatmap (Rubin IPTW)\\n{treatment_var}\", fontsize=15, weight='bold')\n",
    "        plt.xlabel(\"Condition\")\n",
    "        plt.ylabel(\"Covariate\")\n",
    "\n",
    "        # ✅ Bold CAPS5score_baseline if present\n",
    "        if highlight_caps:\n",
    "            ylabels = [label.get_text() for label in ax.get_yticklabels()]\n",
    "            ax.set_yticklabels([\n",
    "                f\"{label} ←\" if label == 'CAPS5score_baseline' else label for label in ylabels\n",
    "            ])\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # ✅ Save image\n",
    "        save_path = os.path.join(output_folder, f'heatmap_smd_{treatment_var}.png')\n",
    "        plt.savefig(save_path, dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "        print(f\"✅ Heatmap saved: {save_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error processing {treatment_var}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711a844e-e3d4-45d5-9781-c324f75d3fbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5fbd63cf-32bb-4417-99c9-b6748d051820",
   "metadata": {},
   "source": [
    "## SubSubCat Analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "262ea436-3978-4fab-a149-f0e3d43f04d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "covariates_SubSubCat_Oxazepam = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antidepressiva', 'CAT_Antipsychotica',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "covariates_SubSubCat_Diazepam = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antidepressiva', 'CAT_Antipsychotica',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "\n",
    "covariates_SubSubCat_Paracetamol = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antidepressiva',\n",
    "    'CAT_Antipsychotica',\n",
    "    'CAT_Benzodiazepine',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "covariates_SubSubCat_Lorazepam = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antidepressiva', 'CAT_Antipsychotica',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "covariates_SubSubCat_Mirtazapine = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antipsychotica',\n",
    "    'CAT_Benzodiazepine',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "covariates_SubSubCat_Escitalopram = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antipsychotica',\n",
    "    'CAT_Benzodiazepine',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "\n",
    "covariates_SubSubCat_Sertraline = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antipsychotica',\n",
    "    'CAT_Benzodiazepine',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "covariates_SubSubCat_Temazepam = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antidepressiva', 'CAT_Antipsychotica',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "covariates_SubSubCat_Citalopram = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antipsychotica',\n",
    "    'CAT_Benzodiazepine',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "covariates_SubSubCat_Quetiapine = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antidepressiva',\n",
    "    'CAT_Benzodiazepine',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "covariates_SubSubCat_Amitriptyline = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antipsychotica',\n",
    "    'CAT_Benzodiazepine',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "\n",
    "covariates_SubSubCat_Venlafaxine = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antipsychotica',\n",
    "    'CAT_Benzodiazepine',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "covariates_SubSubCat_Fluoxetine = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antipsychotica',\n",
    "    'CAT_Benzodiazepine',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "covariates_SubSubCat_Topiramaat = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antidepressiva',\n",
    "    'CAT_Antipsychotica',\n",
    "    'CAT_Benzodiazepine',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "covariates_SubSubCat_Zopiclon = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antidepressiva',\n",
    "    'CAT_Antipsychotica',\n",
    "    'CAT_Benzodiazepine',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "covariates_SubSubCat_Bupropion = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antipsychotica',\n",
    "    'CAT_Benzodiazepine',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "covariates_SubSubCat_Methylfenidaat = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antidepressiva',\n",
    "    'CAT_Antipsychotica',\n",
    "    'CAT_Benzodiazepine',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD',\n",
    "    'DIAGNOSIS_SEXUAL_TRAUMA', 'DIAGNOSIS_SUICIDALITY',\n",
    "    'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "covariates_SubSubCat_Olanzapine = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antidepressiva',\n",
    "    'CAT_Benzodiazepine',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "33230141-1b00-460e-b113-f27cd67a2e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groups found: ['SubSubCat_Oxazepam', 'SubSubCat_Diazepam', 'SubSubCat_Paracetamol', 'SubSubCat_Lorazepam', 'SubSubCat_Mirtazapine', 'SubSubCat_Escitalopram', 'SubSubCat_Sertraline', 'SubSubCat_Temazepam', 'SubSubCat_Citalopram', 'SubSubCat_Quetiapine', 'SubSubCat_Amitriptyline', 'SubSubCat_Venlafaxine', 'SubSubCat_Fluoxetine', 'SubSubCat_Topiramaat', 'SubSubCat_Zopiclon', 'SubSubCat_Bupropion', 'SubSubCat_Methylfenidaat', 'SubSubCat_Olanzapine']\n",
      "['SubSubCat_Oxazepam', 'SubSubCat_Diazepam', 'SubSubCat_Paracetamol', 'SubSubCat_Lorazepam', 'SubSubCat_Mirtazapine', 'SubSubCat_Escitalopram', 'SubSubCat_Sertraline', 'SubSubCat_Temazepam', 'SubSubCat_Citalopram', 'SubSubCat_Quetiapine', 'SubSubCat_Amitriptyline', 'SubSubCat_Venlafaxine', 'SubSubCat_Fluoxetine', 'SubSubCat_Topiramaat', 'SubSubCat_Zopiclon', 'SubSubCat_Bupropion', 'SubSubCat_Methylfenidaat', 'SubSubCat_Olanzapine']\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# This finds all variables that start with covariates_SUbSubCAT_ or covariates_SubSubcat_\n",
    "final_covariates_map = defaultdict(list)\n",
    "final_covariates_map.update({\n",
    "    var.replace(\"covariates_\", \"\"): val\n",
    "    for var, val in globals().items()\n",
    "    if var.lower().startswith(\"covariates_subsubcat_\") and isinstance(val, list)\n",
    "})\n",
    "\n",
    "# Show detected group names\n",
    "print(\"Groups found:\", list(final_covariates_map.keys()))\n",
    "medication_groups = list(final_covariates_map.keys())\n",
    "print(medication_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "00ef235f-c23f-4f2c-a4ba-4be21721cb19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Starting analysis for all SUBSUBCAT groups\n",
      "\n",
      " Processing SUBSUBCAT_Oxazepam...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBSUBCAT_Oxazepam\n",
      "\n",
      " Processing SUBSUBCAT_Diazepam...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBSUBCAT_Diazepam\n",
      "\n",
      " Processing SUBSUBCAT_Paracetamol...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBSUBCAT_Paracetamol\n",
      "\n",
      " Processing SUBSUBCAT_Lorazepam...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBSUBCAT_Lorazepam\n",
      "\n",
      " Processing SUBSUBCAT_Mirtazapine...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBSUBCAT_Mirtazapine\n",
      "\n",
      " Processing SUBSUBCAT_Escitalopram...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBSUBCAT_Escitalopram\n",
      "\n",
      " Processing SUBSUBCAT_Sertraline...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBSUBCAT_Sertraline\n",
      "\n",
      " Processing SUBSUBCAT_Temazepam...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBSUBCAT_Temazepam\n",
      "\n",
      " Processing SUBSUBCAT_Citalopram...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBSUBCAT_Citalopram\n",
      "\n",
      " Processing SUBSUBCAT_Quetiapine...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBSUBCAT_Quetiapine\n",
      "\n",
      " Processing SUBSUBCAT_Amitriptyline...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBSUBCAT_Amitriptyline\n",
      "\n",
      " Processing SUBSUBCAT_Venlafaxine...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBSUBCAT_Venlafaxine\n",
      "\n",
      " Processing SUBSUBCAT_Fluoxetine...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBSUBCAT_Fluoxetine\n",
      "\n",
      " Processing SUBSUBCAT_Topiramaat...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBSUBCAT_Topiramaat\n",
      "\n",
      " Processing SUBSUBCAT_Zopiclon...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBSUBCAT_Zopiclon\n",
      "\n",
      " Processing SUBSUBCAT_Bupropion...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBSUBCAT_Bupropion\n",
      "\n",
      " Processing SUBSUBCAT_Methylfenidaat...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBSUBCAT_Methylfenidaat\n",
      "\n",
      " Processing SUBSUBCAT_Olanzapine...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBSUBCAT_Olanzapine\n",
      "\n",
      " All SUBSUBCAT group analyses complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def run_all_SUBSUBCAT_group_models(imputed_dfs):\n",
    "    \"\"\"\n",
    "    Runs downstream analysis for each SUBSUBCAT medisubsubcation group using imputed datasets.\n",
    "\n",
    "    Parameters:\n",
    "    - imputed_dfs: list of 5 imputed DataFrames (from df_imputed_final_imp1.pkl ... imp5.pkl)\n",
    "    \n",
    "    Notes:\n",
    "    - Covariate lists must be defined as global variables: covariates_subsubcat_<group>\n",
    "    - Outputs are saved in: outputs/SUBSUBCAT_<GROUP>/\n",
    "    \"\"\"\n",
    "\n",
    "    print(\" Starting analysis for all SUBSUBCAT groups\")\n",
    "\n",
    "    for var_name in globals():\n",
    "        if var_name.lower().startswith(\"covariates_subsubcat_\") and isinstance(globals()[var_name], list):\n",
    "            group_name = var_name.replace(\"covariates_\", \"\")\n",
    "            group_name = group_name.replace(\"_\", \" \").title().replace(\" \", \"_\")  # e.g., subsubcat_z_drugs → Subsubcat_Z_Drugs\n",
    "            group_name = group_name.replace(\"Subsubcat_\", \"SUBSUBCAT_\")  # force prefix to uppercase\n",
    "\n",
    "            covariates = globals()[var_name]\n",
    "            output_dir = f\"outputs/{group_name}\"\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "            print(f\"\\n Processing {group_name}...\")\n",
    "\n",
    "            for k, df_imp in enumerate(imputed_dfs):\n",
    "                print(f\"  → Using imputation {k+1}\")\n",
    "\n",
    "                # Define X and Y\n",
    "                X = df_imp[covariates]\n",
    "                Y = df_imp[\"caps5_change_baseline\"]\n",
    "\n",
    "                # === Save X and Y as placeholder (replace with modeling later)\n",
    "                X.to_csv(f\"{output_dir}/X_imp{k+1}.csv\", index=False)\n",
    "                Y.to_frame(name=\"Y\").to_csv(f\"{output_dir}/Y_imp{k+1}.csv\", index=False)\n",
    "\n",
    "            print(f\" Done: {group_name}\")\n",
    "\n",
    "    print(\"\\n All SUBSUBCAT group analyses complete.\")\n",
    "\n",
    "# ========= STEP 4: Execute ========= #\n",
    "run_all_SUBSUBCAT_group_models(imputed_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "d4e790f5-0421-408b-b159-ea2b11e06d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " SubSubCat_Oxazepam\n",
      "  Imp 1: Treated = 206, Control = 3435, Missing = 0\n",
      "  Imp 2: Treated = 206, Control = 3435, Missing = 0\n",
      "  Imp 3: Treated = 206, Control = 3435, Missing = 0\n",
      "  Imp 4: Treated = 206, Control = 3435, Missing = 0\n",
      "  Imp 5: Treated = 206, Control = 3435, Missing = 0\n",
      "\n",
      " SubSubCat_Diazepam\n",
      "  Imp 1: Treated = 42, Control = 3599, Missing = 0\n",
      "  Imp 2: Treated = 42, Control = 3599, Missing = 0\n",
      "  Imp 3: Treated = 42, Control = 3599, Missing = 0\n",
      "  Imp 4: Treated = 42, Control = 3599, Missing = 0\n",
      "  Imp 5: Treated = 42, Control = 3599, Missing = 0\n",
      "\n",
      " SubSubCat_Paracetamol\n",
      "  Imp 1: Treated = 43, Control = 3598, Missing = 0\n",
      "  Imp 2: Treated = 43, Control = 3598, Missing = 0\n",
      "  Imp 3: Treated = 43, Control = 3598, Missing = 0\n",
      "  Imp 4: Treated = 43, Control = 3598, Missing = 0\n",
      "  Imp 5: Treated = 43, Control = 3598, Missing = 0\n",
      "\n",
      " SubSubCat_Lorazepam\n",
      "  Imp 1: Treated = 67, Control = 3574, Missing = 0\n",
      "  Imp 2: Treated = 67, Control = 3574, Missing = 0\n",
      "  Imp 3: Treated = 67, Control = 3574, Missing = 0\n",
      "  Imp 4: Treated = 67, Control = 3574, Missing = 0\n",
      "  Imp 5: Treated = 67, Control = 3574, Missing = 0\n",
      "\n",
      " SubSubCat_Mirtazapine\n",
      "  Imp 1: Treated = 87, Control = 3554, Missing = 0\n",
      "  Imp 2: Treated = 87, Control = 3554, Missing = 0\n",
      "  Imp 3: Treated = 87, Control = 3554, Missing = 0\n",
      "  Imp 4: Treated = 87, Control = 3554, Missing = 0\n",
      "  Imp 5: Treated = 87, Control = 3554, Missing = 0\n",
      "\n",
      " SubSubCat_Escitalopram\n",
      "  Imp 1: Treated = 69, Control = 3572, Missing = 0\n",
      "  Imp 2: Treated = 69, Control = 3572, Missing = 0\n",
      "  Imp 3: Treated = 69, Control = 3572, Missing = 0\n",
      "  Imp 4: Treated = 69, Control = 3572, Missing = 0\n",
      "  Imp 5: Treated = 69, Control = 3572, Missing = 0\n",
      "\n",
      " SubSubCat_Sertraline\n",
      "  Imp 1: Treated = 102, Control = 3539, Missing = 0\n",
      "  Imp 2: Treated = 102, Control = 3539, Missing = 0\n",
      "  Imp 3: Treated = 102, Control = 3539, Missing = 0\n",
      "  Imp 4: Treated = 102, Control = 3539, Missing = 0\n",
      "  Imp 5: Treated = 102, Control = 3539, Missing = 0\n",
      "\n",
      " SubSubCat_Temazepam\n",
      "  Imp 1: Treated = 93, Control = 3548, Missing = 0\n",
      "  Imp 2: Treated = 93, Control = 3548, Missing = 0\n",
      "  Imp 3: Treated = 93, Control = 3548, Missing = 0\n",
      "  Imp 4: Treated = 93, Control = 3548, Missing = 0\n",
      "  Imp 5: Treated = 93, Control = 3548, Missing = 0\n",
      "\n",
      " SubSubCat_Citalopram\n",
      "  Imp 1: Treated = 125, Control = 3516, Missing = 0\n",
      "  Imp 2: Treated = 125, Control = 3516, Missing = 0\n",
      "  Imp 3: Treated = 125, Control = 3516, Missing = 0\n",
      "  Imp 4: Treated = 125, Control = 3516, Missing = 0\n",
      "  Imp 5: Treated = 125, Control = 3516, Missing = 0\n",
      "\n",
      " SubSubCat_Quetiapine\n",
      "  Imp 1: Treated = 203, Control = 3438, Missing = 0\n",
      "  Imp 2: Treated = 203, Control = 3438, Missing = 0\n",
      "  Imp 3: Treated = 203, Control = 3438, Missing = 0\n",
      "  Imp 4: Treated = 203, Control = 3438, Missing = 0\n",
      "  Imp 5: Treated = 203, Control = 3438, Missing = 0\n",
      "\n",
      " SubSubCat_Amitriptyline\n",
      "  Imp 1: Treated = 52, Control = 3589, Missing = 0\n",
      "  Imp 2: Treated = 52, Control = 3589, Missing = 0\n",
      "  Imp 3: Treated = 52, Control = 3589, Missing = 0\n",
      "  Imp 4: Treated = 52, Control = 3589, Missing = 0\n",
      "  Imp 5: Treated = 52, Control = 3589, Missing = 0\n",
      "\n",
      " SubSubCat_Venlafaxine\n",
      "  Imp 1: Treated = 59, Control = 3582, Missing = 0\n",
      "  Imp 2: Treated = 59, Control = 3582, Missing = 0\n",
      "  Imp 3: Treated = 59, Control = 3582, Missing = 0\n",
      "  Imp 4: Treated = 59, Control = 3582, Missing = 0\n",
      "  Imp 5: Treated = 59, Control = 3582, Missing = 0\n",
      "\n",
      " SubSubCat_Fluoxetine\n",
      "  Imp 1: Treated = 71, Control = 3570, Missing = 0\n",
      "  Imp 2: Treated = 71, Control = 3570, Missing = 0\n",
      "  Imp 3: Treated = 71, Control = 3570, Missing = 0\n",
      "  Imp 4: Treated = 71, Control = 3570, Missing = 0\n",
      "  Imp 5: Treated = 71, Control = 3570, Missing = 0\n",
      "\n",
      " SubSubCat_Topiramaat\n",
      "  Imp 1: Treated = 41, Control = 3600, Missing = 0\n",
      "  Imp 2: Treated = 41, Control = 3600, Missing = 0\n",
      "  Imp 3: Treated = 41, Control = 3600, Missing = 0\n",
      "  Imp 4: Treated = 41, Control = 3600, Missing = 0\n",
      "  Imp 5: Treated = 41, Control = 3600, Missing = 0\n",
      "\n",
      " SubSubCat_Zopiclon\n",
      "  Imp 1: Treated = 32, Control = 3609, Missing = 0\n",
      "  Imp 2: Treated = 32, Control = 3609, Missing = 0\n",
      "  Imp 3: Treated = 32, Control = 3609, Missing = 0\n",
      "  Imp 4: Treated = 32, Control = 3609, Missing = 0\n",
      "  Imp 5: Treated = 32, Control = 3609, Missing = 0\n",
      "\n",
      " SubSubCat_Bupropion\n",
      "  Imp 1: Treated = 34, Control = 3607, Missing = 0\n",
      "  Imp 2: Treated = 34, Control = 3607, Missing = 0\n",
      "  Imp 3: Treated = 34, Control = 3607, Missing = 0\n",
      "  Imp 4: Treated = 34, Control = 3607, Missing = 0\n",
      "  Imp 5: Treated = 34, Control = 3607, Missing = 0\n",
      "\n",
      " SubSubCat_Methylfenidaat\n",
      "  Imp 1: Treated = 38, Control = 3603, Missing = 0\n",
      "  Imp 2: Treated = 38, Control = 3603, Missing = 0\n",
      "  Imp 3: Treated = 38, Control = 3603, Missing = 0\n",
      "  Imp 4: Treated = 38, Control = 3603, Missing = 0\n",
      "  Imp 5: Treated = 38, Control = 3603, Missing = 0\n",
      "\n",
      " SubSubCat_Olanzapine\n",
      "  Imp 1: Treated = 33, Control = 3608, Missing = 0\n",
      "  Imp 2: Treated = 33, Control = 3608, Missing = 0\n",
      "  Imp 3: Treated = 33, Control = 3608, Missing = 0\n",
      "  Imp 4: Treated = 33, Control = 3608, Missing = 0\n",
      "  Imp 5: Treated = 33, Control = 3608, Missing = 0\n"
     ]
    }
   ],
   "source": [
    "for treatment_var in medication_groups:\n",
    "    print(f\"\\n {treatment_var}\")\n",
    "    \n",
    "    for i, df in enumerate(imputed_dfs):\n",
    "        if treatment_var not in df.columns:\n",
    "            print(f\"  Imp {i+1}:  Not found in columns.\")\n",
    "            continue\n",
    "\n",
    "        treated = (df[treatment_var] == 1).sum()\n",
    "        control = (df[treatment_var] == 0).sum()\n",
    "        missing = df[treatment_var].isna().sum()\n",
    "\n",
    "        print(f\"  Imp {i+1}: Treated = {treated}, Control = {control}, Missing = {missing}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "07169c03-e41b-408d-b805-a8205c103695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Processing VIF for SubSubCat_Oxazepam\n",
      " ✅ Saved: outputs\\SubSubCat_Oxazepam/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SubSubCat_Diazepam\n",
      " ✅ Saved: outputs\\SubSubCat_Diazepam/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SubSubCat_Paracetamol\n",
      " ✅ Saved: outputs\\SubSubCat_Paracetamol/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SubSubCat_Lorazepam\n",
      " ✅ Saved: outputs\\SubSubCat_Lorazepam/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SubSubCat_Mirtazapine\n",
      " ✅ Saved: outputs\\SubSubCat_Mirtazapine/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SubSubCat_Escitalopram\n",
      " ✅ Saved: outputs\\SubSubCat_Escitalopram/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SubSubCat_Sertraline\n",
      " ✅ Saved: outputs\\SubSubCat_Sertraline/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SubSubCat_Temazepam\n",
      " ✅ Saved: outputs\\SubSubCat_Temazepam/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SubSubCat_Citalopram\n",
      " ✅ Saved: outputs\\SubSubCat_Citalopram/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SubSubCat_Quetiapine\n",
      " ✅ Saved: outputs\\SubSubCat_Quetiapine/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SubSubCat_Amitriptyline\n",
      " ✅ Saved: outputs\\SubSubCat_Amitriptyline/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SubSubCat_Venlafaxine\n",
      " ✅ Saved: outputs\\SubSubCat_Venlafaxine/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SubSubCat_Fluoxetine\n",
      " ✅ Saved: outputs\\SubSubCat_Fluoxetine/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SubSubCat_Topiramaat\n",
      " ✅ Saved: outputs\\SubSubCat_Topiramaat/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SubSubCat_Zopiclon\n",
      " ✅ Saved: outputs\\SubSubCat_Zopiclon/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SubSubCat_Bupropion\n",
      " ✅ Saved: outputs\\SubSubCat_Bupropion/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SubSubCat_Methylfenidaat\n",
      " ✅ Saved: outputs\\SubSubCat_Methylfenidaat/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SubSubCat_Olanzapine\n",
      " ✅ Saved: outputs\\SubSubCat_Olanzapine/pooled_vif.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from collections import defaultdict\n",
    "\n",
    "# ✅ VIF computation function\n",
    "def compute_vif(X):\n",
    "    X = sm.add_constant(X, has_constant='add')\n",
    "    vif_df = pd.DataFrame()\n",
    "    vif_df[\"variable\"] = X.columns\n",
    "    vif_df[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "    return vif_df\n",
    "\n",
    "# ✅ Process each group\n",
    "for group in medication_groups:\n",
    "    print(f\"\\n🔍 Processing VIF for {group}\")\n",
    "\n",
    "    if group not in final_covariates_map:\n",
    "        print(f\" ⚠️ No covariates found for {group}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    covariates = final_covariates_map[group]\n",
    "    vif_list = []\n",
    "\n",
    "    for i, df_imp in enumerate(imputed_dfs):\n",
    "        try:\n",
    "            X = df_imp[covariates].copy()\n",
    "            vif_df = compute_vif(X)\n",
    "            vif_df[\"imputation\"] = i + 1\n",
    "            vif_list.append(vif_df)\n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ Failed on imputation {i+1} for {group}: {e}\")\n",
    "\n",
    "    if vif_list:\n",
    "        all_vif = pd.concat(vif_list)\n",
    "        pooled_vif = all_vif.groupby(\"variable\")[\"VIF\"].mean().reset_index()\n",
    "        pooled_vif = pooled_vif.sort_values(by=\"VIF\", ascending=False)\n",
    "\n",
    "        output_folder = os.path.join(\"outputs\", group)\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        pooled_vif.to_csv(os.path.join(output_folder, \"pooled_vif.csv\"), index=False)\n",
    "\n",
    "        print(f\" ✅ Saved: {output_folder}/pooled_vif.csv\")\n",
    "    else:\n",
    "        print(f\" ⚠️ Skipped {group}: No valid imputations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "926d616b-8015-4b96-92be-8ab6124676ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Running PS estimation for SubSubCat_Oxazepam\n",
      "   Imp 1: AUC = 0.659, ROC saved.\n",
      "   Imp 2: AUC = 0.657, ROC saved.\n",
      "   Imp 3: AUC = 0.644, ROC saved.\n",
      "   Imp 4: AUC = 0.670, ROC saved.\n",
      "   Imp 5: AUC = 0.654, ROC saved.\n",
      " Composite PS + AUC saved for SubSubCat_Oxazepam\n",
      " Running PS estimation for SubSubCat_Diazepam\n",
      "   Imp 1: AUC = 0.737, ROC saved.\n",
      "   Imp 2: AUC = 0.721, ROC saved.\n",
      "   Imp 3: AUC = 0.731, ROC saved.\n",
      "   Imp 4: AUC = 0.750, ROC saved.\n",
      "   Imp 5: AUC = 0.725, ROC saved.\n",
      " Composite PS + AUC saved for SubSubCat_Diazepam\n",
      " Running PS estimation for SubSubCat_Paracetamol\n",
      "   Imp 1: AUC = 0.599, ROC saved.\n",
      "   Imp 2: AUC = 0.618, ROC saved.\n",
      "   Imp 3: AUC = 0.639, ROC saved.\n",
      "   Imp 4: AUC = 0.709, ROC saved.\n",
      "   Imp 5: AUC = 0.660, ROC saved.\n",
      " Composite PS + AUC saved for SubSubCat_Paracetamol\n",
      " Running PS estimation for SubSubCat_Lorazepam\n",
      "   Imp 1: AUC = 0.647, ROC saved.\n",
      "   Imp 2: AUC = 0.705, ROC saved.\n",
      "   Imp 3: AUC = 0.673, ROC saved.\n",
      "   Imp 4: AUC = 0.709, ROC saved.\n",
      "   Imp 5: AUC = 0.667, ROC saved.\n",
      " Composite PS + AUC saved for SubSubCat_Lorazepam\n",
      " Running PS estimation for SubSubCat_Mirtazapine\n",
      "   Imp 1: AUC = 0.610, ROC saved.\n",
      "   Imp 2: AUC = 0.571, ROC saved.\n",
      "   Imp 3: AUC = 0.627, ROC saved.\n",
      "   Imp 4: AUC = 0.609, ROC saved.\n",
      "   Imp 5: AUC = 0.664, ROC saved.\n",
      " Composite PS + AUC saved for SubSubCat_Mirtazapine\n",
      " Running PS estimation for SubSubCat_Escitalopram\n",
      "   Imp 1: AUC = 0.491, ROC saved.\n",
      "   Imp 2: AUC = 0.471, ROC saved.\n",
      "   Imp 3: AUC = 0.499, ROC saved.\n",
      "   Imp 4: AUC = 0.489, ROC saved.\n",
      "   Imp 5: AUC = 0.518, ROC saved.\n",
      " Composite PS + AUC saved for SubSubCat_Escitalopram\n",
      " Running PS estimation for SubSubCat_Sertraline\n",
      "   Imp 1: AUC = 0.692, ROC saved.\n",
      "   Imp 2: AUC = 0.696, ROC saved.\n",
      "   Imp 3: AUC = 0.701, ROC saved.\n",
      "   Imp 4: AUC = 0.694, ROC saved.\n",
      "   Imp 5: AUC = 0.693, ROC saved.\n",
      " Composite PS + AUC saved for SubSubCat_Sertraline\n",
      " Running PS estimation for SubSubCat_Temazepam\n",
      "   Imp 1: AUC = 0.564, ROC saved.\n",
      "   Imp 2: AUC = 0.524, ROC saved.\n",
      "   Imp 3: AUC = 0.565, ROC saved.\n",
      "   Imp 4: AUC = 0.511, ROC saved.\n",
      "   Imp 5: AUC = 0.542, ROC saved.\n",
      " Composite PS + AUC saved for SubSubCat_Temazepam\n",
      " Running PS estimation for SubSubCat_Citalopram\n",
      "   Imp 1: AUC = 0.653, ROC saved.\n",
      "   Imp 2: AUC = 0.660, ROC saved.\n",
      "   Imp 3: AUC = 0.664, ROC saved.\n",
      "   Imp 4: AUC = 0.651, ROC saved.\n",
      "   Imp 5: AUC = 0.657, ROC saved.\n",
      " Composite PS + AUC saved for SubSubCat_Citalopram\n",
      " Running PS estimation for SubSubCat_Quetiapine\n",
      "   Imp 1: AUC = 0.775, ROC saved.\n",
      "   Imp 2: AUC = 0.770, ROC saved.\n",
      "   Imp 3: AUC = 0.798, ROC saved.\n",
      "   Imp 4: AUC = 0.776, ROC saved.\n",
      "   Imp 5: AUC = 0.763, ROC saved.\n",
      " Composite PS + AUC saved for SubSubCat_Quetiapine\n",
      " Running PS estimation for SubSubCat_Amitriptyline\n",
      "   Imp 1: AUC = 0.543, ROC saved.\n",
      "   Imp 2: AUC = 0.526, ROC saved.\n",
      "   Imp 3: AUC = 0.488, ROC saved.\n",
      "   Imp 4: AUC = 0.526, ROC saved.\n",
      "   Imp 5: AUC = 0.608, ROC saved.\n",
      " Composite PS + AUC saved for SubSubCat_Amitriptyline\n",
      " Running PS estimation for SubSubCat_Venlafaxine\n",
      "   Imp 1: AUC = 0.692, ROC saved.\n",
      "   Imp 2: AUC = 0.715, ROC saved.\n",
      "   Imp 3: AUC = 0.617, ROC saved.\n",
      "   Imp 4: AUC = 0.683, ROC saved.\n",
      "   Imp 5: AUC = 0.704, ROC saved.\n",
      " Composite PS + AUC saved for SubSubCat_Venlafaxine\n",
      " Running PS estimation for SubSubCat_Fluoxetine\n",
      "   Imp 1: AUC = 0.698, ROC saved.\n",
      "   Imp 2: AUC = 0.674, ROC saved.\n",
      "   Imp 3: AUC = 0.666, ROC saved.\n",
      "   Imp 4: AUC = 0.732, ROC saved.\n",
      "   Imp 5: AUC = 0.709, ROC saved.\n",
      " Composite PS + AUC saved for SubSubCat_Fluoxetine\n",
      " Running PS estimation for SubSubCat_Topiramaat\n",
      "   Imp 1: AUC = 0.762, ROC saved.\n",
      "   Imp 2: AUC = 0.784, ROC saved.\n",
      "   Imp 3: AUC = 0.790, ROC saved.\n",
      "   Imp 4: AUC = 0.807, ROC saved.\n",
      "   Imp 5: AUC = 0.777, ROC saved.\n",
      " Composite PS + AUC saved for SubSubCat_Topiramaat\n",
      " Running PS estimation for SubSubCat_Zopiclon\n",
      "   Imp 1: AUC = 0.634, ROC saved.\n",
      "   Imp 2: AUC = 0.649, ROC saved.\n",
      "   Imp 3: AUC = 0.649, ROC saved.\n",
      "   Imp 4: AUC = 0.667, ROC saved.\n",
      "   Imp 5: AUC = 0.635, ROC saved.\n",
      " Composite PS + AUC saved for SubSubCat_Zopiclon\n",
      " Running PS estimation for SubSubCat_Bupropion\n",
      "   Imp 1: AUC = 0.524, ROC saved.\n",
      "   Imp 2: AUC = 0.561, ROC saved.\n",
      "   Imp 3: AUC = 0.496, ROC saved.\n",
      "   Imp 4: AUC = 0.547, ROC saved.\n",
      "   Imp 5: AUC = 0.544, ROC saved.\n",
      " Composite PS + AUC saved for SubSubCat_Bupropion\n",
      " Running PS estimation for SubSubCat_Methylfenidaat\n",
      "   Imp 1: AUC = 0.674, ROC saved.\n",
      "   Imp 2: AUC = 0.689, ROC saved.\n",
      "   Imp 3: AUC = 0.625, ROC saved.\n",
      "   Imp 4: AUC = 0.695, ROC saved.\n",
      "   Imp 5: AUC = 0.663, ROC saved.\n",
      " Composite PS + AUC saved for SubSubCat_Methylfenidaat\n",
      " Running PS estimation for SubSubCat_Olanzapine\n",
      "   Imp 1: AUC = 0.601, ROC saved.\n",
      "   Imp 2: AUC = 0.635, ROC saved.\n",
      "   Imp 3: AUC = 0.587, ROC saved.\n",
      "   Imp 4: AUC = 0.653, ROC saved.\n",
      "   Imp 5: AUC = 0.608, ROC saved.\n",
      " Composite PS + AUC saved for SubSubCat_Olanzapine\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ---------- PS Estimation Function ----------\n",
    "def run_xgboost_ps_modeling(imputed_dfs, medication_groups, final_covariates_map):\n",
    "    for group in medication_groups:\n",
    "        print(f\" Running PS estimation for {group}\")\n",
    "\n",
    "        if group not in final_covariates_map:\n",
    "            print(f\" No covariates found for {group}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        output_folder = os.path.join(\"outputs\", group)\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "        covariates = final_covariates_map[group]\n",
    "        ps_matrix = pd.DataFrame()\n",
    "        auc_list = []\n",
    "\n",
    "        for i, df_imp in enumerate(imputed_dfs):\n",
    "            if group not in df_imp.columns:\n",
    "                print(f\" {group} not found in imputed dataset {i+1}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            X = df_imp[covariates].copy()\n",
    "            T = df_imp[group]\n",
    "\n",
    "            # Drop missing treatment rows\n",
    "            valid_idx = T.dropna().index\n",
    "            X = X.loc[valid_idx]\n",
    "            T = T.loc[valid_idx]\n",
    "\n",
    "            # Train-test split for ROC\n",
    "            X_train, X_test, T_train, T_test = train_test_split(\n",
    "                X, T, stratify=T, test_size=0.3, random_state=42\n",
    "            )\n",
    "\n",
    "            try:\n",
    "                model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "                model.fit(X_train, T_train)\n",
    "\n",
    "                ps_scores = model.predict_proba(X)[:, 1]\n",
    "                ps_matrix[f\"ps_imp{i+1}\"] = pd.Series(ps_scores, index=valid_idx)\n",
    "\n",
    "                # ROC & AUC\n",
    "                auc = roc_auc_score(T_test, model.predict_proba(X_test)[:, 1])\n",
    "                auc_list.append(auc)\n",
    "\n",
    "                fpr, tpr, _ = roc_curve(T_test, model.predict_proba(X_test)[:, 1])\n",
    "                plt.figure()\n",
    "                plt.plot(fpr, tpr, label=f\"AUC = {auc:.3f}\")\n",
    "                plt.plot([0, 1], [0, 1], 'k--')\n",
    "                plt.xlabel(\"False Positive Rate\")\n",
    "                plt.ylabel(\"True Positive Rate\")\n",
    "                plt.title(f\"ROC Curve - {group} (Imp {i+1})\")\n",
    "                plt.legend()\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(os.path.join(output_folder, f\"roc_curve_imp{i+1}.png\"))\n",
    "                plt.close()\n",
    "                print(f\"   Imp {i+1}: AUC = {auc:.3f}, ROC saved.\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"   Error in {group} (imp {i+1}): {e}\")\n",
    "\n",
    "        # Save AUCs and Composite PS\n",
    "        if not ps_matrix.empty:\n",
    "            # Fill NaN rows (from dropped subjects in some imputations) with mean\n",
    "            ps_matrix[\"composite_ps\"] = ps_matrix.mean(axis=1)\n",
    "            ps_matrix.to_excel(os.path.join(output_folder, \"propensity_scores.xlsx\"))\n",
    "\n",
    "            auc_df = pd.DataFrame({\n",
    "                \"imputation\": [f\"imp{i+1}\" for i in range(len(auc_list))],\n",
    "                \"AUC\": auc_list\n",
    "            })\n",
    "            auc_df.loc[len(auc_df.index)] = [\"mean\", np.mean(auc_list) if auc_list else np.nan]\n",
    "            auc_df.to_excel(os.path.join(output_folder, \"auc_scores.xlsx\"), index=False)\n",
    "\n",
    "            print(f\" Composite PS + AUC saved for {group}\")\n",
    "        else:\n",
    "            print(f\" No valid PS scores generated for {group}\")\n",
    "\n",
    "# ---------- Run ----------\n",
    "run_xgboost_ps_modeling(imputed_dfs, medication_groups, final_covariates_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "e226945e-7d0a-45c7-b5bc-af3feda0e42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Computing feature importance for SubSubCat_Oxazepam\n",
      " Saved feature importance plot and CSV for SubSubCat_Oxazepam\n",
      "\n",
      " Computing feature importance for SubSubCat_Diazepam\n",
      " Saved feature importance plot and CSV for SubSubCat_Diazepam\n",
      "\n",
      " Computing feature importance for SubSubCat_Paracetamol\n",
      " Saved feature importance plot and CSV for SubSubCat_Paracetamol\n",
      "\n",
      " Computing feature importance for SubSubCat_Lorazepam\n",
      " Saved feature importance plot and CSV for SubSubCat_Lorazepam\n",
      "\n",
      " Computing feature importance for SubSubCat_Mirtazapine\n",
      " Saved feature importance plot and CSV for SubSubCat_Mirtazapine\n",
      "\n",
      " Computing feature importance for SubSubCat_Escitalopram\n",
      " Saved feature importance plot and CSV for SubSubCat_Escitalopram\n",
      "\n",
      " Computing feature importance for SubSubCat_Sertraline\n",
      " Saved feature importance plot and CSV for SubSubCat_Sertraline\n",
      "\n",
      " Computing feature importance for SubSubCat_Temazepam\n",
      " Saved feature importance plot and CSV for SubSubCat_Temazepam\n",
      "\n",
      " Computing feature importance for SubSubCat_Citalopram\n",
      " Saved feature importance plot and CSV for SubSubCat_Citalopram\n",
      "\n",
      " Computing feature importance for SubSubCat_Quetiapine\n",
      " Saved feature importance plot and CSV for SubSubCat_Quetiapine\n",
      "\n",
      " Computing feature importance for SubSubCat_Amitriptyline\n",
      " Saved feature importance plot and CSV for SubSubCat_Amitriptyline\n",
      "\n",
      " Computing feature importance for SubSubCat_Venlafaxine\n",
      " Saved feature importance plot and CSV for SubSubCat_Venlafaxine\n",
      "\n",
      " Computing feature importance for SubSubCat_Fluoxetine\n",
      " Saved feature importance plot and CSV for SubSubCat_Fluoxetine\n",
      "\n",
      " Computing feature importance for SubSubCat_Topiramaat\n",
      " Saved feature importance plot and CSV for SubSubCat_Topiramaat\n",
      "\n",
      " Computing feature importance for SubSubCat_Zopiclon\n",
      " Saved feature importance plot and CSV for SubSubCat_Zopiclon\n",
      "\n",
      " Computing feature importance for SubSubCat_Bupropion\n",
      " Saved feature importance plot and CSV for SubSubCat_Bupropion\n",
      "\n",
      " Computing feature importance for SubSubCat_Methylfenidaat\n",
      " Saved feature importance plot and CSV for SubSubCat_Methylfenidaat\n",
      "\n",
      " Computing feature importance for SubSubCat_Olanzapine\n",
      " Saved feature importance plot and CSV for SubSubCat_Olanzapine\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "def compute_feature_importance(imputed_dfs, medication_groups, final_covariates_map):\n",
    "    for group in medication_groups:\n",
    "        print(f\"\\n Computing feature importance for {group}\")\n",
    "\n",
    "        if group not in final_covariates_map:\n",
    "            print(f\" No covariates found for {group}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        covariates = final_covariates_map[group]\n",
    "        output_folder = os.path.join(\"outputs\", group)\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "        importance_df_list = []\n",
    "\n",
    "        for i, df_imp in enumerate(imputed_dfs):\n",
    "            if group not in df_imp.columns:\n",
    "                print(f\" {group} not in imputed dataset {i+1}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            X = df_imp[covariates].copy()\n",
    "            T = df_imp[group]\n",
    "\n",
    "            # Drop NaNs in treatment\n",
    "            valid_idx = T.dropna().index\n",
    "            X = X.loc[valid_idx]\n",
    "            T = T.loc[valid_idx]\n",
    "\n",
    "            try:\n",
    "                model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "                model.fit(X, T)\n",
    "\n",
    "                # Get feature importance\n",
    "                importances = model.get_booster().get_score(importance_type='gain')\n",
    "                df_feat = pd.DataFrame.from_dict(importances, orient='index', columns=[f\"imp{i+1}\"])\n",
    "                df_feat.index.name = 'feature'\n",
    "                importance_df_list.append(df_feat)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"   Error during modeling: {e}\")\n",
    "\n",
    "        if importance_df_list:\n",
    "            # Combine and average\n",
    "            all_feat = pd.concat(importance_df_list, axis=1).fillna(0)\n",
    "            all_feat[\"mean_importance\"] = all_feat.mean(axis=1)\n",
    "\n",
    "            # Filter top 30 non-zero\n",
    "            non_zero = all_feat[all_feat[\"mean_importance\"] > 0]\n",
    "            top30 = non_zero.sort_values(by=\"mean_importance\", ascending=False).head(30)\n",
    "\n",
    "            # Save to CSV\n",
    "            top30.to_csv(os.path.join(output_folder, \"feature_importance.csv\"))\n",
    "\n",
    "            # Plot\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            plt.barh(top30.index[::-1], top30[\"mean_importance\"][::-1])  # plot top → bottom\n",
    "            plt.xlabel(\"Mean Gain Importance\")\n",
    "            plt.title(f\"Top 30 Feature Importance - {group}\")\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(output_folder, \"feature_importance_top30.png\"))\n",
    "            plt.close()\n",
    "\n",
    "            print(f\" Saved feature importance plot and CSV for {group}\")\n",
    "        else:\n",
    "            print(f\" No valid models for {group}\")\n",
    "\n",
    "#  Run\n",
    "compute_feature_importance(imputed_dfs, medication_groups, final_covariates_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "ccef9e49-f14c-4092-b010-cfcc18a50be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SubSubCat_Oxazepam\n",
      "✅ Saved IPTW weights for SubSubCat_Oxazepam\n",
      "    ℹ️ Retained 592/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Oxazepam/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 615/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Oxazepam/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 619/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Oxazepam/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 585/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Oxazepam/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 590/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Oxazepam/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SubSubCat_Diazepam\n",
      "✅ Saved IPTW weights for SubSubCat_Diazepam\n",
      "    ℹ️ Retained 94/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Diazepam/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 98/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Diazepam/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 93/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Diazepam/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 97/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Diazepam/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 96/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Diazepam/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SubSubCat_Paracetamol\n",
      "✅ Saved IPTW weights for SubSubCat_Paracetamol\n",
      "    ℹ️ Retained 70/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Paracetamol/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 72/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Paracetamol/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 67/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Paracetamol/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 61/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Paracetamol/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 66/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Paracetamol/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SubSubCat_Lorazepam\n",
      "✅ Saved IPTW weights for SubSubCat_Lorazepam\n",
      "    ℹ️ Retained 144/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Lorazepam/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 137/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Lorazepam/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 149/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Lorazepam/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 138/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Lorazepam/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 137/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Lorazepam/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SubSubCat_Mirtazapine\n",
      "✅ Saved IPTW weights for SubSubCat_Mirtazapine\n",
      "    ℹ️ Retained 152/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Mirtazapine/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 178/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Mirtazapine/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 169/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Mirtazapine/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 170/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Mirtazapine/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 161/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Mirtazapine/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SubSubCat_Escitalopram\n",
      "✅ Saved IPTW weights for SubSubCat_Escitalopram\n",
      "    ℹ️ Retained 148/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Escitalopram/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 135/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Escitalopram/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 147/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Escitalopram/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 148/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Escitalopram/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 151/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Escitalopram/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SubSubCat_Sertraline\n",
      "✅ Saved IPTW weights for SubSubCat_Sertraline\n",
      "    ℹ️ Retained 235/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Sertraline/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 259/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Sertraline/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 250/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Sertraline/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 257/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Sertraline/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 237/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Sertraline/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SubSubCat_Temazepam\n",
      "✅ Saved IPTW weights for SubSubCat_Temazepam\n",
      "    ℹ️ Retained 188/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Temazepam/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 197/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Temazepam/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 210/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Temazepam/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 203/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Temazepam/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 198/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Temazepam/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SubSubCat_Citalopram\n",
      "✅ Saved IPTW weights for SubSubCat_Citalopram\n",
      "    ℹ️ Retained 339/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Citalopram/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 342/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Citalopram/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 369/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Citalopram/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 333/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Citalopram/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 334/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Citalopram/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SubSubCat_Quetiapine\n",
      "✅ Saved IPTW weights for SubSubCat_Quetiapine\n",
      "    ℹ️ Retained 490/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Quetiapine/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 509/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Quetiapine/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 495/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Quetiapine/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 480/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Quetiapine/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 491/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Quetiapine/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SubSubCat_Amitriptyline\n",
      "✅ Saved IPTW weights for SubSubCat_Amitriptyline\n",
      "    ℹ️ Retained 107/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Amitriptyline/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 102/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Amitriptyline/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 105/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Amitriptyline/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 104/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Amitriptyline/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 101/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Amitriptyline/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SubSubCat_Venlafaxine\n",
      "✅ Saved IPTW weights for SubSubCat_Venlafaxine\n",
      "    ℹ️ Retained 116/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Venlafaxine/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 112/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Venlafaxine/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 112/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Venlafaxine/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 123/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Venlafaxine/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 115/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Venlafaxine/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SubSubCat_Fluoxetine\n",
      "✅ Saved IPTW weights for SubSubCat_Fluoxetine\n",
      "    ℹ️ Retained 152/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Fluoxetine/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 149/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Fluoxetine/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 132/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Fluoxetine/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 152/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Fluoxetine/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 144/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Fluoxetine/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SubSubCat_Topiramaat\n",
      "✅ Saved IPTW weights for SubSubCat_Topiramaat\n",
      "    ℹ️ Retained 76/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Topiramaat/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 77/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Topiramaat/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 78/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Topiramaat/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 69/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Topiramaat/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 76/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Topiramaat/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SubSubCat_Zopiclon\n",
      "✅ Saved IPTW weights for SubSubCat_Zopiclon\n",
      "    ℹ️ Retained 62/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Zopiclon/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 66/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Zopiclon/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 65/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Zopiclon/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 67/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Zopiclon/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 62/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Zopiclon/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SubSubCat_Bupropion\n",
      "✅ Saved IPTW weights for SubSubCat_Bupropion\n",
      "    ℹ️ Retained 54/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Bupropion/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 60/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Bupropion/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 51/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Bupropion/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 57/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Bupropion/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 60/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Bupropion/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SubSubCat_Methylfenidaat\n",
      "✅ Saved IPTW weights for SubSubCat_Methylfenidaat\n",
      "    ℹ️ Retained 74/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Methylfenidaat/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 77/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Methylfenidaat/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 73/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Methylfenidaat/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 73/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Methylfenidaat/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 74/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Methylfenidaat/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SubSubCat_Olanzapine\n",
      "✅ Saved IPTW weights for SubSubCat_Olanzapine\n",
      "    ℹ️ Retained 59/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Olanzapine/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 61/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Olanzapine/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 64/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Olanzapine/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 56/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Olanzapine/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 53/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Olanzapine/trimmed_data_imp5.*\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_trimmed_clipped_iptw(ps_df, treatment, lower=0.05, upper=0.95, clip_max=10):\n",
    "    weights = []\n",
    "    keep_mask = (ps_df > lower) & (ps_df < upper)\n",
    "\n",
    "    for i in range(ps_df.shape[1]):\n",
    "        ps = ps_df.iloc[:, i].clip(lower=1e-6, upper=1 - 1e-6)  # avoid div by zero\n",
    "        mask = keep_mask.iloc[:, i]\n",
    "        w = pd.Series(np.nan, index=ps.index)\n",
    "\n",
    "        w[mask & (treatment == 1)] = 1 / ps[mask & (treatment == 1)]\n",
    "        w[mask & (treatment == 0)] = 1 / (1 - ps[mask & (treatment == 0)])\n",
    "        w = w.clip(upper=clip_max)\n",
    "        weights.append(w)\n",
    "\n",
    "    return pd.concat(weights, axis=1)\n",
    "\n",
    "\n",
    "def apply_rubins_rule_to_iptw(iptw_matrix):\n",
    "    \"\"\"\n",
    "    Given an IPTW matrix (n rows × M imputations), return Rubin’s rule pooled mean, SD, SE.\n",
    "    \"\"\"\n",
    "    M = iptw_matrix.shape[1]\n",
    "    q_bar = iptw_matrix.mean(axis=1)\n",
    "    u_bar = iptw_matrix.var(axis=1, ddof=1)\n",
    "    B = iptw_matrix.apply(lambda x: x.mean(), axis=1).var(ddof=1)\n",
    "    total_var = u_bar + (1 + 1/M) * B\n",
    "    total_se = np.sqrt(total_var)\n",
    "    return q_bar, u_bar.pow(0.5), total_se\n",
    "\n",
    "\n",
    "def run_trim_clip_save_all(imputed_dfs, medication_groups, final_covariates_map):\n",
    "    for group in medication_groups:\n",
    "        print(f\"\\n🔍 Processing IPTW + trimming + clipping for {group}\")\n",
    "        output_folder = os.path.join(\"outputs\", group)\n",
    "        ps_path = os.path.join(output_folder, \"propensity_scores.xlsx\")\n",
    "\n",
    "        if not os.path.exists(ps_path):\n",
    "            print(f\"⚠️ Missing PS file: {ps_path}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            ps_all = pd.read_excel(ps_path, index_col=0)\n",
    "            ps_cols = [col for col in ps_all.columns if col.startswith(\"ps_imp\")]\n",
    "            composite_index = ps_all.index\n",
    "\n",
    "            # Get treatment from one imputed dataset\n",
    "            T_full = None\n",
    "            for df in imputed_dfs:\n",
    "                if group in df.columns:\n",
    "                    T_full = df.loc[composite_index, group]\n",
    "                    break\n",
    "\n",
    "            if T_full is None:\n",
    "                print(f\"❌ Treatment column {group} not found in any imputed dataset.\")\n",
    "                continue\n",
    "\n",
    "            # Compute IPTW matrix (shape: n × M)\n",
    "            iptw_matrix = compute_trimmed_clipped_iptw(ps_all[ps_cols], T_full)\n",
    "            iptw_matrix.columns = [f\"iptw_imp{i+1}\" for i in range(iptw_matrix.shape[1])]\n",
    "\n",
    "            # Apply Rubin’s Rule for mean, SD, SE\n",
    "            iptw_matrix[\"iptw_mean\"], iptw_matrix[\"iptw_sd\"], iptw_matrix[\"iptw_se\"] = apply_rubins_rule_to_iptw(\n",
    "                iptw_matrix[[f\"iptw_imp{i+1}\" for i in range(iptw_matrix.shape[1])]]\n",
    "            )\n",
    "\n",
    "            # Save IPTW matrix separately\n",
    "            iptw_matrix.to_excel(os.path.join(output_folder, \"iptw_weights.xlsx\"))\n",
    "            print(f\"✅ Saved IPTW weights for {group}\")\n",
    "\n",
    "            # Save trimmed & clipped imputed datasets with IPTW\n",
    "            for i in range(5):\n",
    "                df = imputed_dfs[i].copy()\n",
    "                if group not in df.columns:\n",
    "                    continue\n",
    "\n",
    "                trimmed_idx = iptw_matrix.index.intersection(df.index)\n",
    "                needed_cols = final_covariates_map[group] + [group, \"caps5_change_baseline\"]\n",
    "\n",
    "                # Select only necessary columns\n",
    "                df_trimmed = df.loc[trimmed_idx, needed_cols].copy()\n",
    "                df_trimmed[\"iptw\"] = iptw_matrix[f\"iptw_imp{i+1}\"].loc[trimmed_idx]\n",
    "\n",
    "                # ✅ DROP rows with missing IPTW values\n",
    "                before = len(df_trimmed)\n",
    "                df_trimmed = df_trimmed.dropna(subset=[\"iptw\"])\n",
    "                after = len(df_trimmed)\n",
    "                print(f\"    ℹ️ Retained {after}/{before} rows after IPTW NaN drop.\")\n",
    "\n",
    "                # Save to .pkl\n",
    "                df_trimmed.to_pickle(os.path.join(output_folder, f\"trimmed_data_imp{i+1}.pkl\"))\n",
    "                print(f\"  💾 Saved trimmed dataset: {output_folder}/trimmed_data_imp{i+1}.*\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error in {group}: {e}\")\n",
    "\n",
    "\n",
    "run_trim_clip_save_all(imputed_dfs, medication_groups, final_covariates_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "9b4ab4ce-3b0b-4fa9-bd99-204c2a8c8d47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Plotting PS overlap for SubSubCat_Oxazepam\n",
      "✅ Saved unweighted and weighted PS plots for SubSubCat_Oxazepam\n",
      "\n",
      "📊 Plotting PS overlap for SubSubCat_Diazepam\n",
      "✅ Saved unweighted and weighted PS plots for SubSubCat_Diazepam\n",
      "\n",
      "📊 Plotting PS overlap for SubSubCat_Paracetamol\n",
      "✅ Saved unweighted and weighted PS plots for SubSubCat_Paracetamol\n",
      "\n",
      "📊 Plotting PS overlap for SubSubCat_Lorazepam\n",
      "✅ Saved unweighted and weighted PS plots for SubSubCat_Lorazepam\n",
      "\n",
      "📊 Plotting PS overlap for SubSubCat_Mirtazapine\n",
      "✅ Saved unweighted and weighted PS plots for SubSubCat_Mirtazapine\n",
      "\n",
      "📊 Plotting PS overlap for SubSubCat_Escitalopram\n",
      "✅ Saved unweighted and weighted PS plots for SubSubCat_Escitalopram\n",
      "\n",
      "📊 Plotting PS overlap for SubSubCat_Sertraline\n",
      "✅ Saved unweighted and weighted PS plots for SubSubCat_Sertraline\n",
      "\n",
      "📊 Plotting PS overlap for SubSubCat_Temazepam\n",
      "✅ Saved unweighted and weighted PS plots for SubSubCat_Temazepam\n",
      "\n",
      "📊 Plotting PS overlap for SubSubCat_Citalopram\n",
      "✅ Saved unweighted and weighted PS plots for SubSubCat_Citalopram\n",
      "\n",
      "📊 Plotting PS overlap for SubSubCat_Quetiapine\n",
      "✅ Saved unweighted and weighted PS plots for SubSubCat_Quetiapine\n",
      "\n",
      "📊 Plotting PS overlap for SubSubCat_Amitriptyline\n",
      "✅ Saved unweighted and weighted PS plots for SubSubCat_Amitriptyline\n",
      "\n",
      "📊 Plotting PS overlap for SubSubCat_Venlafaxine\n",
      "✅ Saved unweighted and weighted PS plots for SubSubCat_Venlafaxine\n",
      "\n",
      "📊 Plotting PS overlap for SubSubCat_Fluoxetine\n",
      "✅ Saved unweighted and weighted PS plots for SubSubCat_Fluoxetine\n",
      "\n",
      "📊 Plotting PS overlap for SubSubCat_Topiramaat\n",
      "✅ Saved unweighted and weighted PS plots for SubSubCat_Topiramaat\n",
      "\n",
      "📊 Plotting PS overlap for SubSubCat_Zopiclon\n",
      "✅ Saved unweighted and weighted PS plots for SubSubCat_Zopiclon\n",
      "\n",
      "📊 Plotting PS overlap for SubSubCat_Bupropion\n",
      "✅ Saved unweighted and weighted PS plots for SubSubCat_Bupropion\n",
      "\n",
      "📊 Plotting PS overlap for SubSubCat_Methylfenidaat\n",
      "✅ Saved unweighted and weighted PS plots for SubSubCat_Methylfenidaat\n",
      "\n",
      "📊 Plotting PS overlap for SubSubCat_Olanzapine\n",
      "✅ Saved unweighted and weighted PS plots for SubSubCat_Olanzapine\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_ps_overlap_all_groups(medication_groups):\n",
    "    for group in medication_groups:\n",
    "        print(f\"\\n📊 Plotting PS overlap for {group}\")\n",
    "\n",
    "        folder = os.path.join(\"outputs\", group)\n",
    "        ps_file = os.path.join(folder, \"propensity_scores.xlsx\")\n",
    "        iptw_file = os.path.join(folder, \"iptw_weights.xlsx\")\n",
    "        trimmed_file = os.path.join(folder, \"trimmed_data_imp1.pkl\")\n",
    "\n",
    "        if not all(os.path.exists(f) for f in [ps_file, iptw_file, trimmed_file]):\n",
    "            print(f\"⚠️ Missing required files for {group}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            ps_df = pd.read_excel(ps_file, index_col=0)\n",
    "            iptw_df = pd.read_excel(iptw_file, index_col=0)\n",
    "            trimmed_df = pd.read_pickle(trimmed_file)\n",
    "\n",
    "            # Extract\n",
    "            ps = ps_df[\"composite_ps\"].reindex(trimmed_df.index)\n",
    "            w = iptw_df[\"iptw_mean\"].reindex(trimmed_df.index)\n",
    "            T = trimmed_df[group]\n",
    "\n",
    "            # Masks to remove NaNs\n",
    "            treated_mask = (T == 1) & ps.notna() & w.notna()\n",
    "            control_mask = (T == 0) & ps.notna() & w.notna()\n",
    "\n",
    "            treated = ps[treated_mask]\n",
    "            treated_w = w[treated_mask]\n",
    "\n",
    "            control = ps[control_mask]\n",
    "            control_w = w[control_mask]\n",
    "\n",
    "            # === Unweighted Plot ===\n",
    "            plt.figure(figsize=(8, 5))\n",
    "            plt.hist([treated, control], bins=25, label=[\"Treated\", \"Control\"], alpha=0.6)\n",
    "            plt.title(f\"Unweighted PS Overlap - {group}\")\n",
    "            plt.xlabel(\"Composite Propensity Score\")\n",
    "            plt.ylabel(\"Count\")\n",
    "            plt.legend()\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(folder, \"ps_overlap_unweighted.png\"))\n",
    "            plt.close()\n",
    "\n",
    "            # === Weighted Plot ===\n",
    "            plt.figure(figsize=(8, 5))\n",
    "            plt.hist([treated, control], bins=25, weights=[treated_w, control_w], label=[\"Treated\", \"Control\"], alpha=0.6)\n",
    "            plt.title(f\"Weighted PS Overlap - {group}\")\n",
    "            plt.xlabel(\"Composite Propensity Score\")\n",
    "            plt.ylabel(\"Weighted Count\")\n",
    "            plt.legend()\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(folder, \"ps_overlap_weighted.png\"))\n",
    "            plt.close()\n",
    "\n",
    "            print(f\"✅ Saved unweighted and weighted PS plots for {group}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error processing {group}: {e}\")\n",
    "\n",
    "# 🔁 Run\n",
    "plot_ps_overlap_all_groups(medication_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "641bfc1a-fb30-4961-917d-ebe4ebcd2912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ✅ Saved: outputs\\SubSubCat_Oxazepam\\four_panel_overlap_SubSubCat_Oxazepam.png\n",
      " ✅ Saved: outputs\\SubSubCat_Diazepam\\four_panel_overlap_SubSubCat_Diazepam.png\n",
      " ✅ Saved: outputs\\SubSubCat_Paracetamol\\four_panel_overlap_SubSubCat_Paracetamol.png\n",
      " ✅ Saved: outputs\\SubSubCat_Lorazepam\\four_panel_overlap_SubSubCat_Lorazepam.png\n",
      " ✅ Saved: outputs\\SubSubCat_Mirtazapine\\four_panel_overlap_SubSubCat_Mirtazapine.png\n",
      " ✅ Saved: outputs\\SubSubCat_Escitalopram\\four_panel_overlap_SubSubCat_Escitalopram.png\n",
      " ✅ Saved: outputs\\SubSubCat_Sertraline\\four_panel_overlap_SubSubCat_Sertraline.png\n",
      " ✅ Saved: outputs\\SubSubCat_Temazepam\\four_panel_overlap_SubSubCat_Temazepam.png\n",
      " ✅ Saved: outputs\\SubSubCat_Citalopram\\four_panel_overlap_SubSubCat_Citalopram.png\n",
      " ✅ Saved: outputs\\SubSubCat_Quetiapine\\four_panel_overlap_SubSubCat_Quetiapine.png\n",
      " ✅ Saved: outputs\\SubSubCat_Amitriptyline\\four_panel_overlap_SubSubCat_Amitriptyline.png\n",
      " ✅ Saved: outputs\\SubSubCat_Venlafaxine\\four_panel_overlap_SubSubCat_Venlafaxine.png\n",
      " ✅ Saved: outputs\\SubSubCat_Fluoxetine\\four_panel_overlap_SubSubCat_Fluoxetine.png\n",
      " ✅ Saved: outputs\\SubSubCat_Topiramaat\\four_panel_overlap_SubSubCat_Topiramaat.png\n",
      " ✅ Saved: outputs\\SubSubCat_Zopiclon\\four_panel_overlap_SubSubCat_Zopiclon.png\n",
      " ✅ Saved: outputs\\SubSubCat_Bupropion\\four_panel_overlap_SubSubCat_Bupropion.png\n",
      " ✅ Saved: outputs\\SubSubCat_Methylfenidaat\\four_panel_overlap_SubSubCat_Methylfenidaat.png\n",
      " ✅ Saved: outputs\\SubSubCat_Olanzapine\\four_panel_overlap_SubSubCat_Olanzapine.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set up base output folder\n",
    "output_base = \"outputs\"\n",
    "ps_file = \"propensity_scores.xlsx\"\n",
    "iptw_file = \"iptw_weights.xlsx\"\n",
    "trimmed_data_file = \"trimmed_data_imp1.pkl\"\n",
    "\n",
    "# Collect all treatment group folders\n",
    "groups = [g for g in medication_groups if os.path.isdir(os.path.join(output_base, g))]\n",
    "\n",
    "# Generate 4-panel overlap plots\n",
    "for group in groups:\n",
    "    group_path = os.path.join(output_base, group)\n",
    "    try:\n",
    "        # Load trimmed treatment info\n",
    "        trimmed_df = pd.read_pickle(os.path.join(group_path, trimmed_data_file))\n",
    "        index = trimmed_df.index\n",
    "\n",
    "        # Fix: case-insensitive match for treatment variable\n",
    "        possible_cols = [col for col in trimmed_df.columns if col.upper() == group.upper()]\n",
    "        if not possible_cols:\n",
    "            print(f\" Treatment variable {group} not found in {group}, skipping.\")\n",
    "            continue\n",
    "        treatment_var = possible_cols[0]\n",
    "        T = trimmed_df[treatment_var]\n",
    "\n",
    "        # Load composite PS (aligned to trimmed_df index)\n",
    "        ps_df = pd.read_excel(os.path.join(group_path, ps_file), index_col=0)\n",
    "        if 'composite_ps' not in ps_df.columns:\n",
    "            print(f\" Composite column missing in {ps_file}, skipping {group}.\")\n",
    "            continue\n",
    "        ps = ps_df.loc[index, 'composite_ps']\n",
    "\n",
    "        # Load IPTW weights (aligned to trimmed_df index)\n",
    "        weights_df = pd.read_excel(os.path.join(group_path, iptw_file), index_col=0)\n",
    "        if 'iptw_mean' not in weights_df.columns:\n",
    "            print(f\" IPTW weight column missing in {iptw_file}, skipping {group}.\")\n",
    "            continue\n",
    "        weights = weights_df.loc[index, 'iptw_mean']\n",
    "\n",
    "        # Prepare 4 datasets\n",
    "        raw_treated = ps[T == 1]\n",
    "        raw_control = ps[T == 0]\n",
    "        weighted_treated = (ps[T == 1], weights[T == 1])\n",
    "        weighted_control = (ps[T == 0], weights[T == 0])\n",
    "\n",
    "        # Create plot\n",
    "        fig, axs = plt.subplots(2, 2, figsize=(12, 8))\n",
    "        fig.suptitle(f\"Propensity Score Distribution - {group}\", fontsize=14)\n",
    "\n",
    "        axs[0, 0].hist(raw_treated, bins=20, alpha=0.7, color='blue')\n",
    "        axs[0, 0].set_title(\"Raw Treated\")\n",
    "\n",
    "        axs[0, 1].hist(raw_control, bins=20, alpha=0.7, color='green')\n",
    "        axs[0, 1].set_title(\"Raw Control\")\n",
    "\n",
    "        axs[1, 0].hist(weighted_treated[0], bins=20, weights=weighted_treated[1], alpha=0.7, color='blue')\n",
    "        axs[1, 0].set_title(\"Weighted Treated\")\n",
    "\n",
    "        axs[1, 1].hist(weighted_control[0], bins=20, weights=weighted_control[1], alpha=0.7, color='green')\n",
    "        axs[1, 1].set_title(\"Weighted Control\")\n",
    "\n",
    "        for ax in axs.flat:\n",
    "            ax.set_xlim(0, 1)\n",
    "            ax.set_xlabel(\"Propensity Score\")\n",
    "            ax.set_ylabel(\"Count\")\n",
    "\n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "\n",
    "        # Save figure\n",
    "        plot_path = os.path.join(group_path, f\"four_panel_overlap_{group}.png\")\n",
    "        plt.savefig(plot_path)\n",
    "        plt.close()\n",
    "        print(f\" ✅ Saved: {plot_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\" ❌ Error in {group}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09df311b-eec5-417c-971f-6469e9c3c56d",
   "metadata": {},
   "source": [
    "# ATT calculation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "28309ec4-a8ac-4604-8db3-1d378cf68fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "55852696-eebd-4277-a40c-626400ce90c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Running XGBoost for SubSubCat_Oxazepam\n",
      "✅ SubSubCat_Oxazepam | Seed 1: ATT = 0.1398, SE = 0.6969, p = 0.84264\n",
      "✅ SubSubCat_Oxazepam | Seed 2: ATT = 0.1165, SE = 0.9023, p = 0.89833\n",
      "✅ SubSubCat_Oxazepam | Seed 3: ATT = 0.0600, SE = 0.7555, p = 0.93736\n",
      "✅ SubSubCat_Oxazepam | Seed 4: ATT = 0.1039, SE = 0.8761, p = 0.90661\n",
      "✅ SubSubCat_Oxazepam | Seed 5: ATT = 0.0328, SE = 0.8213, p = 0.96849\n",
      "✅ SubSubCat_Oxazepam | Seed 6: ATT = 0.0943, SE = 0.7141, p = 0.89602\n",
      "✅ SubSubCat_Oxazepam | Seed 7: ATT = 0.0978, SE = 0.6741, p = 0.88581\n",
      "✅ SubSubCat_Oxazepam | Seed 8: ATT = 0.1972, SE = 0.8453, p = 0.81752\n",
      "✅ SubSubCat_Oxazepam | Seed 9: ATT = 0.1709, SE = 0.7148, p = 0.81312\n",
      "✅ SubSubCat_Oxazepam | Seed 10: ATT = 0.0034, SE = 0.7487, p = 0.99636\n",
      "📊 Diagnostic plots saved for SubSubCat_Oxazepam\n",
      "🏆 Best result for SubSubCat_Oxazepam → Seed 7 | SE = 0.6741\n",
      "\n",
      "🚀 Running XGBoost for SubSubCat_Diazepam\n",
      "✅ SubSubCat_Diazepam | Seed 1: ATT = -0.5127, SE = 1.4754, p = 0.73122\n",
      "✅ SubSubCat_Diazepam | Seed 2: ATT = -0.6014, SE = 1.5226, p = 0.69637\n",
      "✅ SubSubCat_Diazepam | Seed 3: ATT = -0.3875, SE = 1.8575, p = 0.83649\n",
      "✅ SubSubCat_Diazepam | Seed 4: ATT = -0.4026, SE = 1.6708, p = 0.81165\n",
      "✅ SubSubCat_Diazepam | Seed 5: ATT = -0.4305, SE = 1.4397, p = 0.76750\n",
      "✅ SubSubCat_Diazepam | Seed 6: ATT = -0.4422, SE = 1.7430, p = 0.80190\n",
      "✅ SubSubCat_Diazepam | Seed 7: ATT = -0.5450, SE = 1.2832, p = 0.67482\n",
      "✅ SubSubCat_Diazepam | Seed 8: ATT = -0.5306, SE = 1.4808, p = 0.72322\n",
      "✅ SubSubCat_Diazepam | Seed 9: ATT = -0.5001, SE = 1.5743, p = 0.75349\n",
      "✅ SubSubCat_Diazepam | Seed 10: ATT = -0.3204, SE = 1.7682, p = 0.85773\n",
      "📊 Diagnostic plots saved for SubSubCat_Diazepam\n",
      "🏆 Best result for SubSubCat_Diazepam → Seed 7 | SE = 1.2832\n",
      "\n",
      "🚀 Running XGBoost for SubSubCat_Paracetamol\n",
      "✅ SubSubCat_Paracetamol | Seed 1: ATT = 2.0060, SE = 2.0653, p = 0.34110\n",
      "✅ SubSubCat_Paracetamol | Seed 2: ATT = 1.3759, SE = 1.9453, p = 0.48619\n",
      "✅ SubSubCat_Paracetamol | Seed 3: ATT = 1.9679, SE = 2.1816, p = 0.37599\n",
      "✅ SubSubCat_Paracetamol | Seed 4: ATT = 1.8281, SE = 1.9382, p = 0.35499\n",
      "✅ SubSubCat_Paracetamol | Seed 5: ATT = 1.9048, SE = 2.1664, p = 0.38798\n",
      "✅ SubSubCat_Paracetamol | Seed 6: ATT = 1.6510, SE = 1.8254, p = 0.37474\n",
      "✅ SubSubCat_Paracetamol | Seed 7: ATT = 1.7165, SE = 1.7410, p = 0.33401\n",
      "✅ SubSubCat_Paracetamol | Seed 8: ATT = 1.8578, SE = 1.8845, p = 0.33404\n",
      "✅ SubSubCat_Paracetamol | Seed 9: ATT = 1.8414, SE = 1.6747, p = 0.28244\n",
      "✅ SubSubCat_Paracetamol | Seed 10: ATT = 1.7825, SE = 1.9482, p = 0.36933\n",
      "📊 Diagnostic plots saved for SubSubCat_Paracetamol\n",
      "🏆 Best result for SubSubCat_Paracetamol → Seed 9 | SE = 1.6747\n",
      "\n",
      "🚀 Running XGBoost for SubSubCat_Lorazepam\n",
      "✅ SubSubCat_Lorazepam | Seed 1: ATT = 0.0293, SE = 1.5040, p = 0.98461\n",
      "✅ SubSubCat_Lorazepam | Seed 2: ATT = -0.0444, SE = 1.6618, p = 0.97892\n",
      "✅ SubSubCat_Lorazepam | Seed 3: ATT = 0.0300, SE = 1.6289, p = 0.98547\n",
      "✅ SubSubCat_Lorazepam | Seed 4: ATT = -0.1560, SE = 1.3570, p = 0.90942\n",
      "✅ SubSubCat_Lorazepam | Seed 5: ATT = -0.0642, SE = 1.2546, p = 0.95963\n",
      "✅ SubSubCat_Lorazepam | Seed 6: ATT = -0.0088, SE = 1.7795, p = 0.99608\n",
      "✅ SubSubCat_Lorazepam | Seed 7: ATT = -0.0527, SE = 1.2798, p = 0.96747\n",
      "✅ SubSubCat_Lorazepam | Seed 8: ATT = -0.1095, SE = 1.2075, p = 0.92847\n",
      "✅ SubSubCat_Lorazepam | Seed 9: ATT = 0.0840, SE = 1.3158, p = 0.94961\n",
      "✅ SubSubCat_Lorazepam | Seed 10: ATT = -0.1499, SE = 1.5363, p = 0.92308\n",
      "📊 Diagnostic plots saved for SubSubCat_Lorazepam\n",
      "🏆 Best result for SubSubCat_Lorazepam → Seed 8 | SE = 1.2075\n",
      "\n",
      "🚀 Running XGBoost for SubSubCat_Mirtazapine\n",
      "✅ SubSubCat_Mirtazapine | Seed 1: ATT = 6.9949, SE = 2.6141, p = 0.01322\n",
      "✅ SubSubCat_Mirtazapine | Seed 2: ATT = 7.1547, SE = 2.2382, p = 0.00387\n",
      "✅ SubSubCat_Mirtazapine | Seed 3: ATT = 7.0458, SE = 2.5208, p = 0.01004\n",
      "✅ SubSubCat_Mirtazapine | Seed 4: ATT = 7.0449, SE = 2.2661, p = 0.00479\n",
      "✅ SubSubCat_Mirtazapine | Seed 5: ATT = 7.1719, SE = 2.0994, p = 0.00227\n",
      "✅ SubSubCat_Mirtazapine | Seed 6: ATT = 7.0633, SE = 2.1695, p = 0.00335\n",
      "✅ SubSubCat_Mirtazapine | Seed 7: ATT = 6.9811, SE = 2.3444, p = 0.00654\n",
      "✅ SubSubCat_Mirtazapine | Seed 8: ATT = 7.1270, SE = 2.5479, p = 0.00999\n",
      "✅ SubSubCat_Mirtazapine | Seed 9: ATT = 7.0067, SE = 2.5934, p = 0.01246\n",
      "✅ SubSubCat_Mirtazapine | Seed 10: ATT = 7.0948, SE = 2.1856, p = 0.00343\n",
      "📊 Diagnostic plots saved for SubSubCat_Mirtazapine\n",
      "🏆 Best result for SubSubCat_Mirtazapine → Seed 5 | SE = 2.0994\n",
      "\n",
      "🚀 Running XGBoost for SubSubCat_Escitalopram\n",
      "✅ SubSubCat_Escitalopram | Seed 1: ATT = -0.0234, SE = 0.9695, p = 0.98095\n",
      "✅ SubSubCat_Escitalopram | Seed 2: ATT = -0.0040, SE = 1.0182, p = 0.99691\n",
      "✅ SubSubCat_Escitalopram | Seed 3: ATT = -0.0254, SE = 0.9935, p = 0.97978\n",
      "✅ SubSubCat_Escitalopram | Seed 4: ATT = 0.2600, SE = 1.0183, p = 0.80062\n",
      "✅ SubSubCat_Escitalopram | Seed 5: ATT = 0.1350, SE = 0.8524, p = 0.87550\n",
      "✅ SubSubCat_Escitalopram | Seed 6: ATT = -0.0313, SE = 0.7857, p = 0.96860\n",
      "✅ SubSubCat_Escitalopram | Seed 7: ATT = 0.0780, SE = 0.9951, p = 0.93815\n",
      "✅ SubSubCat_Escitalopram | Seed 8: ATT = 0.0307, SE = 1.1295, p = 0.97852\n",
      "✅ SubSubCat_Escitalopram | Seed 9: ATT = 0.1055, SE = 1.0853, p = 0.92338\n",
      "✅ SubSubCat_Escitalopram | Seed 10: ATT = -0.0069, SE = 1.0932, p = 0.99500\n",
      "📊 Diagnostic plots saved for SubSubCat_Escitalopram\n",
      "🏆 Best result for SubSubCat_Escitalopram → Seed 6 | SE = 0.7857\n",
      "\n",
      "🚀 Running XGBoost for SubSubCat_Sertraline\n",
      "✅ SubSubCat_Sertraline | Seed 1: ATT = -0.5243, SE = 0.8513, p = 0.54378\n",
      "✅ SubSubCat_Sertraline | Seed 2: ATT = -0.4927, SE = 0.8064, p = 0.54693\n",
      "✅ SubSubCat_Sertraline | Seed 3: ATT = -0.5319, SE = 0.8180, p = 0.52168\n",
      "✅ SubSubCat_Sertraline | Seed 4: ATT = -0.5127, SE = 0.9045, p = 0.57608\n",
      "✅ SubSubCat_Sertraline | Seed 5: ATT = -0.4411, SE = 0.6217, p = 0.48491\n",
      "✅ SubSubCat_Sertraline | Seed 6: ATT = -0.5144, SE = 0.8398, p = 0.54593\n",
      "✅ SubSubCat_Sertraline | Seed 7: ATT = -0.4878, SE = 0.7485, p = 0.52078\n",
      "✅ SubSubCat_Sertraline | Seed 8: ATT = -0.4515, SE = 0.9008, p = 0.62075\n",
      "✅ SubSubCat_Sertraline | Seed 9: ATT = -0.5845, SE = 1.0364, p = 0.57803\n",
      "✅ SubSubCat_Sertraline | Seed 10: ATT = -0.5054, SE = 0.8787, p = 0.57055\n",
      "📊 Diagnostic plots saved for SubSubCat_Sertraline\n",
      "🏆 Best result for SubSubCat_Sertraline → Seed 5 | SE = 0.6217\n",
      "\n",
      "🚀 Running XGBoost for SubSubCat_Temazepam\n",
      "✅ SubSubCat_Temazepam | Seed 1: ATT = -0.0621, SE = 0.9719, p = 0.94962\n",
      "✅ SubSubCat_Temazepam | Seed 2: ATT = -0.2376, SE = 0.6751, p = 0.72795\n",
      "✅ SubSubCat_Temazepam | Seed 3: ATT = -0.1886, SE = 0.9659, p = 0.84682\n",
      "✅ SubSubCat_Temazepam | Seed 4: ATT = -0.1384, SE = 0.7866, p = 0.86180\n",
      "✅ SubSubCat_Temazepam | Seed 5: ATT = -0.1433, SE = 0.8373, p = 0.86552\n",
      "✅ SubSubCat_Temazepam | Seed 6: ATT = -0.0888, SE = 0.9022, p = 0.92239\n",
      "✅ SubSubCat_Temazepam | Seed 7: ATT = -0.1642, SE = 0.8293, p = 0.84470\n",
      "✅ SubSubCat_Temazepam | Seed 8: ATT = -0.1566, SE = 1.1219, p = 0.89012\n",
      "✅ SubSubCat_Temazepam | Seed 9: ATT = -0.1842, SE = 0.8820, p = 0.83633\n",
      "✅ SubSubCat_Temazepam | Seed 10: ATT = -0.0748, SE = 0.7886, p = 0.92524\n",
      "📊 Diagnostic plots saved for SubSubCat_Temazepam\n",
      "🏆 Best result for SubSubCat_Temazepam → Seed 2 | SE = 0.6751\n",
      "\n",
      "🚀 Running XGBoost for SubSubCat_Citalopram\n",
      "✅ SubSubCat_Citalopram | Seed 1: ATT = -2.0497, SE = 0.8688, p = 0.02679\n",
      "✅ SubSubCat_Citalopram | Seed 2: ATT = -2.1069, SE = 0.9193, p = 0.03099\n",
      "✅ SubSubCat_Citalopram | Seed 3: ATT = -2.1842, SE = 0.8670, p = 0.01883\n",
      "✅ SubSubCat_Citalopram | Seed 4: ATT = -2.2210, SE = 1.0466, p = 0.04434\n",
      "✅ SubSubCat_Citalopram | Seed 5: ATT = -2.2056, SE = 1.2059, p = 0.07986\n",
      "✅ SubSubCat_Citalopram | Seed 6: ATT = -2.1148, SE = 1.1336, p = 0.07438\n",
      "✅ SubSubCat_Citalopram | Seed 7: ATT = -2.0866, SE = 0.8535, p = 0.02221\n",
      "✅ SubSubCat_Citalopram | Seed 8: ATT = -2.2219, SE = 0.9348, p = 0.02578\n",
      "✅ SubSubCat_Citalopram | Seed 9: ATT = -2.0976, SE = 0.9326, p = 0.03395\n",
      "✅ SubSubCat_Citalopram | Seed 10: ATT = -2.0986, SE = 0.9219, p = 0.03203\n",
      "📊 Diagnostic plots saved for SubSubCat_Citalopram\n",
      "🏆 Best result for SubSubCat_Citalopram → Seed 7 | SE = 0.8535\n",
      "\n",
      "🚀 Running XGBoost for SubSubCat_Quetiapine\n",
      "✅ SubSubCat_Quetiapine | Seed 1: ATT = 0.8073, SE = 0.9851, p = 0.42052\n",
      "✅ SubSubCat_Quetiapine | Seed 2: ATT = 0.8750, SE = 0.7653, p = 0.26418\n",
      "✅ SubSubCat_Quetiapine | Seed 3: ATT = 0.7276, SE = 0.9760, p = 0.46321\n",
      "✅ SubSubCat_Quetiapine | Seed 4: ATT = 0.8812, SE = 0.9238, p = 0.34966\n",
      "✅ SubSubCat_Quetiapine | Seed 5: ATT = 0.8608, SE = 0.9067, p = 0.35191\n",
      "✅ SubSubCat_Quetiapine | Seed 6: ATT = 0.7567, SE = 0.7418, p = 0.31786\n",
      "✅ SubSubCat_Quetiapine | Seed 7: ATT = 0.9252, SE = 0.9212, p = 0.32522\n",
      "✅ SubSubCat_Quetiapine | Seed 8: ATT = 0.8856, SE = 0.8391, p = 0.30177\n",
      "✅ SubSubCat_Quetiapine | Seed 9: ATT = 0.7939, SE = 0.8243, p = 0.34513\n",
      "✅ SubSubCat_Quetiapine | Seed 10: ATT = 0.8594, SE = 0.7018, p = 0.23265\n",
      "📊 Diagnostic plots saved for SubSubCat_Quetiapine\n",
      "🏆 Best result for SubSubCat_Quetiapine → Seed 10 | SE = 0.7018\n",
      "\n",
      "🚀 Running XGBoost for SubSubCat_Amitriptyline\n",
      "✅ SubSubCat_Amitriptyline | Seed 1: ATT = 3.8183, SE = 2.6899, p = 0.16861\n",
      "✅ SubSubCat_Amitriptyline | Seed 2: ATT = 3.7830, SE = 2.8584, p = 0.19815\n",
      "✅ SubSubCat_Amitriptyline | Seed 3: ATT = 3.6753, SE = 2.7134, p = 0.18819\n",
      "✅ SubSubCat_Amitriptyline | Seed 4: ATT = 3.7052, SE = 2.7016, p = 0.18291\n",
      "✅ SubSubCat_Amitriptyline | Seed 5: ATT = 3.9638, SE = 2.5658, p = 0.13547\n",
      "✅ SubSubCat_Amitriptyline | Seed 6: ATT = 3.5303, SE = 2.6447, p = 0.19445\n",
      "✅ SubSubCat_Amitriptyline | Seed 7: ATT = 3.8263, SE = 2.7481, p = 0.17658\n",
      "✅ SubSubCat_Amitriptyline | Seed 8: ATT = 3.8769, SE = 2.5198, p = 0.13699\n",
      "✅ SubSubCat_Amitriptyline | Seed 9: ATT = 4.0593, SE = 2.7886, p = 0.15844\n",
      "✅ SubSubCat_Amitriptyline | Seed 10: ATT = 3.9017, SE = 3.0781, p = 0.21711\n",
      "📊 Diagnostic plots saved for SubSubCat_Amitriptyline\n",
      "🏆 Best result for SubSubCat_Amitriptyline → Seed 8 | SE = 2.5198\n",
      "\n",
      "🚀 Running XGBoost for SubSubCat_Venlafaxine\n",
      "✅ SubSubCat_Venlafaxine | Seed 1: ATT = 1.8887, SE = 2.1596, p = 0.39049\n",
      "✅ SubSubCat_Venlafaxine | Seed 2: ATT = 1.9534, SE = 1.9466, p = 0.32563\n",
      "✅ SubSubCat_Venlafaxine | Seed 3: ATT = 1.8756, SE = 1.8518, p = 0.32124\n",
      "✅ SubSubCat_Venlafaxine | Seed 4: ATT = 2.2036, SE = 2.3150, p = 0.35064\n",
      "✅ SubSubCat_Venlafaxine | Seed 5: ATT = 2.0009, SE = 2.3106, p = 0.39507\n",
      "✅ SubSubCat_Venlafaxine | Seed 6: ATT = 1.7504, SE = 1.8684, p = 0.35818\n",
      "✅ SubSubCat_Venlafaxine | Seed 7: ATT = 1.7875, SE = 1.8996, p = 0.35608\n",
      "✅ SubSubCat_Venlafaxine | Seed 8: ATT = 2.0064, SE = 2.2272, p = 0.37662\n",
      "✅ SubSubCat_Venlafaxine | Seed 9: ATT = 1.9795, SE = 1.9983, p = 0.33178\n",
      "✅ SubSubCat_Venlafaxine | Seed 10: ATT = 1.8792, SE = 1.8924, p = 0.33059\n",
      "📊 Diagnostic plots saved for SubSubCat_Venlafaxine\n",
      "🏆 Best result for SubSubCat_Venlafaxine → Seed 3 | SE = 1.8518\n",
      "\n",
      "🚀 Running XGBoost for SubSubCat_Fluoxetine\n",
      "✅ SubSubCat_Fluoxetine | Seed 1: ATT = 5.2650, SE = 2.4917, p = 0.04519\n",
      "✅ SubSubCat_Fluoxetine | Seed 2: ATT = 5.3348, SE = 2.3388, p = 0.03172\n",
      "✅ SubSubCat_Fluoxetine | Seed 3: ATT = 5.1862, SE = 1.9065, p = 0.01194\n",
      "✅ SubSubCat_Fluoxetine | Seed 4: ATT = 5.3089, SE = 2.3069, p = 0.03036\n",
      "✅ SubSubCat_Fluoxetine | Seed 5: ATT = 5.1091, SE = 2.3360, p = 0.03871\n",
      "✅ SubSubCat_Fluoxetine | Seed 6: ATT = 5.1460, SE = 2.3176, p = 0.03609\n",
      "✅ SubSubCat_Fluoxetine | Seed 7: ATT = 4.8414, SE = 2.0751, p = 0.02835\n",
      "✅ SubSubCat_Fluoxetine | Seed 8: ATT = 5.1239, SE = 2.1040, p = 0.02268\n",
      "✅ SubSubCat_Fluoxetine | Seed 9: ATT = 4.9493, SE = 1.9955, p = 0.02054\n",
      "✅ SubSubCat_Fluoxetine | Seed 10: ATT = 5.1633, SE = 2.1273, p = 0.02309\n",
      "📊 Diagnostic plots saved for SubSubCat_Fluoxetine\n",
      "🏆 Best result for SubSubCat_Fluoxetine → Seed 3 | SE = 1.9065\n",
      "\n",
      "🚀 Running XGBoost for SubSubCat_Topiramaat\n",
      "✅ SubSubCat_Topiramaat | Seed 1: ATT = 3.4536, SE = 2.7114, p = 0.21495\n",
      "✅ SubSubCat_Topiramaat | Seed 2: ATT = 3.0316, SE = 2.6817, p = 0.26945\n",
      "✅ SubSubCat_Topiramaat | Seed 3: ATT = 2.5105, SE = 1.9003, p = 0.19893\n",
      "✅ SubSubCat_Topiramaat | Seed 4: ATT = 2.7671, SE = 2.1721, p = 0.21489\n",
      "✅ SubSubCat_Topiramaat | Seed 5: ATT = 2.8881, SE = 2.3522, p = 0.23142\n",
      "✅ SubSubCat_Topiramaat | Seed 6: ATT = 3.1317, SE = 2.7142, p = 0.25994\n",
      "✅ SubSubCat_Topiramaat | Seed 7: ATT = 3.2815, SE = 2.6519, p = 0.22790\n",
      "✅ SubSubCat_Topiramaat | Seed 8: ATT = 2.9007, SE = 2.3147, p = 0.22221\n",
      "✅ SubSubCat_Topiramaat | Seed 9: ATT = 3.3438, SE = 2.4440, p = 0.18394\n",
      "✅ SubSubCat_Topiramaat | Seed 10: ATT = 2.6224, SE = 2.1014, p = 0.22410\n",
      "📊 Diagnostic plots saved for SubSubCat_Topiramaat\n",
      "🏆 Best result for SubSubCat_Topiramaat → Seed 3 | SE = 1.9003\n",
      "\n",
      "🚀 Running XGBoost for SubSubCat_Zopiclon\n",
      "✅ SubSubCat_Zopiclon | Seed 1: ATT = 1.2658, SE = 2.0072, p = 0.53423\n",
      "✅ SubSubCat_Zopiclon | Seed 2: ATT = 1.0773, SE = 1.4665, p = 0.46971\n",
      "✅ SubSubCat_Zopiclon | Seed 3: ATT = 0.8900, SE = 1.7521, p = 0.61613\n",
      "✅ SubSubCat_Zopiclon | Seed 4: ATT = 0.6125, SE = 1.5653, p = 0.69903\n",
      "✅ SubSubCat_Zopiclon | Seed 5: ATT = 0.7198, SE = 1.7595, p = 0.68610\n",
      "✅ SubSubCat_Zopiclon | Seed 6: ATT = 1.0698, SE = 1.3154, p = 0.42404\n",
      "✅ SubSubCat_Zopiclon | Seed 7: ATT = 1.0178, SE = 2.3842, p = 0.67326\n",
      "✅ SubSubCat_Zopiclon | Seed 8: ATT = 0.9480, SE = 2.2204, p = 0.67324\n",
      "✅ SubSubCat_Zopiclon | Seed 9: ATT = 0.8826, SE = 1.7891, p = 0.62627\n",
      "✅ SubSubCat_Zopiclon | Seed 10: ATT = 0.9108, SE = 2.0087, p = 0.65430\n",
      "📊 Diagnostic plots saved for SubSubCat_Zopiclon\n",
      "🏆 Best result for SubSubCat_Zopiclon → Seed 6 | SE = 1.3154\n",
      "\n",
      "🚀 Running XGBoost for SubSubCat_Bupropion\n",
      "✅ SubSubCat_Bupropion | Seed 1: ATT = 1.7441, SE = 2.5131, p = 0.49434\n",
      "✅ SubSubCat_Bupropion | Seed 2: ATT = 2.0113, SE = 2.6836, p = 0.46084\n",
      "✅ SubSubCat_Bupropion | Seed 3: ATT = 1.7098, SE = 2.1201, p = 0.42790\n",
      "✅ SubSubCat_Bupropion | Seed 4: ATT = 1.9650, SE = 2.3562, p = 0.41253\n",
      "✅ SubSubCat_Bupropion | Seed 5: ATT = 1.9256, SE = 2.4061, p = 0.43139\n",
      "✅ SubSubCat_Bupropion | Seed 6: ATT = 1.7390, SE = 2.7015, p = 0.52587\n",
      "✅ SubSubCat_Bupropion | Seed 7: ATT = 2.0308, SE = 2.5986, p = 0.44215\n",
      "✅ SubSubCat_Bupropion | Seed 8: ATT = 2.1321, SE = 2.7418, p = 0.44438\n",
      "✅ SubSubCat_Bupropion | Seed 9: ATT = 2.0010, SE = 2.4898, p = 0.42948\n",
      "✅ SubSubCat_Bupropion | Seed 10: ATT = 1.8020, SE = 2.6932, p = 0.50981\n",
      "📊 Diagnostic plots saved for SubSubCat_Bupropion\n",
      "🏆 Best result for SubSubCat_Bupropion → Seed 3 | SE = 2.1201\n",
      "\n",
      "🚀 Running XGBoost for SubSubCat_Methylfenidaat\n",
      "✅ SubSubCat_Methylfenidaat | Seed 1: ATT = -0.2014, SE = 1.7929, p = 0.91148\n",
      "✅ SubSubCat_Methylfenidaat | Seed 2: ATT = 0.0694, SE = 1.4281, p = 0.96165\n",
      "✅ SubSubCat_Methylfenidaat | Seed 3: ATT = -0.1299, SE = 1.9456, p = 0.94733\n",
      "✅ SubSubCat_Methylfenidaat | Seed 4: ATT = 0.1317, SE = 1.7172, p = 0.93953\n",
      "✅ SubSubCat_Methylfenidaat | Seed 5: ATT = 0.0261, SE = 2.0624, p = 0.99002\n",
      "✅ SubSubCat_Methylfenidaat | Seed 6: ATT = 0.0628, SE = 1.4983, p = 0.96691\n",
      "✅ SubSubCat_Methylfenidaat | Seed 7: ATT = -0.3389, SE = 1.7550, p = 0.84850\n",
      "✅ SubSubCat_Methylfenidaat | Seed 8: ATT = 0.0324, SE = 1.3920, p = 0.98162\n",
      "✅ SubSubCat_Methylfenidaat | Seed 9: ATT = 0.2166, SE = 1.5910, p = 0.89284\n",
      "✅ SubSubCat_Methylfenidaat | Seed 10: ATT = 0.1796, SE = 1.5379, p = 0.90799\n",
      "📊 Diagnostic plots saved for SubSubCat_Methylfenidaat\n",
      "🏆 Best result for SubSubCat_Methylfenidaat → Seed 8 | SE = 1.3920\n",
      "\n",
      "🚀 Running XGBoost for SubSubCat_Olanzapine\n",
      "✅ SubSubCat_Olanzapine | Seed 1: ATT = 3.8633, SE = 4.0447, p = 0.34903\n",
      "✅ SubSubCat_Olanzapine | Seed 2: ATT = 3.8465, SE = 4.0344, p = 0.34988\n",
      "✅ SubSubCat_Olanzapine | Seed 3: ATT = 3.5135, SE = 3.5578, p = 0.33323\n",
      "✅ SubSubCat_Olanzapine | Seed 4: ATT = 3.7040, SE = 4.0828, p = 0.37332\n",
      "✅ SubSubCat_Olanzapine | Seed 5: ATT = 3.4194, SE = 4.3791, p = 0.44253\n",
      "✅ SubSubCat_Olanzapine | Seed 6: ATT = 3.6148, SE = 3.8898, p = 0.36199\n",
      "✅ SubSubCat_Olanzapine | Seed 7: ATT = 3.9886, SE = 3.8572, p = 0.31142\n",
      "✅ SubSubCat_Olanzapine | Seed 8: ATT = 3.3019, SE = 3.3285, p = 0.33109\n",
      "✅ SubSubCat_Olanzapine | Seed 9: ATT = 3.7349, SE = 4.1105, p = 0.37259\n",
      "✅ SubSubCat_Olanzapine | Seed 10: ATT = 3.8193, SE = 4.5818, p = 0.41274\n",
      "📊 Diagnostic plots saved for SubSubCat_Olanzapine\n",
      "🏆 Best result for SubSubCat_Olanzapine → Seed 8 | SE = 3.3285\n",
      "\n",
      "🎯 All summary files saved.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy.stats import t, probplot\n",
    "import xgboost as xgb\n",
    "\n",
    "# -----------------------------\n",
    "# Configuration\n",
    "# -----------------------------\n",
    "n_repeats = 1\n",
    "seeds = list(range(1, 11))\n",
    "imputations = 5\n",
    "output_folder = \"outputs\"\n",
    "\n",
    "# -----------------------------\n",
    "# Diagnostic Plotting Function\n",
    "# -----------------------------\n",
    "def create_diagnostic_plots(residuals_data, fitted_data, group_name):\n",
    "    \"\"\"Create 4 diagnostic plots for model validation\"\"\"\n",
    "    plots_dir = os.path.join(output_folder, \"plots\")\n",
    "    os.makedirs(plots_dir, exist_ok=True)\n",
    "    \n",
    "    # Flatten the collected data\n",
    "    all_residuals = np.concatenate(residuals_data)\n",
    "    all_fitted = np.concatenate(fitted_data)\n",
    "    \n",
    "    # Create figure with 2x2 subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    fig.suptitle(f'Diagnostic Plots - {group_name}', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. Residuals vs Fitted\n",
    "    axes[0,0].scatter(all_fitted, all_residuals, alpha=0.6, s=20)\n",
    "    axes[0,0].axhline(y=0, color='red', linestyle='--', alpha=0.8)\n",
    "    axes[0,0].set_xlabel('Fitted Values')\n",
    "    axes[0,0].set_ylabel('Residuals')\n",
    "    axes[0,0].set_title('Residuals vs Fitted')\n",
    "    axes[0,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. QQ Plot\n",
    "    probplot(all_residuals, dist=\"norm\", plot=axes[0,1])\n",
    "    axes[0,1].set_title('Q-Q Plot (Normal)')\n",
    "    axes[0,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Residual Histogram\n",
    "    axes[1,0].hist(all_residuals, bins=30, density=True, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    axes[1,0].set_xlabel('Residuals')\n",
    "    axes[1,0].set_ylabel('Density')\n",
    "    axes[1,0].set_title('Residual Distribution')\n",
    "    axes[1,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Scale-Location Plot\n",
    "    sqrt_abs_residuals = np.sqrt(np.abs(all_residuals))\n",
    "    axes[1,1].scatter(all_fitted, sqrt_abs_residuals, alpha=0.6, s=20)\n",
    "    axes[1,1].set_xlabel('Fitted Values')\n",
    "    axes[1,1].set_ylabel('√|Residuals|')\n",
    "    axes[1,1].set_title('Scale-Location Plot')\n",
    "    axes[1,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save plot\n",
    "    plot_filename = os.path.join(plots_dir, f'{group_name}.png')\n",
    "    plt.savefig(plot_filename, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"📊 Diagnostic plots saved for {group_name}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Rubin's Rule\n",
    "# -----------------------------\n",
    "def rubins_pool(estimates, ses):\n",
    "    m = len(estimates)\n",
    "    q_bar = np.mean(estimates)\n",
    "    u_bar = np.mean(np.square(ses))\n",
    "    b_m = np.var(estimates, ddof=1)\n",
    "    total_var = u_bar + ((1 + 1/m) * b_m)\n",
    "    total_se = np.sqrt(total_var)\n",
    "    ci_lower = q_bar - 1.96 * total_se\n",
    "    ci_upper = q_bar + 1.96 * total_se\n",
    "    p_value = 2 * (1 - t.cdf(np.abs(q_bar / total_se), df=m-1))\n",
    "    rounded_p = round(p_value, 5)\n",
    "    formatted_p = \"< 0.00001\" if rounded_p <= 0.00001 else f\"{rounded_p:.5f}\"\n",
    "    return q_bar, total_se, ci_lower, ci_upper, formatted_p\n",
    "\n",
    "# -----------------------------\n",
    "# SMD + Variance Ratio\n",
    "# -----------------------------\n",
    "def calculate_smd_vr(X, T, weights):\n",
    "    treated = X[T == 1]\n",
    "    control = X[T == 0]\n",
    "    w_treated = weights[T == 1]\n",
    "    w_control = weights[T == 0]\n",
    "    smd, vr = [], []\n",
    "    for col in X.columns:\n",
    "        try:\n",
    "            m1, m0 = np.average(treated[col], weights=w_treated), np.average(control[col], weights=w_control)\n",
    "            s1 = np.sqrt(np.average((treated[col] - m1) ** 2, weights=w_treated))\n",
    "            s0 = np.sqrt(np.average((control[col] - m0) ** 2, weights=w_control))\n",
    "            pooled_sd = np.sqrt((s1 ** 2 + s0 ** 2) / 2)\n",
    "            smd.append((m1 - m0) / pooled_sd if pooled_sd > 0 else 0)\n",
    "            vr.append(s1**2 / s0**2 if s0**2 > 0 else 0)\n",
    "        except Exception:\n",
    "            smd.append(np.nan)\n",
    "            vr.append(np.nan)\n",
    "    return np.nanmean(smd), np.nanmean(vr)\n",
    "\n",
    "# -----------------------------\n",
    "# XGBoost Main Loop (No DML)\n",
    "# -----------------------------\n",
    "def run_xgboost_with_trimmed_data(final_covariates_map):\n",
    "    att_results = []\n",
    "    balance_results = []\n",
    "\n",
    "    for group, covariates in final_covariates_map.items():\n",
    "        print(f\"\\n🚀 Running XGBoost for {group}\")\n",
    "        group_dir = os.path.join(output_folder, group)\n",
    "        os.makedirs(group_dir, exist_ok=True)\n",
    "\n",
    "        best_result = None\n",
    "        best_se = float(\"inf\")\n",
    "        \n",
    "        # Initialize lists to collect residuals and fitted values for diagnostic plots\n",
    "        group_residuals = []\n",
    "        group_fitted = []\n",
    "\n",
    "        for seed in seeds:\n",
    "            att_list, se_list, r2_list, rmse_list, smd_list, vr_list = [], [], [], [], [], []\n",
    "\n",
    "            for imp in range(1, imputations + 1):\n",
    "                file_path = os.path.join(group_dir, f\"trimmed_data_imp{imp}.pkl\")\n",
    "                if not os.path.exists(file_path):\n",
    "                    continue\n",
    "\n",
    "                df = pd.read_pickle(file_path)\n",
    "                if group not in df.columns or \"iptw\" not in df.columns:\n",
    "                    continue\n",
    "\n",
    "                X = df[covariates].copy()\n",
    "                T = df[group]\n",
    "                Y = df[\"caps5_change_baseline\"]\n",
    "                W = df[\"iptw\"]\n",
    "\n",
    "                for repeat in range(n_repeats):\n",
    "                    kf = KFold(n_splits=5, shuffle=True, random_state=seed + repeat)\n",
    "                    for train_idx, test_idx in kf.split(X):\n",
    "                        try:\n",
    "                            X_train, T_train, Y_train, W_train = (\n",
    "                                X.iloc[train_idx],\n",
    "                                T.iloc[train_idx],\n",
    "                                Y.iloc[train_idx],\n",
    "                                W.iloc[train_idx],\n",
    "                            )\n",
    "\n",
    "                            # XGBoost regression model\n",
    "                            model = xgb.XGBRegressor(n_estimators=100, max_depth=3, learning_rate=0.1, n_jobs=1, random_state=seed)\n",
    "                            \n",
    "                            # Add treatment variable to features\n",
    "                            X_train_with_T = X_train.copy()\n",
    "                            X_train_with_T[group] = T_train\n",
    "                            \n",
    "                            # Fit model\n",
    "                            model.fit(X_train_with_T, Y_train, sample_weight=W_train)\n",
    "                            \n",
    "                            # Predict outcomes for treated and control groups\n",
    "                            X_treated = X_train.copy()\n",
    "                            X_treated[group] = 1\n",
    "                            X_control = X_train.copy()\n",
    "                            X_control[group] = 0\n",
    "                            \n",
    "                            Y_pred_treated = model.predict(X_treated)\n",
    "                            Y_pred_control = model.predict(X_control)\n",
    "                            \n",
    "                            # Calculate ATT (Average Treatment Effect on Treated)\n",
    "                            treated_mask = T_train == 1\n",
    "                            if np.any(treated_mask):\n",
    "                                att = np.average(Y_pred_treated[treated_mask] - Y_pred_control[treated_mask], \n",
    "                                               weights=W_train[treated_mask])\n",
    "                                \n",
    "                                # Calculate standard error (approximate)\n",
    "                                treatment_effects = Y_pred_treated[treated_mask] - Y_pred_control[treated_mask]\n",
    "                                residual = treatment_effects - att\n",
    "                                se = np.sqrt(np.sum((W_train[treated_mask] * residual) ** 2)) / np.sum(W_train[treated_mask])\n",
    "\n",
    "                                \n",
    "                                att_list.append(att)\n",
    "                                se_list.append(se)\n",
    "\n",
    "                            # Model performance metrics\n",
    "                            Y_pred = model.predict(X_train_with_T)\n",
    "                            residuals = Y_train - Y_pred\n",
    "                            rmse = mean_squared_error(Y_train, Y_pred, squared=False)\n",
    "                            r2 = r2_score(Y_train, Y_pred)\n",
    "                            r2_list.append(r2)\n",
    "                            rmse_list.append(rmse)\n",
    "                            \n",
    "                            # Collect residuals and fitted values for diagnostic plots\n",
    "                            group_residuals.append(residuals.values)\n",
    "                            group_fitted.append(Y_pred)\n",
    "\n",
    "                            smd, vr = calculate_smd_vr(X_train, T_train, W_train)\n",
    "                            smd_list.append(smd)\n",
    "                            vr_list.append(vr)\n",
    "                        except Exception as e:\n",
    "                            print(f\"⚠️ Error in {group}, seed {seed}, imp {imp}, rep {repeat}: {e}\")\n",
    "\n",
    "            if att_list:\n",
    "                att, se, ci_l, ci_u, p_val = rubins_pool(att_list, se_list)\n",
    "                avg_r2 = np.mean(r2_list)\n",
    "                avg_rmse = np.mean(rmse_list)\n",
    "                avg_smd = np.mean(smd_list)\n",
    "                avg_vr = np.mean(vr_list)\n",
    "\n",
    "                balance_results.append({\n",
    "                    \"group\": group, \"seed\": seed, \"smd\": avg_smd, \"vr\": avg_vr\n",
    "                })\n",
    "\n",
    "                if se < best_se:\n",
    "                    best_se = se\n",
    "                    best_result = {\n",
    "                        \"group\": group, \"seed\": seed, \"att\": att, \"se\": se,\n",
    "                        \"ci_lower\": ci_l, \"ci_upper\": ci_u, \"p_value\": p_val,\n",
    "                        \"r2\": avg_r2, \"rmse\": avg_rmse\n",
    "                    }\n",
    "\n",
    "                print(f\"✅ {group} | Seed {seed}: ATT = {att:.4f}, SE = {se:.4f}, p = {p_val}\")\n",
    "            else:\n",
    "                print(f\"⚠️ No valid results for {group} | Seed {seed}\")\n",
    "\n",
    "        # Create diagnostic plots for this group\n",
    "        if group_residuals and group_fitted:\n",
    "            create_diagnostic_plots(group_residuals, group_fitted, group)\n",
    "\n",
    "        if best_result:\n",
    "            att_results.append(best_result)\n",
    "            print(f\"🏆 Best result for {group} → Seed {best_result['seed']} | SE = {best_result['se']:.4f}\")\n",
    "\n",
    "    # Save final output\n",
    "    pd.DataFrame(att_results).to_excel(\"xgb_rubin_summary_subsubcats.xlsx\", index=False)\n",
    "    pd.DataFrame(balance_results).to_excel(\"smd_vr_summary_subsubcats.xlsx\", index=False)\n",
    "    print(\"\\n🎯 All summary files saved.\")\n",
    "\n",
    "run_xgboost_with_trimmed_data(final_covariates_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "fc754ced-c08e-43a5-85c9-fed4eb54c55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unweighted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "a560fef1-7417-4ef6-900a-9af1618ead6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Running XGBoost for SubSubCat_Oxazepam\n",
      "✅ SubSubCat_Oxazepam | Seed 1: ATT = 0.4660, SE = 0.4607, p = 0.32187\n",
      "✅ SubSubCat_Oxazepam | Seed 2: ATT = 0.5233, SE = 0.6932, p = 0.45764\n",
      "✅ SubSubCat_Oxazepam | Seed 3: ATT = 0.5467, SE = 0.4936, p = 0.27902\n",
      "✅ SubSubCat_Oxazepam | Seed 4: ATT = 0.5285, SE = 0.5555, p = 0.35087\n",
      "✅ SubSubCat_Oxazepam | Seed 5: ATT = 0.4692, SE = 0.6476, p = 0.47577\n",
      "✅ SubSubCat_Oxazepam | Seed 6: ATT = 0.4884, SE = 0.5518, p = 0.38486\n",
      "✅ SubSubCat_Oxazepam | Seed 7: ATT = 0.5387, SE = 0.4879, p = 0.28053\n",
      "✅ SubSubCat_Oxazepam | Seed 8: ATT = 0.6066, SE = 0.5849, p = 0.31007\n",
      "✅ SubSubCat_Oxazepam | Seed 9: ATT = 0.5567, SE = 0.5302, p = 0.30422\n",
      "✅ SubSubCat_Oxazepam | Seed 10: ATT = 0.5311, SE = 0.5072, p = 0.30553\n",
      "📊 Diagnostic plots saved for SubSubCat_Oxazepam\n",
      "🏆 Best result for SubSubCat_Oxazepam → Seed 1 | SE = 0.4607\n",
      "\n",
      "🚀 Running XGBoost for SubSubCat_Diazepam\n",
      "✅ SubSubCat_Diazepam | Seed 1: ATT = -0.8232, SE = 1.3515, p = 0.54817\n",
      "✅ SubSubCat_Diazepam | Seed 2: ATT = -0.8187, SE = 1.5352, p = 0.59875\n",
      "✅ SubSubCat_Diazepam | Seed 3: ATT = -0.6953, SE = 1.7068, p = 0.68734\n",
      "✅ SubSubCat_Diazepam | Seed 4: ATT = -0.8220, SE = 1.3285, p = 0.54192\n",
      "✅ SubSubCat_Diazepam | Seed 5: ATT = -0.5436, SE = 1.2927, p = 0.67787\n",
      "✅ SubSubCat_Diazepam | Seed 6: ATT = -0.8191, SE = 1.5432, p = 0.60045\n",
      "✅ SubSubCat_Diazepam | Seed 7: ATT = -0.6657, SE = 1.0640, p = 0.53748\n",
      "✅ SubSubCat_Diazepam | Seed 8: ATT = -0.8679, SE = 1.3060, p = 0.51266\n",
      "✅ SubSubCat_Diazepam | Seed 9: ATT = -0.7068, SE = 1.5729, p = 0.65721\n",
      "✅ SubSubCat_Diazepam | Seed 10: ATT = -0.6608, SE = 1.5755, p = 0.67861\n",
      "📊 Diagnostic plots saved for SubSubCat_Diazepam\n",
      "🏆 Best result for SubSubCat_Diazepam → Seed 7 | SE = 1.0640\n",
      "\n",
      "🚀 Running XGBoost for SubSubCat_Paracetamol\n",
      "✅ SubSubCat_Paracetamol | Seed 1: ATT = 1.9274, SE = 1.8441, p = 0.30635\n",
      "✅ SubSubCat_Paracetamol | Seed 2: ATT = 1.5930, SE = 2.0781, p = 0.45080\n",
      "✅ SubSubCat_Paracetamol | Seed 3: ATT = 2.0252, SE = 2.2289, p = 0.37258\n",
      "✅ SubSubCat_Paracetamol | Seed 4: ATT = 1.9675, SE = 1.7853, p = 0.28137\n",
      "✅ SubSubCat_Paracetamol | Seed 5: ATT = 1.8697, SE = 2.2250, p = 0.40902\n",
      "✅ SubSubCat_Paracetamol | Seed 6: ATT = 1.8566, SE = 1.8199, p = 0.31783\n",
      "✅ SubSubCat_Paracetamol | Seed 7: ATT = 1.6991, SE = 1.6092, p = 0.30154\n",
      "✅ SubSubCat_Paracetamol | Seed 8: ATT = 1.8300, SE = 2.1035, p = 0.39293\n",
      "✅ SubSubCat_Paracetamol | Seed 9: ATT = 1.7975, SE = 1.8770, p = 0.34779\n",
      "✅ SubSubCat_Paracetamol | Seed 10: ATT = 1.6948, SE = 1.8797, p = 0.37621\n",
      "📊 Diagnostic plots saved for SubSubCat_Paracetamol\n",
      "🏆 Best result for SubSubCat_Paracetamol → Seed 7 | SE = 1.6092\n",
      "\n",
      "🚀 Running XGBoost for SubSubCat_Lorazepam\n",
      "✅ SubSubCat_Lorazepam | Seed 1: ATT = -0.1853, SE = 1.5678, p = 0.90690\n",
      "✅ SubSubCat_Lorazepam | Seed 2: ATT = -0.0735, SE = 1.6109, p = 0.96400\n",
      "✅ SubSubCat_Lorazepam | Seed 3: ATT = -0.0751, SE = 1.5449, p = 0.96163\n",
      "✅ SubSubCat_Lorazepam | Seed 4: ATT = -0.1272, SE = 1.3913, p = 0.92792\n",
      "✅ SubSubCat_Lorazepam | Seed 5: ATT = -0.1747, SE = 1.4357, p = 0.90417\n",
      "✅ SubSubCat_Lorazepam | Seed 6: ATT = 0.0184, SE = 1.6436, p = 0.99115\n",
      "✅ SubSubCat_Lorazepam | Seed 7: ATT = -0.2091, SE = 1.2544, p = 0.86901\n",
      "✅ SubSubCat_Lorazepam | Seed 8: ATT = -0.2403, SE = 1.2460, p = 0.84868\n",
      "✅ SubSubCat_Lorazepam | Seed 9: ATT = 0.0059, SE = 1.3650, p = 0.99656\n",
      "✅ SubSubCat_Lorazepam | Seed 10: ATT = -0.3432, SE = 1.4190, p = 0.81096\n",
      "📊 Diagnostic plots saved for SubSubCat_Lorazepam\n",
      "🏆 Best result for SubSubCat_Lorazepam → Seed 8 | SE = 1.2460\n",
      "\n",
      "🚀 Running XGBoost for SubSubCat_Mirtazapine\n",
      "✅ SubSubCat_Mirtazapine | Seed 1: ATT = 6.4565, SE = 2.4512, p = 0.01454\n",
      "✅ SubSubCat_Mirtazapine | Seed 2: ATT = 6.5516, SE = 2.2933, p = 0.00870\n",
      "✅ SubSubCat_Mirtazapine | Seed 3: ATT = 6.4311, SE = 2.4144, p = 0.01359\n",
      "✅ SubSubCat_Mirtazapine | Seed 4: ATT = 6.3216, SE = 2.1506, p = 0.00716\n",
      "✅ SubSubCat_Mirtazapine | Seed 5: ATT = 6.4096, SE = 2.0691, p = 0.00491\n",
      "✅ SubSubCat_Mirtazapine | Seed 6: ATT = 6.3515, SE = 2.1182, p = 0.00623\n",
      "✅ SubSubCat_Mirtazapine | Seed 7: ATT = 6.3119, SE = 2.1546, p = 0.00733\n",
      "✅ SubSubCat_Mirtazapine | Seed 8: ATT = 6.4621, SE = 2.2972, p = 0.00963\n",
      "✅ SubSubCat_Mirtazapine | Seed 9: ATT = 6.2747, SE = 2.4760, p = 0.01821\n",
      "✅ SubSubCat_Mirtazapine | Seed 10: ATT = 6.2497, SE = 2.0790, p = 0.00612\n",
      "📊 Diagnostic plots saved for SubSubCat_Mirtazapine\n",
      "🏆 Best result for SubSubCat_Mirtazapine → Seed 5 | SE = 2.0691\n",
      "\n",
      "🚀 Running XGBoost for SubSubCat_Escitalopram\n",
      "✅ SubSubCat_Escitalopram | Seed 1: ATT = -0.0118, SE = 0.9331, p = 0.99002\n",
      "✅ SubSubCat_Escitalopram | Seed 2: ATT = 0.0394, SE = 0.9331, p = 0.96664\n",
      "✅ SubSubCat_Escitalopram | Seed 3: ATT = -0.0534, SE = 0.9512, p = 0.95571\n",
      "✅ SubSubCat_Escitalopram | Seed 4: ATT = 0.2721, SE = 1.1518, p = 0.81528\n",
      "✅ SubSubCat_Escitalopram | Seed 5: ATT = 0.0677, SE = 0.8941, p = 0.94026\n",
      "✅ SubSubCat_Escitalopram | Seed 6: ATT = -0.0613, SE = 0.9589, p = 0.94956\n",
      "✅ SubSubCat_Escitalopram | Seed 7: ATT = 0.0483, SE = 0.9494, p = 0.95988\n",
      "✅ SubSubCat_Escitalopram | Seed 8: ATT = -0.0020, SE = 1.0731, p = 0.99854\n",
      "✅ SubSubCat_Escitalopram | Seed 9: ATT = -0.0261, SE = 1.0517, p = 0.98038\n",
      "✅ SubSubCat_Escitalopram | Seed 10: ATT = 0.0533, SE = 1.0154, p = 0.95861\n",
      "📊 Diagnostic plots saved for SubSubCat_Escitalopram\n",
      "🏆 Best result for SubSubCat_Escitalopram → Seed 5 | SE = 0.8941\n",
      "\n",
      "🚀 Running XGBoost for SubSubCat_Sertraline\n",
      "✅ SubSubCat_Sertraline | Seed 1: ATT = -0.2846, SE = 0.5948, p = 0.63666\n",
      "✅ SubSubCat_Sertraline | Seed 2: ATT = -0.2493, SE = 0.6767, p = 0.71585\n",
      "✅ SubSubCat_Sertraline | Seed 3: ATT = -0.2862, SE = 0.7424, p = 0.70328\n",
      "✅ SubSubCat_Sertraline | Seed 4: ATT = -0.2314, SE = 0.8453, p = 0.78660\n",
      "✅ SubSubCat_Sertraline | Seed 5: ATT = -0.3176, SE = 0.4627, p = 0.49912\n",
      "✅ SubSubCat_Sertraline | Seed 6: ATT = -0.3656, SE = 0.6021, p = 0.54944\n",
      "✅ SubSubCat_Sertraline | Seed 7: ATT = -0.3009, SE = 0.6936, p = 0.66827\n",
      "✅ SubSubCat_Sertraline | Seed 8: ATT = -0.2851, SE = 0.6961, p = 0.68578\n",
      "✅ SubSubCat_Sertraline | Seed 9: ATT = -0.3056, SE = 0.9050, p = 0.73856\n",
      "✅ SubSubCat_Sertraline | Seed 10: ATT = -0.2972, SE = 0.5978, p = 0.62361\n",
      "📊 Diagnostic plots saved for SubSubCat_Sertraline\n",
      "🏆 Best result for SubSubCat_Sertraline → Seed 5 | SE = 0.4627\n",
      "\n",
      "🚀 Running XGBoost for SubSubCat_Temazepam\n",
      "✅ SubSubCat_Temazepam | Seed 1: ATT = -0.1251, SE = 1.0239, p = 0.90377\n",
      "✅ SubSubCat_Temazepam | Seed 2: ATT = -0.1745, SE = 0.9197, p = 0.85115\n",
      "✅ SubSubCat_Temazepam | Seed 3: ATT = -0.1086, SE = 1.0850, p = 0.92108\n",
      "✅ SubSubCat_Temazepam | Seed 4: ATT = -0.1974, SE = 0.9193, p = 0.83178\n",
      "✅ SubSubCat_Temazepam | Seed 5: ATT = -0.1972, SE = 0.8636, p = 0.82135\n",
      "✅ SubSubCat_Temazepam | Seed 6: ATT = -0.0524, SE = 0.9444, p = 0.95624\n",
      "✅ SubSubCat_Temazepam | Seed 7: ATT = -0.2180, SE = 0.8524, p = 0.80035\n",
      "✅ SubSubCat_Temazepam | Seed 8: ATT = -0.2639, SE = 1.2234, p = 0.83105\n",
      "✅ SubSubCat_Temazepam | Seed 9: ATT = -0.3106, SE = 0.9365, p = 0.74303\n",
      "✅ SubSubCat_Temazepam | Seed 10: ATT = -0.1367, SE = 0.8507, p = 0.87367\n",
      "📊 Diagnostic plots saved for SubSubCat_Temazepam\n",
      "🏆 Best result for SubSubCat_Temazepam → Seed 10 | SE = 0.8507\n",
      "\n",
      "🚀 Running XGBoost for SubSubCat_Citalopram\n",
      "✅ SubSubCat_Citalopram | Seed 1: ATT = -1.8646, SE = 0.8663, p = 0.04165\n",
      "✅ SubSubCat_Citalopram | Seed 2: ATT = -1.8829, SE = 0.7035, p = 0.01320\n",
      "✅ SubSubCat_Citalopram | Seed 3: ATT = -1.8869, SE = 0.6733, p = 0.00987\n",
      "✅ SubSubCat_Citalopram | Seed 4: ATT = -1.9121, SE = 0.8998, p = 0.04408\n",
      "✅ SubSubCat_Citalopram | Seed 5: ATT = -1.9358, SE = 1.1283, p = 0.09911\n",
      "✅ SubSubCat_Citalopram | Seed 6: ATT = -1.8442, SE = 1.0734, p = 0.09864\n",
      "✅ SubSubCat_Citalopram | Seed 7: ATT = -1.8106, SE = 0.7069, p = 0.01713\n",
      "✅ SubSubCat_Citalopram | Seed 8: ATT = -1.9784, SE = 0.6993, p = 0.00928\n",
      "✅ SubSubCat_Citalopram | Seed 9: ATT = -1.9349, SE = 0.7117, p = 0.01198\n",
      "✅ SubSubCat_Citalopram | Seed 10: ATT = -1.9152, SE = 0.6884, p = 0.01035\n",
      "📊 Diagnostic plots saved for SubSubCat_Citalopram\n",
      "🏆 Best result for SubSubCat_Citalopram → Seed 3 | SE = 0.6733\n",
      "\n",
      "🚀 Running XGBoost for SubSubCat_Quetiapine\n",
      "✅ SubSubCat_Quetiapine | Seed 1: ATT = 1.2665, SE = 0.9670, p = 0.20271\n",
      "✅ SubSubCat_Quetiapine | Seed 2: ATT = 1.2827, SE = 0.7260, p = 0.08997\n",
      "✅ SubSubCat_Quetiapine | Seed 3: ATT = 1.2094, SE = 1.0720, p = 0.27038\n",
      "✅ SubSubCat_Quetiapine | Seed 4: ATT = 1.2556, SE = 0.8839, p = 0.16831\n",
      "✅ SubSubCat_Quetiapine | Seed 5: ATT = 1.3224, SE = 0.8850, p = 0.14815\n",
      "✅ SubSubCat_Quetiapine | Seed 6: ATT = 1.3155, SE = 0.7800, p = 0.10466\n",
      "✅ SubSubCat_Quetiapine | Seed 7: ATT = 1.3573, SE = 0.8512, p = 0.12391\n",
      "✅ SubSubCat_Quetiapine | Seed 8: ATT = 1.2768, SE = 0.8117, p = 0.12879\n",
      "✅ SubSubCat_Quetiapine | Seed 9: ATT = 1.3310, SE = 0.6276, p = 0.04448\n",
      "✅ SubSubCat_Quetiapine | Seed 10: ATT = 1.3377, SE = 0.6444, p = 0.04878\n",
      "📊 Diagnostic plots saved for SubSubCat_Quetiapine\n",
      "🏆 Best result for SubSubCat_Quetiapine → Seed 9 | SE = 0.6276\n",
      "\n",
      "🚀 Running XGBoost for SubSubCat_Amitriptyline\n",
      "✅ SubSubCat_Amitriptyline | Seed 1: ATT = 3.1018, SE = 2.2364, p = 0.17820\n",
      "✅ SubSubCat_Amitriptyline | Seed 2: ATT = 2.9874, SE = 2.4884, p = 0.24165\n",
      "✅ SubSubCat_Amitriptyline | Seed 3: ATT = 2.9090, SE = 2.4124, p = 0.23963\n",
      "✅ SubSubCat_Amitriptyline | Seed 4: ATT = 2.8610, SE = 2.3379, p = 0.23291\n",
      "✅ SubSubCat_Amitriptyline | Seed 5: ATT = 2.9976, SE = 2.2529, p = 0.19584\n",
      "✅ SubSubCat_Amitriptyline | Seed 6: ATT = 2.9277, SE = 2.4384, p = 0.24160\n",
      "✅ SubSubCat_Amitriptyline | Seed 7: ATT = 2.8583, SE = 2.0789, p = 0.18186\n",
      "✅ SubSubCat_Amitriptyline | Seed 8: ATT = 3.1058, SE = 2.2609, p = 0.18223\n",
      "✅ SubSubCat_Amitriptyline | Seed 9: ATT = 3.2415, SE = 2.2029, p = 0.15416\n",
      "✅ SubSubCat_Amitriptyline | Seed 10: ATT = 3.1005, SE = 2.5038, p = 0.22758\n",
      "📊 Diagnostic plots saved for SubSubCat_Amitriptyline\n",
      "🏆 Best result for SubSubCat_Amitriptyline → Seed 7 | SE = 2.0789\n",
      "\n",
      "🚀 Running XGBoost for SubSubCat_Venlafaxine\n",
      "✅ SubSubCat_Venlafaxine | Seed 1: ATT = 1.7290, SE = 1.8229, p = 0.35235\n",
      "✅ SubSubCat_Venlafaxine | Seed 2: ATT = 1.8714, SE = 1.8832, p = 0.33025\n",
      "✅ SubSubCat_Venlafaxine | Seed 3: ATT = 1.7196, SE = 1.6661, p = 0.31230\n",
      "✅ SubSubCat_Venlafaxine | Seed 4: ATT = 1.9439, SE = 1.8178, p = 0.29554\n",
      "✅ SubSubCat_Venlafaxine | Seed 5: ATT = 1.8039, SE = 1.9653, p = 0.36781\n",
      "✅ SubSubCat_Venlafaxine | Seed 6: ATT = 1.7529, SE = 1.7471, p = 0.32572\n",
      "✅ SubSubCat_Venlafaxine | Seed 7: ATT = 1.7454, SE = 1.7191, p = 0.32009\n",
      "✅ SubSubCat_Venlafaxine | Seed 8: ATT = 1.7849, SE = 1.8625, p = 0.34743\n",
      "✅ SubSubCat_Venlafaxine | Seed 9: ATT = 1.7006, SE = 1.6883, p = 0.32385\n",
      "✅ SubSubCat_Venlafaxine | Seed 10: ATT = 1.8843, SE = 1.6991, p = 0.27840\n",
      "📊 Diagnostic plots saved for SubSubCat_Venlafaxine\n",
      "🏆 Best result for SubSubCat_Venlafaxine → Seed 3 | SE = 1.6661\n",
      "\n",
      "🚀 Running XGBoost for SubSubCat_Fluoxetine\n",
      "✅ SubSubCat_Fluoxetine | Seed 1: ATT = 5.0924, SE = 1.9797, p = 0.01672\n",
      "✅ SubSubCat_Fluoxetine | Seed 2: ATT = 5.1378, SE = 1.9536, p = 0.01467\n",
      "✅ SubSubCat_Fluoxetine | Seed 3: ATT = 5.0647, SE = 1.7380, p = 0.00760\n",
      "✅ SubSubCat_Fluoxetine | Seed 4: ATT = 5.1351, SE = 1.9817, p = 0.01602\n",
      "✅ SubSubCat_Fluoxetine | Seed 5: ATT = 5.1818, SE = 1.9019, p = 0.01182\n",
      "✅ SubSubCat_Fluoxetine | Seed 6: ATT = 4.9757, SE = 2.0182, p = 0.02122\n",
      "✅ SubSubCat_Fluoxetine | Seed 7: ATT = 4.9657, SE = 1.6205, p = 0.00532\n",
      "✅ SubSubCat_Fluoxetine | Seed 8: ATT = 4.9381, SE = 1.7410, p = 0.00912\n",
      "✅ SubSubCat_Fluoxetine | Seed 9: ATT = 5.0025, SE = 1.7321, p = 0.00808\n",
      "✅ SubSubCat_Fluoxetine | Seed 10: ATT = 5.0827, SE = 1.7466, p = 0.00768\n",
      "📊 Diagnostic plots saved for SubSubCat_Fluoxetine\n",
      "🏆 Best result for SubSubCat_Fluoxetine → Seed 7 | SE = 1.6205\n",
      "\n",
      "🚀 Running XGBoost for SubSubCat_Topiramaat\n",
      "✅ SubSubCat_Topiramaat | Seed 1: ATT = 4.3095, SE = 2.9770, p = 0.16067\n",
      "✅ SubSubCat_Topiramaat | Seed 2: ATT = 3.9709, SE = 2.8417, p = 0.17510\n",
      "✅ SubSubCat_Topiramaat | Seed 3: ATT = 3.5628, SE = 1.9714, p = 0.08327\n",
      "✅ SubSubCat_Topiramaat | Seed 4: ATT = 3.7498, SE = 2.5046, p = 0.14738\n",
      "✅ SubSubCat_Topiramaat | Seed 5: ATT = 3.9689, SE = 2.8306, p = 0.17368\n",
      "✅ SubSubCat_Topiramaat | Seed 6: ATT = 4.1517, SE = 3.0444, p = 0.18531\n",
      "✅ SubSubCat_Topiramaat | Seed 7: ATT = 4.0571, SE = 3.0424, p = 0.19488\n",
      "✅ SubSubCat_Topiramaat | Seed 8: ATT = 4.0615, SE = 2.8501, p = 0.16702\n",
      "✅ SubSubCat_Topiramaat | Seed 9: ATT = 3.9627, SE = 2.4394, p = 0.11734\n",
      "✅ SubSubCat_Topiramaat | Seed 10: ATT = 3.8922, SE = 2.8609, p = 0.18632\n",
      "📊 Diagnostic plots saved for SubSubCat_Topiramaat\n",
      "🏆 Best result for SubSubCat_Topiramaat → Seed 3 | SE = 1.9714\n",
      "\n",
      "🚀 Running XGBoost for SubSubCat_Zopiclon\n",
      "✅ SubSubCat_Zopiclon | Seed 1: ATT = 1.3762, SE = 1.9049, p = 0.47700\n",
      "✅ SubSubCat_Zopiclon | Seed 2: ATT = 1.0310, SE = 1.5114, p = 0.50167\n",
      "✅ SubSubCat_Zopiclon | Seed 3: ATT = 0.8567, SE = 1.8110, p = 0.64046\n",
      "✅ SubSubCat_Zopiclon | Seed 4: ATT = 0.8153, SE = 1.5572, p = 0.60539\n",
      "✅ SubSubCat_Zopiclon | Seed 5: ATT = 0.8365, SE = 1.6685, p = 0.62069\n",
      "✅ SubSubCat_Zopiclon | Seed 6: ATT = 1.0399, SE = 1.2995, p = 0.43144\n",
      "✅ SubSubCat_Zopiclon | Seed 7: ATT = 0.9385, SE = 2.3552, p = 0.69379\n",
      "✅ SubSubCat_Zopiclon | Seed 8: ATT = 1.0560, SE = 2.1605, p = 0.62943\n",
      "✅ SubSubCat_Zopiclon | Seed 9: ATT = 0.8261, SE = 1.9424, p = 0.67443\n",
      "✅ SubSubCat_Zopiclon | Seed 10: ATT = 0.9562, SE = 1.9962, p = 0.63624\n",
      "📊 Diagnostic plots saved for SubSubCat_Zopiclon\n",
      "🏆 Best result for SubSubCat_Zopiclon → Seed 6 | SE = 1.2995\n",
      "\n",
      "🚀 Running XGBoost for SubSubCat_Bupropion\n",
      "✅ SubSubCat_Bupropion | Seed 1: ATT = 1.9689, SE = 2.4976, p = 0.43824\n",
      "✅ SubSubCat_Bupropion | Seed 2: ATT = 2.2258, SE = 2.7322, p = 0.42327\n",
      "✅ SubSubCat_Bupropion | Seed 3: ATT = 1.9299, SE = 2.4187, p = 0.43276\n",
      "✅ SubSubCat_Bupropion | Seed 4: ATT = 2.0894, SE = 2.4268, p = 0.39777\n",
      "✅ SubSubCat_Bupropion | Seed 5: ATT = 2.4066, SE = 2.6896, p = 0.37979\n",
      "✅ SubSubCat_Bupropion | Seed 6: ATT = 1.9853, SE = 2.6640, p = 0.46336\n",
      "✅ SubSubCat_Bupropion | Seed 7: ATT = 2.1240, SE = 2.7283, p = 0.44386\n",
      "✅ SubSubCat_Bupropion | Seed 8: ATT = 2.2006, SE = 2.6047, p = 0.40653\n",
      "✅ SubSubCat_Bupropion | Seed 9: ATT = 2.1360, SE = 2.3916, p = 0.38065\n",
      "✅ SubSubCat_Bupropion | Seed 10: ATT = 2.0239, SE = 2.6591, p = 0.45400\n",
      "📊 Diagnostic plots saved for SubSubCat_Bupropion\n",
      "🏆 Best result for SubSubCat_Bupropion → Seed 9 | SE = 2.3916\n",
      "\n",
      "🚀 Running XGBoost for SubSubCat_Methylfenidaat\n",
      "✅ SubSubCat_Methylfenidaat | Seed 1: ATT = -1.0266, SE = 1.3317, p = 0.44828\n",
      "✅ SubSubCat_Methylfenidaat | Seed 2: ATT = -0.8027, SE = 1.3947, p = 0.57029\n",
      "✅ SubSubCat_Methylfenidaat | Seed 3: ATT = -0.9997, SE = 1.7284, p = 0.56840\n",
      "✅ SubSubCat_Methylfenidaat | Seed 4: ATT = -0.7320, SE = 1.3032, p = 0.57955\n",
      "✅ SubSubCat_Methylfenidaat | Seed 5: ATT = -0.8186, SE = 1.6429, p = 0.62282\n",
      "✅ SubSubCat_Methylfenidaat | Seed 6: ATT = -0.6955, SE = 1.2789, p = 0.59158\n",
      "✅ SubSubCat_Methylfenidaat | Seed 7: ATT = -1.0126, SE = 1.4956, p = 0.50485\n",
      "✅ SubSubCat_Methylfenidaat | Seed 8: ATT = -0.8985, SE = 1.2211, p = 0.46894\n",
      "✅ SubSubCat_Methylfenidaat | Seed 9: ATT = -0.6849, SE = 1.3566, p = 0.61826\n",
      "✅ SubSubCat_Methylfenidaat | Seed 10: ATT = -0.6802, SE = 1.1437, p = 0.55760\n",
      "📊 Diagnostic plots saved for SubSubCat_Methylfenidaat\n",
      "🏆 Best result for SubSubCat_Methylfenidaat → Seed 10 | SE = 1.1437\n",
      "\n",
      "🚀 Running XGBoost for SubSubCat_Olanzapine\n",
      "✅ SubSubCat_Olanzapine | Seed 1: ATT = 2.9606, SE = 3.0100, p = 0.33513\n",
      "✅ SubSubCat_Olanzapine | Seed 2: ATT = 3.0630, SE = 3.0861, p = 0.33085\n",
      "✅ SubSubCat_Olanzapine | Seed 3: ATT = 2.7056, SE = 2.8892, p = 0.35836\n",
      "✅ SubSubCat_Olanzapine | Seed 4: ATT = 2.9493, SE = 2.9180, p = 0.32223\n",
      "✅ SubSubCat_Olanzapine | Seed 5: ATT = 2.4097, SE = 3.6342, p = 0.51361\n",
      "✅ SubSubCat_Olanzapine | Seed 6: ATT = 3.0241, SE = 2.8665, p = 0.30194\n",
      "✅ SubSubCat_Olanzapine | Seed 7: ATT = 3.2479, SE = 2.9850, p = 0.28737\n",
      "✅ SubSubCat_Olanzapine | Seed 8: ATT = 2.9072, SE = 2.6809, p = 0.28895\n",
      "✅ SubSubCat_Olanzapine | Seed 9: ATT = 2.8861, SE = 3.1007, p = 0.36123\n",
      "✅ SubSubCat_Olanzapine | Seed 10: ATT = 3.0888, SE = 3.6664, p = 0.40785\n",
      "📊 Diagnostic plots saved for SubSubCat_Olanzapine\n",
      "🏆 Best result for SubSubCat_Olanzapine → Seed 8 | SE = 2.6809\n",
      "\n",
      "🎯 All summary files saved.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy.stats import t, probplot\n",
    "import xgboost as xgb\n",
    "\n",
    "# -----------------------------\n",
    "# Configuration\n",
    "# -----------------------------\n",
    "n_repeats = 1\n",
    "seeds = list(range(1, 11))\n",
    "imputations = 5\n",
    "output_folder = \"outputs\"\n",
    "\n",
    "# -----------------------------\n",
    "# Diagnostic Plotting Function\n",
    "# -----------------------------\n",
    "def create_diagnostic_plots(residuals_data, fitted_data, group_name):\n",
    "    \"\"\"Create 4 diagnostic plots for model validation\"\"\"\n",
    "    plots_dir = os.path.join(output_folder, \"plots\")\n",
    "    os.makedirs(plots_dir, exist_ok=True)\n",
    "    \n",
    "    # Flatten the collected data\n",
    "    all_residuals = np.concatenate(residuals_data)\n",
    "    all_fitted = np.concatenate(fitted_data)\n",
    "    \n",
    "    # Create figure with 2x2 subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    fig.suptitle(f'Diagnostic Plots - {group_name}', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. Residuals vs Fitted\n",
    "    axes[0,0].scatter(all_fitted, all_residuals, alpha=0.6, s=20)\n",
    "    axes[0,0].axhline(y=0, color='red', linestyle='--', alpha=0.8)\n",
    "    axes[0,0].set_xlabel('Fitted Values')\n",
    "    axes[0,0].set_ylabel('Residuals')\n",
    "    axes[0,0].set_title('Residuals vs Fitted')\n",
    "    axes[0,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. QQ Plot\n",
    "    probplot(all_residuals, dist=\"norm\", plot=axes[0,1])\n",
    "    axes[0,1].set_title('Q-Q Plot (Normal)')\n",
    "    axes[0,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Residual Histogram\n",
    "    axes[1,0].hist(all_residuals, bins=30, density=True, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    axes[1,0].set_xlabel('Residuals')\n",
    "    axes[1,0].set_ylabel('Density')\n",
    "    axes[1,0].set_title('Residual Distribution')\n",
    "    axes[1,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Scale-Location Plot\n",
    "    sqrt_abs_residuals = np.sqrt(np.abs(all_residuals))\n",
    "    axes[1,1].scatter(all_fitted, sqrt_abs_residuals, alpha=0.6, s=20)\n",
    "    axes[1,1].set_xlabel('Fitted Values')\n",
    "    axes[1,1].set_ylabel('√|Residuals|')\n",
    "    axes[1,1].set_title('Scale-Location Plot')\n",
    "    axes[1,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save plot\n",
    "    plot_filename = os.path.join(plots_dir, f'{group_name}_unweighted.png')\n",
    "    plt.savefig(plot_filename, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"📊 Diagnostic plots saved for {group_name}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Rubin's Rule\n",
    "# -----------------------------\n",
    "def rubins_pool(estimates, ses):\n",
    "    m = len(estimates)\n",
    "    q_bar = np.mean(estimates)\n",
    "    u_bar = np.mean(np.square(ses))\n",
    "    b_m = np.var(estimates, ddof=1)\n",
    "    total_var = u_bar + ((1 + 1/m) * b_m)\n",
    "    total_se = np.sqrt(total_var)\n",
    "    ci_lower = q_bar - 1.96 * total_se\n",
    "    ci_upper = q_bar + 1.96 * total_se\n",
    "    p_value = 2 * (1 - t.cdf(np.abs(q_bar / total_se), df=m-1))\n",
    "    rounded_p = round(p_value, 5)\n",
    "    formatted_p = \"< 0.00001\" if rounded_p <= 0.00001 else f\"{rounded_p:.5f}\"\n",
    "    return q_bar, total_se, ci_lower, ci_upper, formatted_p\n",
    "\n",
    "# -----------------------------\n",
    "# SMD + Variance Ratio\n",
    "# -----------------------------\n",
    "def calculate_smd_vr(X, T):\n",
    "    treated = X[T == 1]\n",
    "    control = X[T == 0]\n",
    "    smd, vr = [], []\n",
    "    for col in X.columns:\n",
    "        try:\n",
    "            m1, m0 = np.mean(treated[col]), np.mean(control[col])\n",
    "            s1 = np.std(treated[col])\n",
    "            s0 = np.std(control[col])\n",
    "            pooled_sd = np.sqrt((s1 ** 2 + s0 ** 2) / 2)\n",
    "            smd.append((m1 - m0) / pooled_sd if pooled_sd > 0 else 0)\n",
    "            vr.append(s1**2 / s0**2 if s0**2 > 0 else 0)\n",
    "        except Exception:\n",
    "            smd.append(np.nan)\n",
    "            vr.append(np.nan)\n",
    "    return np.nanmean(smd), np.nanmean(vr)\n",
    "\n",
    "# -----------------------------\n",
    "# XGBoost Main Loop (No DML)\n",
    "# -----------------------------\n",
    "def run_xgboost_with_trimmed_data(final_covariates_map):\n",
    "    att_results = []\n",
    "    balance_results = []\n",
    "\n",
    "    for group, covariates in final_covariates_map.items():\n",
    "        print(f\"\\n🚀 Running XGBoost for {group}\")\n",
    "        group_dir = os.path.join(output_folder, group)\n",
    "        os.makedirs(group_dir, exist_ok=True)\n",
    "\n",
    "        best_result = None\n",
    "        best_se = float(\"inf\")\n",
    "        \n",
    "        # Initialize lists to collect residuals and fitted values for diagnostic plots\n",
    "        group_residuals = []\n",
    "        group_fitted = []\n",
    "\n",
    "        for seed in seeds:\n",
    "            att_list, se_list, r2_list, rmse_list, smd_list, vr_list = [], [], [], [], [], []\n",
    "\n",
    "            for imp in range(1, imputations + 1):\n",
    "                file_path = os.path.join(group_dir, f\"trimmed_data_imp{imp}.pkl\")\n",
    "                if not os.path.exists(file_path):\n",
    "                    continue\n",
    "\n",
    "                df = pd.read_pickle(file_path)\n",
    "                if group not in df.columns or \"iptw\" not in df.columns:\n",
    "                    continue\n",
    "\n",
    "                X = df[covariates].copy()\n",
    "                T = df[group]\n",
    "                Y = df[\"caps5_change_baseline\"]\n",
    "                #W = df[\"iptw\"]\n",
    "\n",
    "                for repeat in range(n_repeats):\n",
    "                    kf = KFold(n_splits=5, shuffle=True, random_state=seed + repeat)\n",
    "                    for train_idx, test_idx in kf.split(X):\n",
    "                        try:\n",
    "                            X_train = X.iloc[train_idx]\n",
    "                            T_train = T.iloc[train_idx]\n",
    "                            Y_train = Y.iloc[train_idx]\n",
    "                            \n",
    "                            # XGBoost regression model\n",
    "                            model = xgb.XGBRegressor(n_estimators=100, max_depth=3, learning_rate=0.1, n_jobs=1, random_state=seed)\n",
    "                            \n",
    "                            # Add treatment variable to features\n",
    "                            X_train_with_T = X_train.copy()\n",
    "                            X_train_with_T[group] = T_train\n",
    "                            \n",
    "                            # Fit model\n",
    "                            model.fit(X_train_with_T, Y_train)\n",
    "                            \n",
    "                            # Predict outcomes for treated and control groups\n",
    "                            X_treated = X_train.copy()\n",
    "                            X_treated[group] = 1\n",
    "                            X_control = X_train.copy()\n",
    "                            X_control[group] = 0\n",
    "                            \n",
    "                            Y_pred_treated = model.predict(X_treated)\n",
    "                            Y_pred_control = model.predict(X_control)\n",
    "                            \n",
    "                            # Calculate ATT (Average Treatment Effect on Treated)\n",
    "                            treated_mask = T_train == 1\n",
    "                            if np.any(treated_mask):\n",
    "                                att = np.mean(Y_pred_treated[treated_mask] - Y_pred_control[treated_mask])\n",
    "                                \n",
    "                                # Calculate standard error (approximate)\n",
    "                                treatment_effects = Y_pred_treated[treated_mask] - Y_pred_control[treated_mask]\n",
    "                                residual = treatment_effects - att\n",
    "                                se = np.sqrt(np.sum((residual) ** 2)) / np.sum(treated_mask)\n",
    "                                att_list.append(att)\n",
    "                                se_list.append(se)\n",
    "\n",
    "                            # Model performance metrics\n",
    "                            Y_pred = model.predict(X_train_with_T)\n",
    "                            residuals = Y_train - Y_pred\n",
    "                            rmse = mean_squared_error(Y_train, Y_pred, squared=False)\n",
    "                            r2 = r2_score(Y_train, Y_pred)\n",
    "                            r2_list.append(r2)\n",
    "                            rmse_list.append(rmse)\n",
    "                            \n",
    "                            # Collect residuals and fitted values for diagnostic plots\n",
    "                            group_residuals.append(residuals.values)\n",
    "                            group_fitted.append(Y_pred)\n",
    "\n",
    "                            smd, vr = calculate_smd_vr(X_train, T_train)\n",
    "                            smd_list.append(smd)\n",
    "                            vr_list.append(vr)\n",
    "                        except Exception as e:\n",
    "                            print(f\"⚠️ Error in {group}, seed {seed}, imp {imp}, rep {repeat}: {e}\")\n",
    "\n",
    "            if att_list:\n",
    "                att, se, ci_l, ci_u, p_val = rubins_pool(att_list, se_list)\n",
    "                avg_r2 = np.mean(r2_list)\n",
    "                avg_rmse = np.mean(rmse_list)\n",
    "                avg_smd = np.mean(smd_list)\n",
    "                avg_vr = np.mean(vr_list)\n",
    "\n",
    "                balance_results.append({\n",
    "                    \"group\": group, \"seed\": seed, \"smd\": avg_smd, \"vr\": avg_vr\n",
    "                })\n",
    "\n",
    "                if se < best_se:\n",
    "                    best_se = se\n",
    "                    best_result = {\n",
    "                        \"group\": group, \"seed\": seed, \"att\": att, \"se\": se,\n",
    "                        \"ci_lower\": ci_l, \"ci_upper\": ci_u, \"p_value\": p_val,\n",
    "                        \"r2\": avg_r2, \"rmse\": avg_rmse\n",
    "                    }\n",
    "\n",
    "                print(f\"✅ {group} | Seed {seed}: ATT = {att:.4f}, SE = {se:.4f}, p = {p_val}\")\n",
    "            else:\n",
    "                print(f\"⚠️ No valid results for {group} | Seed {seed}\")\n",
    "\n",
    "        # Create diagnostic plots for this group\n",
    "        if group_residuals and group_fitted:\n",
    "            create_diagnostic_plots(group_residuals, group_fitted, group)\n",
    "\n",
    "        if best_result:\n",
    "            att_results.append(best_result)\n",
    "            print(f\"🏆 Best result for {group} → Seed {best_result['seed']} | SE = {best_result['se']:.4f}\")\n",
    "\n",
    "    # Save final output\n",
    "    pd.DataFrame(att_results).to_excel(\"xgb_rubin_summary_subsubcats_unweighted.xlsx\", index=False)\n",
    "    pd.DataFrame(balance_results).to_excel(\"smd_vr_summary_subsubcats_unweighted.xlsx\", index=False)\n",
    "    print(\"\\n🎯 All summary files saved.\")\n",
    "\n",
    "run_xgboost_with_trimmed_data(final_covariates_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "a4934729-7169-4ea1-8dd7-035896f38f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Final_ATT_Summary_SubSubCat saved.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import sem, ttest_ind\n",
    "\n",
    "# ----------------------------------\n",
    "# File paths\n",
    "# ----------------------------------\n",
    "output_base = \"outputs\"\n",
    "att_file = \"xgb_rubin_summary_subsubcats.xlsx\"\n",
    "trimmed_file = \"trimmed_data_imp1.pkl\"\n",
    "auc_file = \"auc_scores.xlsx\"  # NEW\n",
    "\n",
    "# ----------------------------------\n",
    "# Load ATT Summary\n",
    "# ----------------------------------\n",
    "if os.path.exists(att_file):\n",
    "    att_df = pd.read_excel(att_file)\n",
    "else:\n",
    "    raise FileNotFoundError(\"❌ ATT summary file not found: xgb_rubin_summary_subsubcats.xlsx\")\n",
    "\n",
    "summary_rows = []\n",
    "\n",
    "# ----------------------------------\n",
    "# Loop over medication groups\n",
    "# ----------------------------------\n",
    "groups = [g for g in medication_groups if os.path.isdir(os.path.join(output_base, g))]\n",
    "\n",
    "for med in groups:\n",
    "    try:\n",
    "        group_path = os.path.join(output_base, med)\n",
    "\n",
    "        # Load trimmed data\n",
    "        df = pd.read_pickle(os.path.join(group_path, trimmed_file))\n",
    "\n",
    "        # Detect treatment column\n",
    "        treatment_cols = [col for col in df.columns if col.upper() == med.upper()]\n",
    "        if not treatment_cols:\n",
    "            print(f\"⚠️ Treatment column {med} not found in trimmed data. Skipping.\")\n",
    "            continue\n",
    "        treatment_var = treatment_cols[0]\n",
    "\n",
    "        # Extract treatment and outcome\n",
    "        T = df[treatment_var]\n",
    "        Y = df[\"caps5_change_baseline\"]\n",
    "\n",
    "        # Treated and control stats\n",
    "        treated = Y[T == 1]\n",
    "        control = Y[T == 0]\n",
    "\n",
    "        mean_treat = treated.mean()\n",
    "        se_treat = sem(treated) if len(treated) > 1 else np.nan\n",
    "\n",
    "        mean_ctrl = control.mean()\n",
    "        se_ctrl = sem(control) if len(control) > 1 else np.nan\n",
    "\n",
    "        # Cohen's d (unadjusted)\n",
    "        pooled_sd = np.sqrt(((treated.std() ** 2) + (control.std() ** 2)) / 2)\n",
    "        cohen_d = (mean_treat - mean_ctrl) / pooled_sd if pooled_sd > 0 else np.nan\n",
    "\n",
    "        # E-value (unadjusted)\n",
    "        delta = mean_treat - mean_ctrl\n",
    "        E = delta / abs(mean_ctrl) * 100 if mean_ctrl != 0 else np.nan\n",
    "\n",
    "        # Unadjusted p-value\n",
    "        try:\n",
    "            t_stat, p_val = ttest_ind(treated, control, equal_var=False, nan_policy=\"omit\")\n",
    "            rounded_p = round(p_val, 5)\n",
    "            formatted_p = \"< 0.00001\" if rounded_p < 0.00001 else rounded_p\n",
    "        except Exception:\n",
    "            formatted_p = np.nan\n",
    "\n",
    "        # AUC from new auc_scores.xlsx file\n",
    "        auc_val = np.nan\n",
    "        auc_path = os.path.join(group_path, auc_file)\n",
    "        if os.path.exists(auc_path):\n",
    "            auc_df = pd.read_excel(auc_path)\n",
    "            if \"AUC\" in auc_df.columns:\n",
    "                auc_val = auc_df[\"AUC\"].dropna().mean()\n",
    "\n",
    "        # Adjusted stats from Rubin summary\n",
    "        att_row = att_df[att_df[\"group\"].str.strip().str.upper() == med.strip().upper()]\n",
    "        if not att_row.empty:\n",
    "            att = att_row.iloc[0][\"att\"]\n",
    "            att_se = att_row.iloc[0][\"se\"]\n",
    "            att_p_val = att_row.iloc[0][\"p_value\"]\n",
    "            r2 = att_row.iloc[0][\"r2\"]\n",
    "            rmse = att_row.iloc[0][\"rmse\"]\n",
    "\n",
    "            try:\n",
    "                rounded_att_p = round(float(att_p_val), 5)\n",
    "                formatted_att_p = \"< 0.00001\" if rounded_att_p < 0.00001 else rounded_att_p\n",
    "            except:\n",
    "                formatted_att_p = att_p_val\n",
    "        else:\n",
    "            att, att_se, formatted_att_p, r2, rmse = np.nan, np.nan, np.nan, np.nan, np.nan\n",
    "\n",
    "        # Append full row\n",
    "        summary_rows.append({\n",
    "            'Medication Group': med,\n",
    "            'Mean Treated': mean_treat,\n",
    "            'SE Treated': se_treat,\n",
    "            'Mean Control': mean_ctrl,\n",
    "            'SE Control': se_ctrl,\n",
    "            'Cohen d': cohen_d,\n",
    "            'E (Unadjusted)': E,\n",
    "            'n Treated': len(treated),\n",
    "            'n Control': len(control),\n",
    "            #'Unadjusted p-value': formatted_p,\n",
    "            'ATT Estimate': att,\n",
    "            'ATT SE (Robust)': att_se,\n",
    "            'ATT p-value': formatted_att_p,\n",
    "            'R²': r2,\n",
    "            'RMSE': rmse,\n",
    "            'AUC': auc_val\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error in {med}: {e}\")\n",
    "\n",
    "# ----------------------------------\n",
    "# Save final summary\n",
    "# ----------------------------------\n",
    "summary_df = pd.DataFrame(summary_rows)\n",
    "summary_df = summary_df.sort_values(\"Medication Group\")\n",
    "summary_df.to_excel(\"Final_ATT_Summary_SubSubCat.xlsx\", index=False)\n",
    "print(\"✅ Final_ATT_Summary_SubSubCat saved.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "d9fc6c9a-6722-4950-bc5c-eae4aca6bc4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ dml_att_barplot_subsubcat saved.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "# ✅ Load the final summary table\n",
    "final_df = pd.read_excel(\"Final_ATT_Summary_SubSubCat.xlsx\")\n",
    "\n",
    "# ✅ Parse DML p-values (handle \"< 0.00001\")\n",
    "def parse_pval(p):\n",
    "    try:\n",
    "        if isinstance(p, str) and \"<\" in p:\n",
    "            return 0.000001\n",
    "        return float(p)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "final_df['ATT p-value'] = final_df['ATT p-value'].apply(parse_pval)\n",
    "\n",
    "# ✅ Plot settings\n",
    "width = 0.35\n",
    "\n",
    "# ✅ Plotting function for a single medication group\n",
    "def plot_single_group(row):\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    bars1 = ax.bar(-width/2, row['Mean Control'], width, \n",
    "                   yerr=row['SE Control'], label='Control', hatch='//', color='gray', capsize=5)\n",
    "    bars2 = ax.bar(+width/2, row['Mean Treated'], width, \n",
    "                   yerr=row['SE Treated'], label='Treated', color='steelblue', capsize=5)\n",
    "\n",
    "    label = (\n",
    "        f\"ATT = {row['ATT Estimate']:.2f}\\n\"\n",
    "        f\"d = {row['Cohen d']:.2f}, p = {row['ATT p-value']:.3f}\\n\"\n",
    "        f\"nT = {row['n Treated']}, nC = {row['n Control']}\\n\"\n",
    "        f\"E = {row['E (Unadjusted)']:.1f}%\"\n",
    "    )\n",
    "    max_y = max(row['Mean Control'], row['Mean Treated']) + 1.5\n",
    "    ax.text(0, max_y, label, ha='center', va='bottom', fontsize=9, color='#FFD700')\n",
    "\n",
    "    ax.axhline(0, color='black', linewidth=0.8)\n",
    "    ax.set_xticks([-width/2, +width/2])\n",
    "    ax.set_xticklabels(['Control', 'Treated'])\n",
    "    ax.set_title(f\"Group: {row['Medication Group']}\", fontsize=12, weight='bold')\n",
    "    ax.set_ylabel(\"CAPS5 Change Score\")\n",
    "    ax.set_ylim(bottom=0, top=max_y + 2)\n",
    "    ax.legend()\n",
    "    fig.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# ✅ Generate and save all plots into a multi-page PDF\n",
    "with PdfPages(\"dml_att_barplot_subsubcat.pdf\") as pdf:\n",
    "    for idx, row in final_df.iterrows():\n",
    "        fig = plot_single_group(row)\n",
    "        pdf.savefig(fig, dpi=300, bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "\n",
    "print(\"✅ dml_att_barplot_subsubcat saved.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "3fb20a16-342a-43ce-a51f-2a9d7e47c07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Love plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "fb55a5b1-1691-474a-a290-ba7b2e229dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Processing SUBSUBCAT_Amitriptyline...\n",
      "📊 Exported numeric summary to: outputs\\SUBSUBCAT_Amitriptyline\\covariate_balance_table_SUBSUBCAT_Amitriptyline.xlsx\n",
      "✅ Saved love plot: outputs\\SUBSUBCAT_Amitriptyline\\love_plot_SUBSUBCAT_Amitriptyline.pdf\n",
      "📏 Max weighted SMD for SUBSUBCAT_Amitriptyline: 0.457\n",
      "\n",
      "🔍 Processing SUBSUBCAT_Bupropion...\n",
      "📊 Exported numeric summary to: outputs\\SUBSUBCAT_Bupropion\\covariate_balance_table_SUBSUBCAT_Bupropion.xlsx\n",
      "✅ Saved love plot: outputs\\SUBSUBCAT_Bupropion\\love_plot_SUBSUBCAT_Bupropion.pdf\n",
      "📏 Max weighted SMD for SUBSUBCAT_Bupropion: 0.256\n",
      "\n",
      "🔍 Processing SUBSUBCAT_Citalopram...\n",
      "📊 Exported numeric summary to: outputs\\SUBSUBCAT_Citalopram\\covariate_balance_table_SUBSUBCAT_Citalopram.xlsx\n",
      "✅ Saved love plot: outputs\\SUBSUBCAT_Citalopram\\love_plot_SUBSUBCAT_Citalopram.pdf\n",
      "📏 Max weighted SMD for SUBSUBCAT_Citalopram: 0.285\n",
      "\n",
      "🔍 Processing SUBSUBCAT_Diazepam...\n",
      "📊 Exported numeric summary to: outputs\\SUBSUBCAT_Diazepam\\covariate_balance_table_SUBSUBCAT_Diazepam.xlsx\n",
      "✅ Saved love plot: outputs\\SUBSUBCAT_Diazepam\\love_plot_SUBSUBCAT_Diazepam.pdf\n",
      "📏 Max weighted SMD for SUBSUBCAT_Diazepam: 0.492\n",
      "\n",
      "🔍 Processing SUBSUBCAT_Escitalopram...\n",
      "📊 Exported numeric summary to: outputs\\SUBSUBCAT_Escitalopram\\covariate_balance_table_SUBSUBCAT_Escitalopram.xlsx\n",
      "✅ Saved love plot: outputs\\SUBSUBCAT_Escitalopram\\love_plot_SUBSUBCAT_Escitalopram.pdf\n",
      "📏 Max weighted SMD for SUBSUBCAT_Escitalopram: 0.224\n",
      "\n",
      "🔍 Processing SUBSUBCAT_Fluoxetine...\n",
      "📊 Exported numeric summary to: outputs\\SUBSUBCAT_Fluoxetine\\covariate_balance_table_SUBSUBCAT_Fluoxetine.xlsx\n",
      "✅ Saved love plot: outputs\\SUBSUBCAT_Fluoxetine\\love_plot_SUBSUBCAT_Fluoxetine.pdf\n",
      "📏 Max weighted SMD for SUBSUBCAT_Fluoxetine: 0.269\n",
      "\n",
      "🔍 Processing SUBSUBCAT_Lorazepam...\n",
      "📊 Exported numeric summary to: outputs\\SUBSUBCAT_Lorazepam\\covariate_balance_table_SUBSUBCAT_Lorazepam.xlsx\n",
      "✅ Saved love plot: outputs\\SUBSUBCAT_Lorazepam\\love_plot_SUBSUBCAT_Lorazepam.pdf\n",
      "📏 Max weighted SMD for SUBSUBCAT_Lorazepam: 0.403\n",
      "\n",
      "🔍 Processing SUBSUBCAT_Methylfenidaat...\n",
      "📊 Exported numeric summary to: outputs\\SUBSUBCAT_Methylfenidaat\\covariate_balance_table_SUBSUBCAT_Methylfenidaat.xlsx\n",
      "✅ Saved love plot: outputs\\SUBSUBCAT_Methylfenidaat\\love_plot_SUBSUBCAT_Methylfenidaat.pdf\n",
      "📏 Max weighted SMD for SUBSUBCAT_Methylfenidaat: 0.379\n",
      "\n",
      "🔍 Processing SUBSUBCAT_Mirtazapine...\n",
      "📊 Exported numeric summary to: outputs\\SUBSUBCAT_Mirtazapine\\covariate_balance_table_SUBSUBCAT_Mirtazapine.xlsx\n",
      "✅ Saved love plot: outputs\\SUBSUBCAT_Mirtazapine\\love_plot_SUBSUBCAT_Mirtazapine.pdf\n",
      "📏 Max weighted SMD for SUBSUBCAT_Mirtazapine: 0.270\n",
      "\n",
      "🔍 Processing SUBSUBCAT_Olanzapine...\n",
      "📊 Exported numeric summary to: outputs\\SUBSUBCAT_Olanzapine\\covariate_balance_table_SUBSUBCAT_Olanzapine.xlsx\n",
      "✅ Saved love plot: outputs\\SUBSUBCAT_Olanzapine\\love_plot_SUBSUBCAT_Olanzapine.pdf\n",
      "📏 Max weighted SMD for SUBSUBCAT_Olanzapine: 0.342\n",
      "\n",
      "🔍 Processing SUBSUBCAT_Oxazepam...\n",
      "📊 Exported numeric summary to: outputs\\SUBSUBCAT_Oxazepam\\covariate_balance_table_SUBSUBCAT_Oxazepam.xlsx\n",
      "✅ Saved love plot: outputs\\SUBSUBCAT_Oxazepam\\love_plot_SUBSUBCAT_Oxazepam.pdf\n",
      "📏 Max weighted SMD for SUBSUBCAT_Oxazepam: 0.104\n",
      "\n",
      "🔍 Processing SUBSUBCAT_Paracetamol...\n",
      "📊 Exported numeric summary to: outputs\\SUBSUBCAT_Paracetamol\\covariate_balance_table_SUBSUBCAT_Paracetamol.xlsx\n",
      "✅ Saved love plot: outputs\\SUBSUBCAT_Paracetamol\\love_plot_SUBSUBCAT_Paracetamol.pdf\n",
      "📏 Max weighted SMD for SUBSUBCAT_Paracetamol: 0.349\n",
      "\n",
      "🔍 Processing SUBSUBCAT_Quetiapine...\n",
      "📊 Exported numeric summary to: outputs\\SUBSUBCAT_Quetiapine\\covariate_balance_table_SUBSUBCAT_Quetiapine.xlsx\n",
      "✅ Saved love plot: outputs\\SUBSUBCAT_Quetiapine\\love_plot_SUBSUBCAT_Quetiapine.pdf\n",
      "📏 Max weighted SMD for SUBSUBCAT_Quetiapine: 0.215\n",
      "\n",
      "🔍 Processing SUBSUBCAT_Sertraline...\n",
      "📊 Exported numeric summary to: outputs\\SUBSUBCAT_Sertraline\\covariate_balance_table_SUBSUBCAT_Sertraline.xlsx\n",
      "✅ Saved love plot: outputs\\SUBSUBCAT_Sertraline\\love_plot_SUBSUBCAT_Sertraline.pdf\n",
      "📏 Max weighted SMD for SUBSUBCAT_Sertraline: 0.171\n",
      "\n",
      "🔍 Processing SUBSUBCAT_Temazepam...\n",
      "📊 Exported numeric summary to: outputs\\SUBSUBCAT_Temazepam\\covariate_balance_table_SUBSUBCAT_Temazepam.xlsx\n",
      "✅ Saved love plot: outputs\\SUBSUBCAT_Temazepam\\love_plot_SUBSUBCAT_Temazepam.pdf\n",
      "📏 Max weighted SMD for SUBSUBCAT_Temazepam: 0.239\n",
      "\n",
      "🔍 Processing SUBSUBCAT_Topiramaat...\n",
      "📊 Exported numeric summary to: outputs\\SUBSUBCAT_Topiramaat\\covariate_balance_table_SUBSUBCAT_Topiramaat.xlsx\n",
      "✅ Saved love plot: outputs\\SUBSUBCAT_Topiramaat\\love_plot_SUBSUBCAT_Topiramaat.pdf\n",
      "📏 Max weighted SMD for SUBSUBCAT_Topiramaat: 0.548\n",
      "\n",
      "🔍 Processing SUBSUBCAT_Venlafaxine...\n",
      "📊 Exported numeric summary to: outputs\\SUBSUBCAT_Venlafaxine\\covariate_balance_table_SUBSUBCAT_Venlafaxine.xlsx\n",
      "✅ Saved love plot: outputs\\SUBSUBCAT_Venlafaxine\\love_plot_SUBSUBCAT_Venlafaxine.pdf\n",
      "📏 Max weighted SMD for SUBSUBCAT_Venlafaxine: 0.235\n",
      "\n",
      "🔍 Processing SUBSUBCAT_Zopiclon...\n",
      "📊 Exported numeric summary to: outputs\\SUBSUBCAT_Zopiclon\\covariate_balance_table_SUBSUBCAT_Zopiclon.xlsx\n",
      "✅ Saved love plot: outputs\\SUBSUBCAT_Zopiclon\\love_plot_SUBSUBCAT_Zopiclon.pdf\n",
      "📏 Max weighted SMD for SUBSUBCAT_Zopiclon: 0.365\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "# ----------------------------------------\n",
    "# Functions to calculate balance\n",
    "# ----------------------------------------\n",
    "def calculate_smd(x1, x2, w1=None, w2=None):\n",
    "    def weighted_mean(x, w): return np.average(x, weights=w)\n",
    "    def weighted_var(x, w):\n",
    "        m = np.average(x, weights=w)\n",
    "        return np.average((x - m) ** 2, weights=w)\n",
    "    \n",
    "    m1 = weighted_mean(x1, w1) if w1 is not None else np.mean(x1)\n",
    "    m2 = weighted_mean(x2, w2) if w2 is not None else np.mean(x2)\n",
    "    v1 = weighted_var(x1, w1) if w1 is not None else np.var(x1, ddof=1)\n",
    "    v2 = weighted_var(x2, w2) if w2 is not None else np.var(x2, ddof=1)\n",
    "    \n",
    "    pooled_sd = np.sqrt((v1 + v2) / 2)\n",
    "    return np.abs(m1 - m2) / pooled_sd if pooled_sd > 0 else 0\n",
    "\n",
    "def variance_ratio(x1, x2, w1=None, w2=None):\n",
    "    def weighted_var(x, w):\n",
    "        m = np.average(x, weights=w)\n",
    "        return np.average((x - m) ** 2, weights=w)\n",
    "    \n",
    "    v1 = weighted_var(x1, w1) if w1 is not None else np.var(x1, ddof=1)\n",
    "    v2 = weighted_var(x2, w2) if w2 is not None else np.var(x2, ddof=1)\n",
    "    \n",
    "    return max(v1 / v2, v2 / v1) if v1 > 0 and v2 > 0 else 1\n",
    "\n",
    "# ----------------------------------------\n",
    "# Setup\n",
    "# ----------------------------------------\n",
    "output_base = \"outputs\"\n",
    "groups = [g for g in os.listdir(output_base) if os.path.isdir(os.path.join(output_base, g))]\n",
    "\n",
    "# Create a case-insensitive mapping\n",
    "final_covariates_map_lower = {k.lower(): v for k, v in final_covariates_map.items()}\n",
    "\n",
    "# ----------------------------------------\n",
    "# Main Loop\n",
    "# ----------------------------------------\n",
    "for group in groups:\n",
    "    if group.lower() not in final_covariates_map_lower:\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n🔍 Processing {group}...\")\n",
    "\n",
    "    try:\n",
    "        group_path = os.path.join(output_base, group)\n",
    "        covariates = final_covariates_map_lower[group.lower()]\n",
    "        \n",
    "        column_name = None\n",
    "        for col in pd.read_pickle(os.path.join(group_path, \"trimmed_data_imp1.pkl\")).columns:\n",
    "            if col.lower() == group.lower():\n",
    "                column_name = col\n",
    "                break\n",
    "        if column_name is None:\n",
    "            print(f\"⚠️ Column not found for {group}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        smd_unw_all, smd_w_all = [], []\n",
    "        vr_unw_all, vr_w_all = [], []\n",
    "\n",
    "        for i in range(1, 6):\n",
    "            df_path = os.path.join(group_path, f\"trimmed_data_imp{i}.pkl\")\n",
    "            iptw_path = os.path.join(group_path, \"iptw_weights.xlsx\")\n",
    "\n",
    "            if not os.path.exists(df_path) or not os.path.exists(iptw_path):\n",
    "                print(f\"⚠️ Missing data for {group} imp{i}, skipping.\")\n",
    "                continue\n",
    "\n",
    "            df = pd.read_pickle(df_path)\n",
    "            iptw_df = pd.read_excel(iptw_path, index_col=0)\n",
    "            T = df[column_name]\n",
    "            W = iptw_df.loc[df.index, \"iptw_mean\"]\n",
    "\n",
    "            smd_unw_i, smd_w_i, vr_unw_i, vr_w_i = [], [], [], []\n",
    "\n",
    "            for cov in covariates:\n",
    "                x1, x0 = df.loc[T == 1, cov], df.loc[T == 0, cov]\n",
    "                w1, w0 = W[T == 1], W[T == 0]\n",
    "\n",
    "                su = calculate_smd(x1, x0)\n",
    "                sw = calculate_smd(x1, x0, w1, w0)\n",
    "\n",
    "                vu = variance_ratio(x1, x0) if cov in ['treatmentdurationdays', 'CAPS5score_baseline', 'age'] else np.nan\n",
    "                vw = variance_ratio(x1, x0, w1, w0) if cov in ['treatmentdurationdays', 'CAPS5score_baseline', 'age'] else np.nan\n",
    "\n",
    "                smd_unw_i.append(su)\n",
    "                smd_w_i.append(sw)\n",
    "                vr_unw_i.append(vu)\n",
    "                vr_w_i.append(vw)\n",
    "\n",
    "            smd_unw_all.append(smd_unw_i)\n",
    "            smd_w_all.append(smd_w_i)\n",
    "            vr_unw_all.append(vr_unw_i)\n",
    "            vr_w_all.append(vr_w_i)\n",
    "\n",
    "        smd_unw = np.mean(smd_unw_all, axis=0)\n",
    "        smd_w = np.mean(smd_w_all, axis=0)\n",
    "        vr_unw = np.nanmean(vr_unw_all, axis=0)\n",
    "        vr_w = np.nanmean(vr_w_all, axis=0)\n",
    "\n",
    "        severity = []\n",
    "        for sw in smd_w:\n",
    "            if sw <= 0.1:\n",
    "                severity.append(\"Good\")\n",
    "            elif sw <= 0.2:\n",
    "                severity.append(\"Moderate\")\n",
    "            else:\n",
    "                severity.append(\"Poor\")\n",
    "\n",
    "        covariate_names = covariates\n",
    "        numeric_df = pd.DataFrame({\n",
    "            \"Covariate\": covariate_names,\n",
    "            \"SMD_Unweighted\": smd_unw,\n",
    "            \"SMD_Weighted\": smd_w,\n",
    "            \"Imbalance_Severity\": severity,\n",
    "            \"VR_Unweighted\": vr_unw,\n",
    "            \"VR_Weighted\": vr_w\n",
    "        })\n",
    "\n",
    "        numeric_path = os.path.join(group_path, f\"covariate_balance_table_{group}.xlsx\")\n",
    "        numeric_df.to_excel(numeric_path, index=False)\n",
    "        print(f\"📊 Exported numeric summary to: {numeric_path}\")\n",
    "\n",
    "        # -------------------------\n",
    "        # Plot\n",
    "        # -------------------------\n",
    "        labels = covariates\n",
    "        y_pos = np.arange(len(labels))\n",
    "\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(18, len(labels) * 0.45))\n",
    "\n",
    "        axes[0].scatter(smd_unw, y_pos, color='red', label=\"Unweighted\")\n",
    "        axes[0].scatter(smd_w, y_pos, color='blue', label=\"Weighted\")\n",
    "        axes[0].axvline(0.1, color='gray', linestyle='--', label=\"Threshold 0.1\")\n",
    "        axes[0].axvline(0.2, color='black', linestyle='--', label=\"Threshold 0.2\")\n",
    "        axes[0].set_xlim(0, max(max(smd_unw), max(smd_w), 0.25) + 0.05)\n",
    "        axes[0].set_yticks(y_pos)\n",
    "        axes[0].set_yticklabels(labels)\n",
    "        axes[0].invert_yaxis()\n",
    "        axes[0].set_title(\"Standardized Mean Differences (SMD)\")\n",
    "        axes[0].legend(loc=\"upper right\")\n",
    "        axes[0].grid(True)\n",
    "\n",
    "        vr_mask = [cov in ['treatmentdurationdays', 'CAPS5score_baseline', 'age'] for cov in covariates]\n",
    "        filtered_y = [i for i, b in enumerate(vr_mask) if b]\n",
    "        filtered_labels = [labels[i] for i in filtered_y]\n",
    "        filtered_vr_unw = [vr_unw[i] for i in filtered_y]\n",
    "        filtered_vr_w = [vr_w[i] for i in filtered_y]\n",
    "\n",
    "        axes[1].scatter(filtered_vr_unw, filtered_y, color='blue', marker='o', label=\"Unweighted\")\n",
    "        axes[1].scatter(filtered_vr_w, filtered_y, color='red', marker='x', label=\"Weighted\")\n",
    "        axes[1].axvline(2, color='gray', linestyle='--')\n",
    "        axes[1].axvline(0.5, color='gray', linestyle='--')\n",
    "        axes[1].set_xlim(0, max(filtered_vr_unw + filtered_vr_w + [2.5]) + 0.5)\n",
    "        axes[1].set_yticks(filtered_y)\n",
    "        axes[1].set_yticklabels(filtered_labels)\n",
    "        axes[1].invert_yaxis()\n",
    "        axes[1].set_title(\"Variance Ratio (VR)\")\n",
    "        axes[1].legend()\n",
    "        axes[1].grid(True)\n",
    "\n",
    "        fig.suptitle(f\"Covariate Balance for {group.replace('CAT_', '')}\", fontsize=14, weight='bold')\n",
    "        fig.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "        plot_path = os.path.join(group_path, f\"love_plot_{group}.pdf\")\n",
    "        fig.savefig(plot_path, dpi=300)\n",
    "        plt.close()\n",
    "        print(f\"✅ Saved love plot: {plot_path}\")\n",
    "        print(f\"📏 Max weighted SMD for {group}: {np.max(smd_w):.3f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error in {group}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "ddcdd856-d7d1-4798-a62a-e15111f052d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "5954afc7-c558-47c5-8220-2e870f68f38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Creating Heatmap for SubSubCat_Oxazepam ==========\n",
      "✅ Heatmap saved: outputs\\SubSubCat_Oxazepam\\heatmap_smd_SubSubCat_Oxazepam.png\n",
      "\n",
      "========== Creating Heatmap for SubSubCat_Diazepam ==========\n",
      "✅ Heatmap saved: outputs\\SubSubCat_Diazepam\\heatmap_smd_SubSubCat_Diazepam.png\n",
      "\n",
      "========== Creating Heatmap for SubSubCat_Paracetamol ==========\n",
      "✅ Heatmap saved: outputs\\SubSubCat_Paracetamol\\heatmap_smd_SubSubCat_Paracetamol.png\n",
      "\n",
      "========== Creating Heatmap for SubSubCat_Lorazepam ==========\n",
      "✅ Heatmap saved: outputs\\SubSubCat_Lorazepam\\heatmap_smd_SubSubCat_Lorazepam.png\n",
      "\n",
      "========== Creating Heatmap for SubSubCat_Mirtazapine ==========\n",
      "✅ Heatmap saved: outputs\\SubSubCat_Mirtazapine\\heatmap_smd_SubSubCat_Mirtazapine.png\n",
      "\n",
      "========== Creating Heatmap for SubSubCat_Escitalopram ==========\n",
      "✅ Heatmap saved: outputs\\SubSubCat_Escitalopram\\heatmap_smd_SubSubCat_Escitalopram.png\n",
      "\n",
      "========== Creating Heatmap for SubSubCat_Sertraline ==========\n",
      "✅ Heatmap saved: outputs\\SubSubCat_Sertraline\\heatmap_smd_SubSubCat_Sertraline.png\n",
      "\n",
      "========== Creating Heatmap for SubSubCat_Temazepam ==========\n",
      "✅ Heatmap saved: outputs\\SubSubCat_Temazepam\\heatmap_smd_SubSubCat_Temazepam.png\n",
      "\n",
      "========== Creating Heatmap for SubSubCat_Citalopram ==========\n",
      "✅ Heatmap saved: outputs\\SubSubCat_Citalopram\\heatmap_smd_SubSubCat_Citalopram.png\n",
      "\n",
      "========== Creating Heatmap for SubSubCat_Quetiapine ==========\n",
      "✅ Heatmap saved: outputs\\SubSubCat_Quetiapine\\heatmap_smd_SubSubCat_Quetiapine.png\n",
      "\n",
      "========== Creating Heatmap for SubSubCat_Amitriptyline ==========\n",
      "✅ Heatmap saved: outputs\\SubSubCat_Amitriptyline\\heatmap_smd_SubSubCat_Amitriptyline.png\n",
      "\n",
      "========== Creating Heatmap for SubSubCat_Venlafaxine ==========\n",
      "✅ Heatmap saved: outputs\\SubSubCat_Venlafaxine\\heatmap_smd_SubSubCat_Venlafaxine.png\n",
      "\n",
      "========== Creating Heatmap for SubSubCat_Fluoxetine ==========\n",
      "✅ Heatmap saved: outputs\\SubSubCat_Fluoxetine\\heatmap_smd_SubSubCat_Fluoxetine.png\n",
      "\n",
      "========== Creating Heatmap for SubSubCat_Topiramaat ==========\n",
      "✅ Heatmap saved: outputs\\SubSubCat_Topiramaat\\heatmap_smd_SubSubCat_Topiramaat.png\n",
      "\n",
      "========== Creating Heatmap for SubSubCat_Zopiclon ==========\n",
      "✅ Heatmap saved: outputs\\SubSubCat_Zopiclon\\heatmap_smd_SubSubCat_Zopiclon.png\n",
      "\n",
      "========== Creating Heatmap for SubSubCat_Bupropion ==========\n",
      "✅ Heatmap saved: outputs\\SubSubCat_Bupropion\\heatmap_smd_SubSubCat_Bupropion.png\n",
      "\n",
      "========== Creating Heatmap for SubSubCat_Methylfenidaat ==========\n",
      "✅ Heatmap saved: outputs\\SubSubCat_Methylfenidaat\\heatmap_smd_SubSubCat_Methylfenidaat.png\n",
      "\n",
      "========== Creating Heatmap for SubSubCat_Olanzapine ==========\n",
      "✅ Heatmap saved: outputs\\SubSubCat_Olanzapine\\heatmap_smd_SubSubCat_Olanzapine.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "#-----------------------------\n",
    "# Generate heatmaps\n",
    "# -------------------------------\n",
    "for treatment_var in medication_groups:\n",
    "    print(f\"\\n========== Creating Heatmap for {treatment_var} ==========\")\n",
    "\n",
    "    try:\n",
    "        output_folder = os.path.join('outputs', treatment_var)\n",
    "        balance_path = os.path.join(output_folder, f'covariate_balance_table_{treatment_var}.xlsx')\n",
    "\n",
    "        if not os.path.exists(balance_path):\n",
    "            print(f\"❌ Balance file not found: {balance_path}\")\n",
    "            continue\n",
    "\n",
    "        balance_df = pd.read_excel(balance_path)\n",
    "\n",
    "        # ✅ Use finalized covariates + 'Propensity Score'\n",
    "        covariates = final_covariates_map[treatment_var] + ['Propensity Score']\n",
    "        balance_df = balance_df[balance_df['Covariate'].isin(covariates)]\n",
    "\n",
    "        # ✅ Check for CAPS5score_baseline\n",
    "        highlight_caps = 'CAPS5score_baseline' in balance_df['Covariate'].values\n",
    "\n",
    "        # ✅ Format for heatmap\n",
    "        heatmap_df = balance_df[['Covariate', 'SMD_Unweighted', 'SMD_Weighted']].copy()\n",
    "        heatmap_df.columns = ['Covariate', 'Unweighted', 'Weighted']\n",
    "        heatmap_df = heatmap_df.set_index('Covariate')\n",
    "        heatmap_df = heatmap_df.sort_values(by='Unweighted', ascending=False)\n",
    "\n",
    "        # ✅ Plot\n",
    "        plt.figure(figsize=(12, max(10, len(heatmap_df) * 0.35)))\n",
    "        ax = sns.heatmap(\n",
    "            heatmap_df,\n",
    "            cmap=\"coolwarm\",\n",
    "            annot=True,\n",
    "            fmt=\".2f\",\n",
    "            linewidths=0.6,\n",
    "            linecolor='gray',\n",
    "            cbar_kws={\"label\": \"Standardized Mean Difference\"}\n",
    "        )\n",
    "\n",
    "        plt.title(f\"Covariate Balance Heatmap (Rubin IPTW)\\n{treatment_var}\", fontsize=15, weight='bold')\n",
    "        plt.xlabel(\"Condition\")\n",
    "        plt.ylabel(\"Covariate\")\n",
    "\n",
    "        # ✅ Bold CAPS5score_baseline if present\n",
    "        if highlight_caps:\n",
    "            ylabels = [label.get_text() for label in ax.get_yticklabels()]\n",
    "            ax.set_yticklabels([\n",
    "                f\"{label} ←\" if label == 'CAPS5score_baseline' else label for label in ylabels\n",
    "            ])\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # ✅ Save image\n",
    "        save_path = os.path.join(output_folder, f'heatmap_smd_{treatment_var}.png')\n",
    "        plt.savefig(save_path, dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "        print(f\"✅ Heatmap saved: {save_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error processing {treatment_var}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41205247-e0b5-4fbc-ba3e-6aef9f0db831",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2fa40d9-c5d4-4d72-b2bb-c7fc640070bd",
   "metadata": {},
   "source": [
    "#### Linear:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "603b1f68-ffa1-4f34-af91-6e956a00dbea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed to: D:\\Work\\PTSD_Followup\\Linear\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")  # optional\n",
    "\n",
    "# Option 1 (recommended)\n",
    "new_path = r\"D:\\Work\\PTSD_Followup\\Linear\"\n",
    "\n",
    "os.chdir(new_path)  # Change working directory\n",
    "print(\"Changed to:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "d71fe1e9-9097-47b9-a5ae-72f9408705de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(r\"data_baseline.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde047be-55f7-4cad-b980-cf121cf7ec5e",
   "metadata": {},
   "source": [
    "### CAT analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "2be65d52-1c12-486c-9558-a1eecf3d9b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "# For visualization and future steps\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer  # Needed to enable the experimental feature\n",
    "from sklearn.impute import IterativeImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "e4e72b91-21f3-4b13-bdfc-d027fb163745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataset: (6125, 465)\n",
      "\n",
      "Sample columns: ['CIN5', 'StartDatum', 'BEH_MOD', 'BEHDAGEN_GEPLAND', 'AANTAL_PCL', 'TOESTWO', 'BEH_AFG', 'TK', 'MM_CAPS_IN', 'MM_CAPS_TK']\n",
      "\n",
      "Missing values:\n",
      " instrument_SDV_IN    6125\n",
      "Eaantal_TK           6125\n",
      "Dcriterium_FU        6125\n",
      "Cernst_FU            6125\n",
      "Caantal_FU           6125\n",
      "Ccriterium_FU        6125\n",
      "Bernst_FU            6125\n",
      "Baantal_FU           6125\n",
      "Bcriterium_FU        6125\n",
      "Eernst_TK            6125\n",
      "dtype: int64\n",
      "Shape after removing duplicates: (6125, 465)\n"
     ]
    }
   ],
   "source": [
    "# Check basic structure\n",
    "print(\"Shape of dataset:\", df.shape)\n",
    "print(\"\\nSample columns:\", df.columns.tolist()[:10])\n",
    "print(\"\\nMissing values:\\n\", df.isnull().sum().sort_values(ascending=False).head(10))\n",
    "\n",
    "# Remove duplicate rows\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Confirm shape after removing duplicates\n",
    "print(\"Shape after removing duplicates:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "34494260-4db2-4e0e-9415-bd65ce18a0da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDV_SEXE  gender_label\n",
      "2.0       Female          4602\n",
      "1.0       Male            1475\n",
      "3.0       Other             48\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pyreadstat\n",
    "\n",
    "# Load gender info\n",
    "gender_df, meta = pyreadstat.read_sav(\"SDV_IN_Gender_2019_2024.sav\")\n",
    "\n",
    "# Just extract SDV_SEXE column and append to df\n",
    "df[\"SDV_SEXE\"] = gender_df[\"SDV_SEXE\"].reset_index(drop=True)\n",
    "\n",
    "# Optional: map to labels\n",
    "gender_map = {1.0: \"Male\", 2.0: \"Female\", 3.0: \"Other\"}\n",
    "df[\"gender_label\"] = df[\"SDV_SEXE\"].map(gender_map)\n",
    "\n",
    "# Done! Check a sample\n",
    "print(df[[\"SDV_SEXE\", \"gender_label\"]].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "f8c8ee38-b998-4ab6-9123-8dbc00c7014b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gender dummy variables\n",
    "df['gender_1'] = (df['gender'] == 1).astype(int)\n",
    "df['gender_2'] = (df['gender'] == 2).astype(int)\n",
    "\n",
    "# SDV_SEXE dummy variables\n",
    "df['SDV_SEXE_1'] = (df['SDV_SEXE'] == 1).astype(int)\n",
    "df['SDV_SEXE_2'] = (df['SDV_SEXE'] == 2).astype(int)\n",
    "df['SDV_SEXE_3'] = (df['SDV_SEXE'] == 3).astype(int)\n",
    "\n",
    "# Create binary columns\n",
    "df['ethnicity_Dutch'] = np.where(df['ethnicity'] == 1, 1, 0)\n",
    "df['ethnicity_other'] = np.where(df['ethnicity'] != 1, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "39916736-26ad-496b-aad5-ad8971ebd97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining columns: 458\n"
     ]
    }
   ],
   "source": [
    "# Columns manually identified for removal (example set from the R script)\n",
    "cols_to_drop = [\n",
    "    'gender', 'ethnicity', 'CIN5', 'SDV_SEXE', 'StartDatum', 'STARTDATUM', 'DROPOUT_EARLYCOMPLETER', 'TOEST_WO',\n",
    "    'depressie_IN', 'TERUGKOMER', 'VROEGK_ST', 'gender_label',\n",
    "    'depr_m_psychose_huid', 'depr_z_psychose_huid', 'depr_z_psychose_verl',\n",
    "    'depr_m_psychose_verl', 'CAPS5score_followup', 'CAPS5_DAT_IN'\n",
    "]\n",
    "\n",
    "df = df.drop(columns=[col for col in cols_to_drop if col in df.columns])\n",
    "print(\"Remaining columns:\", df.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "64d8554a-5a61-4e93-aad3-cccbb21e91ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'BEH_DAGEN' in df.columns:\n",
    "    df.rename(columns={'BEH_DAGEN': 'treatmentdurationdays'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "13ecc924-a101-4aa2-8bda-6ccb35757f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean and standardize column names\n",
    "df.columns = (\n",
    "    df.columns\n",
    "    .str.replace(r\"\\.+\", \"_\", regex=True)\n",
    "    .str.replace(r\"[^a-zA-Z0-9_]\", \"\", regex=True)\n",
    "    .str.replace(\" \", \"_\")\n",
    "    .str.strip()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "5cbcc1fe-29a8-487d-83e7-89ebc407d9df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAPS5score_baseline: 0 missing\n",
      "CAPS5Score_TK: 0 missing\n"
     ]
    }
   ],
   "source": [
    "# Preview key outcome variables\n",
    "outcome_vars = ['CAPS5score_baseline', 'CAPS5Score_TK']\n",
    "for col in outcome_vars:\n",
    "    if col in df.columns:\n",
    "        print(f\"{col}: {df[col].isnull().sum()} missing\")\n",
    "\n",
    "# Calculate change score\n",
    "if 'CAPS5score_baseline' in df.columns and 'CAPS5Score_TK' in df.columns:\n",
    "    df['caps5_change_baseline'] = df['CAPS5Score_TK'] - df['CAPS5score_baseline']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "b6b826fa-2bcc-47be-b765-b9e0ec65d2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define exceptions to keep\n",
    "protected_cols = [\n",
    "    \"DIAGNOSIS_ANXIETY_OCD\",\n",
    "    \"DIAGNOSIS_PSYCHOTIC\",\n",
    "    \"DIAGNOSIS_EATING_DISORDER\",\n",
    "    \"DIAGNOSIS_SUBSTANCE_DISORDER\", \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"EB_NON_TF_THERAPY\", \"OTHER_TREATM_APPROACH\", \"Bipolar_and_Mood_disorder\", 'SUBCAT_Selectieve_immunosuppresiva', 'treatmentdurationdays',\n",
    "'SUBCAT_Corticosteroiden',\n",
    "'SUBCAT_Immunomodulerend_Coxibs',\n",
    "'SUBCAT_Aminosalicylaten',\n",
    "'SUBCAT_calcineurineremmers',\n",
    "'SUBCAT_Anti_epileptica_Benzodiazepine',\n",
    "'SUBCAT_Paracetamol_overig_combinatie', 'SUBCAT_MAO_remmers', 'SUBCAT_psychostimulans_overige', 'SUBCAT_Interleukine_remmers'\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "# ----------------------------------------\n",
    "# 1. Drop columns with >95% missing values (except protected)\n",
    "thresh_missing = int(0.95 * len(df))\n",
    "missing_cols = [col for col in df.columns if df[col].isnull().sum() > (len(df) - thresh_missing)]\n",
    "missing_cols_to_drop = [col for col in missing_cols if col not in protected_cols]\n",
    "df = df.drop(columns=missing_cols_to_drop)\n",
    "\n",
    "# ----------------------------------------\n",
    "# 2. Drop near-zero variance columns (except protected)\n",
    "low_variance_cols = [col for col in df.columns if df[col].nunique(dropna=True) <= 1 and col not in protected_cols]\n",
    "df = df.drop(columns=low_variance_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "7ce9cb46-a001-4a67-a879-12609fe04975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Step 1 Complete: Cleaned dataset saved.\n"
     ]
    }
   ],
   "source": [
    "df.to_csv(\"cleaned_data_baseline.csv\", index=False)\n",
    "print(\" Step 1 Complete: Cleaned dataset saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "efec01fd-23a3-422f-a48f-2c743d1a95b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "3d2cb15a-68ac-48dc-950d-468a617fa482",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from fancyimpute import IterativeImputer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "961b11fc-d3ff-48fe-8f66-8f376dc1f989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6125, 204)\n",
      "DIAGNOSIS_ANXIETY_OCD           float64\n",
      "DIAGNOSIS_SMOKING               float64\n",
      "DIAGNOSIS_EATING_DISORDER       float64\n",
      "DIAGNOSIS_SUBSTANCE_DISORDER    float64\n",
      "DIAGNOSIS_PSYCHOTIC             float64\n",
      "DIAGNOSIS_SUICIDALITY           float64\n",
      "DIAGNOSIS_SEXUAL_TRAUMA         float64\n",
      "DIAGNOSIS_CHILDHOOD_TRAUMA        int64\n",
      "DIAGNOSIS_CPTSD                 float64\n",
      "treatmentdurationdays           float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Load the cleaned dataset from Step 1\n",
    "df = pd.read_csv(\"cleaned_data_baseline.csv\")\n",
    "\n",
    "# Quick check\n",
    "print(df.shape)\n",
    "print(df.dtypes.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "4d323534-760c-4cbe-bd3d-b5f256772198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate Numerical and Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "06098718-4825-4c06-9b9c-31c5299ec0e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical Columns: 204\n",
      "Categorical Columns: 0\n"
     ]
    }
   ],
   "source": [
    "# Identify numerical and categorical columns\n",
    "numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "print(f\"Numerical Columns: {len(numerical_cols)}\")\n",
    "print(f\"Categorical Columns: {len(categorical_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "4ded6f4e-93b5-4070-80e3-f49c67f60ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values summary:\n",
      "DIAGNOSIS_PSYCHOTIC_missing: 2484\n",
      "DIAGNOSIS_ANXIETY_OCD_missing: 2484\n",
      "Bipolar_and_Mood_disorder_missing: 2484\n",
      "DIAGNOSIS_EATING_DISORDER_missing: 2484\n",
      "total_rows: 6125\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Check missing values for each variable\n",
    "missing_summary = {\n",
    "    'DIAGNOSIS_PSYCHOTIC_missing': df['DIAGNOSIS_PSYCHOTIC'].isna().sum(),\n",
    "    'DIAGNOSIS_ANXIETY_OCD_missing': df['DIAGNOSIS_ANXIETY_OCD'].isna().sum(),\n",
    "    'Bipolar_and_Mood_disorder_missing': df['Bipolar_and_Mood_disorder'].isna().sum(),\n",
    "    'DIAGNOSIS_EATING_DISORDER_missing': df['DIAGNOSIS_EATING_DISORDER'].isna().sum(),\n",
    "    'total_rows': len(df)\n",
    "}\n",
    "\n",
    "print(\"Missing values summary:\")\n",
    "for key, value in missing_summary.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "504c0817-ce8c-480a-9c95-84cccf05af8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing data pattern:\n",
      "has_missing\n",
      "False    3641\n",
      "True     2484\n",
      "Name: count, dtype: int64\n",
      "Patients with missing data: 2484\n",
      "Patients with complete data: 3641\n"
     ]
    }
   ],
   "source": [
    "# Define the mental health variables\n",
    "mental_health_vars = ['DIAGNOSIS_PSYCHOTIC', 'DIAGNOSIS_ANXIETY_OCD', \n",
    "                      'Bipolar_and_Mood_disorder', 'DIAGNOSIS_EATING_DISORDER']\n",
    "\n",
    "# Check patients with missing data on any of the 4 variables\n",
    "df['has_missing'] = df[mental_health_vars].isna().any(axis=1)\n",
    "\n",
    "# Summary of missing pattern\n",
    "print(\"\\nMissing data pattern:\")\n",
    "print(df['has_missing'].value_counts())\n",
    "print(f\"Patients with missing data: {df['has_missing'].sum()}\")\n",
    "print(f\"Patients with complete data: {(~df['has_missing']).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "5eeef0d4-84c0-4015-b9c9-d7717beca3de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset summary:\n",
      "Original dataset: 6125 observations\n",
      "Complete cases: 3641 observations\n",
      "Excluded (missing): 2484 observations\n"
     ]
    }
   ],
   "source": [
    "# Store original count before filtering\n",
    "original_count = len(df)\n",
    "\n",
    "# Filter to keep only complete cases (this modifies df)\n",
    "df = df.dropna(subset=mental_health_vars)\n",
    "\n",
    "# Get the count after filtering\n",
    "complete_count = len(df)\n",
    "\n",
    "# Calculate excluded count\n",
    "excluded_count = original_count - complete_count\n",
    "\n",
    "# Verify the counts\n",
    "print(f\"\\nDataset summary:\")\n",
    "print(f\"Original dataset: {original_count} observations\")\n",
    "print(f\"Complete cases: {complete_count} observations\")\n",
    "print(f\"Excluded (missing): {excluded_count} observations\")\n",
    "\n",
    "# Remove the temporary column (if it exists)\n",
    "if 'has_missing' in df.columns:\n",
    "    df = df.drop('has_missing', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "9e6f3da8-9252-40e9-9816-402ddc5c3033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values in mental health variables:\n",
      "DIAGNOSIS_PSYCHOTIC: 0\n",
      "DIAGNOSIS_ANXIETY_OCD: 0\n",
      "Bipolar_and_Mood_disorder: 0\n",
      "DIAGNOSIS_EATING_DISORDER: 0\n"
     ]
    }
   ],
   "source": [
    "# Check the 4 variables you filtered on (should be 0 missing)\n",
    "mental_health_vars = ['DIAGNOSIS_PSYCHOTIC', 'DIAGNOSIS_ANXIETY_OCD', \n",
    "                      'Bipolar_and_Mood_disorder', 'DIAGNOSIS_EATING_DISORDER']\n",
    "\n",
    "print(f\"\\nMissing values in mental health variables:\")\n",
    "for var in mental_health_vars:\n",
    "    missing = df[var].isnull().sum()\n",
    "    print(f\"{var}: {missing}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "975828d9-69eb-4e4f-9d85-274ae2afaadc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3641 entries, 0 to 6124\n",
      "Columns: 204 entries, DIAGNOSIS_ANXIETY_OCD to ethnicity_other\n",
      "dtypes: float64(10), int64(194)\n",
      "memory usage: 5.7 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "3dff8ed0-c7ad-4031-8c73-56704d132a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Step 2 Complete: Final prepared dataset saved as 'final_prepared_data.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Save the fully prepared data\n",
    "df.to_csv(\"final_prepared_data.csv\", index=False)\n",
    "print(\" Step 2 Complete: Final prepared dataset saved as 'final_prepared_data.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "9213b96c-1f3e-4537-9881-1cf57f1cae8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "STEP 1: MICE IMPUTATION\n",
      "==================================================\n",
      "\n",
      "=== Running MICE Imputation: Dataset 1 ===\n",
      " Completed imputation 1\n",
      "\n",
      "=== Running MICE Imputation: Dataset 2 ===\n",
      " Completed imputation 2\n",
      "\n",
      "=== Running MICE Imputation: Dataset 3 ===\n",
      " Completed imputation 3\n",
      "\n",
      "=== Running MICE Imputation: Dataset 4 ===\n",
      " Completed imputation 4\n",
      "\n",
      "=== Running MICE Imputation: Dataset 5 ===\n",
      " Completed imputation 5\n",
      "\n",
      "==================================================\n",
      "STEP 2: ROUNDING NUMERIC COLUMNS\n",
      "==================================================\n",
      " Imputation 1: Rounded 204 numeric columns to 0 decimal place(s).\n",
      " Imputation 2: Rounded 204 numeric columns to 0 decimal place(s).\n",
      " Imputation 3: Rounded 204 numeric columns to 0 decimal place(s).\n",
      " Imputation 4: Rounded 204 numeric columns to 0 decimal place(s).\n",
      " Imputation 5: Rounded 204 numeric columns to 0 decimal place(s).\n",
      "\n",
      "==================================================\n",
      "STEP 3: SAVING FINAL DATASETS\n",
      "==================================================\n",
      " Saved files for imputation 1:\n",
      "   → imputed_data/df_imputed_final_imp1.pkl\n",
      "   → imputed_data/df_imputed_final_imp1.csv\n",
      "   → imputed_data/df_imputed_final_imp1.xlsx\n",
      " Saved files for imputation 2:\n",
      "   → imputed_data/df_imputed_final_imp2.pkl\n",
      "   → imputed_data/df_imputed_final_imp2.csv\n",
      "   → imputed_data/df_imputed_final_imp2.xlsx\n",
      " Saved files for imputation 3:\n",
      "   → imputed_data/df_imputed_final_imp3.pkl\n",
      "   → imputed_data/df_imputed_final_imp3.csv\n",
      "   → imputed_data/df_imputed_final_imp3.xlsx\n",
      " Saved files for imputation 4:\n",
      "   → imputed_data/df_imputed_final_imp4.pkl\n",
      "   → imputed_data/df_imputed_final_imp4.csv\n",
      "   → imputed_data/df_imputed_final_imp4.xlsx\n",
      " Saved files for imputation 5:\n",
      "   → imputed_data/df_imputed_final_imp5.pkl\n",
      "   → imputed_data/df_imputed_final_imp5.csv\n",
      "   → imputed_data/df_imputed_final_imp5.xlsx\n",
      "\n",
      "==================================================\n",
      "STEP 4: VERIFYING DATASET DIFFERENCES\n",
      "==================================================\n",
      " Checking differences in 4 columns that had missing values...\n",
      " Column 'DIAGNOSIS_SMOKING': 34 different values between datasets 1 & 2\n",
      " Column 'DIAGNOSIS_SEXUAL_TRAUMA': 11 different values between datasets 1 & 2\n",
      " Column 'DIAGNOSIS_CPTSD': 21 different values between datasets 1 & 2\n",
      "\n",
      " SUCCESS: Datasets show proper variability!\n",
      "\n",
      "==================================================\n",
      " MICE IMPUTATION COMPLETE!\n",
      "==================================================\n",
      " Created 5 imputed datasets\n",
      " Applied rounding to all numeric columns\n",
      " Saved files in: imputed_data/\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "# ========== CONFIG ==========\n",
    "save_folder = \"imputed_data\"\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "n_imputations = 5\n",
    "\n",
    "# ========== LOAD ==========\n",
    "# Ensure df is already defined\n",
    "assert 'df' in globals(), \"Please load the original DataFrame as `df` before running this script.\"\n",
    "\n",
    "# ========== IDENTIFY NUMERIC COLUMNS ==========\n",
    "numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "\n",
    "# ========== STEP 1: MICE IMPUTATION ==========\n",
    "print(\"=\" * 50)\n",
    "print(\"STEP 1: MICE IMPUTATION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "imputed_dfs = []\n",
    "for i in range(1, n_imputations + 1):\n",
    "    print(f\"\\n=== Running MICE Imputation: Dataset {i} ===\")\n",
    "    #  NEW instance with different seed AND sample_posterior=True for randomness\n",
    "    mice_imputer = IterativeImputer(\n",
    "        max_iter=10, \n",
    "        random_state=42+i,  # Different base to avoid low numbers\n",
    "        sample_posterior=True,  #  KEY: This adds randomness!\n",
    "        n_nearest_features=None,\n",
    "        initial_strategy='mean'\n",
    "    )\n",
    "    # Fit-transform on numeric columns\n",
    "    imputed_array = mice_imputer.fit_transform(df[numeric_cols])\n",
    "    # Replace numeric columns in a copy of the original df\n",
    "    df_imputed = df.copy()\n",
    "    df_imputed[numeric_cols] = pd.DataFrame(imputed_array, columns=numeric_cols, index=df.index)\n",
    "    # Append to list\n",
    "    imputed_dfs.append(df_imputed)\n",
    "    print(f\" Completed imputation {i}\")\n",
    "\n",
    "# ========== STEP 2: ROUNDING ==========\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"STEP 2: ROUNDING NUMERIC COLUMNS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "def round_all_numeric_columns_all_imputations(imputed_dfs, decimals=0, verbose=True):\n",
    "    rounded_dfs = []\n",
    "    for i, df in enumerate(imputed_dfs):\n",
    "        df_copy = df.copy()\n",
    "        numeric_cols = df_copy.select_dtypes(include=[np.number]).columns\n",
    "        df_copy[numeric_cols] = df_copy[numeric_cols].round(decimals)\n",
    "        rounded_dfs.append(df_copy)\n",
    "        if verbose:\n",
    "            print(f\" Imputation {i+1}: Rounded {len(numeric_cols)} numeric columns to {decimals} decimal place(s).\")\n",
    "    return rounded_dfs\n",
    "\n",
    "# Apply rounding to all imputed datasets\n",
    "imputed_dfs = round_all_numeric_columns_all_imputations(imputed_dfs)\n",
    "\n",
    "# ========== STEP 3: SAVE FINAL DATASETS ==========\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"STEP 3: SAVING FINAL DATASETS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for i, df_imputed in enumerate(imputed_dfs, 1):\n",
    "    # Save outputs\n",
    "    pkl_path = f\"{save_folder}/df_imputed_final_imp{i}.pkl\"\n",
    "    csv_path = f\"{save_folder}/df_imputed_final_imp{i}.csv\"\n",
    "    excel_path = f\"{save_folder}/df_imputed_final_imp{i}.xlsx\"\n",
    "    \n",
    "    df_imputed.to_pickle(pkl_path)\n",
    "    df_imputed.to_csv(csv_path, index=False)\n",
    "    df_imputed.to_excel(excel_path, index=False)\n",
    "    \n",
    "    print(f\" Saved files for imputation {i}:\")\n",
    "    print(f\"   → {pkl_path}\")\n",
    "    print(f\"   → {csv_path}\")\n",
    "    print(f\"   → {excel_path}\")\n",
    "\n",
    "# ========== STEP 4: VERIFY DATASETS ARE DIFFERENT ==========\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"STEP 4: VERIFYING DATASET DIFFERENCES\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "def check_imputation_differences(imputed_dfs, verbose=True):\n",
    "    \"\"\"Check if imputed datasets are actually different from each other\"\"\"\n",
    "    if len(imputed_dfs) < 2:\n",
    "        print(\"  Only one dataset - cannot check differences\")\n",
    "        return\n",
    "    \n",
    "    # Get numeric columns that had missing values originally\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    missing_cols = [col for col in numeric_cols if df[col].isnull().any()]\n",
    "    \n",
    "    if not missing_cols:\n",
    "        print(\"  No missing values found in original data\")\n",
    "        return\n",
    "    \n",
    "    print(f\" Checking differences in {len(missing_cols)} columns that had missing values...\")\n",
    "    \n",
    "    differences_found = False\n",
    "    \n",
    "    for col in missing_cols[:3]:  # Check first 3 columns with missing values\n",
    "        # Compare first two datasets for this column\n",
    "        values_1 = imputed_dfs[0][col].values\n",
    "        values_2 = imputed_dfs[1][col].values\n",
    "        \n",
    "        if not np.array_equal(values_1, values_2):\n",
    "            differences_found = True\n",
    "            # Count how many values are different\n",
    "            diff_count = np.sum(values_1 != values_2)\n",
    "            print(f\" Column '{col}': {diff_count} different values between datasets 1 & 2\")\n",
    "        else:\n",
    "            print(f\" Column '{col}': IDENTICAL values between datasets 1 & 2\")\n",
    "    \n",
    "    if differences_found:\n",
    "        print(f\"\\n SUCCESS: Datasets show proper variability!\")\n",
    "    else:\n",
    "        print(f\"\\n  WARNING: Datasets appear identical - check random_state implementation\")\n",
    "    \n",
    "    return differences_found\n",
    "\n",
    "# Run the check\n",
    "check_imputation_differences(imputed_dfs)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\" MICE IMPUTATION COMPLETE!\")\n",
    "print(\"=\" * 50)\n",
    "print(f\" Created {n_imputations} imputed datasets\")\n",
    "print(f\" Applied rounding to all numeric columns\")\n",
    "print(f\" Saved files in: {save_folder}/\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "c137e3fd-a734-4ec2-ba57-fb0c19225709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CHECKING IMPUTATION DIFFERENCES\n",
      "============================================================\n",
      "Dataset 1 vs Dataset 2: DIFFERENT ✅\n",
      "  'DIAGNOSIS_SMOKING': 34 different values\n",
      "  'DIAGNOSIS_SEXUAL_TRAUMA': 11 different values\n",
      "  'DIAGNOSIS_CPTSD': 21 different values\n",
      "  'treatmentdurationdays': 1127 different values\n",
      "  Total different values: 1193\n",
      "\n",
      "=== Checking all 5 datasets ===\n",
      "Dataset 1 vs Dataset 2: DIFFERENT ✅\n",
      "Dataset 1 vs Dataset 3: DIFFERENT ✅\n",
      "Dataset 1 vs Dataset 4: DIFFERENT ✅\n",
      "Dataset 1 vs Dataset 5: DIFFERENT ✅\n",
      "Dataset 2 vs Dataset 3: DIFFERENT ✅\n",
      "Dataset 2 vs Dataset 4: DIFFERENT ✅\n",
      "Dataset 2 vs Dataset 5: DIFFERENT ✅\n",
      "Dataset 3 vs Dataset 4: DIFFERENT ✅\n",
      "Dataset 3 vs Dataset 5: DIFFERENT ✅\n",
      "Dataset 4 vs Dataset 5: DIFFERENT ✅\n",
      "\n",
      "=== Checking differences in originally missing positions ===\n",
      "\n",
      "Column 'DIAGNOSIS_SMOKING' (64 missing values):\n",
      "  Dataset 1 vs 2: 34/64 different imputed values ✅\n",
      "  Dataset 2 vs 3: 35/64 different imputed values ✅\n",
      "  Dataset 3 vs 4: 33/64 different imputed values ✅\n",
      "  Dataset 4 vs 5: 35/64 different imputed values ✅\n",
      "\n",
      "Column 'DIAGNOSIS_SEXUAL_TRAUMA' (29 missing values):\n",
      "  Dataset 1 vs 2: 11/29 different imputed values ✅\n",
      "  Dataset 2 vs 3: 14/29 different imputed values ✅\n",
      "  Dataset 3 vs 4: 16/29 different imputed values ✅\n",
      "  Dataset 4 vs 5: 17/29 different imputed values ✅\n",
      "\n",
      "Column 'DIAGNOSIS_CPTSD' (51 missing values):\n",
      "  Dataset 1 vs 2: 21/51 different imputed values ✅\n",
      "  Dataset 2 vs 3: 24/51 different imputed values ✅\n",
      "  Dataset 3 vs 4: 29/51 different imputed values ✅\n",
      "  Dataset 4 vs 5: 22/51 different imputed values ✅\n",
      "\n",
      "Column 'treatmentdurationdays' (1412 missing values):\n",
      "  Dataset 1 vs 2: 1127/1412 different imputed values ✅\n",
      "  Dataset 2 vs 3: 1151/1412 different imputed values ✅\n",
      "  Dataset 3 vs 4: 1175/1412 different imputed values ✅\n",
      "  Dataset 4 vs 5: 1146/1412 different imputed values ✅\n",
      "\n",
      "🎉 SUCCESS: Found differences in imputed values!\n",
      "\n",
      "=== Sample imputed values (first 3 missing positions) ===\n",
      "\n",
      "Column 'DIAGNOSIS_SMOKING' at positions [5, 8, 65]:\n",
      "  Dataset 1: [-1.  0.  1.]\n",
      "  Dataset 2: [ 0. -1.  1.]\n",
      "  Dataset 3: [ 0. -0.  1.]\n",
      "  Dataset 4: [ 1. -1.  1.]\n",
      "  Dataset 5: [0. 0. 0.]\n",
      "\n",
      "Column 'DIAGNOSIS_SEXUAL_TRAUMA' at positions [34, 35, 36]:\n",
      "  Dataset 1: [1. 1. 1.]\n",
      "  Dataset 2: [1. 1. 1.]\n",
      "  Dataset 3: [1. 2. 0.]\n",
      "  Dataset 4: [ 0.  1. -0.]\n",
      "  Dataset 5: [0. 1. 1.]\n",
      "\n",
      "Column 'DIAGNOSIS_CPTSD' at positions [8, 65, 248]:\n",
      "  Dataset 1: [0. 1. 1.]\n",
      "  Dataset 2: [1. 1. 1.]\n",
      "  Dataset 3: [1. 1. 1.]\n",
      "  Dataset 4: [0. 1. 1.]\n",
      "  Dataset 5: [0. 1. 1.]\n",
      "\n",
      "Column 'treatmentdurationdays' at positions [0, 1, 6]:\n",
      "  Dataset 1: [3. 5. 2.]\n",
      "  Dataset 2: [3. 4. 5.]\n",
      "  Dataset 3: [3. 3. 3.]\n",
      "  Dataset 4: [3. 4. 4.]\n",
      "  Dataset 5: [5. 4. 1.]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ========== METHOD 1: QUICK CHECK - Compare first 2 datasets ==========\n",
    "def quick_difference_check(imputed_dfs):\n",
    "    \"\"\"Quick check to see if first two datasets are different\"\"\"\n",
    "    if len(imputed_dfs) < 2:\n",
    "        print(\"Need at least 2 datasets to compare\")\n",
    "        return\n",
    "    \n",
    "    df1 = imputed_dfs[0]\n",
    "    df2 = imputed_dfs[1]\n",
    "    \n",
    "    # Check if dataframes are identical\n",
    "    are_identical = df1.equals(df2)\n",
    "    print(f\"Dataset 1 vs Dataset 2: {'IDENTICAL ❌' if are_identical else 'DIFFERENT ✅'}\")\n",
    "    \n",
    "    if not are_identical:\n",
    "        # Count different values\n",
    "        numeric_cols = df1.select_dtypes(include=[np.number]).columns\n",
    "        total_diff = 0\n",
    "        for col in numeric_cols:\n",
    "            diff_count = np.sum(df1[col] != df2[col])\n",
    "            if diff_count > 0:\n",
    "                total_diff += diff_count\n",
    "                print(f\"  '{col}': {diff_count} different values\")\n",
    "        print(f\"  Total different values: {total_diff}\")\n",
    "\n",
    "# ========== METHOD 2: DETAILED CHECK - All pairwise comparisons ==========\n",
    "def detailed_difference_check(imputed_dfs):\n",
    "    \"\"\"Check differences between all pairs of datasets\"\"\"\n",
    "    n_datasets = len(imputed_dfs)\n",
    "    print(f\"\\n=== Checking all {n_datasets} datasets ===\")\n",
    "    \n",
    "    numeric_cols = imputed_dfs[0].select_dtypes(include=[np.number]).columns\n",
    "    \n",
    "    for i in range(n_datasets):\n",
    "        for j in range(i+1, n_datasets):\n",
    "            are_identical = imputed_dfs[i].equals(imputed_dfs[j])\n",
    "            print(f\"Dataset {i+1} vs Dataset {j+1}: {'IDENTICAL ❌' if are_identical else 'DIFFERENT ✅'}\")\n",
    "\n",
    "# ========== METHOD 3: FOCUS ON ORIGINALLY MISSING VALUES ==========\n",
    "def check_missing_value_differences(original_df, imputed_dfs):\n",
    "    \"\"\"Check differences only in originally missing positions\"\"\"\n",
    "    print(f\"\\n=== Checking differences in originally missing positions ===\")\n",
    "    \n",
    "    numeric_cols = original_df.select_dtypes(include=[np.number]).columns\n",
    "    \n",
    "    differences_found = False\n",
    "    for col in numeric_cols:\n",
    "        if original_df[col].isnull().any():\n",
    "            missing_mask = original_df[col].isnull()\n",
    "            print(f\"\\nColumn '{col}' ({missing_mask.sum()} missing values):\")\n",
    "            \n",
    "            # Compare imputed values at missing positions\n",
    "            for i in range(len(imputed_dfs)-1):\n",
    "                imp1_values = imputed_dfs[i].loc[missing_mask, col]\n",
    "                imp2_values = imputed_dfs[i+1].loc[missing_mask, col]\n",
    "                \n",
    "                are_same = np.array_equal(imp1_values.values, imp2_values.values)\n",
    "                if not are_same:\n",
    "                    differences_found = True\n",
    "                    diff_count = np.sum(imp1_values.values != imp2_values.values)\n",
    "                    print(f\"  Dataset {i+1} vs {i+2}: {diff_count}/{len(imp1_values)} different imputed values ✅\")\n",
    "                else:\n",
    "                    print(f\"  Dataset {i+1} vs {i+2}: IDENTICAL imputed values ❌\")\n",
    "    \n",
    "    return differences_found\n",
    "\n",
    "# ========== METHOD 4: SAMPLE VALUES FROM EACH DATASET ==========\n",
    "def show_sample_imputed_values(original_df, imputed_dfs, n_samples=5):\n",
    "    \"\"\"Show sample imputed values from each dataset\"\"\"\n",
    "    print(f\"\\n=== Sample imputed values (first {n_samples} missing positions) ===\")\n",
    "    \n",
    "    numeric_cols = original_df.select_dtypes(include=[np.number]).columns\n",
    "    \n",
    "    for col in numeric_cols:\n",
    "        if original_df[col].isnull().any():\n",
    "            missing_positions = original_df[original_df[col].isnull()].index[:n_samples]\n",
    "            \n",
    "            print(f\"\\nColumn '{col}' at positions {list(missing_positions)}:\")\n",
    "            for i, df_imp in enumerate(imputed_dfs):\n",
    "                values = df_imp.loc[missing_positions, col].values\n",
    "                print(f\"  Dataset {i+1}: {values}\")\n",
    "\n",
    "# ========== RUN ALL CHECKS ==========\n",
    "print(\"=\" * 60)\n",
    "print(\"CHECKING IMPUTATION DIFFERENCES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Method 1: Quick check\n",
    "quick_difference_check(imputed_dfs)\n",
    "\n",
    "# Method 2: All pairwise comparisons  \n",
    "detailed_difference_check(imputed_dfs)\n",
    "\n",
    "# Method 3: Focus on originally missing values (assumes 'df' is your original dataframe)\n",
    "if 'df' in globals():\n",
    "    differences_found = check_missing_value_differences(df, imputed_dfs)\n",
    "    if differences_found:\n",
    "        print(f\"\\n🎉 SUCCESS: Found differences in imputed values!\")\n",
    "    else:\n",
    "        print(f\"\\n⚠️ WARNING: No differences found in imputed values!\")\n",
    "\n",
    "# Method 4: Show sample values\n",
    "if 'df' in globals():\n",
    "    show_sample_imputed_values(df, imputed_dfs, n_samples=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "24870e2f-65b4-4d77-b866-6c0ccdc2e409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y for imputation 1 defined. Sample values:\n",
      "0   -41.0\n",
      "1   -15.0\n",
      "2   -46.0\n",
      "3   -41.0\n",
      "4   -20.0\n",
      "Name: caps5_change_baseline, dtype: float64\n",
      "Y for imputation 2 defined. Sample values:\n",
      "0   -41.0\n",
      "1   -15.0\n",
      "2   -46.0\n",
      "3   -41.0\n",
      "4   -20.0\n",
      "Name: caps5_change_baseline, dtype: float64\n",
      "Y for imputation 3 defined. Sample values:\n",
      "0   -41.0\n",
      "1   -15.0\n",
      "2   -46.0\n",
      "3   -41.0\n",
      "4   -20.0\n",
      "Name: caps5_change_baseline, dtype: float64\n",
      "Y for imputation 4 defined. Sample values:\n",
      "0   -41.0\n",
      "1   -15.0\n",
      "2   -46.0\n",
      "3   -41.0\n",
      "4   -20.0\n",
      "Name: caps5_change_baseline, dtype: float64\n",
      "Y for imputation 5 defined. Sample values:\n",
      "0   -41.0\n",
      "1   -15.0\n",
      "2   -46.0\n",
      "3   -41.0\n",
      "4   -20.0\n",
      "Name: caps5_change_baseline, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "imputed_folder = \"imputed_data\"\n",
    "n_imputations = 5\n",
    "\n",
    "# Lists to hold DataFrames and Y vectors\n",
    "imputed_dfs = []\n",
    "Y_list = []\n",
    "\n",
    "for i in range(1, n_imputations + 1):\n",
    "    file_path = f\"{imputed_folder}/df_imputed_final_imp{i}.pkl\"\n",
    "    \n",
    "    # Load imputed DataFrame\n",
    "    df_imp = pd.read_pickle(file_path)\n",
    "    imputed_dfs.append(df_imp)\n",
    "\n",
    "    # Define Y for this imputation\n",
    "    Y = df_imp[\"caps5_change_baseline\"]\n",
    "    Y_list.append(Y)\n",
    "\n",
    "    print(f\"Y for imputation {i} defined. Sample values:\")\n",
    "    print(Y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "34bb8f95-ea33-4ba5-89eb-708abf2aa238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Imputed Dataset 1 ===\n",
      "Medication Groups:\n",
      "['CAT_Antidepressiva', 'CAT_Benzodiazepine', 'CAT_Anti_epileptica', 'CAT_Antihistaminica', 'CAT_Opioden', 'CAT_Antipsychotica', 'CAT_Aceetanilidederivaten', 'CAT_Antihypertensiva', 'CAT_Salicylaat', 'CAT_NSAIDs', 'CAT_Migrainemiddelen', 'CAT_ADHD', 'CAT_Anticonceptiva', 'CAT_Z_drugs', 'CAT_Spierrelaxantia', 'CAT_Immunomodulerende_middelen', 'CAT_Alcoholverslaving', 'CAT_Stemmingsstabilisatoren', 'CAT_Parkinson', 'CAT_ALL', 'CAT_ALL_PSYCHOTROPICS', 'CAT_ALL_PSYCHOTROPICS_EXCL_BENZO', 'CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS']\n",
      "Total Medication Groups Found: 23\n",
      "\n",
      "=== Imputed Dataset 2 ===\n",
      "Medication Groups:\n",
      "['CAT_Antidepressiva', 'CAT_Benzodiazepine', 'CAT_Anti_epileptica', 'CAT_Antihistaminica', 'CAT_Opioden', 'CAT_Antipsychotica', 'CAT_Aceetanilidederivaten', 'CAT_Antihypertensiva', 'CAT_Salicylaat', 'CAT_NSAIDs', 'CAT_Migrainemiddelen', 'CAT_ADHD', 'CAT_Anticonceptiva', 'CAT_Z_drugs', 'CAT_Spierrelaxantia', 'CAT_Immunomodulerende_middelen', 'CAT_Alcoholverslaving', 'CAT_Stemmingsstabilisatoren', 'CAT_Parkinson', 'CAT_ALL', 'CAT_ALL_PSYCHOTROPICS', 'CAT_ALL_PSYCHOTROPICS_EXCL_BENZO', 'CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS']\n",
      "Total Medication Groups Found: 23\n",
      "\n",
      "=== Imputed Dataset 3 ===\n",
      "Medication Groups:\n",
      "['CAT_Antidepressiva', 'CAT_Benzodiazepine', 'CAT_Anti_epileptica', 'CAT_Antihistaminica', 'CAT_Opioden', 'CAT_Antipsychotica', 'CAT_Aceetanilidederivaten', 'CAT_Antihypertensiva', 'CAT_Salicylaat', 'CAT_NSAIDs', 'CAT_Migrainemiddelen', 'CAT_ADHD', 'CAT_Anticonceptiva', 'CAT_Z_drugs', 'CAT_Spierrelaxantia', 'CAT_Immunomodulerende_middelen', 'CAT_Alcoholverslaving', 'CAT_Stemmingsstabilisatoren', 'CAT_Parkinson', 'CAT_ALL', 'CAT_ALL_PSYCHOTROPICS', 'CAT_ALL_PSYCHOTROPICS_EXCL_BENZO', 'CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS']\n",
      "Total Medication Groups Found: 23\n",
      "\n",
      "=== Imputed Dataset 4 ===\n",
      "Medication Groups:\n",
      "['CAT_Antidepressiva', 'CAT_Benzodiazepine', 'CAT_Anti_epileptica', 'CAT_Antihistaminica', 'CAT_Opioden', 'CAT_Antipsychotica', 'CAT_Aceetanilidederivaten', 'CAT_Antihypertensiva', 'CAT_Salicylaat', 'CAT_NSAIDs', 'CAT_Migrainemiddelen', 'CAT_ADHD', 'CAT_Anticonceptiva', 'CAT_Z_drugs', 'CAT_Spierrelaxantia', 'CAT_Immunomodulerende_middelen', 'CAT_Alcoholverslaving', 'CAT_Stemmingsstabilisatoren', 'CAT_Parkinson', 'CAT_ALL', 'CAT_ALL_PSYCHOTROPICS', 'CAT_ALL_PSYCHOTROPICS_EXCL_BENZO', 'CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS']\n",
      "Total Medication Groups Found: 23\n",
      "\n",
      "=== Imputed Dataset 5 ===\n",
      "Medication Groups:\n",
      "['CAT_Antidepressiva', 'CAT_Benzodiazepine', 'CAT_Anti_epileptica', 'CAT_Antihistaminica', 'CAT_Opioden', 'CAT_Antipsychotica', 'CAT_Aceetanilidederivaten', 'CAT_Antihypertensiva', 'CAT_Salicylaat', 'CAT_NSAIDs', 'CAT_Migrainemiddelen', 'CAT_ADHD', 'CAT_Anticonceptiva', 'CAT_Z_drugs', 'CAT_Spierrelaxantia', 'CAT_Immunomodulerende_middelen', 'CAT_Alcoholverslaving', 'CAT_Stemmingsstabilisatoren', 'CAT_Parkinson', 'CAT_ALL', 'CAT_ALL_PSYCHOTROPICS', 'CAT_ALL_PSYCHOTROPICS_EXCL_BENZO', 'CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS']\n",
      "Total Medication Groups Found: 23\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load imputed DataFrames from saved files\n",
    "imputed_folder = \"imputed_data\"\n",
    "n_imputations = 5\n",
    "\n",
    "for i in range(1, n_imputations + 1):\n",
    "    print(f\"\\n=== Imputed Dataset {i} ===\")\n",
    "\n",
    "    # Load each imputed dataset\n",
    "    df_imp = pd.read_pickle(f\"{imputed_folder}/df_imputed_final_imp{i}.pkl\")\n",
    "\n",
    "    # Get all CAT_* columns\n",
    "    cat_columns = [col for col in df_imp.columns if col.startswith('CAT_')]\n",
    "\n",
    "    print(\"Medication Groups:\")\n",
    "    print(cat_columns)\n",
    "    print(\"Total Medication Groups Found:\", len(cat_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "1dfbe506-f470-4787-9bda-417a090be3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "covariates_CAT_ADHD = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline', 'CAT_Anti_epileptica', 'CAT_Antidepressiva', 'CAT_Antipsychotica',\n",
    "    'CAT_Benzodiazepine', 'CAT_Opioden',\n",
    "    'CAT_Z_drugs', 'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD',\n",
    "    'DIAGNOSIS_SEXUAL_TRAUMA', 'DIAGNOSIS_SMOKING', 'DIAGNOSIS_SUICIDALITY',\n",
    "    'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"EB_NON_TF_THERAPY\", \"OTHER_TREATM_APPROACH\", \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "\n",
    "covariates_CAT_Aceetanilidederivaten = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline', 'CAT_Anti_epileptica', 'CAT_Antidepressiva', 'CAT_Antipsychotica',\n",
    "    'CAT_Benzodiazepine', 'CAT_Opioden', 'CAT_Z_drugs',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SMOKING', 'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"EB_NON_TF_THERAPY\", \"OTHER_TREATM_APPROACH\", \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "\n",
    "covariates_CAT_Z_drugs = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline', 'CAT_Anti_epileptica', 'CAT_Antidepressiva', 'CAT_Antipsychotica',\n",
    "    'CAT_Benzodiazepine', 'CAT_Opioden',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SMOKING', 'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"EB_NON_TF_THERAPY\", \"OTHER_TREATM_APPROACH\", \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "\n",
    "covariates_CAT_Opioden = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline', 'CAT_Anti_epileptica',\n",
    "    'CAT_Antidepressiva',\n",
    "    'CAT_Antipsychotica', 'CAT_Benzodiazepine', 'CAT_Z_drugs',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SMOKING', 'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"EB_NON_TF_THERAPY\", \"OTHER_TREATM_APPROACH\", \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "\n",
    "covariates_CAT_NSAIDs = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline', 'CAT_Anti_epileptica',\n",
    "    'CAT_Antidepressiva',\n",
    "    'CAT_Antipsychotica', 'CAT_Benzodiazepine', 'CAT_Opioden', 'CAT_Z_drugs',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SMOKING', 'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"EB_NON_TF_THERAPY\", \"OTHER_TREATM_APPROACH\", \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "covariates_CAT_Benzodiazepine = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline', 'CAT_Anti_epileptica',\n",
    "    'CAT_Antidepressiva',\n",
    "    'CAT_Antipsychotica', 'CAT_Opioden', 'CAT_Z_drugs',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SMOKING', 'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"EB_NON_TF_THERAPY\", \"OTHER_TREATM_APPROACH\", \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "\n",
    "covariates_CAT_Antihypertensiva = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline', 'CAT_Anti_epileptica',\n",
    "    'CAT_Antidepressiva', 'CAT_Antipsychotica',\n",
    "    'CAT_Benzodiazepine', 'CAT_Opioden', 'CAT_Z_drugs',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SMOKING', 'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"EB_NON_TF_THERAPY\", \"OTHER_TREATM_APPROACH\", \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "\n",
    "covariates_CAT_Antihistaminica = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline', 'CAT_Anti_epileptica',\n",
    "    'CAT_Antidepressiva', 'CAT_Antipsychotica',\n",
    "    'CAT_Benzodiazepine', 'CAT_Opioden', 'CAT_Z_drugs',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SMOKING', 'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"EB_NON_TF_THERAPY\", \"OTHER_TREATM_APPROACH\", \"Bipolar_and_Mood_disorder\"\n",
    "]\n",
    "\n",
    "\n",
    "covariates_CAT_Anti_epileptica = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline', 'CAT_Antidepressiva', 'CAT_Antipsychotica',\n",
    "    'CAT_Benzodiazepine', 'CAT_Opioden', 'CAT_Z_drugs',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SMOKING', 'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"EB_NON_TF_THERAPY\", \"OTHER_TREATM_APPROACH\", \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "\n",
    "covariates_CAT_Antidepressiva = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline', 'CAT_Anti_epileptica', 'CAT_Antipsychotica',\n",
    "    'CAT_Benzodiazepine', 'CAT_Opioden', 'CAT_Z_drugs',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SMOKING', 'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"EB_NON_TF_THERAPY\", \"OTHER_TREATM_APPROACH\", \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "\n",
    "covariates_CAT_Antipsychotica = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline', 'CAT_Anti_epileptica',\n",
    "    'CAT_Antidepressiva',\n",
    "    'CAT_Benzodiazepine', 'CAT_Opioden', 'CAT_Z_drugs',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SMOKING', 'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"EB_NON_TF_THERAPY\", \"OTHER_TREATM_APPROACH\", \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "covariates_CAT_ALL_PSYCHOTROPICS_EXCL_BENZO = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Benzodiazepine', 'CAT_Anticonceptiva',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SMOKING', 'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"EB_NON_TF_THERAPY\", \"OTHER_TREATM_APPROACH\", \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "covariates_CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Benzodiazepine', 'CAT_Z_drugs', 'CAT_Anticonceptiva',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SMOKING', 'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"EB_NON_TF_THERAPY\", \"OTHER_TREATM_APPROACH\", \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "\n",
    "covariates_CAT_ALL_PSYCHOTROPICS = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SMOKING', 'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"EB_NON_TF_THERAPY\", \"OTHER_TREATM_APPROACH\", \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "\n",
    "covariates_CAT_ALL = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA',\n",
    "    'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SMOKING', 'DIAGNOSIS_SUICIDALITY',\n",
    "    'age', 'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"EB_NON_TF_THERAPY\", \"OTHER_TREATM_APPROACH\", \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "85b6d585-f09c-4502-b467-7a8c20a8fe8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groups found: ['CAT_ADHD', 'CAT_Aceetanilidederivaten', 'CAT_Z_drugs', 'CAT_Opioden', 'CAT_NSAIDs', 'CAT_Benzodiazepine', 'CAT_Antihypertensiva', 'CAT_Antihistaminica', 'CAT_Anti_epileptica', 'CAT_Antidepressiva', 'CAT_Antipsychotica', 'CAT_ALL_PSYCHOTROPICS_EXCL_BENZO', 'CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS', 'CAT_ALL_PSYCHOTROPICS', 'CAT_ALL']\n",
      "['CAT_ADHD', 'CAT_Aceetanilidederivaten', 'CAT_Z_drugs', 'CAT_Opioden', 'CAT_NSAIDs', 'CAT_Benzodiazepine', 'CAT_Antihypertensiva', 'CAT_Antihistaminica', 'CAT_Anti_epileptica', 'CAT_Antidepressiva', 'CAT_Antipsychotica', 'CAT_ALL_PSYCHOTROPICS_EXCL_BENZO', 'CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS', 'CAT_ALL_PSYCHOTROPICS', 'CAT_ALL']\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# This finds all variables that start with covariates_CAT_ or covariates_cat_\n",
    "final_covariates_map = defaultdict(list)\n",
    "final_covariates_map.update({\n",
    "    var.replace(\"covariates_\", \"\"): val\n",
    "    for var, val in globals().items()\n",
    "    if var.lower().startswith(\"covariates_cat_\") and isinstance(val, list)\n",
    "})\n",
    "\n",
    "# Show detected group names\n",
    "print(\"Groups found:\", list(final_covariates_map.keys()))\n",
    "medication_groups = list(final_covariates_map.keys())\n",
    "print(medication_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "a5d938d8-9224-4db0-b753-03d15061db06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Starting analysis for all CAT groups\n",
      "\n",
      " Processing CAT_Adhd...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: CAT_Adhd\n",
      "\n",
      " Processing CAT_Aceetanilidederivaten...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: CAT_Aceetanilidederivaten\n",
      "\n",
      " Processing CAT_Z_Drugs...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: CAT_Z_Drugs\n",
      "\n",
      " Processing CAT_Opioden...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: CAT_Opioden\n",
      "\n",
      " Processing CAT_Nsaids...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: CAT_Nsaids\n",
      "\n",
      " Processing CAT_Benzodiazepine...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: CAT_Benzodiazepine\n",
      "\n",
      " Processing CAT_Antihypertensiva...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: CAT_Antihypertensiva\n",
      "\n",
      " Processing CAT_Antihistaminica...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: CAT_Antihistaminica\n",
      "\n",
      " Processing CAT_Anti_Epileptica...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: CAT_Anti_Epileptica\n",
      "\n",
      " Processing CAT_Antidepressiva...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: CAT_Antidepressiva\n",
      "\n",
      " Processing CAT_Antipsychotica...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: CAT_Antipsychotica\n",
      "\n",
      " Processing CAT_All_Psychotropics_Excl_Benzo...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: CAT_All_Psychotropics_Excl_Benzo\n",
      "\n",
      " Processing CAT_All_Psychotropics_Excl_Sedatives_Hypnotics...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: CAT_All_Psychotropics_Excl_Sedatives_Hypnotics\n",
      "\n",
      " Processing CAT_All_Psychotropics...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: CAT_All_Psychotropics\n",
      "\n",
      " Processing CAT_All...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: CAT_All\n",
      "\n",
      " All CAT group analyses complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def run_all_CAT_group_models(imputed_dfs):\n",
    "    \"\"\"\n",
    "    Runs downstream analysis for each CAT medication group using imputed datasets.\n",
    "\n",
    "    Parameters:\n",
    "    - imputed_dfs: list of 5 imputed DataFrames (from df_imputed_final_imp1.pkl ... imp5.pkl)\n",
    "    \n",
    "    Notes:\n",
    "    - Covariate lists must be defined as global variables: covariates_cat_<group>\n",
    "    - Outputs are saved in: outputs/CAT_<GROUP>/\n",
    "    \"\"\"\n",
    "\n",
    "    print(\" Starting analysis for all CAT groups\")\n",
    "\n",
    "    for var_name in globals():\n",
    "        if var_name.lower().startswith(\"covariates_cat_\") and isinstance(globals()[var_name], list):\n",
    "            group_name = var_name.replace(\"covariates_\", \"\")\n",
    "            group_name = group_name.replace(\"_\", \" \").title().replace(\" \", \"_\")  # e.g., cat_z_drugs → Cat_Z_Drugs\n",
    "            group_name = group_name.replace(\"Cat_\", \"CAT_\")  # force prefix to uppercase\n",
    "\n",
    "            covariates = globals()[var_name]\n",
    "            output_dir = f\"outputs/{group_name}\"\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "            print(f\"\\n Processing {group_name}...\")\n",
    "\n",
    "            for k, df_imp in enumerate(imputed_dfs):\n",
    "                print(f\"  → Using imputation {k+1}\")\n",
    "\n",
    "                # Define X and Y\n",
    "                X = df_imp[covariates]\n",
    "                Y = df_imp[\"caps5_change_baseline\"]\n",
    "\n",
    "                # === Save X and Y as placeholder (replace with modeling later)\n",
    "                X.to_csv(f\"{output_dir}/X_imp{k+1}.csv\", index=False)\n",
    "                Y.to_frame(name=\"Y\").to_csv(f\"{output_dir}/Y_imp{k+1}.csv\", index=False)\n",
    "\n",
    "            print(f\" Done: {group_name}\")\n",
    "\n",
    "    print(\"\\n All CAT group analyses complete.\")\n",
    "\n",
    "# ========= STEP 4: Execute ========= #\n",
    "run_all_CAT_group_models(imputed_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "6241fae9-50ab-4dfa-a004-474392a4f6ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " CAT_ADHD\n",
      "  Imp 1: Treated = 56, Control = 3585, Missing = 0\n",
      "  Imp 2: Treated = 56, Control = 3585, Missing = 0\n",
      "  Imp 3: Treated = 56, Control = 3585, Missing = 0\n",
      "  Imp 4: Treated = 56, Control = 3585, Missing = 0\n",
      "  Imp 5: Treated = 56, Control = 3585, Missing = 0\n",
      "\n",
      " CAT_Aceetanilidederivaten\n",
      "  Imp 1: Treated = 50, Control = 3591, Missing = 0\n",
      "  Imp 2: Treated = 50, Control = 3591, Missing = 0\n",
      "  Imp 3: Treated = 50, Control = 3591, Missing = 0\n",
      "  Imp 4: Treated = 50, Control = 3591, Missing = 0\n",
      "  Imp 5: Treated = 50, Control = 3591, Missing = 0\n",
      "\n",
      " CAT_Z_drugs\n",
      "  Imp 1: Treated = 57, Control = 3584, Missing = 0\n",
      "  Imp 2: Treated = 57, Control = 3584, Missing = 0\n",
      "  Imp 3: Treated = 57, Control = 3584, Missing = 0\n",
      "  Imp 4: Treated = 57, Control = 3584, Missing = 0\n",
      "  Imp 5: Treated = 57, Control = 3584, Missing = 0\n",
      "\n",
      " CAT_Opioden\n",
      "  Imp 1: Treated = 54, Control = 3587, Missing = 0\n",
      "  Imp 2: Treated = 54, Control = 3587, Missing = 0\n",
      "  Imp 3: Treated = 54, Control = 3587, Missing = 0\n",
      "  Imp 4: Treated = 54, Control = 3587, Missing = 0\n",
      "  Imp 5: Treated = 54, Control = 3587, Missing = 0\n",
      "\n",
      " CAT_NSAIDs\n",
      "  Imp 1: Treated = 37, Control = 3604, Missing = 0\n",
      "  Imp 2: Treated = 37, Control = 3604, Missing = 0\n",
      "  Imp 3: Treated = 37, Control = 3604, Missing = 0\n",
      "  Imp 4: Treated = 37, Control = 3604, Missing = 0\n",
      "  Imp 5: Treated = 37, Control = 3604, Missing = 0\n",
      "\n",
      " CAT_Benzodiazepine\n",
      "  Imp 1: Treated = 396, Control = 3245, Missing = 0\n",
      "  Imp 2: Treated = 396, Control = 3245, Missing = 0\n",
      "  Imp 3: Treated = 396, Control = 3245, Missing = 0\n",
      "  Imp 4: Treated = 396, Control = 3245, Missing = 0\n",
      "  Imp 5: Treated = 396, Control = 3245, Missing = 0\n",
      "\n",
      " CAT_Antihypertensiva\n",
      "  Imp 1: Treated = 45, Control = 3596, Missing = 0\n",
      "  Imp 2: Treated = 45, Control = 3596, Missing = 0\n",
      "  Imp 3: Treated = 45, Control = 3596, Missing = 0\n",
      "  Imp 4: Treated = 45, Control = 3596, Missing = 0\n",
      "  Imp 5: Treated = 45, Control = 3596, Missing = 0\n",
      "\n",
      " CAT_Antihistaminica\n",
      "  Imp 1: Treated = 56, Control = 3585, Missing = 0\n",
      "  Imp 2: Treated = 56, Control = 3585, Missing = 0\n",
      "  Imp 3: Treated = 56, Control = 3585, Missing = 0\n",
      "  Imp 4: Treated = 56, Control = 3585, Missing = 0\n",
      "  Imp 5: Treated = 56, Control = 3585, Missing = 0\n",
      "\n",
      " CAT_Anti_epileptica\n",
      "  Imp 1: Treated = 84, Control = 3557, Missing = 0\n",
      "  Imp 2: Treated = 84, Control = 3557, Missing = 0\n",
      "  Imp 3: Treated = 84, Control = 3557, Missing = 0\n",
      "  Imp 4: Treated = 84, Control = 3557, Missing = 0\n",
      "  Imp 5: Treated = 84, Control = 3557, Missing = 0\n",
      "\n",
      " CAT_Antidepressiva\n",
      "  Imp 1: Treated = 636, Control = 3005, Missing = 0\n",
      "  Imp 2: Treated = 636, Control = 3005, Missing = 0\n",
      "  Imp 3: Treated = 636, Control = 3005, Missing = 0\n",
      "  Imp 4: Treated = 636, Control = 3005, Missing = 0\n",
      "  Imp 5: Treated = 636, Control = 3005, Missing = 0\n",
      "\n",
      " CAT_Antipsychotica\n",
      "  Imp 1: Treated = 268, Control = 3373, Missing = 0\n",
      "  Imp 2: Treated = 268, Control = 3373, Missing = 0\n",
      "  Imp 3: Treated = 268, Control = 3373, Missing = 0\n",
      "  Imp 4: Treated = 268, Control = 3373, Missing = 0\n",
      "  Imp 5: Treated = 268, Control = 3373, Missing = 0\n",
      "\n",
      " CAT_ALL_PSYCHOTROPICS_EXCL_BENZO\n",
      "  Imp 1: Treated = 869, Control = 2772, Missing = 0\n",
      "  Imp 2: Treated = 869, Control = 2772, Missing = 0\n",
      "  Imp 3: Treated = 869, Control = 2772, Missing = 0\n",
      "  Imp 4: Treated = 869, Control = 2772, Missing = 0\n",
      "  Imp 5: Treated = 869, Control = 2772, Missing = 0\n",
      "\n",
      " CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS\n",
      "  Imp 1: Treated = 846, Control = 2795, Missing = 0\n",
      "  Imp 2: Treated = 846, Control = 2795, Missing = 0\n",
      "  Imp 3: Treated = 846, Control = 2795, Missing = 0\n",
      "  Imp 4: Treated = 846, Control = 2795, Missing = 0\n",
      "  Imp 5: Treated = 846, Control = 2795, Missing = 0\n",
      "\n",
      " CAT_ALL_PSYCHOTROPICS\n",
      "  Imp 1: Treated = 1031, Control = 2610, Missing = 0\n",
      "  Imp 2: Treated = 1031, Control = 2610, Missing = 0\n",
      "  Imp 3: Treated = 1031, Control = 2610, Missing = 0\n",
      "  Imp 4: Treated = 1031, Control = 2610, Missing = 0\n",
      "  Imp 5: Treated = 1031, Control = 2610, Missing = 0\n",
      "\n",
      " CAT_ALL\n",
      "  Imp 1: Treated = 1072, Control = 2569, Missing = 0\n",
      "  Imp 2: Treated = 1072, Control = 2569, Missing = 0\n",
      "  Imp 3: Treated = 1072, Control = 2569, Missing = 0\n",
      "  Imp 4: Treated = 1072, Control = 2569, Missing = 0\n",
      "  Imp 5: Treated = 1072, Control = 2569, Missing = 0\n"
     ]
    }
   ],
   "source": [
    "for treatment_var in medication_groups:\n",
    "    print(f\"\\n {treatment_var}\")\n",
    "    \n",
    "    for i, df in enumerate(imputed_dfs):\n",
    "        if treatment_var not in df.columns:\n",
    "            print(f\"  Imp {i+1}:  Not found in columns.\")\n",
    "            continue\n",
    "\n",
    "        treated = (df[treatment_var] == 1).sum()\n",
    "        control = (df[treatment_var] == 0).sum()\n",
    "        missing = df[treatment_var].isna().sum()\n",
    "\n",
    "        print(f\"  Imp {i+1}: Treated = {treated}, Control = {control}, Missing = {missing}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "42eeaea9-4e28-4afc-9c6d-201f5af8a3be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Processing VIF for CAT_ADHD\n",
      " ✅ Saved: outputs\\CAT_ADHD/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for CAT_Aceetanilidederivaten\n",
      " ✅ Saved: outputs\\CAT_Aceetanilidederivaten/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for CAT_Z_drugs\n",
      " ✅ Saved: outputs\\CAT_Z_drugs/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for CAT_Opioden\n",
      " ✅ Saved: outputs\\CAT_Opioden/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for CAT_NSAIDs\n",
      " ✅ Saved: outputs\\CAT_NSAIDs/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for CAT_Benzodiazepine\n",
      " ✅ Saved: outputs\\CAT_Benzodiazepine/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for CAT_Antihypertensiva\n",
      " ✅ Saved: outputs\\CAT_Antihypertensiva/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for CAT_Antihistaminica\n",
      " ✅ Saved: outputs\\CAT_Antihistaminica/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for CAT_Anti_epileptica\n",
      " ✅ Saved: outputs\\CAT_Anti_epileptica/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for CAT_Antidepressiva\n",
      " ✅ Saved: outputs\\CAT_Antidepressiva/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for CAT_Antipsychotica\n",
      " ✅ Saved: outputs\\CAT_Antipsychotica/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for CAT_ALL_PSYCHOTROPICS_EXCL_BENZO\n",
      " ✅ Saved: outputs\\CAT_ALL_PSYCHOTROPICS_EXCL_BENZO/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS\n",
      " ✅ Saved: outputs\\CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for CAT_ALL_PSYCHOTROPICS\n",
      " ✅ Saved: outputs\\CAT_ALL_PSYCHOTROPICS/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for CAT_ALL\n",
      " ✅ Saved: outputs\\CAT_ALL/pooled_vif.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from collections import defaultdict\n",
    "\n",
    "# ✅ VIF computation function\n",
    "def compute_vif(X):\n",
    "    X = sm.add_constant(X, has_constant='add')\n",
    "    vif_df = pd.DataFrame()\n",
    "    vif_df[\"variable\"] = X.columns\n",
    "    vif_df[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "    return vif_df\n",
    "\n",
    "# ✅ Process each group\n",
    "for group in medication_groups:\n",
    "    print(f\"\\n🔍 Processing VIF for {group}\")\n",
    "\n",
    "    if group not in final_covariates_map:\n",
    "        print(f\" ⚠️ No covariates found for {group}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    covariates = final_covariates_map[group]\n",
    "    vif_list = []\n",
    "\n",
    "    for i, df_imp in enumerate(imputed_dfs):\n",
    "        try:\n",
    "            X = df_imp[covariates].copy()\n",
    "            vif_df = compute_vif(X)\n",
    "            vif_df[\"imputation\"] = i + 1\n",
    "            vif_list.append(vif_df)\n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ Failed on imputation {i+1} for {group}: {e}\")\n",
    "\n",
    "    if vif_list:\n",
    "        all_vif = pd.concat(vif_list)\n",
    "        pooled_vif = all_vif.groupby(\"variable\")[\"VIF\"].mean().reset_index()\n",
    "        pooled_vif = pooled_vif.sort_values(by=\"VIF\", ascending=False)\n",
    "\n",
    "        output_folder = os.path.join(\"outputs\", group)\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        pooled_vif.to_csv(os.path.join(output_folder, \"pooled_vif.csv\"), index=False)\n",
    "\n",
    "        print(f\" ✅ Saved: {output_folder}/pooled_vif.csv\")\n",
    "    else:\n",
    "        print(f\" ⚠️ Skipped {group}: No valid imputations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "dc6c0f67-a42e-4156-8916-137f0284544a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Running PS estimation for CAT_ADHD\n",
      "   Imp 1: AUC = 0.643, ROC saved.\n",
      "   Imp 2: AUC = 0.644, ROC saved.\n",
      "   Imp 3: AUC = 0.633, ROC saved.\n",
      "   Imp 4: AUC = 0.651, ROC saved.\n",
      "   Imp 5: AUC = 0.639, ROC saved.\n",
      " Composite PS + AUC saved for CAT_ADHD\n",
      " Running PS estimation for CAT_Aceetanilidederivaten\n",
      "   Imp 1: AUC = 0.849, ROC saved.\n",
      "   Imp 2: AUC = 0.852, ROC saved.\n",
      "   Imp 3: AUC = 0.846, ROC saved.\n",
      "   Imp 4: AUC = 0.852, ROC saved.\n",
      "   Imp 5: AUC = 0.859, ROC saved.\n",
      " Composite PS + AUC saved for CAT_Aceetanilidederivaten\n",
      " Running PS estimation for CAT_Z_drugs\n",
      "   Imp 1: AUC = 0.732, ROC saved.\n",
      "   Imp 2: AUC = 0.734, ROC saved.\n",
      "   Imp 3: AUC = 0.732, ROC saved.\n",
      "   Imp 4: AUC = 0.729, ROC saved.\n",
      "   Imp 5: AUC = 0.727, ROC saved.\n",
      " Composite PS + AUC saved for CAT_Z_drugs\n",
      " Running PS estimation for CAT_Opioden\n",
      "   Imp 1: AUC = 0.873, ROC saved.\n",
      "   Imp 2: AUC = 0.873, ROC saved.\n",
      "   Imp 3: AUC = 0.874, ROC saved.\n",
      "   Imp 4: AUC = 0.873, ROC saved.\n",
      "   Imp 5: AUC = 0.871, ROC saved.\n",
      " Composite PS + AUC saved for CAT_Opioden\n",
      " Running PS estimation for CAT_NSAIDs\n",
      "   Imp 1: AUC = 0.827, ROC saved.\n",
      "   Imp 2: AUC = 0.811, ROC saved.\n",
      "   Imp 3: AUC = 0.799, ROC saved.\n",
      "   Imp 4: AUC = 0.840, ROC saved.\n",
      "   Imp 5: AUC = 0.837, ROC saved.\n",
      " Composite PS + AUC saved for CAT_NSAIDs\n",
      " Running PS estimation for CAT_Benzodiazepine\n",
      "   Imp 1: AUC = 0.811, ROC saved.\n",
      "   Imp 2: AUC = 0.811, ROC saved.\n",
      "   Imp 3: AUC = 0.810, ROC saved.\n",
      "   Imp 4: AUC = 0.809, ROC saved.\n",
      "   Imp 5: AUC = 0.810, ROC saved.\n",
      " Composite PS + AUC saved for CAT_Benzodiazepine\n",
      " Running PS estimation for CAT_Antihypertensiva\n",
      "   Imp 1: AUC = 0.777, ROC saved.\n",
      "   Imp 2: AUC = 0.806, ROC saved.\n",
      "   Imp 3: AUC = 0.776, ROC saved.\n",
      "   Imp 4: AUC = 0.782, ROC saved.\n",
      "   Imp 5: AUC = 0.783, ROC saved.\n",
      " Composite PS + AUC saved for CAT_Antihypertensiva\n",
      " Running PS estimation for CAT_Antihistaminica\n",
      "   Imp 1: AUC = 0.759, ROC saved.\n",
      "   Imp 2: AUC = 0.757, ROC saved.\n",
      "   Imp 3: AUC = 0.751, ROC saved.\n",
      "   Imp 4: AUC = 0.751, ROC saved.\n",
      "   Imp 5: AUC = 0.762, ROC saved.\n",
      " Composite PS + AUC saved for CAT_Antihistaminica\n",
      " Running PS estimation for CAT_Anti_epileptica\n",
      "   Imp 1: AUC = 0.818, ROC saved.\n",
      "   Imp 2: AUC = 0.835, ROC saved.\n",
      "   Imp 3: AUC = 0.833, ROC saved.\n",
      "   Imp 4: AUC = 0.825, ROC saved.\n",
      "   Imp 5: AUC = 0.826, ROC saved.\n",
      " Composite PS + AUC saved for CAT_Anti_epileptica\n",
      " Running PS estimation for CAT_Antidepressiva\n",
      "   Imp 1: AUC = 0.826, ROC saved.\n",
      "   Imp 2: AUC = 0.825, ROC saved.\n",
      "   Imp 3: AUC = 0.826, ROC saved.\n",
      "   Imp 4: AUC = 0.827, ROC saved.\n",
      "   Imp 5: AUC = 0.827, ROC saved.\n",
      " Composite PS + AUC saved for CAT_Antidepressiva\n",
      " Running PS estimation for CAT_Antipsychotica\n",
      "   Imp 1: AUC = 0.870, ROC saved.\n",
      "   Imp 2: AUC = 0.871, ROC saved.\n",
      "   Imp 3: AUC = 0.869, ROC saved.\n",
      "   Imp 4: AUC = 0.868, ROC saved.\n",
      "   Imp 5: AUC = 0.869, ROC saved.\n",
      " Composite PS + AUC saved for CAT_Antipsychotica\n",
      " Running PS estimation for CAT_ALL_PSYCHOTROPICS_EXCL_BENZO\n",
      "   Imp 1: AUC = 0.814, ROC saved.\n",
      "   Imp 2: AUC = 0.816, ROC saved.\n",
      "   Imp 3: AUC = 0.816, ROC saved.\n",
      "   Imp 4: AUC = 0.815, ROC saved.\n",
      "   Imp 5: AUC = 0.818, ROC saved.\n",
      " Composite PS + AUC saved for CAT_ALL_PSYCHOTROPICS_EXCL_BENZO\n",
      " Running PS estimation for CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS\n",
      "   Imp 1: AUC = 0.825, ROC saved.\n",
      "   Imp 2: AUC = 0.825, ROC saved.\n",
      "   Imp 3: AUC = 0.825, ROC saved.\n",
      "   Imp 4: AUC = 0.826, ROC saved.\n",
      "   Imp 5: AUC = 0.827, ROC saved.\n",
      " Composite PS + AUC saved for CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS\n",
      " Running PS estimation for CAT_ALL_PSYCHOTROPICS\n",
      "   Imp 1: AUC = 0.819, ROC saved.\n",
      "   Imp 2: AUC = 0.819, ROC saved.\n",
      "   Imp 3: AUC = 0.820, ROC saved.\n",
      "   Imp 4: AUC = 0.819, ROC saved.\n",
      "   Imp 5: AUC = 0.821, ROC saved.\n",
      " Composite PS + AUC saved for CAT_ALL_PSYCHOTROPICS\n",
      " Running PS estimation for CAT_ALL\n",
      "   Imp 1: AUC = 0.819, ROC saved.\n",
      "   Imp 2: AUC = 0.820, ROC saved.\n",
      "   Imp 3: AUC = 0.819, ROC saved.\n",
      "   Imp 4: AUC = 0.819, ROC saved.\n",
      "   Imp 5: AUC = 0.822, ROC saved.\n",
      " Composite PS + AUC saved for CAT_ALL\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ---------- PS Estimation Function ----------\n",
    "def run_logistic_ps_modeling(imputed_dfs, medication_groups, final_covariates_map):\n",
    "    for group in medication_groups:\n",
    "        print(f\" Running PS estimation for {group}\")\n",
    "\n",
    "        if group not in final_covariates_map:\n",
    "            print(f\" No covariates found for {group}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        output_folder = os.path.join(\"outputs\", group)\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "        covariates = final_covariates_map[group]\n",
    "        ps_matrix = pd.DataFrame()\n",
    "        auc_list = []\n",
    "\n",
    "        for i, df_imp in enumerate(imputed_dfs):\n",
    "            if group not in df_imp.columns:\n",
    "                print(f\" {group} not found in imputed dataset {i+1}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            X = df_imp[covariates].copy()\n",
    "            T = df_imp[group]\n",
    "\n",
    "            # Drop missing treatment rows\n",
    "            valid_idx = T.dropna().index\n",
    "            X = X.loc[valid_idx]\n",
    "            T = T.loc[valid_idx]\n",
    "\n",
    "            # Train-test split for ROC\n",
    "            X_train, X_test, T_train, T_test = train_test_split(\n",
    "                X, T, stratify=T, test_size=0.3, random_state=42\n",
    "            )\n",
    "\n",
    "            try:\n",
    "                model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "                model.fit(X_train, T_train)\n",
    "\n",
    "                ps_scores = model.predict_proba(X)[:, 1]\n",
    "                ps_matrix[f\"ps_imp{i+1}\"] = pd.Series(ps_scores, index=valid_idx)\n",
    "\n",
    "                # ROC & AUC\n",
    "                auc = roc_auc_score(T_test, model.predict_proba(X_test)[:, 1])\n",
    "                auc_list.append(auc)\n",
    "\n",
    "                fpr, tpr, _ = roc_curve(T_test, model.predict_proba(X_test)[:, 1])\n",
    "                plt.figure()\n",
    "                plt.plot(fpr, tpr, label=f\"AUC = {auc:.3f}\")\n",
    "                plt.plot([0, 1], [0, 1], 'k--')\n",
    "                plt.xlabel(\"False Positive Rate\")\n",
    "                plt.ylabel(\"True Positive Rate\")\n",
    "                plt.title(f\"ROC Curve - {group} (Imp {i+1})\")\n",
    "                plt.legend()\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(os.path.join(output_folder, f\"roc_curve_imp{i+1}.png\"))\n",
    "                plt.close()\n",
    "                print(f\"   Imp {i+1}: AUC = {auc:.3f}, ROC saved.\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"   Error in {group} (imp {i+1}): {e}\")\n",
    "\n",
    "        # Save AUCs and Composite PS\n",
    "        if not ps_matrix.empty:\n",
    "            # Fill NaN rows (from dropped subjects in some imputations) with mean\n",
    "            ps_matrix[\"composite_ps\"] = ps_matrix.mean(axis=1)\n",
    "            ps_matrix.to_excel(os.path.join(output_folder, \"propensity_scores.xlsx\"))\n",
    "\n",
    "            auc_df = pd.DataFrame({\n",
    "                \"imputation\": [f\"imp{i+1}\" for i in range(len(auc_list))],\n",
    "                \"AUC\": auc_list\n",
    "            })\n",
    "            auc_df.loc[len(auc_df.index)] = [\"mean\", np.mean(auc_list) if auc_list else np.nan]\n",
    "            auc_df.to_excel(os.path.join(output_folder, \"auc_scores.xlsx\"), index=False)\n",
    "\n",
    "            print(f\" Composite PS + AUC saved for {group}\")\n",
    "        else:\n",
    "            print(f\" No valid PS scores generated for {group}\")\n",
    "\n",
    "# ---------- Run ----------\n",
    "run_logistic_ps_modeling(imputed_dfs, medication_groups, final_covariates_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "44cdd960-01e8-4562-ae13-a8e282fcd019",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Computing feature importance for CAT_ADHD\n",
      " Saved feature importance plot and CSV for CAT_ADHD\n",
      "\n",
      " Computing feature importance for CAT_Aceetanilidederivaten\n",
      " Saved feature importance plot and CSV for CAT_Aceetanilidederivaten\n",
      "\n",
      " Computing feature importance for CAT_Z_drugs\n",
      " Saved feature importance plot and CSV for CAT_Z_drugs\n",
      "\n",
      " Computing feature importance for CAT_Opioden\n",
      " Saved feature importance plot and CSV for CAT_Opioden\n",
      "\n",
      " Computing feature importance for CAT_NSAIDs\n",
      " Saved feature importance plot and CSV for CAT_NSAIDs\n",
      "\n",
      " Computing feature importance for CAT_Benzodiazepine\n",
      " Saved feature importance plot and CSV for CAT_Benzodiazepine\n",
      "\n",
      " Computing feature importance for CAT_Antihypertensiva\n",
      " Saved feature importance plot and CSV for CAT_Antihypertensiva\n",
      "\n",
      " Computing feature importance for CAT_Antihistaminica\n",
      " Saved feature importance plot and CSV for CAT_Antihistaminica\n",
      "\n",
      " Computing feature importance for CAT_Anti_epileptica\n",
      " Saved feature importance plot and CSV for CAT_Anti_epileptica\n",
      "\n",
      " Computing feature importance for CAT_Antidepressiva\n",
      " Saved feature importance plot and CSV for CAT_Antidepressiva\n",
      "\n",
      " Computing feature importance for CAT_Antipsychotica\n",
      " Saved feature importance plot and CSV for CAT_Antipsychotica\n",
      "\n",
      " Computing feature importance for CAT_ALL_PSYCHOTROPICS_EXCL_BENZO\n",
      " Saved feature importance plot and CSV for CAT_ALL_PSYCHOTROPICS_EXCL_BENZO\n",
      "\n",
      " Computing feature importance for CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS\n",
      " Saved feature importance plot and CSV for CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS\n",
      "\n",
      " Computing feature importance for CAT_ALL_PSYCHOTROPICS\n",
      " Saved feature importance plot and CSV for CAT_ALL_PSYCHOTROPICS\n",
      "\n",
      " Computing feature importance for CAT_ALL\n",
      " Saved feature importance plot and CSV for CAT_ALL\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def compute_feature_importance(imputed_dfs, medication_groups, final_covariates_map):\n",
    "    for group in medication_groups:\n",
    "        print(f\"\\n Computing feature importance for {group}\")\n",
    "\n",
    "        if group not in final_covariates_map:\n",
    "            print(f\" No covariates found for {group}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        covariates = final_covariates_map[group]\n",
    "        output_folder = os.path.join(\"outputs\", group)\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "        importance_df_list = []\n",
    "\n",
    "        for i, df_imp in enumerate(imputed_dfs):\n",
    "            if group not in df_imp.columns:\n",
    "                print(f\" {group} not in imputed dataset {i+1}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            X = df_imp[covariates].copy()\n",
    "            T = df_imp[group]\n",
    "\n",
    "            # Drop NaNs in treatment\n",
    "            valid_idx = T.dropna().index\n",
    "            X = X.loc[valid_idx]\n",
    "            T = T.loc[valid_idx]\n",
    "\n",
    "            try:\n",
    "                model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "                model.fit(X, T)\n",
    "\n",
    "                # Get feature importance (absolute coefficients)\n",
    "                importances = np.abs(model.coef_[0])\n",
    "                importance_dict = dict(zip(X.columns, importances))\n",
    "                df_feat = pd.DataFrame.from_dict(importance_dict, orient='index', columns=[f\"imp{i+1}\"])\n",
    "                df_feat.index.name = 'feature'\n",
    "                importance_df_list.append(df_feat)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"   Error during modeling: {e}\")\n",
    "\n",
    "        if importance_df_list:\n",
    "            # Combine and average\n",
    "            all_feat = pd.concat(importance_df_list, axis=1).fillna(0)\n",
    "            all_feat[\"mean_importance\"] = all_feat.mean(axis=1)\n",
    "\n",
    "            # Filter top 30 non-zero\n",
    "            non_zero = all_feat[all_feat[\"mean_importance\"] > 0]\n",
    "            top30 = non_zero.sort_values(by=\"mean_importance\", ascending=False).head(30)\n",
    "\n",
    "            # Save to CSV\n",
    "            top30.to_csv(os.path.join(output_folder, \"feature_importance.csv\"))\n",
    "\n",
    "            # Plot\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            plt.barh(top30.index[::-1], top30[\"mean_importance\"][::-1])  # plot top → bottom\n",
    "            plt.xlabel(\"Mean Gain Importance\")\n",
    "            plt.title(f\"Top 30 Feature Importance - {group}\")\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(output_folder, \"feature_importance_top30.png\"))\n",
    "            plt.close()\n",
    "\n",
    "            print(f\" Saved feature importance plot and CSV for {group}\")\n",
    "        else:\n",
    "            print(f\" No valid models for {group}\")\n",
    "\n",
    "#  Run\n",
    "compute_feature_importance(imputed_dfs, medication_groups, final_covariates_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "229b8d60-d190-472b-8594-d2b70c09a2a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Processing IPTW + trimming + clipping for CAT_ADHD\n",
      "✅ Saved IPTW weights for CAT_ADHD\n",
      "    ℹ️ Retained 156/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_ADHD/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 157/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_ADHD/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 160/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_ADHD/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 168/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_ADHD/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 163/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_ADHD/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for CAT_Aceetanilidederivaten\n",
      "✅ Saved IPTW weights for CAT_Aceetanilidederivaten\n",
      "    ℹ️ Retained 136/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Aceetanilidederivaten/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 132/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Aceetanilidederivaten/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 131/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Aceetanilidederivaten/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 134/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Aceetanilidederivaten/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 138/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Aceetanilidederivaten/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for CAT_Z_drugs\n",
      "✅ Saved IPTW weights for CAT_Z_drugs\n",
      "    ℹ️ Retained 250/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Z_drugs/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 248/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Z_drugs/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 250/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Z_drugs/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 257/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Z_drugs/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 255/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Z_drugs/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for CAT_Opioden\n",
      "✅ Saved IPTW weights for CAT_Opioden\n",
      "    ℹ️ Retained 234/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Opioden/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 235/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Opioden/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 228/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Opioden/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 226/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Opioden/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 236/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Opioden/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for CAT_NSAIDs\n",
      "✅ Saved IPTW weights for CAT_NSAIDs\n",
      "    ℹ️ Retained 140/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_NSAIDs/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 144/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_NSAIDs/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 134/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_NSAIDs/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 143/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_NSAIDs/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 141/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_NSAIDs/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for CAT_Benzodiazepine\n",
      "✅ Saved IPTW weights for CAT_Benzodiazepine\n",
      "    ℹ️ Retained 1971/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Benzodiazepine/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 1959/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Benzodiazepine/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 1962/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Benzodiazepine/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 1960/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Benzodiazepine/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 1969/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Benzodiazepine/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for CAT_Antihypertensiva\n",
      "✅ Saved IPTW weights for CAT_Antihypertensiva\n",
      "    ℹ️ Retained 166/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Antihypertensiva/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 172/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Antihypertensiva/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 168/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Antihypertensiva/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 169/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Antihypertensiva/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 170/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Antihypertensiva/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for CAT_Antihistaminica\n",
      "✅ Saved IPTW weights for CAT_Antihistaminica\n",
      "    ℹ️ Retained 202/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Antihistaminica/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 197/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Antihistaminica/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 196/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Antihistaminica/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 198/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Antihistaminica/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 195/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Antihistaminica/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for CAT_Anti_epileptica\n",
      "✅ Saved IPTW weights for CAT_Anti_epileptica\n",
      "    ℹ️ Retained 402/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Anti_epileptica/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 397/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Anti_epileptica/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 395/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Anti_epileptica/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 408/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Anti_epileptica/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 405/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Anti_epileptica/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for CAT_Antidepressiva\n",
      "✅ Saved IPTW weights for CAT_Antidepressiva\n",
      "    ℹ️ Retained 2836/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Antidepressiva/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 2872/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Antidepressiva/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 2866/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Antidepressiva/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 2865/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Antidepressiva/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 2825/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Antidepressiva/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for CAT_Antipsychotica\n",
      "✅ Saved IPTW weights for CAT_Antipsychotica\n",
      "    ℹ️ Retained 1284/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Antipsychotica/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 1289/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Antipsychotica/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 1287/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Antipsychotica/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 1284/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Antipsychotica/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 1299/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_Antipsychotica/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for CAT_ALL_PSYCHOTROPICS_EXCL_BENZO\n",
      "✅ Saved IPTW weights for CAT_ALL_PSYCHOTROPICS_EXCL_BENZO\n",
      "    ℹ️ Retained 3433/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_ALL_PSYCHOTROPICS_EXCL_BENZO/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 3446/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_ALL_PSYCHOTROPICS_EXCL_BENZO/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 3440/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_ALL_PSYCHOTROPICS_EXCL_BENZO/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 3443/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_ALL_PSYCHOTROPICS_EXCL_BENZO/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 3435/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_ALL_PSYCHOTROPICS_EXCL_BENZO/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS\n",
      "✅ Saved IPTW weights for CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS\n",
      "    ℹ️ Retained 3323/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 3332/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 3303/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 3304/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 3304/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for CAT_ALL_PSYCHOTROPICS\n",
      "✅ Saved IPTW weights for CAT_ALL_PSYCHOTROPICS\n",
      "    ℹ️ Retained 3596/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_ALL_PSYCHOTROPICS/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 3597/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_ALL_PSYCHOTROPICS/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 3590/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_ALL_PSYCHOTROPICS/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 3586/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_ALL_PSYCHOTROPICS/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 3588/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_ALL_PSYCHOTROPICS/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for CAT_ALL\n",
      "✅ Saved IPTW weights for CAT_ALL\n",
      "    ℹ️ Retained 3568/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_ALL/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 3569/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_ALL/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 3564/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_ALL/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 3571/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_ALL/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 3563/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\CAT_ALL/trimmed_data_imp5.*\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_trimmed_clipped_iptw(ps_df, treatment, lower=0.05, upper=0.95, clip_max=10):\n",
    "    weights = []\n",
    "    keep_mask = (ps_df > lower) & (ps_df < upper)\n",
    "\n",
    "    for i in range(ps_df.shape[1]):\n",
    "        ps = ps_df.iloc[:, i].clip(lower=1e-6, upper=1 - 1e-6)  # avoid div by zero\n",
    "        mask = keep_mask.iloc[:, i]\n",
    "        w = pd.Series(np.nan, index=ps.index)\n",
    "\n",
    "        w[mask & (treatment == 1)] = 1 / ps[mask & (treatment == 1)]\n",
    "        w[mask & (treatment == 0)] = 1 / (1 - ps[mask & (treatment == 0)])\n",
    "        w = w.clip(upper=clip_max)\n",
    "        weights.append(w)\n",
    "\n",
    "    return pd.concat(weights, axis=1)\n",
    "\n",
    "\n",
    "def apply_rubins_rule_to_iptw(iptw_matrix):\n",
    "    \"\"\"\n",
    "    Given an IPTW matrix (n rows × M imputations), return Rubin’s rule pooled mean, SD, SE.\n",
    "    \"\"\"\n",
    "    M = iptw_matrix.shape[1]\n",
    "    q_bar = iptw_matrix.mean(axis=1)\n",
    "    u_bar = iptw_matrix.var(axis=1, ddof=1)\n",
    "    B = iptw_matrix.apply(lambda x: x.mean(), axis=1).var(ddof=1)\n",
    "    total_var = u_bar + (1 + 1/M) * B\n",
    "    total_se = np.sqrt(total_var)\n",
    "    return q_bar, u_bar.pow(0.5), total_se\n",
    "\n",
    "\n",
    "def run_trim_clip_save_all(imputed_dfs, medication_groups, final_covariates_map):\n",
    "    for group in medication_groups:\n",
    "        print(f\"\\n🔍 Processing IPTW + trimming + clipping for {group}\")\n",
    "        output_folder = os.path.join(\"outputs\", group)\n",
    "        ps_path = os.path.join(output_folder, \"propensity_scores.xlsx\")\n",
    "\n",
    "        if not os.path.exists(ps_path):\n",
    "            print(f\"⚠️ Missing PS file: {ps_path}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            ps_all = pd.read_excel(ps_path, index_col=0)\n",
    "            ps_cols = [col for col in ps_all.columns if col.startswith(\"ps_imp\")]\n",
    "            composite_index = ps_all.index\n",
    "\n",
    "            # Get treatment from one imputed dataset\n",
    "            T_full = None\n",
    "            for df in imputed_dfs:\n",
    "                if group in df.columns:\n",
    "                    T_full = df.loc[composite_index, group]\n",
    "                    break\n",
    "\n",
    "            if T_full is None:\n",
    "                print(f\"❌ Treatment column {group} not found in any imputed dataset.\")\n",
    "                continue\n",
    "\n",
    "            # Compute IPTW matrix (shape: n × M)\n",
    "            iptw_matrix = compute_trimmed_clipped_iptw(ps_all[ps_cols], T_full)\n",
    "            iptw_matrix.columns = [f\"iptw_imp{i+1}\" for i in range(iptw_matrix.shape[1])]\n",
    "\n",
    "            # Apply Rubin’s Rule for mean, SD, SE\n",
    "            iptw_matrix[\"iptw_mean\"], iptw_matrix[\"iptw_sd\"], iptw_matrix[\"iptw_se\"] = apply_rubins_rule_to_iptw(\n",
    "                iptw_matrix[[f\"iptw_imp{i+1}\" for i in range(iptw_matrix.shape[1])]]\n",
    "            )\n",
    "\n",
    "            # Save IPTW matrix separately\n",
    "            iptw_matrix.to_excel(os.path.join(output_folder, \"iptw_weights.xlsx\"))\n",
    "            print(f\"✅ Saved IPTW weights for {group}\")\n",
    "\n",
    "            # Save trimmed & clipped imputed datasets with IPTW\n",
    "            for i in range(5):\n",
    "                df = imputed_dfs[i].copy()\n",
    "                if group not in df.columns:\n",
    "                    continue\n",
    "\n",
    "                trimmed_idx = iptw_matrix.index.intersection(df.index)\n",
    "                needed_cols = final_covariates_map[group] + [group, \"caps5_change_baseline\"]\n",
    "\n",
    "                # Select only necessary columns\n",
    "                df_trimmed = df.loc[trimmed_idx, needed_cols].copy()\n",
    "                df_trimmed[\"iptw\"] = iptw_matrix[f\"iptw_imp{i+1}\"].loc[trimmed_idx]\n",
    "\n",
    "                # ✅ DROP rows with missing IPTW values\n",
    "                before = len(df_trimmed)\n",
    "                df_trimmed = df_trimmed.dropna(subset=[\"iptw\"])\n",
    "                after = len(df_trimmed)\n",
    "                print(f\"    ℹ️ Retained {after}/{before} rows after IPTW NaN drop.\")\n",
    "\n",
    "                # Save to .pkl\n",
    "                df_trimmed.to_pickle(os.path.join(output_folder, f\"trimmed_data_imp{i+1}.pkl\"))\n",
    "                print(f\"  💾 Saved trimmed dataset: {output_folder}/trimmed_data_imp{i+1}.*\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error in {group}: {e}\")\n",
    "\n",
    "\n",
    "run_trim_clip_save_all(imputed_dfs, medication_groups, final_covariates_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "045e9079-9f4c-4aa3-aefe-5235be369d24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Plotting PS overlap for CAT_ADHD\n",
      "✅ Saved unweighted and weighted PS plots for CAT_ADHD\n",
      "\n",
      "📊 Plotting PS overlap for CAT_Aceetanilidederivaten\n",
      "✅ Saved unweighted and weighted PS plots for CAT_Aceetanilidederivaten\n",
      "\n",
      "📊 Plotting PS overlap for CAT_Z_drugs\n",
      "✅ Saved unweighted and weighted PS plots for CAT_Z_drugs\n",
      "\n",
      "📊 Plotting PS overlap for CAT_Opioden\n",
      "✅ Saved unweighted and weighted PS plots for CAT_Opioden\n",
      "\n",
      "📊 Plotting PS overlap for CAT_NSAIDs\n",
      "✅ Saved unweighted and weighted PS plots for CAT_NSAIDs\n",
      "\n",
      "📊 Plotting PS overlap for CAT_Benzodiazepine\n",
      "✅ Saved unweighted and weighted PS plots for CAT_Benzodiazepine\n",
      "\n",
      "📊 Plotting PS overlap for CAT_Antihypertensiva\n",
      "✅ Saved unweighted and weighted PS plots for CAT_Antihypertensiva\n",
      "\n",
      "📊 Plotting PS overlap for CAT_Antihistaminica\n",
      "✅ Saved unweighted and weighted PS plots for CAT_Antihistaminica\n",
      "\n",
      "📊 Plotting PS overlap for CAT_Anti_epileptica\n",
      "✅ Saved unweighted and weighted PS plots for CAT_Anti_epileptica\n",
      "\n",
      "📊 Plotting PS overlap for CAT_Antidepressiva\n",
      "✅ Saved unweighted and weighted PS plots for CAT_Antidepressiva\n",
      "\n",
      "📊 Plotting PS overlap for CAT_Antipsychotica\n",
      "✅ Saved unweighted and weighted PS plots for CAT_Antipsychotica\n",
      "\n",
      "📊 Plotting PS overlap for CAT_ALL_PSYCHOTROPICS_EXCL_BENZO\n",
      "✅ Saved unweighted and weighted PS plots for CAT_ALL_PSYCHOTROPICS_EXCL_BENZO\n",
      "\n",
      "📊 Plotting PS overlap for CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS\n",
      "✅ Saved unweighted and weighted PS plots for CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS\n",
      "\n",
      "📊 Plotting PS overlap for CAT_ALL_PSYCHOTROPICS\n",
      "✅ Saved unweighted and weighted PS plots for CAT_ALL_PSYCHOTROPICS\n",
      "\n",
      "📊 Plotting PS overlap for CAT_ALL\n",
      "✅ Saved unweighted and weighted PS plots for CAT_ALL\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_ps_overlap_all_groups(medication_groups):\n",
    "    for group in medication_groups:\n",
    "        print(f\"\\n📊 Plotting PS overlap for {group}\")\n",
    "\n",
    "        folder = os.path.join(\"outputs\", group)\n",
    "        ps_file = os.path.join(folder, \"propensity_scores.xlsx\")\n",
    "        iptw_file = os.path.join(folder, \"iptw_weights.xlsx\")\n",
    "        trimmed_file = os.path.join(folder, \"trimmed_data_imp1.pkl\")\n",
    "\n",
    "        if not all(os.path.exists(f) for f in [ps_file, iptw_file, trimmed_file]):\n",
    "            print(f\"⚠️ Missing required files for {group}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            ps_df = pd.read_excel(ps_file, index_col=0)\n",
    "            iptw_df = pd.read_excel(iptw_file, index_col=0)\n",
    "            trimmed_df = pd.read_pickle(trimmed_file)\n",
    "\n",
    "            # Extract\n",
    "            ps = ps_df[\"composite_ps\"].reindex(trimmed_df.index)\n",
    "            w = iptw_df[\"iptw_mean\"].reindex(trimmed_df.index)\n",
    "            T = trimmed_df[group]\n",
    "\n",
    "            # Masks to remove NaNs\n",
    "            treated_mask = (T == 1) & ps.notna() & w.notna()\n",
    "            control_mask = (T == 0) & ps.notna() & w.notna()\n",
    "\n",
    "            treated = ps[treated_mask]\n",
    "            treated_w = w[treated_mask]\n",
    "\n",
    "            control = ps[control_mask]\n",
    "            control_w = w[control_mask]\n",
    "\n",
    "            # === Unweighted Plot ===\n",
    "            plt.figure(figsize=(8, 5))\n",
    "            plt.hist([treated, control], bins=25, label=[\"Treated\", \"Control\"], alpha=0.6)\n",
    "            plt.title(f\"Unweighted PS Overlap - {group}\")\n",
    "            plt.xlabel(\"Composite Propensity Score\")\n",
    "            plt.ylabel(\"Count\")\n",
    "            plt.legend()\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(folder, \"ps_overlap_unweighted.png\"))\n",
    "            plt.close()\n",
    "\n",
    "            # === Weighted Plot ===\n",
    "            plt.figure(figsize=(8, 5))\n",
    "            plt.hist([treated, control], bins=25, weights=[treated_w, control_w], label=[\"Treated\", \"Control\"], alpha=0.6)\n",
    "            plt.title(f\"Weighted PS Overlap - {group}\")\n",
    "            plt.xlabel(\"Composite Propensity Score\")\n",
    "            plt.ylabel(\"Weighted Count\")\n",
    "            plt.legend()\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(folder, \"ps_overlap_weighted.png\"))\n",
    "            plt.close()\n",
    "\n",
    "            print(f\"✅ Saved unweighted and weighted PS plots for {group}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error processing {group}: {e}\")\n",
    "\n",
    "# 🔁 Run\n",
    "plot_ps_overlap_all_groups(medication_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "a63f995d-519c-4bdc-a3e2-c1abe92c4c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ✅ Saved: outputs\\CAT_ADHD\\four_panel_overlap_CAT_ADHD.png\n",
      " ✅ Saved: outputs\\CAT_Aceetanilidederivaten\\four_panel_overlap_CAT_Aceetanilidederivaten.png\n",
      " ✅ Saved: outputs\\CAT_Z_drugs\\four_panel_overlap_CAT_Z_drugs.png\n",
      " ✅ Saved: outputs\\CAT_Opioden\\four_panel_overlap_CAT_Opioden.png\n",
      " ✅ Saved: outputs\\CAT_NSAIDs\\four_panel_overlap_CAT_NSAIDs.png\n",
      " ✅ Saved: outputs\\CAT_Benzodiazepine\\four_panel_overlap_CAT_Benzodiazepine.png\n",
      " ✅ Saved: outputs\\CAT_Antihypertensiva\\four_panel_overlap_CAT_Antihypertensiva.png\n",
      " ✅ Saved: outputs\\CAT_Antihistaminica\\four_panel_overlap_CAT_Antihistaminica.png\n",
      " ✅ Saved: outputs\\CAT_Anti_epileptica\\four_panel_overlap_CAT_Anti_epileptica.png\n",
      " ✅ Saved: outputs\\CAT_Antidepressiva\\four_panel_overlap_CAT_Antidepressiva.png\n",
      " ✅ Saved: outputs\\CAT_Antipsychotica\\four_panel_overlap_CAT_Antipsychotica.png\n",
      " ✅ Saved: outputs\\CAT_ALL_PSYCHOTROPICS_EXCL_BENZO\\four_panel_overlap_CAT_ALL_PSYCHOTROPICS_EXCL_BENZO.png\n",
      " ✅ Saved: outputs\\CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS\\four_panel_overlap_CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS.png\n",
      " ✅ Saved: outputs\\CAT_ALL_PSYCHOTROPICS\\four_panel_overlap_CAT_ALL_PSYCHOTROPICS.png\n",
      " ✅ Saved: outputs\\CAT_ALL\\four_panel_overlap_CAT_ALL.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set up base output folder\n",
    "output_base = \"outputs\"\n",
    "ps_file = \"propensity_scores.xlsx\"\n",
    "iptw_file = \"iptw_weights.xlsx\"\n",
    "trimmed_data_file = \"trimmed_data_imp1.pkl\"\n",
    "\n",
    "# Collect all treatment group folders\n",
    "groups = [g for g in medication_groups if os.path.isdir(os.path.join(output_base, g))]\n",
    "\n",
    "# Generate 4-panel overlap plots\n",
    "for group in groups:\n",
    "    group_path = os.path.join(output_base, group)\n",
    "    try:\n",
    "        # Load trimmed treatment info\n",
    "        trimmed_df = pd.read_pickle(os.path.join(group_path, trimmed_data_file))\n",
    "        index = trimmed_df.index\n",
    "\n",
    "        # Fix: case-insensitive match for treatment variable\n",
    "        possible_cols = [col for col in trimmed_df.columns if col.upper() == group.upper()]\n",
    "        if not possible_cols:\n",
    "            print(f\" Treatment variable {group} not found in {group}, skipping.\")\n",
    "            continue\n",
    "        treatment_var = possible_cols[0]\n",
    "        T = trimmed_df[treatment_var]\n",
    "\n",
    "        # Load composite PS (aligned to trimmed_df index)\n",
    "        ps_df = pd.read_excel(os.path.join(group_path, ps_file), index_col=0)\n",
    "        if 'composite_ps' not in ps_df.columns:\n",
    "            print(f\" Composite column missing in {ps_file}, skipping {group}.\")\n",
    "            continue\n",
    "        ps = ps_df.loc[index, 'composite_ps']\n",
    "\n",
    "        # Load IPTW weights (aligned to trimmed_df index)\n",
    "        weights_df = pd.read_excel(os.path.join(group_path, iptw_file), index_col=0)\n",
    "        if 'iptw_mean' not in weights_df.columns:\n",
    "            print(f\" IPTW weight column missing in {iptw_file}, skipping {group}.\")\n",
    "            continue\n",
    "        weights = weights_df.loc[index, 'iptw_mean']\n",
    "\n",
    "        # Prepare 4 datasets\n",
    "        raw_treated = ps[T == 1]\n",
    "        raw_control = ps[T == 0]\n",
    "        weighted_treated = (ps[T == 1], weights[T == 1])\n",
    "        weighted_control = (ps[T == 0], weights[T == 0])\n",
    "\n",
    "        # Create plot\n",
    "        fig, axs = plt.subplots(2, 2, figsize=(12, 8))\n",
    "        fig.suptitle(f\"Propensity Score Distribution - {group}\", fontsize=14)\n",
    "\n",
    "        axs[0, 0].hist(raw_treated, bins=20, alpha=0.7, color='blue')\n",
    "        axs[0, 0].set_title(\"Raw Treated\")\n",
    "\n",
    "        axs[0, 1].hist(raw_control, bins=20, alpha=0.7, color='green')\n",
    "        axs[0, 1].set_title(\"Raw Control\")\n",
    "\n",
    "        axs[1, 0].hist(weighted_treated[0], bins=20, weights=weighted_treated[1], alpha=0.7, color='blue')\n",
    "        axs[1, 0].set_title(\"Weighted Treated\")\n",
    "\n",
    "        axs[1, 1].hist(weighted_control[0], bins=20, weights=weighted_control[1], alpha=0.7, color='green')\n",
    "        axs[1, 1].set_title(\"Weighted Control\")\n",
    "\n",
    "        for ax in axs.flat:\n",
    "            ax.set_xlim(0, 1)\n",
    "            ax.set_xlabel(\"Propensity Score\")\n",
    "            ax.set_ylabel(\"Count\")\n",
    "\n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "\n",
    "        # Save figure\n",
    "        plot_path = os.path.join(group_path, f\"four_panel_overlap_{group}.png\")\n",
    "        plt.savefig(plot_path)\n",
    "        plt.close()\n",
    "        print(f\" ✅ Saved: {plot_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\" ❌ Error in {group}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "9ae9b6b5-f873-4db1-a724-174b17b565c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ATT calculation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "0d8ec178-4c5a-4efb-8a0b-7af1743d12fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weighted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "385e2c8c-d84f-413c-97ac-97aaacfd3190",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Running OLS for CAT_ADHD\n",
      "✅ CAT_ADHD | Seed 1: ATT = 2.2169, SE = 4.6029, p = 0.65523\n",
      "✅ CAT_ADHD | Seed 2: ATT = 4.2091, SE = 3.6719, p = 0.31559\n",
      "✅ CAT_ADHD | Seed 3: ATT = 0.8551, SE = 5.3635, p = 0.88106\n",
      "✅ CAT_ADHD | Seed 4: ATT = 0.7429, SE = 4.1065, p = 0.86524\n",
      "✅ CAT_ADHD | Seed 5: ATT = 0.6460, SE = 5.5854, p = 0.91350\n",
      "✅ CAT_ADHD | Seed 6: ATT = 0.3525, SE = 4.0702, p = 0.93514\n",
      "✅ CAT_ADHD | Seed 7: ATT = -0.5100, SE = 6.0831, p = 0.93721\n",
      "✅ CAT_ADHD | Seed 8: ATT = -0.1210, SE = 5.6935, p = 0.98407\n",
      "✅ CAT_ADHD | Seed 9: ATT = 1.0282, SE = 6.8455, p = 0.88787\n",
      "✅ CAT_ADHD | Seed 10: ATT = -0.3066, SE = 5.1878, p = 0.95571\n",
      "📊 Diagnostic plots saved for CAT_ADHD\n",
      "🏆 Best result for CAT_ADHD → Seed 2 | SE = 3.6719\n",
      "\n",
      "🚀 Running OLS for CAT_Aceetanilidederivaten\n",
      "✅ CAT_Aceetanilidederivaten | Seed 1: ATT = -0.6440, SE = 4.5879, p = 0.89515\n",
      "✅ CAT_Aceetanilidederivaten | Seed 2: ATT = 0.2526, SE = 8.5349, p = 0.97781\n",
      "✅ CAT_Aceetanilidederivaten | Seed 3: ATT = -0.0429, SE = 5.2668, p = 0.99389\n",
      "✅ CAT_Aceetanilidederivaten | Seed 4: ATT = -2.4911, SE = 4.4843, p = 0.60815\n",
      "✅ CAT_Aceetanilidederivaten | Seed 5: ATT = 0.1025, SE = 4.4687, p = 0.98280\n",
      "✅ CAT_Aceetanilidederivaten | Seed 6: ATT = -1.8631, SE = 4.6953, p = 0.71178\n",
      "✅ CAT_Aceetanilidederivaten | Seed 7: ATT = -2.2572, SE = 5.5077, p = 0.70293\n",
      "✅ CAT_Aceetanilidederivaten | Seed 8: ATT = 1.8612, SE = 6.9384, p = 0.80177\n",
      "✅ CAT_Aceetanilidederivaten | Seed 9: ATT = 0.3798, SE = 5.9300, p = 0.95200\n",
      "✅ CAT_Aceetanilidederivaten | Seed 10: ATT = -3.3899, SE = 4.6838, p = 0.50928\n",
      "📊 Diagnostic plots saved for CAT_Aceetanilidederivaten\n",
      "🏆 Best result for CAT_Aceetanilidederivaten → Seed 5 | SE = 4.4687\n",
      "\n",
      "🚀 Running OLS for CAT_Z_drugs\n",
      "✅ CAT_Z_drugs | Seed 1: ATT = 6.1797, SE = 2.7047, p = 0.08434\n",
      "✅ CAT_Z_drugs | Seed 2: ATT = 5.1670, SE = 3.9584, p = 0.26180\n",
      "✅ CAT_Z_drugs | Seed 3: ATT = 4.0703, SE = 3.0996, p = 0.25939\n",
      "✅ CAT_Z_drugs | Seed 4: ATT = 2.7699, SE = 3.6537, p = 0.49060\n",
      "✅ CAT_Z_drugs | Seed 5: ATT = 3.5578, SE = 2.4924, p = 0.22663\n",
      "✅ CAT_Z_drugs | Seed 6: ATT = 5.6613, SE = 3.4580, p = 0.17694\n",
      "✅ CAT_Z_drugs | Seed 7: ATT = 3.4740, SE = 3.2419, p = 0.34426\n",
      "✅ CAT_Z_drugs | Seed 8: ATT = 4.0807, SE = 3.4523, p = 0.30267\n",
      "✅ CAT_Z_drugs | Seed 9: ATT = 5.8440, SE = 2.8994, p = 0.11407\n",
      "✅ CAT_Z_drugs | Seed 10: ATT = 7.3256, SE = 2.6726, p = 0.05185\n",
      "📊 Diagnostic plots saved for CAT_Z_drugs\n",
      "🏆 Best result for CAT_Z_drugs → Seed 5 | SE = 2.4924\n",
      "\n",
      "🚀 Running OLS for CAT_Opioden\n",
      "✅ CAT_Opioden | Seed 1: ATT = 3.2050, SE = 5.9956, p = 0.62129\n",
      "✅ CAT_Opioden | Seed 2: ATT = 5.4001, SE = 6.0424, p = 0.42199\n",
      "✅ CAT_Opioden | Seed 3: ATT = 5.3883, SE = 5.5618, p = 0.38750\n",
      "✅ CAT_Opioden | Seed 4: ATT = 2.4019, SE = 5.3635, p = 0.67746\n",
      "✅ CAT_Opioden | Seed 5: ATT = 6.3656, SE = 5.8048, p = 0.33440\n",
      "✅ CAT_Opioden | Seed 6: ATT = 4.5452, SE = 3.9373, p = 0.31261\n",
      "✅ CAT_Opioden | Seed 7: ATT = 5.0385, SE = 5.4301, p = 0.40598\n",
      "✅ CAT_Opioden | Seed 8: ATT = 4.9308, SE = 4.4942, p = 0.33419\n",
      "✅ CAT_Opioden | Seed 9: ATT = 6.3893, SE = 8.4199, p = 0.49021\n",
      "✅ CAT_Opioden | Seed 10: ATT = 4.0434, SE = 4.1348, p = 0.38350\n",
      "📊 Diagnostic plots saved for CAT_Opioden\n",
      "🏆 Best result for CAT_Opioden → Seed 6 | SE = 3.9373\n",
      "\n",
      "🚀 Running OLS for CAT_NSAIDs\n",
      "✅ CAT_NSAIDs | Seed 1: ATT = -0.4325, SE = 8.9497, p = 0.96377\n",
      "✅ CAT_NSAIDs | Seed 2: ATT = -4.3579, SE = 9.9025, p = 0.68261\n",
      "✅ CAT_NSAIDs | Seed 3: ATT = -1.4121, SE = 10.4341, p = 0.89888\n",
      "✅ CAT_NSAIDs | Seed 4: ATT = -6.3255, SE = 6.9858, p = 0.41642\n",
      "✅ CAT_NSAIDs | Seed 5: ATT = -1.1666, SE = 7.6042, p = 0.88550\n",
      "✅ CAT_NSAIDs | Seed 6: ATT = -1.9540, SE = 7.4685, p = 0.80652\n",
      "✅ CAT_NSAIDs | Seed 7: ATT = 2.7988, SE = 8.6579, p = 0.76269\n",
      "✅ CAT_NSAIDs | Seed 8: ATT = -7.6175, SE = 6.9415, p = 0.33409\n",
      "✅ CAT_NSAIDs | Seed 9: ATT = -3.6687, SE = 7.3124, p = 0.64223\n",
      "✅ CAT_NSAIDs | Seed 10: ATT = -2.2783, SE = 11.0861, p = 0.84721\n",
      "📊 Diagnostic plots saved for CAT_NSAIDs\n",
      "🏆 Best result for CAT_NSAIDs → Seed 8 | SE = 6.9415\n",
      "\n",
      "🚀 Running OLS for CAT_Benzodiazepine\n",
      "✅ CAT_Benzodiazepine | Seed 1: ATT = 2.3278, SE = 0.9835, p = 0.07709\n",
      "✅ CAT_Benzodiazepine | Seed 2: ATT = 1.6416, SE = 1.6544, p = 0.37721\n",
      "✅ CAT_Benzodiazepine | Seed 3: ATT = 1.6255, SE = 1.2087, p = 0.24987\n",
      "✅ CAT_Benzodiazepine | Seed 4: ATT = 1.4059, SE = 1.1063, p = 0.27268\n",
      "✅ CAT_Benzodiazepine | Seed 5: ATT = 2.0990, SE = 1.2480, p = 0.16789\n",
      "✅ CAT_Benzodiazepine | Seed 6: ATT = 1.1903, SE = 1.1803, p = 0.37029\n",
      "✅ CAT_Benzodiazepine | Seed 7: ATT = 1.4139, SE = 1.3083, p = 0.34062\n",
      "✅ CAT_Benzodiazepine | Seed 8: ATT = 1.4961, SE = 1.5910, p = 0.40029\n",
      "✅ CAT_Benzodiazepine | Seed 9: ATT = 1.8980, SE = 1.4048, p = 0.24802\n",
      "✅ CAT_Benzodiazepine | Seed 10: ATT = 2.6565, SE = 1.3289, p = 0.11625\n",
      "📊 Diagnostic plots saved for CAT_Benzodiazepine\n",
      "🏆 Best result for CAT_Benzodiazepine → Seed 1 | SE = 0.9835\n",
      "\n",
      "🚀 Running OLS for CAT_Antihypertensiva\n",
      "✅ CAT_Antihypertensiva | Seed 1: ATT = 0.7929, SE = 6.5678, p = 0.90973\n",
      "✅ CAT_Antihypertensiva | Seed 2: ATT = 4.2476, SE = 3.3312, p = 0.27131\n",
      "✅ CAT_Antihypertensiva | Seed 3: ATT = 2.7274, SE = 5.1191, p = 0.62241\n",
      "✅ CAT_Antihypertensiva | Seed 4: ATT = 0.0992, SE = 3.3127, p = 0.97754\n",
      "✅ CAT_Antihypertensiva | Seed 5: ATT = -1.7421, SE = 6.7532, p = 0.80917\n",
      "✅ CAT_Antihypertensiva | Seed 6: ATT = 0.2603, SE = 6.5054, p = 0.97000\n",
      "✅ CAT_Antihypertensiva | Seed 7: ATT = 0.2249, SE = 6.4078, p = 0.97368\n",
      "✅ CAT_Antihypertensiva | Seed 8: ATT = 0.9812, SE = 3.9302, p = 0.81516\n",
      "✅ CAT_Antihypertensiva | Seed 9: ATT = -1.1019, SE = 7.1206, p = 0.88451\n",
      "✅ CAT_Antihypertensiva | Seed 10: ATT = 1.0659, SE = 5.3797, p = 0.85260\n",
      "📊 Diagnostic plots saved for CAT_Antihypertensiva\n",
      "🏆 Best result for CAT_Antihypertensiva → Seed 4 | SE = 3.3127\n",
      "\n",
      "🚀 Running OLS for CAT_Antihistaminica\n",
      "✅ CAT_Antihistaminica | Seed 1: ATT = 5.0258, SE = 5.9689, p = 0.44719\n",
      "✅ CAT_Antihistaminica | Seed 2: ATT = 2.6380, SE = 5.0951, p = 0.63195\n",
      "✅ CAT_Antihistaminica | Seed 3: ATT = 4.3770, SE = 4.4199, p = 0.37809\n",
      "✅ CAT_Antihistaminica | Seed 4: ATT = 3.1103, SE = 5.0543, p = 0.57159\n",
      "✅ CAT_Antihistaminica | Seed 5: ATT = 7.4493, SE = 5.3393, p = 0.23544\n",
      "✅ CAT_Antihistaminica | Seed 6: ATT = 4.0274, SE = 3.8740, p = 0.35723\n",
      "✅ CAT_Antihistaminica | Seed 7: ATT = 2.2920, SE = 4.0579, p = 0.60237\n",
      "✅ CAT_Antihistaminica | Seed 8: ATT = 3.8791, SE = 4.6369, p = 0.44990\n",
      "✅ CAT_Antihistaminica | Seed 9: ATT = 5.2151, SE = 5.2170, p = 0.37406\n",
      "✅ CAT_Antihistaminica | Seed 10: ATT = 6.0494, SE = 3.5325, p = 0.16196\n",
      "📊 Diagnostic plots saved for CAT_Antihistaminica\n",
      "🏆 Best result for CAT_Antihistaminica → Seed 10 | SE = 3.5325\n",
      "\n",
      "🚀 Running OLS for CAT_Anti_epileptica\n",
      "✅ CAT_Anti_epileptica | Seed 1: ATT = 5.4193, SE = 3.7903, p = 0.22600\n",
      "✅ CAT_Anti_epileptica | Seed 2: ATT = 5.5635, SE = 3.0343, p = 0.14065\n",
      "✅ CAT_Anti_epileptica | Seed 3: ATT = 6.6231, SE = 2.8413, p = 0.08016\n",
      "✅ CAT_Anti_epileptica | Seed 4: ATT = 6.0262, SE = 4.3799, p = 0.24087\n",
      "✅ CAT_Anti_epileptica | Seed 5: ATT = 7.2976, SE = 2.3841, p = 0.03763\n",
      "✅ CAT_Anti_epileptica | Seed 6: ATT = 6.6857, SE = 4.0112, p = 0.17089\n",
      "✅ CAT_Anti_epileptica | Seed 7: ATT = 5.8138, SE = 2.8892, p = 0.11450\n",
      "✅ CAT_Anti_epileptica | Seed 8: ATT = 5.7980, SE = 3.7942, p = 0.20121\n",
      "✅ CAT_Anti_epileptica | Seed 9: ATT = 6.9598, SE = 3.3618, p = 0.10720\n",
      "✅ CAT_Anti_epileptica | Seed 10: ATT = 4.0946, SE = 3.3782, p = 0.29218\n",
      "📊 Diagnostic plots saved for CAT_Anti_epileptica\n",
      "🏆 Best result for CAT_Anti_epileptica → Seed 5 | SE = 2.3841\n",
      "\n",
      "🚀 Running OLS for CAT_Antidepressiva\n",
      "✅ CAT_Antidepressiva | Seed 1: ATT = 0.8556, SE = 0.9284, p = 0.40892\n",
      "✅ CAT_Antidepressiva | Seed 2: ATT = 1.3691, SE = 1.0197, p = 0.25052\n",
      "✅ CAT_Antidepressiva | Seed 3: ATT = 1.4959, SE = 1.0636, p = 0.23230\n",
      "✅ CAT_Antidepressiva | Seed 4: ATT = 1.0568, SE = 1.0018, p = 0.35100\n",
      "✅ CAT_Antidepressiva | Seed 5: ATT = 1.2913, SE = 0.9251, p = 0.23524\n",
      "✅ CAT_Antidepressiva | Seed 6: ATT = 1.0525, SE = 1.0069, p = 0.35492\n",
      "✅ CAT_Antidepressiva | Seed 7: ATT = 1.5072, SE = 0.9092, p = 0.17271\n",
      "✅ CAT_Antidepressiva | Seed 8: ATT = 1.3595, SE = 0.7575, p = 0.14716\n",
      "✅ CAT_Antidepressiva | Seed 9: ATT = 1.3901, SE = 1.0321, p = 0.24928\n",
      "✅ CAT_Antidepressiva | Seed 10: ATT = 1.8554, SE = 1.2041, p = 0.19820\n",
      "📊 Diagnostic plots saved for CAT_Antidepressiva\n",
      "🏆 Best result for CAT_Antidepressiva → Seed 8 | SE = 0.7575\n",
      "\n",
      "🚀 Running OLS for CAT_Antipsychotica\n",
      "✅ CAT_Antipsychotica | Seed 1: ATT = 1.1885, SE = 1.6182, p = 0.50342\n",
      "✅ CAT_Antipsychotica | Seed 2: ATT = 1.5434, SE = 1.4324, p = 0.34190\n",
      "✅ CAT_Antipsychotica | Seed 3: ATT = 1.8718, SE = 1.3398, p = 0.23490\n",
      "✅ CAT_Antipsychotica | Seed 4: ATT = 1.6171, SE = 1.8164, p = 0.42361\n",
      "✅ CAT_Antipsychotica | Seed 5: ATT = 2.3424, SE = 1.9373, p = 0.29321\n",
      "✅ CAT_Antipsychotica | Seed 6: ATT = 1.0168, SE = 1.5986, p = 0.55930\n",
      "✅ CAT_Antipsychotica | Seed 7: ATT = 1.8399, SE = 1.4822, p = 0.28229\n",
      "✅ CAT_Antipsychotica | Seed 8: ATT = 2.1019, SE = 2.2632, p = 0.40559\n",
      "✅ CAT_Antipsychotica | Seed 9: ATT = 1.9104, SE = 1.6938, p = 0.32243\n",
      "✅ CAT_Antipsychotica | Seed 10: ATT = 1.0726, SE = 1.7089, p = 0.56429\n",
      "📊 Diagnostic plots saved for CAT_Antipsychotica\n",
      "🏆 Best result for CAT_Antipsychotica → Seed 3 | SE = 1.3398\n",
      "\n",
      "🚀 Running OLS for CAT_ALL_PSYCHOTROPICS_EXCL_BENZO\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_BENZO | Seed 1: ATT = 1.8701, SE = 0.9522, p = 0.12099\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_BENZO | Seed 2: ATT = 2.4707, SE = 1.3608, p = 0.14360\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_BENZO | Seed 3: ATT = 2.5358, SE = 1.1970, p = 0.10152\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_BENZO | Seed 4: ATT = 2.1184, SE = 1.0246, p = 0.10754\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_BENZO | Seed 5: ATT = 2.5901, SE = 0.8851, p = 0.04297\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_BENZO | Seed 6: ATT = 2.5750, SE = 1.1623, p = 0.09108\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_BENZO | Seed 7: ATT = 2.0797, SE = 0.8456, p = 0.06973\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_BENZO | Seed 8: ATT = 2.0897, SE = 0.9267, p = 0.08716\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_BENZO | Seed 9: ATT = 2.2678, SE = 1.3382, p = 0.16539\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_BENZO | Seed 10: ATT = 2.2203, SE = 0.9688, p = 0.08370\n",
      "📊 Diagnostic plots saved for CAT_ALL_PSYCHOTROPICS_EXCL_BENZO\n",
      "🏆 Best result for CAT_ALL_PSYCHOTROPICS_EXCL_BENZO → Seed 7 | SE = 0.8456\n",
      "\n",
      "🚀 Running OLS for CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS | Seed 1: ATT = 2.5033, SE = 1.4557, p = 0.16063\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS | Seed 2: ATT = 1.6925, SE = 1.1990, p = 0.23090\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS | Seed 3: ATT = 2.2284, SE = 0.9363, p = 0.07599\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS | Seed 4: ATT = 2.0073, SE = 0.7327, p = 0.05192\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS | Seed 5: ATT = 2.6700, SE = 1.0198, p = 0.05891\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS | Seed 6: ATT = 2.2008, SE = 0.9016, p = 0.07114\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS | Seed 7: ATT = 1.8029, SE = 1.1577, p = 0.19441\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS | Seed 8: ATT = 2.2019, SE = 1.3430, p = 0.17645\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS | Seed 9: ATT = 2.2857, SE = 1.0287, p = 0.09041\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS | Seed 10: ATT = 2.0574, SE = 0.8811, p = 0.07982\n",
      "📊 Diagnostic plots saved for CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS\n",
      "🏆 Best result for CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS → Seed 4 | SE = 0.7327\n",
      "\n",
      "🚀 Running OLS for CAT_ALL_PSYCHOTROPICS\n",
      "✅ CAT_ALL_PSYCHOTROPICS | Seed 1: ATT = 2.8905, SE = 0.6677, p = 0.01236\n",
      "✅ CAT_ALL_PSYCHOTROPICS | Seed 2: ATT = 2.5281, SE = 0.8508, p = 0.04108\n",
      "✅ CAT_ALL_PSYCHOTROPICS | Seed 3: ATT = 3.0217, SE = 0.8514, p = 0.02382\n",
      "✅ CAT_ALL_PSYCHOTROPICS | Seed 4: ATT = 2.4606, SE = 0.8693, p = 0.04732\n",
      "✅ CAT_ALL_PSYCHOTROPICS | Seed 5: ATT = 2.5126, SE = 0.9002, p = 0.04926\n",
      "✅ CAT_ALL_PSYCHOTROPICS | Seed 6: ATT = 2.8232, SE = 0.8627, p = 0.03072\n",
      "✅ CAT_ALL_PSYCHOTROPICS | Seed 7: ATT = 2.8804, SE = 0.9171, p = 0.03482\n",
      "✅ CAT_ALL_PSYCHOTROPICS | Seed 8: ATT = 2.4046, SE = 0.9179, p = 0.05882\n",
      "✅ CAT_ALL_PSYCHOTROPICS | Seed 9: ATT = 3.3355, SE = 0.8359, p = 0.01626\n",
      "✅ CAT_ALL_PSYCHOTROPICS | Seed 10: ATT = 2.6314, SE = 0.7274, p = 0.02240\n",
      "📊 Diagnostic plots saved for CAT_ALL_PSYCHOTROPICS\n",
      "🏆 Best result for CAT_ALL_PSYCHOTROPICS → Seed 1 | SE = 0.6677\n",
      "\n",
      "🚀 Running OLS for CAT_ALL\n",
      "✅ CAT_ALL | Seed 1: ATT = 2.9530, SE = 0.9007, p = 0.03054\n",
      "✅ CAT_ALL | Seed 2: ATT = 2.9655, SE = 0.6171, p = 0.00861\n",
      "✅ CAT_ALL | Seed 3: ATT = 3.3278, SE = 0.8525, p = 0.01749\n",
      "✅ CAT_ALL | Seed 4: ATT = 2.6706, SE = 0.8098, p = 0.03000\n",
      "✅ CAT_ALL | Seed 5: ATT = 3.4366, SE = 1.1991, p = 0.04565\n",
      "✅ CAT_ALL | Seed 6: ATT = 3.1041, SE = 0.6530, p = 0.00895\n",
      "✅ CAT_ALL | Seed 7: ATT = 2.7380, SE = 0.6692, p = 0.01496\n",
      "✅ CAT_ALL | Seed 8: ATT = 3.2569, SE = 0.6618, p = 0.00792\n",
      "✅ CAT_ALL | Seed 9: ATT = 3.2541, SE = 0.9901, p = 0.03031\n",
      "✅ CAT_ALL | Seed 10: ATT = 2.9626, SE = 0.9123, p = 0.03145\n",
      "📊 Diagnostic plots saved for CAT_ALL\n",
      "🏆 Best result for CAT_ALL → Seed 2 | SE = 0.6171\n",
      "\n",
      "🎯 All summary files saved.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import t, probplot\n",
    "import xgboost as xgb\n",
    "\n",
    "# -----------------------------\n",
    "# Configuration\n",
    "# -----------------------------\n",
    "seeds = list(range(1, 11))\n",
    "imputations = 5\n",
    "output_folder = \"outputs\"\n",
    "\n",
    "# -----------------------------\n",
    "# Diagnostic Plotting Function\n",
    "# -----------------------------\n",
    "def create_diagnostic_plots(residuals_data, fitted_data, group_name):\n",
    "    \"\"\"Create 4 diagnostic plots for model validation\"\"\"\n",
    "    plots_dir = os.path.join(output_folder, \"plots\")\n",
    "    os.makedirs(plots_dir, exist_ok=True)\n",
    "    \n",
    "    # Flatten the collected data\n",
    "    all_residuals = np.concatenate(residuals_data)\n",
    "    all_fitted = np.concatenate(fitted_data)\n",
    "    \n",
    "    # Create figure with 2x2 subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    fig.suptitle(f'Diagnostic Plots - {group_name}', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. Residuals vs Fitted\n",
    "    axes[0,0].scatter(all_fitted, all_residuals, alpha=0.6, s=20)\n",
    "    axes[0,0].axhline(y=0, color='red', linestyle='--', alpha=0.8)\n",
    "    axes[0,0].set_xlabel('Fitted Values')\n",
    "    axes[0,0].set_ylabel('Residuals')\n",
    "    axes[0,0].set_title('Residuals vs Fitted')\n",
    "    axes[0,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. QQ Plot\n",
    "    probplot(all_residuals, dist=\"norm\", plot=axes[0,1])\n",
    "    axes[0,1].set_title('Q-Q Plot (Normal)')\n",
    "    axes[0,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Residual Histogram\n",
    "    axes[1,0].hist(all_residuals, bins=30, density=True, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    axes[1,0].set_xlabel('Residuals')\n",
    "    axes[1,0].set_ylabel('Density')\n",
    "    axes[1,0].set_title('Residual Distribution')\n",
    "    axes[1,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Scale-Location Plot\n",
    "    sqrt_abs_residuals = np.sqrt(np.abs(all_residuals))\n",
    "    axes[1,1].scatter(all_fitted, sqrt_abs_residuals, alpha=0.6, s=20)\n",
    "    axes[1,1].set_xlabel('Fitted Values')\n",
    "    axes[1,1].set_ylabel('√|Residuals|')\n",
    "    axes[1,1].set_title('Scale-Location Plot')\n",
    "    axes[1,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save plot\n",
    "    plot_filename = os.path.join(plots_dir, f'{group_name}.png')\n",
    "    plt.savefig(plot_filename, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"📊 Diagnostic plots saved for {group_name}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Rubin's Rule\n",
    "# -----------------------------\n",
    "def rubins_pool(estimates, ses):\n",
    "    m = len(estimates)\n",
    "    q_bar = np.mean(estimates)\n",
    "    u_bar = np.mean(np.square(ses))\n",
    "    b_m = np.var(estimates, ddof=1)\n",
    "    total_var = u_bar + ((1 + 1/m) * b_m)\n",
    "    total_se = np.sqrt(total_var)\n",
    "    ci_lower = q_bar - 1.96 * total_se\n",
    "    ci_upper = q_bar + 1.96 * total_se\n",
    "    p_value = 2 * (1 - t.cdf(np.abs(q_bar / total_se), df=m-1))\n",
    "    rounded_p = round(p_value, 5)\n",
    "    formatted_p = \"< 0.00001\" if rounded_p <= 0.00001 else f\"{rounded_p:.5f}\"\n",
    "    return q_bar, total_se, ci_lower, ci_upper, formatted_p\n",
    "\n",
    "# -----------------------------\n",
    "# SMD + Variance Ratio\n",
    "# -----------------------------\n",
    "def calculate_smd_vr(X, T, weights):\n",
    "    treated = X[T == 1]\n",
    "    control = X[T == 0]\n",
    "    w_treated = weights[T == 1]\n",
    "    w_control = weights[T == 0]\n",
    "    smd, vr = [], []\n",
    "    for col in X.columns:\n",
    "        try:\n",
    "            m1, m0 = np.average(treated[col], weights=w_treated), np.average(control[col], weights=w_control)\n",
    "            s1 = np.sqrt(np.average((treated[col] - m1) ** 2, weights=w_treated))\n",
    "            s0 = np.sqrt(np.average((control[col] - m0) ** 2, weights=w_control))\n",
    "            pooled_sd = np.sqrt((s1 ** 2 + s0 ** 2) / 2)\n",
    "            smd.append((m1 - m0) / pooled_sd if pooled_sd > 0 else 0)\n",
    "            vr.append(s1**2 / s0**2 if s0**2 > 0 else 0)\n",
    "        except Exception:\n",
    "            smd.append(np.nan)\n",
    "            vr.append(np.nan)\n",
    "    return np.nanmean(smd), np.nanmean(vr)\n",
    "\n",
    "# -----------------------------\n",
    "# OLS Main Loop\n",
    "# -----------------------------\n",
    "def run_dml_with_trimmed_data(final_covariates_map):\n",
    "    att_results = []\n",
    "    balance_results = []\n",
    "\n",
    "    for group, covariates in final_covariates_map.items():\n",
    "        print(f\"\\n🚀 Running OLS for {group}\")\n",
    "        group_dir = os.path.join(output_folder, group)\n",
    "        os.makedirs(group_dir, exist_ok=True)\n",
    "\n",
    "        best_result = None\n",
    "        best_se = float(\"inf\")\n",
    "        \n",
    "        # Initialize lists to collect residuals and fitted values for diagnostic plots\n",
    "        group_residuals = []\n",
    "        group_fitted = []\n",
    "\n",
    "        for seed in seeds:\n",
    "            # Set random seed for this iteration\n",
    "            np.random.seed(seed)\n",
    "            \n",
    "            att_list, se_list, r2_list, rmse_list, smd_list, vr_list = [], [], [], [], [], []\n",
    "\n",
    "            for imp in range(1, imputations + 1):\n",
    "                file_path = os.path.join(group_dir, f\"trimmed_data_imp{imp}.pkl\")\n",
    "                if not os.path.exists(file_path):\n",
    "                    continue\n",
    "\n",
    "                df = pd.read_pickle(file_path)\n",
    "                if group not in df.columns or \"iptw\" not in df.columns:\n",
    "                    continue\n",
    "\n",
    "                # Add bootstrap sampling with seed-based randomization\n",
    "                n_samples = len(df)\n",
    "                bootstrap_idx = np.random.choice(n_samples, size=n_samples, replace=True)\n",
    "                df_bootstrap = df.iloc[bootstrap_idx].reset_index(drop=True)\n",
    "\n",
    "                X = df_bootstrap[covariates].copy()\n",
    "                T = df_bootstrap[group]\n",
    "                Y = df_bootstrap[\"caps5_change_baseline\"]\n",
    "                W = df_bootstrap[\"iptw\"]\n",
    "\n",
    "                try:\n",
    "                    # Create design matrix with treatment variable and covariates\n",
    "                    X_ols = pd.concat([T, X], axis=1)\n",
    "                    X_ols = sm.add_constant(X_ols)\n",
    "                    \n",
    "                    # Fit weighted OLS with robust standard errors\n",
    "                    ols_model = sm.WLS(Y, X_ols, weights=W).fit(cov_type='HC1')\n",
    "                    \n",
    "                    # Extract treatment effect (coefficient of treatment variable)\n",
    "                    att = ols_model.params[group]  # Treatment coefficient\n",
    "                    se = ols_model.bse[group]  # Robust standard error for treatment\n",
    "                    \n",
    "                    att_list.append(att)\n",
    "                    se_list.append(se)\n",
    "\n",
    "                    # Calculate model fit statistics\n",
    "                    Y_pred = ols_model.fittedvalues\n",
    "                    residuals = ols_model.resid\n",
    "                    rmse = mean_squared_error(Y, Y_pred, squared=False)\n",
    "                    r2 = ols_model.rsquared\n",
    "                    r2_list.append(r2)\n",
    "                    rmse_list.append(rmse)\n",
    "                    \n",
    "                    # Collect residuals and fitted values for diagnostic plots\n",
    "                    group_residuals.append(residuals.values)\n",
    "                    group_fitted.append(Y_pred.values)\n",
    "\n",
    "                    smd, vr = calculate_smd_vr(X, T, W)\n",
    "                    smd_list.append(smd)\n",
    "                    vr_list.append(vr)\n",
    "                except Exception as e:\n",
    "                    print(f\"⚠️ Error in {group}, seed {seed}, imp {imp}: {e}\")\n",
    "\n",
    "            if att_list:\n",
    "                att, se, ci_l, ci_u, p_val = rubins_pool(att_list, se_list)\n",
    "                avg_r2 = np.mean(r2_list)\n",
    "                avg_rmse = np.mean(rmse_list)\n",
    "                avg_smd = np.mean(smd_list)\n",
    "                avg_vr = np.mean(vr_list)\n",
    "\n",
    "                balance_results.append({\n",
    "                    \"group\": group, \"seed\": seed, \"smd\": avg_smd, \"vr\": avg_vr\n",
    "                })\n",
    "\n",
    "                if se < best_se:\n",
    "                    best_se = se\n",
    "                    best_result = {\n",
    "                        \"group\": group, \"seed\": seed, \"att\": att, \"se\": se,\n",
    "                        \"ci_lower\": ci_l, \"ci_upper\": ci_u, \"p_value\": p_val,\n",
    "                        \"r2\": avg_r2, \"rmse\": avg_rmse\n",
    "                    }\n",
    "\n",
    "                print(f\"✅ {group} | Seed {seed}: ATT = {att:.4f}, SE = {se:.4f}, p = {p_val}\")\n",
    "            else:\n",
    "                print(f\"⚠️ No valid results for {group} | Seed {seed}\")\n",
    "\n",
    "        # Create diagnostic plots for this group\n",
    "        if group_residuals and group_fitted:\n",
    "            create_diagnostic_plots(group_residuals, group_fitted, group)\n",
    "\n",
    "        if best_result:\n",
    "            att_results.append(best_result)\n",
    "            print(f\"🏆 Best result for {group} → Seed {best_result['seed']} | SE = {best_result['se']:.4f}\")\n",
    "\n",
    "    # Save final output\n",
    "    pd.DataFrame(att_results).to_excel(\"ols_rubin_summary_cats.xlsx\", index=False)\n",
    "    pd.DataFrame(balance_results).to_excel(\"smd_vr_summary_cats.xlsx\", index=False)\n",
    "    print(\"\\n🎯 All summary files saved.\")\n",
    "\n",
    "run_dml_with_trimmed_data(final_covariates_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "711869a8-2bfe-485e-aff1-ce2d761df39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unweighted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "354cb95e-628a-4234-b37a-085d0fd153ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Running OLS for CAT_ADHD\n",
      "✅ CAT_ADHD | Seed 1: ATT = 1.3674, SE = 5.4795, p = 0.81522\n",
      "✅ CAT_ADHD | Seed 2: ATT = 2.6991, SE = 5.1155, p = 0.62567\n",
      "✅ CAT_ADHD | Seed 3: ATT = 0.3165, SE = 7.0745, p = 0.96646\n",
      "✅ CAT_ADHD | Seed 4: ATT = 1.0238, SE = 6.8883, p = 0.88904\n",
      "✅ CAT_ADHD | Seed 5: ATT = 0.8215, SE = 7.8247, p = 0.92144\n",
      "✅ CAT_ADHD | Seed 6: ATT = 0.2706, SE = 5.7255, p = 0.96457\n",
      "✅ CAT_ADHD | Seed 7: ATT = -0.1040, SE = 7.2635, p = 0.98926\n",
      "✅ CAT_ADHD | Seed 8: ATT = -1.8000, SE = 7.6022, p = 0.82447\n",
      "✅ CAT_ADHD | Seed 9: ATT = 0.9549, SE = 7.1465, p = 0.90016\n",
      "✅ CAT_ADHD | Seed 10: ATT = -1.3080, SE = 5.5137, p = 0.82413\n",
      "📊 Diagnostic plots saved for CAT_ADHD\n",
      "🏆 Best result for CAT_ADHD → Seed 2 | SE = 5.1155\n",
      "\n",
      "🚀 Running OLS for CAT_Aceetanilidederivaten\n",
      "✅ CAT_Aceetanilidederivaten | Seed 1: ATT = 1.8247, SE = 4.8795, p = 0.72742\n",
      "✅ CAT_Aceetanilidederivaten | Seed 2: ATT = 1.9373, SE = 9.4798, p = 0.84805\n",
      "✅ CAT_Aceetanilidederivaten | Seed 3: ATT = 2.7035, SE = 6.1414, p = 0.68252\n",
      "✅ CAT_Aceetanilidederivaten | Seed 4: ATT = -0.0039, SE = 6.4825, p = 0.99955\n",
      "✅ CAT_Aceetanilidederivaten | Seed 5: ATT = 1.8825, SE = 4.6162, p = 0.70430\n",
      "✅ CAT_Aceetanilidederivaten | Seed 6: ATT = 0.4054, SE = 5.6780, p = 0.94651\n",
      "✅ CAT_Aceetanilidederivaten | Seed 7: ATT = -0.0293, SE = 5.3483, p = 0.99589\n",
      "✅ CAT_Aceetanilidederivaten | Seed 8: ATT = 3.1005, SE = 6.8913, p = 0.67608\n",
      "✅ CAT_Aceetanilidederivaten | Seed 9: ATT = 1.7500, SE = 6.0199, p = 0.78573\n",
      "✅ CAT_Aceetanilidederivaten | Seed 10: ATT = -1.5583, SE = 4.5800, p = 0.75079\n",
      "📊 Diagnostic plots saved for CAT_Aceetanilidederivaten\n",
      "🏆 Best result for CAT_Aceetanilidederivaten → Seed 10 | SE = 4.5800\n",
      "\n",
      "🚀 Running OLS for CAT_Z_drugs\n",
      "✅ CAT_Z_drugs | Seed 1: ATT = 7.1080, SE = 3.3952, p = 0.10441\n",
      "✅ CAT_Z_drugs | Seed 2: ATT = 7.2580, SE = 4.7459, p = 0.20092\n",
      "✅ CAT_Z_drugs | Seed 3: ATT = 5.2818, SE = 3.7763, p = 0.23447\n",
      "✅ CAT_Z_drugs | Seed 4: ATT = 4.1408, SE = 5.0653, p = 0.45954\n",
      "✅ CAT_Z_drugs | Seed 5: ATT = 4.9129, SE = 2.8076, p = 0.15504\n",
      "✅ CAT_Z_drugs | Seed 6: ATT = 6.2276, SE = 3.8765, p = 0.18344\n",
      "✅ CAT_Z_drugs | Seed 7: ATT = 3.8605, SE = 3.6826, p = 0.35365\n",
      "✅ CAT_Z_drugs | Seed 8: ATT = 4.2235, SE = 3.7479, p = 0.32281\n",
      "✅ CAT_Z_drugs | Seed 9: ATT = 6.6835, SE = 3.7577, p = 0.14993\n",
      "✅ CAT_Z_drugs | Seed 10: ATT = 7.8847, SE = 3.3103, p = 0.07584\n",
      "📊 Diagnostic plots saved for CAT_Z_drugs\n",
      "🏆 Best result for CAT_Z_drugs → Seed 5 | SE = 2.8076\n",
      "\n",
      "🚀 Running OLS for CAT_Opioden\n",
      "✅ CAT_Opioden | Seed 1: ATT = 3.0347, SE = 6.3785, p = 0.65906\n",
      "✅ CAT_Opioden | Seed 2: ATT = 4.7794, SE = 7.0895, p = 0.53717\n",
      "✅ CAT_Opioden | Seed 3: ATT = 5.2488, SE = 6.6041, p = 0.47123\n",
      "✅ CAT_Opioden | Seed 4: ATT = 1.8597, SE = 6.9393, p = 0.80195\n",
      "✅ CAT_Opioden | Seed 5: ATT = 5.9853, SE = 5.8068, p = 0.36090\n",
      "✅ CAT_Opioden | Seed 6: ATT = 5.1217, SE = 4.2494, p = 0.29453\n",
      "✅ CAT_Opioden | Seed 7: ATT = 5.4775, SE = 5.3218, p = 0.36153\n",
      "✅ CAT_Opioden | Seed 8: ATT = 3.8273, SE = 5.4837, p = 0.52366\n",
      "✅ CAT_Opioden | Seed 9: ATT = 5.6116, SE = 8.1080, p = 0.52695\n",
      "✅ CAT_Opioden | Seed 10: ATT = 3.3666, SE = 5.6117, p = 0.58088\n",
      "📊 Diagnostic plots saved for CAT_Opioden\n",
      "🏆 Best result for CAT_Opioden → Seed 6 | SE = 4.2494\n",
      "\n",
      "🚀 Running OLS for CAT_NSAIDs\n",
      "✅ CAT_NSAIDs | Seed 1: ATT = -3.3895, SE = 7.0812, p = 0.65717\n",
      "✅ CAT_NSAIDs | Seed 2: ATT = -5.0673, SE = 8.6143, p = 0.58797\n",
      "✅ CAT_NSAIDs | Seed 3: ATT = -2.7267, SE = 8.1605, p = 0.75506\n",
      "✅ CAT_NSAIDs | Seed 4: ATT = -6.4394, SE = 5.9080, p = 0.33700\n",
      "✅ CAT_NSAIDs | Seed 5: ATT = -4.7776, SE = 6.3354, p = 0.49274\n",
      "✅ CAT_NSAIDs | Seed 6: ATT = -3.4963, SE = 7.3435, p = 0.65884\n",
      "✅ CAT_NSAIDs | Seed 7: ATT = 0.9708, SE = 7.1104, p = 0.89800\n",
      "✅ CAT_NSAIDs | Seed 8: ATT = -8.1215, SE = 7.0493, p = 0.31345\n",
      "✅ CAT_NSAIDs | Seed 9: ATT = -5.2280, SE = 5.8817, p = 0.42430\n",
      "✅ CAT_NSAIDs | Seed 10: ATT = -1.9005, SE = 9.4774, p = 0.85085\n",
      "📊 Diagnostic plots saved for CAT_NSAIDs\n",
      "🏆 Best result for CAT_NSAIDs → Seed 9 | SE = 5.8817\n",
      "\n",
      "🚀 Running OLS for CAT_Benzodiazepine\n",
      "✅ CAT_Benzodiazepine | Seed 1: ATT = 1.5091, SE = 0.9870, p = 0.20100\n",
      "✅ CAT_Benzodiazepine | Seed 2: ATT = 1.0167, SE = 1.6003, p = 0.55975\n",
      "✅ CAT_Benzodiazepine | Seed 3: ATT = 1.0736, SE = 1.1273, p = 0.39483\n",
      "✅ CAT_Benzodiazepine | Seed 4: ATT = 0.9334, SE = 1.1768, p = 0.47208\n",
      "✅ CAT_Benzodiazepine | Seed 5: ATT = 1.2678, SE = 1.2763, p = 0.37676\n",
      "✅ CAT_Benzodiazepine | Seed 6: ATT = 0.6155, SE = 1.2824, p = 0.65631\n",
      "✅ CAT_Benzodiazepine | Seed 7: ATT = 0.9700, SE = 1.3386, p = 0.50879\n",
      "✅ CAT_Benzodiazepine | Seed 8: ATT = 0.5778, SE = 1.4120, p = 0.70333\n",
      "✅ CAT_Benzodiazepine | Seed 9: ATT = 1.4036, SE = 1.2957, p = 0.33962\n",
      "✅ CAT_Benzodiazepine | Seed 10: ATT = 1.9171, SE = 1.4012, p = 0.24307\n",
      "📊 Diagnostic plots saved for CAT_Benzodiazepine\n",
      "🏆 Best result for CAT_Benzodiazepine → Seed 1 | SE = 0.9870\n",
      "\n",
      "🚀 Running OLS for CAT_Antihypertensiva\n",
      "✅ CAT_Antihypertensiva | Seed 1: ATT = 0.6450, SE = 8.8973, p = 0.94569\n",
      "✅ CAT_Antihypertensiva | Seed 2: ATT = 4.8985, SE = 5.2041, p = 0.39986\n",
      "✅ CAT_Antihypertensiva | Seed 3: ATT = 1.8370, SE = 5.7236, p = 0.76431\n",
      "✅ CAT_Antihypertensiva | Seed 4: ATT = -1.3299, SE = 4.9545, p = 0.80164\n",
      "✅ CAT_Antihypertensiva | Seed 5: ATT = -1.6827, SE = 8.1739, p = 0.84695\n",
      "✅ CAT_Antihypertensiva | Seed 6: ATT = -1.2178, SE = 6.9573, p = 0.86955\n",
      "✅ CAT_Antihypertensiva | Seed 7: ATT = 1.2332, SE = 7.5808, p = 0.87867\n",
      "✅ CAT_Antihypertensiva | Seed 8: ATT = 1.4916, SE = 6.0337, p = 0.81692\n",
      "✅ CAT_Antihypertensiva | Seed 9: ATT = -2.4365, SE = 6.7421, p = 0.73609\n",
      "✅ CAT_Antihypertensiva | Seed 10: ATT = 0.8974, SE = 7.1372, p = 0.90600\n",
      "📊 Diagnostic plots saved for CAT_Antihypertensiva\n",
      "🏆 Best result for CAT_Antihypertensiva → Seed 4 | SE = 4.9545\n",
      "\n",
      "🚀 Running OLS for CAT_Antihistaminica\n",
      "✅ CAT_Antihistaminica | Seed 1: ATT = 4.2477, SE = 5.9296, p = 0.51337\n",
      "✅ CAT_Antihistaminica | Seed 2: ATT = 2.6100, SE = 5.4271, p = 0.65570\n",
      "✅ CAT_Antihistaminica | Seed 3: ATT = 4.5370, SE = 4.6262, p = 0.38226\n",
      "✅ CAT_Antihistaminica | Seed 4: ATT = 2.7854, SE = 4.5665, p = 0.57484\n",
      "✅ CAT_Antihistaminica | Seed 5: ATT = 6.7092, SE = 6.4402, p = 0.35634\n",
      "✅ CAT_Antihistaminica | Seed 6: ATT = 3.8065, SE = 5.0956, p = 0.49657\n",
      "✅ CAT_Antihistaminica | Seed 7: ATT = 0.7275, SE = 5.2567, p = 0.89661\n",
      "✅ CAT_Antihistaminica | Seed 8: ATT = 2.6282, SE = 5.2009, p = 0.63990\n",
      "✅ CAT_Antihistaminica | Seed 9: ATT = 2.3122, SE = 7.1649, p = 0.76307\n",
      "✅ CAT_Antihistaminica | Seed 10: ATT = 3.7702, SE = 4.4615, p = 0.44567\n",
      "📊 Diagnostic plots saved for CAT_Antihistaminica\n",
      "🏆 Best result for CAT_Antihistaminica → Seed 10 | SE = 4.4615\n",
      "\n",
      "🚀 Running OLS for CAT_Anti_epileptica\n",
      "✅ CAT_Anti_epileptica | Seed 1: ATT = 4.2509, SE = 4.2763, p = 0.37646\n",
      "✅ CAT_Anti_epileptica | Seed 2: ATT = 4.9216, SE = 3.5516, p = 0.23808\n",
      "✅ CAT_Anti_epileptica | Seed 3: ATT = 5.9294, SE = 4.4070, p = 0.24969\n",
      "✅ CAT_Anti_epileptica | Seed 4: ATT = 5.8176, SE = 5.2034, p = 0.32617\n",
      "✅ CAT_Anti_epileptica | Seed 5: ATT = 5.9474, SE = 3.1433, p = 0.13143\n",
      "✅ CAT_Anti_epileptica | Seed 6: ATT = 7.0798, SE = 4.4433, p = 0.18629\n",
      "✅ CAT_Anti_epileptica | Seed 7: ATT = 5.3288, SE = 3.6890, p = 0.22211\n",
      "✅ CAT_Anti_epileptica | Seed 8: ATT = 6.0822, SE = 3.9659, p = 0.19991\n",
      "✅ CAT_Anti_epileptica | Seed 9: ATT = 5.2901, SE = 2.8291, p = 0.13484\n",
      "✅ CAT_Anti_epileptica | Seed 10: ATT = 3.5347, SE = 3.7795, p = 0.40261\n",
      "📊 Diagnostic plots saved for CAT_Anti_epileptica\n",
      "🏆 Best result for CAT_Anti_epileptica → Seed 9 | SE = 2.8291\n",
      "\n",
      "🚀 Running OLS for CAT_Antidepressiva\n",
      "✅ CAT_Antidepressiva | Seed 1: ATT = 0.6549, SE = 0.7111, p = 0.40924\n",
      "✅ CAT_Antidepressiva | Seed 2: ATT = 1.1262, SE = 1.0048, p = 0.32510\n",
      "✅ CAT_Antidepressiva | Seed 3: ATT = 1.2191, SE = 1.2372, p = 0.38023\n",
      "✅ CAT_Antidepressiva | Seed 4: ATT = 0.5422, SE = 1.2407, p = 0.68464\n",
      "✅ CAT_Antidepressiva | Seed 5: ATT = 1.1236, SE = 0.7998, p = 0.23274\n",
      "✅ CAT_Antidepressiva | Seed 6: ATT = 0.8411, SE = 0.7861, p = 0.34489\n",
      "✅ CAT_Antidepressiva | Seed 7: ATT = 1.2725, SE = 0.8333, p = 0.20145\n",
      "✅ CAT_Antidepressiva | Seed 8: ATT = 0.8750, SE = 0.7859, p = 0.32791\n",
      "✅ CAT_Antidepressiva | Seed 9: ATT = 1.1545, SE = 0.7986, p = 0.22182\n",
      "✅ CAT_Antidepressiva | Seed 10: ATT = 1.5842, SE = 0.9788, p = 0.18086\n",
      "📊 Diagnostic plots saved for CAT_Antidepressiva\n",
      "🏆 Best result for CAT_Antidepressiva → Seed 1 | SE = 0.7111\n",
      "\n",
      "🚀 Running OLS for CAT_Antipsychotica\n",
      "✅ CAT_Antipsychotica | Seed 1: ATT = 1.2385, SE = 1.5067, p = 0.45725\n",
      "✅ CAT_Antipsychotica | Seed 2: ATT = 2.2315, SE = 1.4236, p = 0.19206\n",
      "✅ CAT_Antipsychotica | Seed 3: ATT = 2.1980, SE = 1.1960, p = 0.13994\n",
      "✅ CAT_Antipsychotica | Seed 4: ATT = 2.0843, SE = 1.9261, p = 0.34007\n",
      "✅ CAT_Antipsychotica | Seed 5: ATT = 2.6614, SE = 2.1630, p = 0.28595\n",
      "✅ CAT_Antipsychotica | Seed 6: ATT = 1.3491, SE = 1.4291, p = 0.39861\n",
      "✅ CAT_Antipsychotica | Seed 7: ATT = 1.7779, SE = 1.3276, p = 0.25154\n",
      "✅ CAT_Antipsychotica | Seed 8: ATT = 2.5474, SE = 2.4616, p = 0.35920\n",
      "✅ CAT_Antipsychotica | Seed 9: ATT = 2.0266, SE = 2.0567, p = 0.38024\n",
      "✅ CAT_Antipsychotica | Seed 10: ATT = 1.5249, SE = 1.8564, p = 0.45754\n",
      "📊 Diagnostic plots saved for CAT_Antipsychotica\n",
      "🏆 Best result for CAT_Antipsychotica → Seed 3 | SE = 1.1960\n",
      "\n",
      "🚀 Running OLS for CAT_ALL_PSYCHOTROPICS_EXCL_BENZO\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_BENZO | Seed 1: ATT = 1.5200, SE = 0.7950, p = 0.12847\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_BENZO | Seed 2: ATT = 1.7677, SE = 1.0916, p = 0.18069\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_BENZO | Seed 3: ATT = 1.7991, SE = 1.1224, p = 0.18423\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_BENZO | Seed 4: ATT = 1.5653, SE = 0.8373, p = 0.13493\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_BENZO | Seed 5: ATT = 1.8810, SE = 0.8550, p = 0.09265\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_BENZO | Seed 6: ATT = 1.9707, SE = 0.8923, p = 0.09177\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_BENZO | Seed 7: ATT = 1.5271, SE = 0.7572, p = 0.11393\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_BENZO | Seed 8: ATT = 1.5620, SE = 0.8343, p = 0.13447\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_BENZO | Seed 9: ATT = 1.6017, SE = 1.1791, p = 0.24590\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_BENZO | Seed 10: ATT = 1.5587, SE = 1.0668, p = 0.21777\n",
      "📊 Diagnostic plots saved for CAT_ALL_PSYCHOTROPICS_EXCL_BENZO\n",
      "🏆 Best result for CAT_ALL_PSYCHOTROPICS_EXCL_BENZO → Seed 7 | SE = 0.7572\n",
      "\n",
      "🚀 Running OLS for CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS | Seed 1: ATT = 1.8726, SE = 1.1399, p = 0.17578\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS | Seed 2: ATT = 1.3208, SE = 1.0163, p = 0.26358\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS | Seed 3: ATT = 1.7783, SE = 0.7958, p = 0.08916\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS | Seed 4: ATT = 1.5569, SE = 0.8055, p = 0.12540\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS | Seed 5: ATT = 1.9906, SE = 0.7638, p = 0.05965\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS | Seed 6: ATT = 1.6622, SE = 0.7230, p = 0.08302\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS | Seed 7: ATT = 1.2438, SE = 0.9422, p = 0.25729\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS | Seed 8: ATT = 1.6433, SE = 1.2625, p = 0.26296\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS | Seed 9: ATT = 1.8436, SE = 0.8545, p = 0.09717\n",
      "✅ CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS | Seed 10: ATT = 1.3570, SE = 0.9965, p = 0.24492\n",
      "📊 Diagnostic plots saved for CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS\n",
      "🏆 Best result for CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS → Seed 6 | SE = 0.7230\n",
      "\n",
      "🚀 Running OLS for CAT_ALL_PSYCHOTROPICS\n",
      "✅ CAT_ALL_PSYCHOTROPICS | Seed 1: ATT = 2.5486, SE = 0.6561, p = 0.01778\n",
      "✅ CAT_ALL_PSYCHOTROPICS | Seed 2: ATT = 2.0259, SE = 0.9169, p = 0.09166\n",
      "✅ CAT_ALL_PSYCHOTROPICS | Seed 3: ATT = 2.6001, SE = 0.6942, p = 0.02003\n",
      "✅ CAT_ALL_PSYCHOTROPICS | Seed 4: ATT = 2.0357, SE = 0.7480, p = 0.05290\n",
      "✅ CAT_ALL_PSYCHOTROPICS | Seed 5: ATT = 2.1731, SE = 0.6480, p = 0.02848\n",
      "✅ CAT_ALL_PSYCHOTROPICS | Seed 6: ATT = 2.2232, SE = 1.0012, p = 0.09057\n",
      "✅ CAT_ALL_PSYCHOTROPICS | Seed 7: ATT = 2.3756, SE = 0.8146, p = 0.04340\n",
      "✅ CAT_ALL_PSYCHOTROPICS | Seed 8: ATT = 2.0080, SE = 0.9903, p = 0.11250\n",
      "✅ CAT_ALL_PSYCHOTROPICS | Seed 9: ATT = 2.9438, SE = 0.8370, p = 0.02452\n",
      "✅ CAT_ALL_PSYCHOTROPICS | Seed 10: ATT = 2.1550, SE = 0.6563, p = 0.03040\n",
      "📊 Diagnostic plots saved for CAT_ALL_PSYCHOTROPICS\n",
      "🏆 Best result for CAT_ALL_PSYCHOTROPICS → Seed 5 | SE = 0.6480\n",
      "\n",
      "🚀 Running OLS for CAT_ALL\n",
      "✅ CAT_ALL | Seed 1: ATT = 2.4103, SE = 0.8579, p = 0.04834\n",
      "✅ CAT_ALL | Seed 2: ATT = 2.5950, SE = 0.5891, p = 0.01165\n",
      "✅ CAT_ALL | Seed 3: ATT = 2.7852, SE = 0.8240, p = 0.02778\n",
      "✅ CAT_ALL | Seed 4: ATT = 2.3153, SE = 0.7133, p = 0.03150\n",
      "✅ CAT_ALL | Seed 5: ATT = 2.8674, SE = 1.0873, p = 0.05776\n",
      "✅ CAT_ALL | Seed 6: ATT = 2.7560, SE = 0.6394, p = 0.01254\n",
      "✅ CAT_ALL | Seed 7: ATT = 2.5181, SE = 0.7003, p = 0.02284\n",
      "✅ CAT_ALL | Seed 8: ATT = 2.8622, SE = 0.6927, p = 0.01447\n",
      "✅ CAT_ALL | Seed 9: ATT = 2.8696, SE = 0.9629, p = 0.04073\n",
      "✅ CAT_ALL | Seed 10: ATT = 2.4701, SE = 0.8080, p = 0.03777\n",
      "📊 Diagnostic plots saved for CAT_ALL\n",
      "🏆 Best result for CAT_ALL → Seed 2 | SE = 0.5891\n",
      "\n",
      "🎯 All summary files saved.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import t, probplot\n",
    "import xgboost as xgb\n",
    "\n",
    "# -----------------------------\n",
    "# Configuration\n",
    "# -----------------------------\n",
    "seeds = list(range(1, 11))\n",
    "imputations = 5\n",
    "output_folder = \"outputs\"\n",
    "\n",
    "# -----------------------------\n",
    "# Diagnostic Plotting Function\n",
    "# -----------------------------\n",
    "def create_diagnostic_plots(residuals_data, fitted_data, group_name):\n",
    "    \"\"\"Create 4 diagnostic plots for model validation\"\"\"\n",
    "    plots_dir = os.path.join(output_folder, \"plots\")\n",
    "    os.makedirs(plots_dir, exist_ok=True)\n",
    "    \n",
    "    # Flatten the collected data\n",
    "    all_residuals = np.concatenate(residuals_data)\n",
    "    all_fitted = np.concatenate(fitted_data)\n",
    "    \n",
    "    # Create figure with 2x2 subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    fig.suptitle(f'Diagnostic Plots - {group_name}', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. Residuals vs Fitted\n",
    "    axes[0,0].scatter(all_fitted, all_residuals, alpha=0.6, s=20)\n",
    "    axes[0,0].axhline(y=0, color='red', linestyle='--', alpha=0.8)\n",
    "    axes[0,0].set_xlabel('Fitted Values')\n",
    "    axes[0,0].set_ylabel('Residuals')\n",
    "    axes[0,0].set_title('Residuals vs Fitted')\n",
    "    axes[0,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. QQ Plot\n",
    "    probplot(all_residuals, dist=\"norm\", plot=axes[0,1])\n",
    "    axes[0,1].set_title('Q-Q Plot (Normal)')\n",
    "    axes[0,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Residual Histogram\n",
    "    axes[1,0].hist(all_residuals, bins=30, density=True, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    axes[1,0].set_xlabel('Residuals')\n",
    "    axes[1,0].set_ylabel('Density')\n",
    "    axes[1,0].set_title('Residual Distribution')\n",
    "    axes[1,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Scale-Location Plot\n",
    "    sqrt_abs_residuals = np.sqrt(np.abs(all_residuals))\n",
    "    axes[1,1].scatter(all_fitted, sqrt_abs_residuals, alpha=0.6, s=20)\n",
    "    axes[1,1].set_xlabel('Fitted Values')\n",
    "    axes[1,1].set_ylabel('√|Residuals|')\n",
    "    axes[1,1].set_title('Scale-Location Plot')\n",
    "    axes[1,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save plot\n",
    "    plot_filename = os.path.join(plots_dir, f'{group_name}_unweighted.png')\n",
    "    plt.savefig(plot_filename, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"📊 Diagnostic plots saved for {group_name}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Rubin's Rule\n",
    "# -----------------------------\n",
    "def rubins_pool(estimates, ses):\n",
    "    m = len(estimates)\n",
    "    q_bar = np.mean(estimates)\n",
    "    u_bar = np.mean(np.square(ses))\n",
    "    b_m = np.var(estimates, ddof=1)\n",
    "    total_var = u_bar + ((1 + 1/m) * b_m)\n",
    "    total_se = np.sqrt(total_var)\n",
    "    ci_lower = q_bar - 1.96 * total_se\n",
    "    ci_upper = q_bar + 1.96 * total_se\n",
    "    p_value = 2 * (1 - t.cdf(np.abs(q_bar / total_se), df=m-1))\n",
    "    rounded_p = round(p_value, 5)\n",
    "    formatted_p = \"< 0.00001\" if rounded_p <= 0.00001 else f\"{rounded_p:.5f}\"\n",
    "    return q_bar, total_se, ci_lower, ci_upper, formatted_p\n",
    "\n",
    "# -----------------------------\n",
    "# SMD + Variance Ratio\n",
    "# -----------------------------\n",
    "def calculate_smd_vr(X, T):\n",
    "    treated = X[T == 1]\n",
    "    control = X[T == 0]\n",
    "    smd, vr = [], []\n",
    "    for col in X.columns:\n",
    "        try:\n",
    "            m1, m0 = treated[col].mean(), control[col].mean()\n",
    "            s1 = treated[col].std()\n",
    "            s0 = control[col].std()\n",
    "            pooled_sd = np.sqrt((s1 ** 2 + s0 ** 2) / 2)\n",
    "            smd.append((m1 - m0) / pooled_sd if pooled_sd > 0 else 0)\n",
    "            vr.append(s1**2 / s0**2 if s0**2 > 0 else 0)\n",
    "        except Exception:\n",
    "            smd.append(np.nan)\n",
    "            vr.append(np.nan)\n",
    "    return np.nanmean(smd), np.nanmean(vr)\n",
    "\n",
    "# -----------------------------\n",
    "# OLS Main Loop\n",
    "# -----------------------------\n",
    "def run_dml_with_trimmed_data(final_covariates_map):\n",
    "    att_results = []\n",
    "    balance_results = []\n",
    "\n",
    "    for group, covariates in final_covariates_map.items():\n",
    "        print(f\"\\n🚀 Running OLS for {group}\")\n",
    "        group_dir = os.path.join(output_folder, group)\n",
    "        os.makedirs(group_dir, exist_ok=True)\n",
    "\n",
    "        best_result = None\n",
    "        best_se = float(\"inf\")\n",
    "        \n",
    "        # Initialize lists to collect residuals and fitted values for diagnostic plots\n",
    "        group_residuals = []\n",
    "        group_fitted = []\n",
    "\n",
    "        for seed in seeds:\n",
    "            # Set random seed for this iteration\n",
    "            np.random.seed(seed)\n",
    "            \n",
    "            att_list, se_list, r2_list, rmse_list, smd_list, vr_list = [], [], [], [], [], []\n",
    "\n",
    "            for imp in range(1, imputations + 1):\n",
    "                file_path = os.path.join(group_dir, f\"trimmed_data_imp{imp}.pkl\")\n",
    "                if not os.path.exists(file_path):\n",
    "                    continue\n",
    "\n",
    "                df = pd.read_pickle(file_path)\n",
    "                if group not in df.columns or \"iptw\" not in df.columns:\n",
    "                    continue\n",
    "\n",
    "                # Add bootstrap sampling with seed-based randomization\n",
    "                n_samples = len(df)\n",
    "                bootstrap_idx = np.random.choice(n_samples, size=n_samples, replace=True)\n",
    "                df_bootstrap = df.iloc[bootstrap_idx].reset_index(drop=True)\n",
    "\n",
    "                X = df_bootstrap[covariates].copy()\n",
    "                T = df_bootstrap[group]\n",
    "                Y = df_bootstrap[\"caps5_change_baseline\"]\n",
    "                #W = df_bootstrap[\"iptw\"]\n",
    "\n",
    "                try:\n",
    "                    # Create design matrix with treatment variable and covariates\n",
    "                    X_ols = pd.concat([T, X], axis=1)\n",
    "                    X_ols = sm.add_constant(X_ols)\n",
    "                    \n",
    "                    # Fit OLS with robust standard errors (unweighted)\n",
    "                    ols_model = sm.OLS(Y, X_ols).fit(cov_type='HC1')\n",
    "                    \n",
    "                    # Extract treatment effect (coefficient of treatment variable)\n",
    "                    att = ols_model.params[group]  # Treatment coefficient\n",
    "                    se = ols_model.bse[group]  # Robust standard error for treatment\n",
    "                    \n",
    "                    att_list.append(att)\n",
    "                    se_list.append(se)\n",
    "\n",
    "                    # Calculate model fit statistics\n",
    "                    Y_pred = ols_model.fittedvalues\n",
    "                    residuals = ols_model.resid\n",
    "                    rmse = mean_squared_error(Y, Y_pred, squared=False)\n",
    "                    r2 = ols_model.rsquared\n",
    "                    r2_list.append(r2)\n",
    "                    rmse_list.append(rmse)\n",
    "                    \n",
    "                    # Collect residuals and fitted values for diagnostic plots\n",
    "                    group_residuals.append(residuals.values)\n",
    "                    group_fitted.append(Y_pred.values)\n",
    "\n",
    "                    smd, vr = calculate_smd_vr(X, T)\n",
    "                    smd_list.append(smd)\n",
    "                    vr_list.append(vr)\n",
    "                except Exception as e:\n",
    "                    print(f\"⚠️ Error in {group}, seed {seed}, imp {imp}: {e}\")\n",
    "\n",
    "            if att_list:\n",
    "                att, se, ci_l, ci_u, p_val = rubins_pool(att_list, se_list)\n",
    "                avg_r2 = np.mean(r2_list)\n",
    "                avg_rmse = np.mean(rmse_list)\n",
    "                avg_smd = np.mean(smd_list)\n",
    "                avg_vr = np.mean(vr_list)\n",
    "\n",
    "                balance_results.append({\n",
    "                    \"group\": group, \"seed\": seed, \"smd\": avg_smd, \"vr\": avg_vr\n",
    "                })\n",
    "\n",
    "                if se < best_se:\n",
    "                    best_se = se\n",
    "                    best_result = {\n",
    "                        \"group\": group, \"seed\": seed, \"att\": att, \"se\": se,\n",
    "                        \"ci_lower\": ci_l, \"ci_upper\": ci_u, \"p_value\": p_val,\n",
    "                        \"r2\": avg_r2, \"rmse\": avg_rmse\n",
    "                    }\n",
    "\n",
    "                print(f\"✅ {group} | Seed {seed}: ATT = {att:.4f}, SE = {se:.4f}, p = {p_val}\")\n",
    "            else:\n",
    "                print(f\"⚠️ No valid results for {group} | Seed {seed}\")\n",
    "\n",
    "        # Create diagnostic plots for this group\n",
    "        if group_residuals and group_fitted:\n",
    "            create_diagnostic_plots(group_residuals, group_fitted, group)\n",
    "\n",
    "        if best_result:\n",
    "            att_results.append(best_result)\n",
    "            print(f\"🏆 Best result for {group} → Seed {best_result['seed']} | SE = {best_result['se']:.4f}\")\n",
    "\n",
    "    # Save final output\n",
    "    pd.DataFrame(att_results).to_excel(\"ols_rubin_summary_cats_unweighted.xlsx\", index=False)\n",
    "    pd.DataFrame(balance_results).to_excel(\"smd_vr_summary_cats_unweighted.xlsx\", index=False)\n",
    "    print(\"\\n🎯 All summary files saved.\")\n",
    "\n",
    "run_dml_with_trimmed_data(final_covariates_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "fc4dc9d3-d7a4-48e4-9c44-8c3e1c375a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Final_ATT_Summary_Cat saved\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import sem, ttest_ind\n",
    "\n",
    "# ----------------------------------\n",
    "# File paths\n",
    "# ----------------------------------\n",
    "output_base = \"outputs\"\n",
    "att_file = \"ols_rubin_summary_cats.xlsx\"\n",
    "trimmed_file = \"trimmed_data_imp1.pkl\"\n",
    "auc_file = \"auc_scores.xlsx\"  # NEW\n",
    "\n",
    "# ----------------------------------\n",
    "# Load ATT Summary\n",
    "# ----------------------------------\n",
    "if os.path.exists(att_file):\n",
    "    att_df = pd.read_excel(att_file)\n",
    "else:\n",
    "    raise FileNotFoundError(\"❌ ATT summary file not found: ols_rubin_summary_cats.xlsx\")\n",
    "\n",
    "summary_rows = []\n",
    "\n",
    "# ----------------------------------\n",
    "# Loop over medication groups\n",
    "# ----------------------------------\n",
    "groups = [g for g in medication_groups if os.path.isdir(os.path.join(output_base, g))]\n",
    "\n",
    "for med in groups:\n",
    "    try:\n",
    "        group_path = os.path.join(output_base, med)\n",
    "\n",
    "        # Load trimmed data\n",
    "        df = pd.read_pickle(os.path.join(group_path, trimmed_file))\n",
    "\n",
    "        # Detect treatment column\n",
    "        treatment_cols = [col for col in df.columns if col.upper() == med.upper()]\n",
    "        if not treatment_cols:\n",
    "            print(f\"⚠️ Treatment column {med} not found in trimmed data. Skipping.\")\n",
    "            continue\n",
    "        treatment_var = treatment_cols[0]\n",
    "\n",
    "        # Extract treatment and outcome\n",
    "        T = df[treatment_var]\n",
    "        Y = df[\"caps5_change_baseline\"]\n",
    "\n",
    "        # Treated and control stats\n",
    "        treated = Y[T == 1]\n",
    "        control = Y[T == 0]\n",
    "\n",
    "        mean_treat = treated.mean()\n",
    "        se_treat = sem(treated) if len(treated) > 1 else np.nan\n",
    "\n",
    "        mean_ctrl = control.mean()\n",
    "        se_ctrl = sem(control) if len(control) > 1 else np.nan\n",
    "\n",
    "        # Cohen's d (unadjusted)\n",
    "        pooled_sd = np.sqrt(((treated.std() ** 2) + (control.std() ** 2)) / 2)\n",
    "        cohen_d = (mean_treat - mean_ctrl) / pooled_sd if pooled_sd > 0 else np.nan\n",
    "\n",
    "        # E-value (unadjusted)\n",
    "        delta = mean_treat - mean_ctrl\n",
    "        E = delta / abs(mean_ctrl) * 100 if mean_ctrl != 0 else np.nan\n",
    "\n",
    "        # Unadjusted p-value\n",
    "        try:\n",
    "            t_stat, p_val = ttest_ind(treated, control, equal_var=False, nan_policy=\"omit\")\n",
    "            rounded_p = round(p_val, 5)\n",
    "            formatted_p = \"< 0.00001\" if rounded_p < 0.00001 else rounded_p\n",
    "        except Exception:\n",
    "            formatted_p = np.nan\n",
    "\n",
    "        # AUC from new auc_scores.xlsx file\n",
    "        auc_val = np.nan\n",
    "        auc_path = os.path.join(group_path, auc_file)\n",
    "        if os.path.exists(auc_path):\n",
    "            auc_df = pd.read_excel(auc_path)\n",
    "            if \"AUC\" in auc_df.columns:\n",
    "                auc_val = auc_df[\"AUC\"].dropna().mean()\n",
    "\n",
    "        # Adjusted stats from Rubin summary\n",
    "        att_row = att_df[att_df[\"group\"].str.strip().str.upper() == med.strip().upper()]\n",
    "        if not att_row.empty:\n",
    "            att = att_row.iloc[0][\"att\"]\n",
    "            att_se = att_row.iloc[0][\"se\"]\n",
    "            att_p_val = att_row.iloc[0][\"p_value\"]\n",
    "            r2 = att_row.iloc[0][\"r2\"]\n",
    "            rmse = att_row.iloc[0][\"rmse\"]\n",
    "\n",
    "            try:\n",
    "                rounded_att_p = round(float(att_p_val), 5)\n",
    "                formatted_att_p = \"< 0.00001\" if rounded_att_p < 0.00001 else rounded_att_p\n",
    "            except:\n",
    "                formatted_att_p = att_p_val\n",
    "        else:\n",
    "            att, att_se, formatted_att_p, r2, rmse = np.nan, np.nan, np.nan, np.nan, np.nan\n",
    "\n",
    "        # Append full row\n",
    "        summary_rows.append({\n",
    "            'Medication Group': med,\n",
    "            'Mean Treated': mean_treat,\n",
    "            'SE Treated': se_treat,\n",
    "            'Mean Control': mean_ctrl,\n",
    "            'SE Control': se_ctrl,\n",
    "            'Cohen d': cohen_d,\n",
    "            'E (Unadjusted)': E,\n",
    "            'n Treated': len(treated),\n",
    "            'n Control': len(control),\n",
    "            #'Unadjusted p-value': formatted_p,\n",
    "            'ATT Estimate': att,\n",
    "            'ATT SE (Robust)': att_se,\n",
    "            'ATT p-value': formatted_att_p,\n",
    "            'R²': r2,\n",
    "            'RMSE': rmse,\n",
    "            'AUC': auc_val\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error in {med}: {e}\")\n",
    "\n",
    "# ----------------------------------\n",
    "# Save final summary\n",
    "# ----------------------------------\n",
    "summary_df = pd.DataFrame(summary_rows)\n",
    "summary_df = summary_df.sort_values(\"Medication Group\")\n",
    "summary_df.to_excel(\"Final_ATT_Summary_Cat.xlsx\", index=False)\n",
    "print(\"✅ Final_ATT_Summary_Cat saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "98d3f0ff-8ebf-4379-b380-afb212a49f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ols_att_barplot_cat saved\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "# ✅ Load the final summary table\n",
    "final_df = pd.read_excel(\"Final_ATT_Summary_Cat.xlsx\")\n",
    "\n",
    "# ✅ Parse DML p-values (handle \"< 0.00001\")\n",
    "def parse_pval(p):\n",
    "    try:\n",
    "        if isinstance(p, str) and \"<\" in p:\n",
    "            return 0.000001\n",
    "        return float(p)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "final_df['ATT p-value'] = final_df['ATT p-value'].apply(parse_pval)\n",
    "\n",
    "# ✅ Plot settings\n",
    "width = 0.35\n",
    "\n",
    "# ✅ Plotting function for a single medication group\n",
    "def plot_single_group(row):\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    bars1 = ax.bar(-width/2, row['Mean Control'], width, \n",
    "                   yerr=row['SE Control'], label='Control', hatch='//', color='gray', capsize=5)\n",
    "    bars2 = ax.bar(+width/2, row['Mean Treated'], width, \n",
    "                   yerr=row['SE Treated'], label='Treated', color='steelblue', capsize=5)\n",
    "\n",
    "    label = (\n",
    "        f\"ATT = {row['ATT Estimate']:.2f}\\n\"\n",
    "        f\"d = {row['Cohen d']:.2f}, p = {row['ATT p-value']:.3f}\\n\"\n",
    "        f\"nT = {row['n Treated']}, nC = {row['n Control']}\\n\"\n",
    "        f\"E = {row['E (Unadjusted)']:.1f}%\"\n",
    "    )\n",
    "    max_y = max(row['Mean Control'], row['Mean Treated']) + 1.5\n",
    "    ax.text(0, max_y, label, ha='center', va='bottom', fontsize=9, color='#FFD700')\n",
    "\n",
    "    ax.axhline(0, color='black', linewidth=0.8)\n",
    "    ax.set_xticks([-width/2, +width/2])\n",
    "    ax.set_xticklabels(['Control', 'Treated'])\n",
    "    ax.set_title(f\"Group: {row['Medication Group']}\", fontsize=12, weight='bold')\n",
    "    ax.set_ylabel(\"CAPS5 Change Score\")\n",
    "    ax.set_ylim(bottom=0, top=max_y + 2)\n",
    "    ax.legend()\n",
    "    fig.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# ✅ Generate and save all plots into a multi-page PDF\n",
    "with PdfPages(\"ols_att_barplot_cat.pdf\") as pdf:\n",
    "    for idx, row in final_df.iterrows():\n",
    "        fig = plot_single_group(row)\n",
    "        pdf.savefig(fig, dpi=300, bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "print(\"✅ ols_att_barplot_cat saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "a3e741d8-2d5c-4c48-997c-a50d1f651061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Love plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "47b4d0de-9bff-4bf7-a497-ead963faa064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Processing CAT_Aceetanilidederivaten...\n",
      "📊 Exported numeric summary to: outputs\\CAT_Aceetanilidederivaten\\covariate_balance_table_CAT_Aceetanilidederivaten.xlsx\n",
      "✅ Saved love plot: outputs\\CAT_Aceetanilidederivaten\\love_plot_CAT_Aceetanilidederivaten.pdf\n",
      "📏 Max weighted SMD for CAT_Aceetanilidederivaten: 0.599\n",
      "\n",
      "🔍 Processing CAT_Adhd...\n",
      "📊 Exported numeric summary to: outputs\\CAT_Adhd\\covariate_balance_table_CAT_Adhd.xlsx\n",
      "✅ Saved love plot: outputs\\CAT_Adhd\\love_plot_CAT_Adhd.pdf\n",
      "📏 Max weighted SMD for CAT_Adhd: 0.520\n",
      "\n",
      "🔍 Processing CAT_All...\n",
      "📊 Exported numeric summary to: outputs\\CAT_All\\covariate_balance_table_CAT_All.xlsx\n",
      "✅ Saved love plot: outputs\\CAT_All\\love_plot_CAT_All.pdf\n",
      "📏 Max weighted SMD for CAT_All: 0.076\n",
      "\n",
      "🔍 Processing CAT_All_Psychotropics...\n",
      "📊 Exported numeric summary to: outputs\\CAT_All_Psychotropics\\covariate_balance_table_CAT_All_Psychotropics.xlsx\n",
      "✅ Saved love plot: outputs\\CAT_All_Psychotropics\\love_plot_CAT_All_Psychotropics.pdf\n",
      "📏 Max weighted SMD for CAT_All_Psychotropics: 0.121\n",
      "\n",
      "🔍 Processing CAT_All_Psychotropics_Excl_Benzo...\n",
      "📊 Exported numeric summary to: outputs\\CAT_All_Psychotropics_Excl_Benzo\\covariate_balance_table_CAT_All_Psychotropics_Excl_Benzo.xlsx\n",
      "✅ Saved love plot: outputs\\CAT_All_Psychotropics_Excl_Benzo\\love_plot_CAT_All_Psychotropics_Excl_Benzo.pdf\n",
      "📏 Max weighted SMD for CAT_All_Psychotropics_Excl_Benzo: 0.157\n",
      "\n",
      "🔍 Processing CAT_All_Psychotropics_Excl_Sedatives_Hypnotics...\n",
      "📊 Exported numeric summary to: outputs\\CAT_All_Psychotropics_Excl_Sedatives_Hypnotics\\covariate_balance_table_CAT_All_Psychotropics_Excl_Sedatives_Hypnotics.xlsx\n",
      "✅ Saved love plot: outputs\\CAT_All_Psychotropics_Excl_Sedatives_Hypnotics\\love_plot_CAT_All_Psychotropics_Excl_Sedatives_Hypnotics.pdf\n",
      "📏 Max weighted SMD for CAT_All_Psychotropics_Excl_Sedatives_Hypnotics: 0.158\n",
      "\n",
      "🔍 Processing CAT_Antidepressiva...\n",
      "📊 Exported numeric summary to: outputs\\CAT_Antidepressiva\\covariate_balance_table_CAT_Antidepressiva.xlsx\n",
      "✅ Saved love plot: outputs\\CAT_Antidepressiva\\love_plot_CAT_Antidepressiva.pdf\n",
      "📏 Max weighted SMD for CAT_Antidepressiva: 0.205\n",
      "\n",
      "🔍 Processing CAT_Antihistaminica...\n",
      "📊 Exported numeric summary to: outputs\\CAT_Antihistaminica\\covariate_balance_table_CAT_Antihistaminica.xlsx\n",
      "✅ Saved love plot: outputs\\CAT_Antihistaminica\\love_plot_CAT_Antihistaminica.pdf\n",
      "📏 Max weighted SMD for CAT_Antihistaminica: 0.535\n",
      "\n",
      "🔍 Processing CAT_Antihypertensiva...\n",
      "📊 Exported numeric summary to: outputs\\CAT_Antihypertensiva\\covariate_balance_table_CAT_Antihypertensiva.xlsx\n",
      "✅ Saved love plot: outputs\\CAT_Antihypertensiva\\love_plot_CAT_Antihypertensiva.pdf\n",
      "📏 Max weighted SMD for CAT_Antihypertensiva: 0.629\n",
      "\n",
      "🔍 Processing CAT_Antipsychotica...\n",
      "📊 Exported numeric summary to: outputs\\CAT_Antipsychotica\\covariate_balance_table_CAT_Antipsychotica.xlsx\n",
      "✅ Saved love plot: outputs\\CAT_Antipsychotica\\love_plot_CAT_Antipsychotica.pdf\n",
      "📏 Max weighted SMD for CAT_Antipsychotica: 0.145\n",
      "\n",
      "🔍 Processing CAT_Anti_Epileptica...\n",
      "📊 Exported numeric summary to: outputs\\CAT_Anti_Epileptica\\covariate_balance_table_CAT_Anti_Epileptica.xlsx\n",
      "✅ Saved love plot: outputs\\CAT_Anti_Epileptica\\love_plot_CAT_Anti_Epileptica.pdf\n",
      "📏 Max weighted SMD for CAT_Anti_Epileptica: 0.194\n",
      "\n",
      "🔍 Processing CAT_Benzodiazepine...\n",
      "📊 Exported numeric summary to: outputs\\CAT_Benzodiazepine\\covariate_balance_table_CAT_Benzodiazepine.xlsx\n",
      "✅ Saved love plot: outputs\\CAT_Benzodiazepine\\love_plot_CAT_Benzodiazepine.pdf\n",
      "📏 Max weighted SMD for CAT_Benzodiazepine: 0.126\n",
      "\n",
      "🔍 Processing CAT_Nsaids...\n",
      "📊 Exported numeric summary to: outputs\\CAT_Nsaids\\covariate_balance_table_CAT_Nsaids.xlsx\n",
      "✅ Saved love plot: outputs\\CAT_Nsaids\\love_plot_CAT_Nsaids.pdf\n",
      "📏 Max weighted SMD for CAT_Nsaids: 0.647\n",
      "\n",
      "🔍 Processing CAT_Opioden...\n",
      "📊 Exported numeric summary to: outputs\\CAT_Opioden\\covariate_balance_table_CAT_Opioden.xlsx\n",
      "✅ Saved love plot: outputs\\CAT_Opioden\\love_plot_CAT_Opioden.pdf\n",
      "📏 Max weighted SMD for CAT_Opioden: 0.315\n",
      "\n",
      "🔍 Processing CAT_Z_Drugs...\n",
      "📊 Exported numeric summary to: outputs\\CAT_Z_Drugs\\covariate_balance_table_CAT_Z_Drugs.xlsx\n",
      "✅ Saved love plot: outputs\\CAT_Z_Drugs\\love_plot_CAT_Z_Drugs.pdf\n",
      "📏 Max weighted SMD for CAT_Z_Drugs: 0.259\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "# ----------------------------------------\n",
    "# Functions to calculate balance\n",
    "# ----------------------------------------\n",
    "def calculate_smd(x1, x2, w1=None, w2=None):\n",
    "    def weighted_mean(x, w): return np.average(x, weights=w)\n",
    "    def weighted_var(x, w):\n",
    "        m = np.average(x, weights=w)\n",
    "        return np.average((x - m) ** 2, weights=w)\n",
    "    \n",
    "    m1 = weighted_mean(x1, w1) if w1 is not None else np.mean(x1)\n",
    "    m2 = weighted_mean(x2, w2) if w2 is not None else np.mean(x2)\n",
    "    v1 = weighted_var(x1, w1) if w1 is not None else np.var(x1, ddof=1)\n",
    "    v2 = weighted_var(x2, w2) if w2 is not None else np.var(x2, ddof=1)\n",
    "    \n",
    "    pooled_sd = np.sqrt((v1 + v2) / 2)\n",
    "    return np.abs(m1 - m2) / pooled_sd if pooled_sd > 0 else 0\n",
    "\n",
    "def variance_ratio(x1, x2, w1=None, w2=None):\n",
    "    def weighted_var(x, w):\n",
    "        m = np.average(x, weights=w)\n",
    "        return np.average((x - m) ** 2, weights=w)\n",
    "    \n",
    "    v1 = weighted_var(x1, w1) if w1 is not None else np.var(x1, ddof=1)\n",
    "    v2 = weighted_var(x2, w2) if w2 is not None else np.var(x2, ddof=1)\n",
    "    \n",
    "    return max(v1 / v2, v2 / v1) if v1 > 0 and v2 > 0 else 1\n",
    "\n",
    "# ----------------------------------------\n",
    "# Setup\n",
    "# ----------------------------------------\n",
    "output_base = \"outputs\"\n",
    "groups = [g for g in os.listdir(output_base) if os.path.isdir(os.path.join(output_base, g))]\n",
    "\n",
    "# Create a case-insensitive mapping\n",
    "final_covariates_map_lower = {k.lower(): v for k, v in final_covariates_map.items()}\n",
    "\n",
    "# ----------------------------------------\n",
    "# Main Loop\n",
    "# ----------------------------------------\n",
    "for group in groups:\n",
    "    if group.lower() not in final_covariates_map_lower:\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n🔍 Processing {group}...\")\n",
    "\n",
    "    try:\n",
    "        group_path = os.path.join(output_base, group)\n",
    "        covariates = final_covariates_map_lower[group.lower()]\n",
    "        \n",
    "        column_name = None\n",
    "        for col in pd.read_pickle(os.path.join(group_path, \"trimmed_data_imp1.pkl\")).columns:\n",
    "            if col.lower() == group.lower():\n",
    "                column_name = col\n",
    "                break\n",
    "        if column_name is None:\n",
    "            print(f\"⚠️ Column not found for {group}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        smd_unw_all, smd_w_all = [], []\n",
    "        vr_unw_all, vr_w_all = [], []\n",
    "\n",
    "        for i in range(1, 6):\n",
    "            df_path = os.path.join(group_path, f\"trimmed_data_imp{i}.pkl\")\n",
    "            iptw_path = os.path.join(group_path, \"iptw_weights.xlsx\")\n",
    "\n",
    "            if not os.path.exists(df_path) or not os.path.exists(iptw_path):\n",
    "                print(f\"⚠️ Missing data for {group} imp{i}, skipping.\")\n",
    "                continue\n",
    "\n",
    "            df = pd.read_pickle(df_path)\n",
    "            iptw_df = pd.read_excel(iptw_path, index_col=0)\n",
    "            T = df[column_name]\n",
    "            W = iptw_df.loc[df.index, \"iptw_mean\"]\n",
    "\n",
    "            smd_unw_i, smd_w_i, vr_unw_i, vr_w_i = [], [], [], []\n",
    "\n",
    "            for cov in covariates:\n",
    "                x1, x0 = df.loc[T == 1, cov], df.loc[T == 0, cov]\n",
    "                w1, w0 = W[T == 1], W[T == 0]\n",
    "\n",
    "                su = calculate_smd(x1, x0)\n",
    "                sw = calculate_smd(x1, x0, w1, w0)\n",
    "\n",
    "                vu = variance_ratio(x1, x0) if cov in ['treatmentdurationdays', 'CAPS5score_baseline', 'age'] else np.nan\n",
    "                vw = variance_ratio(x1, x0, w1, w0) if cov in ['treatmentdurationdays', 'CAPS5score_baseline', 'age'] else np.nan\n",
    "\n",
    "                smd_unw_i.append(su)\n",
    "                smd_w_i.append(sw)\n",
    "                vr_unw_i.append(vu)\n",
    "                vr_w_i.append(vw)\n",
    "\n",
    "            smd_unw_all.append(smd_unw_i)\n",
    "            smd_w_all.append(smd_w_i)\n",
    "            vr_unw_all.append(vr_unw_i)\n",
    "            vr_w_all.append(vr_w_i)\n",
    "\n",
    "        smd_unw = np.mean(smd_unw_all, axis=0)\n",
    "        smd_w = np.mean(smd_w_all, axis=0)\n",
    "        vr_unw = np.nanmean(vr_unw_all, axis=0)\n",
    "        vr_w = np.nanmean(vr_w_all, axis=0)\n",
    "\n",
    "        severity = []\n",
    "        for sw in smd_w:\n",
    "            if sw <= 0.1:\n",
    "                severity.append(\"Good\")\n",
    "            elif sw <= 0.2:\n",
    "                severity.append(\"Moderate\")\n",
    "            else:\n",
    "                severity.append(\"Poor\")\n",
    "\n",
    "        covariate_names = covariates\n",
    "        numeric_df = pd.DataFrame({\n",
    "            \"Covariate\": covariate_names,\n",
    "            \"SMD_Unweighted\": smd_unw,\n",
    "            \"SMD_Weighted\": smd_w,\n",
    "            \"Imbalance_Severity\": severity,\n",
    "            \"VR_Unweighted\": vr_unw,\n",
    "            \"VR_Weighted\": vr_w\n",
    "        })\n",
    "\n",
    "        numeric_path = os.path.join(group_path, f\"covariate_balance_table_{group}.xlsx\")\n",
    "        numeric_df.to_excel(numeric_path, index=False)\n",
    "        print(f\"📊 Exported numeric summary to: {numeric_path}\")\n",
    "\n",
    "        # -------------------------\n",
    "        # Plot\n",
    "        # -------------------------\n",
    "        labels = covariates\n",
    "        y_pos = np.arange(len(labels))\n",
    "\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(18, len(labels) * 0.45))\n",
    "\n",
    "        axes[0].scatter(smd_unw, y_pos, color='red', label=\"Unweighted\")\n",
    "        axes[0].scatter(smd_w, y_pos, color='blue', label=\"Weighted\")\n",
    "        axes[0].axvline(0.1, color='gray', linestyle='--', label=\"Threshold 0.1\")\n",
    "        axes[0].axvline(0.2, color='black', linestyle='--', label=\"Threshold 0.2\")\n",
    "        axes[0].set_xlim(0, max(max(smd_unw), max(smd_w), 0.25) + 0.05)\n",
    "        axes[0].set_yticks(y_pos)\n",
    "        axes[0].set_yticklabels(labels)\n",
    "        axes[0].invert_yaxis()\n",
    "        axes[0].set_title(\"Standardized Mean Differences (SMD)\")\n",
    "        axes[0].legend(loc=\"upper right\")\n",
    "        axes[0].grid(True)\n",
    "\n",
    "        vr_mask = [cov in ['treatmentdurationdays', 'CAPS5score_baseline', 'age'] for cov in covariates]\n",
    "        filtered_y = [i for i, b in enumerate(vr_mask) if b]\n",
    "        filtered_labels = [labels[i] for i in filtered_y]\n",
    "        filtered_vr_unw = [vr_unw[i] for i in filtered_y]\n",
    "        filtered_vr_w = [vr_w[i] for i in filtered_y]\n",
    "\n",
    "        axes[1].scatter(filtered_vr_unw, filtered_y, color='blue', marker='o', label=\"Unweighted\")\n",
    "        axes[1].scatter(filtered_vr_w, filtered_y, color='red', marker='x', label=\"Weighted\")\n",
    "        axes[1].axvline(2, color='gray', linestyle='--')\n",
    "        axes[1].axvline(0.5, color='gray', linestyle='--')\n",
    "        axes[1].set_xlim(0, max(filtered_vr_unw + filtered_vr_w + [2.5]) + 0.5)\n",
    "        axes[1].set_yticks(filtered_y)\n",
    "        axes[1].set_yticklabels(filtered_labels)\n",
    "        axes[1].invert_yaxis()\n",
    "        axes[1].set_title(\"Variance Ratio (VR)\")\n",
    "        axes[1].legend()\n",
    "        axes[1].grid(True)\n",
    "\n",
    "        fig.suptitle(f\"Covariate Balance for {group.replace('CAT_', '')}\", fontsize=14, weight='bold')\n",
    "        fig.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "        plot_path = os.path.join(group_path, f\"love_plot_{group}.pdf\")\n",
    "        fig.savefig(plot_path, dpi=300)\n",
    "        plt.close()\n",
    "        print(f\"✅ Saved love plot: {plot_path}\")\n",
    "        print(f\"📏 Max weighted SMD for {group}: {np.max(smd_w):.3f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error in {group}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "70cac837-729f-49b1-b10d-d0ef9c0992a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "fbcc8601-6f31-421d-bdf4-6da70b6d6101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Creating Heatmap for CAT_ADHD ==========\n",
      "✅ Heatmap saved: outputs\\CAT_ADHD\\heatmap_smd_CAT_ADHD.png\n",
      "\n",
      "========== Creating Heatmap for CAT_Aceetanilidederivaten ==========\n",
      "✅ Heatmap saved: outputs\\CAT_Aceetanilidederivaten\\heatmap_smd_CAT_Aceetanilidederivaten.png\n",
      "\n",
      "========== Creating Heatmap for CAT_Z_drugs ==========\n",
      "✅ Heatmap saved: outputs\\CAT_Z_drugs\\heatmap_smd_CAT_Z_drugs.png\n",
      "\n",
      "========== Creating Heatmap for CAT_Opioden ==========\n",
      "✅ Heatmap saved: outputs\\CAT_Opioden\\heatmap_smd_CAT_Opioden.png\n",
      "\n",
      "========== Creating Heatmap for CAT_NSAIDs ==========\n",
      "✅ Heatmap saved: outputs\\CAT_NSAIDs\\heatmap_smd_CAT_NSAIDs.png\n",
      "\n",
      "========== Creating Heatmap for CAT_Benzodiazepine ==========\n",
      "✅ Heatmap saved: outputs\\CAT_Benzodiazepine\\heatmap_smd_CAT_Benzodiazepine.png\n",
      "\n",
      "========== Creating Heatmap for CAT_Antihypertensiva ==========\n",
      "✅ Heatmap saved: outputs\\CAT_Antihypertensiva\\heatmap_smd_CAT_Antihypertensiva.png\n",
      "\n",
      "========== Creating Heatmap for CAT_Antihistaminica ==========\n",
      "✅ Heatmap saved: outputs\\CAT_Antihistaminica\\heatmap_smd_CAT_Antihistaminica.png\n",
      "\n",
      "========== Creating Heatmap for CAT_Anti_epileptica ==========\n",
      "✅ Heatmap saved: outputs\\CAT_Anti_epileptica\\heatmap_smd_CAT_Anti_epileptica.png\n",
      "\n",
      "========== Creating Heatmap for CAT_Antidepressiva ==========\n",
      "✅ Heatmap saved: outputs\\CAT_Antidepressiva\\heatmap_smd_CAT_Antidepressiva.png\n",
      "\n",
      "========== Creating Heatmap for CAT_Antipsychotica ==========\n",
      "✅ Heatmap saved: outputs\\CAT_Antipsychotica\\heatmap_smd_CAT_Antipsychotica.png\n",
      "\n",
      "========== Creating Heatmap for CAT_ALL_PSYCHOTROPICS_EXCL_BENZO ==========\n",
      "✅ Heatmap saved: outputs\\CAT_ALL_PSYCHOTROPICS_EXCL_BENZO\\heatmap_smd_CAT_ALL_PSYCHOTROPICS_EXCL_BENZO.png\n",
      "\n",
      "========== Creating Heatmap for CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS ==========\n",
      "✅ Heatmap saved: outputs\\CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS\\heatmap_smd_CAT_ALL_PSYCHOTROPICS_EXCL_SEDATIVES_HYPNOTICS.png\n",
      "\n",
      "========== Creating Heatmap for CAT_ALL_PSYCHOTROPICS ==========\n",
      "✅ Heatmap saved: outputs\\CAT_ALL_PSYCHOTROPICS\\heatmap_smd_CAT_ALL_PSYCHOTROPICS.png\n",
      "\n",
      "========== Creating Heatmap for CAT_ALL ==========\n",
      "✅ Heatmap saved: outputs\\CAT_ALL\\heatmap_smd_CAT_ALL.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "#-----------------------------\n",
    "# Generate heatmaps\n",
    "# -------------------------------\n",
    "for treatment_var in medication_groups:\n",
    "    print(f\"\\n========== Creating Heatmap for {treatment_var} ==========\")\n",
    "\n",
    "    try:\n",
    "        output_folder = os.path.join('outputs', treatment_var)\n",
    "        balance_path = os.path.join(output_folder, f'covariate_balance_table_{treatment_var}.xlsx')\n",
    "\n",
    "        if not os.path.exists(balance_path):\n",
    "            print(f\"❌ Balance file not found: {balance_path}\")\n",
    "            continue\n",
    "\n",
    "        balance_df = pd.read_excel(balance_path)\n",
    "\n",
    "        # ✅ Use finalized covariates + 'Propensity Score'\n",
    "        covariates = final_covariates_map[treatment_var] + ['Propensity Score']\n",
    "        balance_df = balance_df[balance_df['Covariate'].isin(covariates)]\n",
    "\n",
    "        # ✅ Check for CAPS5score_baseline\n",
    "        highlight_caps = 'CAPS5score_baseline' in balance_df['Covariate'].values\n",
    "\n",
    "        # ✅ Format for heatmap\n",
    "        heatmap_df = balance_df[['Covariate', 'SMD_Unweighted', 'SMD_Weighted']].copy()\n",
    "        heatmap_df.columns = ['Covariate', 'Unweighted', 'Weighted']\n",
    "        heatmap_df = heatmap_df.set_index('Covariate')\n",
    "        heatmap_df = heatmap_df.sort_values(by='Unweighted', ascending=False)\n",
    "\n",
    "        # ✅ Plot\n",
    "        plt.figure(figsize=(12, max(10, len(heatmap_df) * 0.35)))\n",
    "        ax = sns.heatmap(\n",
    "            heatmap_df,\n",
    "            cmap=\"coolwarm\",\n",
    "            annot=True,\n",
    "            fmt=\".2f\",\n",
    "            linewidths=0.6,\n",
    "            linecolor='gray',\n",
    "            cbar_kws={\"label\": \"Standardized Mean Difference\"}\n",
    "        )\n",
    "\n",
    "        plt.title(f\"Covariate Balance Heatmap (Rubin IPTW)\\n{treatment_var}\", fontsize=15, weight='bold')\n",
    "        plt.xlabel(\"Condition\")\n",
    "        plt.ylabel(\"Covariate\")\n",
    "\n",
    "        # ✅ Bold CAPS5score_baseline if present\n",
    "        if highlight_caps:\n",
    "            ylabels = [label.get_text() for label in ax.get_yticklabels()]\n",
    "            ax.set_yticklabels([\n",
    "                f\"{label} ←\" if label == 'CAPS5score_baseline' else label for label in ylabels\n",
    "            ])\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # ✅ Save image\n",
    "        save_path = os.path.join(output_folder, f'heatmap_smd_{treatment_var}.png')\n",
    "        plt.savefig(save_path, dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "        print(f\"✅ Heatmap saved: {save_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error processing {treatment_var}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f20d353-a1a6-41d1-a07e-d83cd907131e",
   "metadata": {},
   "source": [
    "### Subcat analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "74cf789e-8d11-46b8-9fc6-4c93ac6375d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "covariates_SUBCAT_Antipsychotica_atypisch = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antidepressiva', 'CAT_Antipsychotica',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "covariates_SUBCAT_TCA = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antipsychotica',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "covariates_SUBCAT_SSRI = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antipsychotica',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "covariates_SUBCAT_SNRI = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antipsychotica',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "\n",
    "covariates_SUBCAT_Tetracyclische_antidepressiva = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antipsychotica',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "covariates_SUBCAT_Antidepressiva_overige = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antipsychotica',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "covariates_SUBCAT_Systemische_antihistaminica = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antidepressiva', 'CAT_Antipsychotica',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "\n",
    "covariates_SUBCAT_anxiolytica_Benzodiazepine = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antidepressiva',\n",
    "    'CAT_Antipsychotica',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "covariates_SUBCAT_hypnotica_Benzodiazepine = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antidepressiva',\n",
    "    'CAT_Antipsychotica',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "\n",
    "covariates_SUBCAT_Amfetaminen = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline', 'CAT_Antidepressiva', 'CAT_Antipsychotica',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD',\n",
    "    'DIAGNOSIS_SEXUAL_TRAUMA', 'DIAGNOSIS_SUICIDALITY',\n",
    "    'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "\n",
    "covariates_SUBCAT_Paracetamol_mono = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antidepressiva', 'CAT_Antipsychotica',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "\n",
    "covariates_SUBCAT_Anti_epileptica_stemmingsstabilisatoren = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antidepressiva',\n",
    "    'CAT_Antipsychotica',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age', \n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "covariates_SUBCAT_Opioden = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antidepressiva',\n",
    "    'CAT_Antipsychotica',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "covariates_SUBCAT_Z_drugs = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antidepressiva', 'CAT_Antipsychotica',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "covariates_SUBCAT_NSAIDs = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antidepressiva',\n",
    "    'CAT_Antipsychotica',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "0a20737a-265c-405f-ad41-e29a7dca8e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groups found: ['SUBCAT_Antipsychotica_atypisch', 'SUBCAT_TCA', 'SUBCAT_SSRI', 'SUBCAT_SNRI', 'SUBCAT_Tetracyclische_antidepressiva', 'SUBCAT_Antidepressiva_overige', 'SUBCAT_Systemische_antihistaminica', 'SUBCAT_anxiolytica_Benzodiazepine', 'SUBCAT_hypnotica_Benzodiazepine', 'SUBCAT_Amfetaminen', 'SUBCAT_Paracetamol_mono', 'SUBCAT_Anti_epileptica_stemmingsstabilisatoren', 'SUBCAT_Opioden', 'SUBCAT_Z_drugs', 'SUBCAT_NSAIDs']\n",
      "['SUBCAT_Antipsychotica_atypisch', 'SUBCAT_TCA', 'SUBCAT_SSRI', 'SUBCAT_SNRI', 'SUBCAT_Tetracyclische_antidepressiva', 'SUBCAT_Antidepressiva_overige', 'SUBCAT_Systemische_antihistaminica', 'SUBCAT_anxiolytica_Benzodiazepine', 'SUBCAT_hypnotica_Benzodiazepine', 'SUBCAT_Amfetaminen', 'SUBCAT_Paracetamol_mono', 'SUBCAT_Anti_epileptica_stemmingsstabilisatoren', 'SUBCAT_Opioden', 'SUBCAT_Z_drugs', 'SUBCAT_NSAIDs']\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# This finds all variables that start with covariates_SUBCAT_\n",
    "final_covariates_map = defaultdict(list)\n",
    "final_covariates_map.update({\n",
    "    var.replace(\"covariates_\", \"\"): val\n",
    "    for var, val in globals().items()\n",
    "    if var.lower().startswith(\"covariates_subcat_\") and isinstance(val, list)\n",
    "})\n",
    "\n",
    "# Show detected group names\n",
    "print(\"Groups found:\", list(final_covariates_map.keys()))\n",
    "medication_groups = list(final_covariates_map.keys())\n",
    "print(medication_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "0c5d1b8a-3cb1-4a30-af1a-a414bccd3b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Starting analysis for all SUBCAT groups\n",
      "\n",
      " Processing SUBCAT_Antipsychotica_Atypisch...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBCAT_Antipsychotica_Atypisch\n",
      "\n",
      " Processing SUBCAT_Tca...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBCAT_Tca\n",
      "\n",
      " Processing SUBCAT_Ssri...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBCAT_Ssri\n",
      "\n",
      " Processing SUBCAT_Snri...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBCAT_Snri\n",
      "\n",
      " Processing SUBCAT_Tetracyclische_Antidepressiva...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBCAT_Tetracyclische_Antidepressiva\n",
      "\n",
      " Processing SUBCAT_Antidepressiva_Overige...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBCAT_Antidepressiva_Overige\n",
      "\n",
      " Processing SUBCAT_Systemische_Antihistaminica...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBCAT_Systemische_Antihistaminica\n",
      "\n",
      " Processing SUBCAT_Anxiolytica_Benzodiazepine...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBCAT_Anxiolytica_Benzodiazepine\n",
      "\n",
      " Processing SUBCAT_Hypnotica_Benzodiazepine...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBCAT_Hypnotica_Benzodiazepine\n",
      "\n",
      " Processing SUBCAT_Amfetaminen...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBCAT_Amfetaminen\n",
      "\n",
      " Processing SUBCAT_Paracetamol_Mono...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBCAT_Paracetamol_Mono\n",
      "\n",
      " Processing SUBCAT_Anti_Epileptica_Stemmingsstabilisatoren...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBCAT_Anti_Epileptica_Stemmingsstabilisatoren\n",
      "\n",
      " Processing SUBCAT_Opioden...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBCAT_Opioden\n",
      "\n",
      " Processing SUBCAT_Z_Drugs...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBCAT_Z_Drugs\n",
      "\n",
      " Processing SUBCAT_Nsaids...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBCAT_Nsaids\n",
      "\n",
      " All SUBCAT group analyses complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def run_all_SUBCAT_group_models(imputed_dfs):\n",
    "    \"\"\"\n",
    "    Runs downstream analysis for each SUBCAT medisubcation group using imputed datasets.\n",
    "\n",
    "    Parameters:\n",
    "    - imputed_dfs: list of 5 imputed DataFrames (from df_imputed_final_imp1.pkl ... imp5.pkl)\n",
    "    \n",
    "    Notes:\n",
    "    - Covariate lists must be defined as global variables: covariates_subcat_<group>\n",
    "    - Outputs are saved in: outputs/SUBCAT_<GROUP>/\n",
    "    \"\"\"\n",
    "\n",
    "    print(\" Starting analysis for all SUBCAT groups\")\n",
    "\n",
    "    for var_name in globals():\n",
    "        if var_name.lower().startswith(\"covariates_subcat_\") and isinstance(globals()[var_name], list):\n",
    "            group_name = var_name.replace(\"covariates_\", \"\")\n",
    "            group_name = group_name.replace(\"_\", \" \").title().replace(\" \", \"_\")  # e.g., subcat_z_drugs → Subcat_Z_Drugs\n",
    "            group_name = group_name.replace(\"Subcat_\", \"SUBCAT_\")  # force prefix to uppercase\n",
    "\n",
    "            covariates = globals()[var_name]\n",
    "            output_dir = f\"outputs/{group_name}\"\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "            print(f\"\\n Processing {group_name}...\")\n",
    "\n",
    "            for k, df_imp in enumerate(imputed_dfs):\n",
    "                print(f\"  → Using imputation {k+1}\")\n",
    "\n",
    "                # Define X and Y\n",
    "                X = df_imp[covariates]\n",
    "                Y = df_imp[\"caps5_change_baseline\"]\n",
    "\n",
    "                # === Save X and Y as placeholder (replace with modeling later)\n",
    "                X.to_csv(f\"{output_dir}/X_imp{k+1}.csv\", index=False)\n",
    "                Y.to_frame(name=\"Y\").to_csv(f\"{output_dir}/Y_imp{k+1}.csv\", index=False)\n",
    "\n",
    "            print(f\" Done: {group_name}\")\n",
    "\n",
    "    print(\"\\n All SUBCAT group analyses complete.\")\n",
    "\n",
    "# ========= STEP 4: Execute ========= #\n",
    "run_all_SUBCAT_group_models(imputed_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "675d93ec-45cf-4e6d-ae5e-c44c514bf83d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " SUBCAT_Antipsychotica_atypisch\n",
      "  Imp 1: Treated = 256, Control = 3385, Missing = 0\n",
      "  Imp 2: Treated = 256, Control = 3385, Missing = 0\n",
      "  Imp 3: Treated = 256, Control = 3385, Missing = 0\n",
      "  Imp 4: Treated = 256, Control = 3385, Missing = 0\n",
      "  Imp 5: Treated = 256, Control = 3385, Missing = 0\n",
      "\n",
      " SUBCAT_TCA\n",
      "  Imp 1: Treated = 86, Control = 3555, Missing = 0\n",
      "  Imp 2: Treated = 86, Control = 3555, Missing = 0\n",
      "  Imp 3: Treated = 86, Control = 3555, Missing = 0\n",
      "  Imp 4: Treated = 86, Control = 3555, Missing = 0\n",
      "  Imp 5: Treated = 86, Control = 3555, Missing = 0\n",
      "\n",
      " SUBCAT_SSRI\n",
      "  Imp 1: Treated = 396, Control = 3245, Missing = 0\n",
      "  Imp 2: Treated = 396, Control = 3245, Missing = 0\n",
      "  Imp 3: Treated = 396, Control = 3245, Missing = 0\n",
      "  Imp 4: Treated = 396, Control = 3245, Missing = 0\n",
      "  Imp 5: Treated = 396, Control = 3245, Missing = 0\n",
      "\n",
      " SUBCAT_SNRI\n",
      "  Imp 1: Treated = 82, Control = 3559, Missing = 0\n",
      "  Imp 2: Treated = 82, Control = 3559, Missing = 0\n",
      "  Imp 3: Treated = 82, Control = 3559, Missing = 0\n",
      "  Imp 4: Treated = 82, Control = 3559, Missing = 0\n",
      "  Imp 5: Treated = 82, Control = 3559, Missing = 0\n",
      "\n",
      " SUBCAT_Tetracyclische_antidepressiva\n",
      "  Imp 1: Treated = 87, Control = 3554, Missing = 0\n",
      "  Imp 2: Treated = 87, Control = 3554, Missing = 0\n",
      "  Imp 3: Treated = 87, Control = 3554, Missing = 0\n",
      "  Imp 4: Treated = 87, Control = 3554, Missing = 0\n",
      "  Imp 5: Treated = 87, Control = 3554, Missing = 0\n",
      "\n",
      " SUBCAT_Antidepressiva_overige\n",
      "  Imp 1: Treated = 42, Control = 3599, Missing = 0\n",
      "  Imp 2: Treated = 42, Control = 3599, Missing = 0\n",
      "  Imp 3: Treated = 42, Control = 3599, Missing = 0\n",
      "  Imp 4: Treated = 42, Control = 3599, Missing = 0\n",
      "  Imp 5: Treated = 42, Control = 3599, Missing = 0\n",
      "\n",
      " SUBCAT_Systemische_antihistaminica\n",
      "  Imp 1: Treated = 56, Control = 3585, Missing = 0\n",
      "  Imp 2: Treated = 56, Control = 3585, Missing = 0\n",
      "  Imp 3: Treated = 56, Control = 3585, Missing = 0\n",
      "  Imp 4: Treated = 56, Control = 3585, Missing = 0\n",
      "  Imp 5: Treated = 56, Control = 3585, Missing = 0\n",
      "\n",
      " SUBCAT_anxiolytica_Benzodiazepine\n",
      "  Imp 1: Treated = 311, Control = 3330, Missing = 0\n",
      "  Imp 2: Treated = 311, Control = 3330, Missing = 0\n",
      "  Imp 3: Treated = 311, Control = 3330, Missing = 0\n",
      "  Imp 4: Treated = 311, Control = 3330, Missing = 0\n",
      "  Imp 5: Treated = 311, Control = 3330, Missing = 0\n",
      "\n",
      " SUBCAT_hypnotica_Benzodiazepine\n",
      "  Imp 1: Treated = 132, Control = 3509, Missing = 0\n",
      "  Imp 2: Treated = 132, Control = 3509, Missing = 0\n",
      "  Imp 3: Treated = 132, Control = 3509, Missing = 0\n",
      "  Imp 4: Treated = 132, Control = 3509, Missing = 0\n",
      "  Imp 5: Treated = 132, Control = 3509, Missing = 0\n",
      "\n",
      " SUBCAT_Amfetaminen\n",
      "  Imp 1: Treated = 52, Control = 3589, Missing = 0\n",
      "  Imp 2: Treated = 52, Control = 3589, Missing = 0\n",
      "  Imp 3: Treated = 52, Control = 3589, Missing = 0\n",
      "  Imp 4: Treated = 52, Control = 3589, Missing = 0\n",
      "  Imp 5: Treated = 52, Control = 3589, Missing = 0\n",
      "\n",
      " SUBCAT_Paracetamol_mono\n",
      "  Imp 1: Treated = 43, Control = 3598, Missing = 0\n",
      "  Imp 2: Treated = 43, Control = 3598, Missing = 0\n",
      "  Imp 3: Treated = 43, Control = 3598, Missing = 0\n",
      "  Imp 4: Treated = 43, Control = 3598, Missing = 0\n",
      "  Imp 5: Treated = 43, Control = 3598, Missing = 0\n",
      "\n",
      " SUBCAT_Anti_epileptica_stemmingsstabilisatoren\n",
      "  Imp 1: Treated = 57, Control = 3584, Missing = 0\n",
      "  Imp 2: Treated = 57, Control = 3584, Missing = 0\n",
      "  Imp 3: Treated = 57, Control = 3584, Missing = 0\n",
      "  Imp 4: Treated = 57, Control = 3584, Missing = 0\n",
      "  Imp 5: Treated = 57, Control = 3584, Missing = 0\n",
      "\n",
      " SUBCAT_Opioden\n",
      "  Imp 1: Treated = 54, Control = 3587, Missing = 0\n",
      "  Imp 2: Treated = 54, Control = 3587, Missing = 0\n",
      "  Imp 3: Treated = 54, Control = 3587, Missing = 0\n",
      "  Imp 4: Treated = 54, Control = 3587, Missing = 0\n",
      "  Imp 5: Treated = 54, Control = 3587, Missing = 0\n",
      "\n",
      " SUBCAT_Z_drugs\n",
      "  Imp 1: Treated = 57, Control = 3584, Missing = 0\n",
      "  Imp 2: Treated = 57, Control = 3584, Missing = 0\n",
      "  Imp 3: Treated = 57, Control = 3584, Missing = 0\n",
      "  Imp 4: Treated = 57, Control = 3584, Missing = 0\n",
      "  Imp 5: Treated = 57, Control = 3584, Missing = 0\n",
      "\n",
      " SUBCAT_NSAIDs\n",
      "  Imp 1: Treated = 37, Control = 3604, Missing = 0\n",
      "  Imp 2: Treated = 37, Control = 3604, Missing = 0\n",
      "  Imp 3: Treated = 37, Control = 3604, Missing = 0\n",
      "  Imp 4: Treated = 37, Control = 3604, Missing = 0\n",
      "  Imp 5: Treated = 37, Control = 3604, Missing = 0\n"
     ]
    }
   ],
   "source": [
    "for treatment_var in medication_groups:\n",
    "    print(f\"\\n {treatment_var}\")\n",
    "    \n",
    "    for i, df in enumerate(imputed_dfs):\n",
    "        if treatment_var not in df.columns:\n",
    "            print(f\"  Imp {i+1}:  Not found in columns.\")\n",
    "            continue\n",
    "\n",
    "        treated = (df[treatment_var] == 1).sum()\n",
    "        control = (df[treatment_var] == 0).sum()\n",
    "        missing = df[treatment_var].isna().sum()\n",
    "\n",
    "        print(f\"  Imp {i+1}: Treated = {treated}, Control = {control}, Missing = {missing}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "56242839-e5b1-4303-b947-ddf075afb59d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Processing VIF for SUBCAT_Antipsychotica_atypisch\n",
      " ✅ Saved: outputs\\SUBCAT_Antipsychotica_atypisch/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SUBCAT_TCA\n",
      " ✅ Saved: outputs\\SUBCAT_TCA/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SUBCAT_SSRI\n",
      " ✅ Saved: outputs\\SUBCAT_SSRI/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SUBCAT_SNRI\n",
      " ✅ Saved: outputs\\SUBCAT_SNRI/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SUBCAT_Tetracyclische_antidepressiva\n",
      " ✅ Saved: outputs\\SUBCAT_Tetracyclische_antidepressiva/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SUBCAT_Antidepressiva_overige\n",
      " ✅ Saved: outputs\\SUBCAT_Antidepressiva_overige/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SUBCAT_Systemische_antihistaminica\n",
      " ✅ Saved: outputs\\SUBCAT_Systemische_antihistaminica/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SUBCAT_anxiolytica_Benzodiazepine\n",
      " ✅ Saved: outputs\\SUBCAT_anxiolytica_Benzodiazepine/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SUBCAT_hypnotica_Benzodiazepine\n",
      " ✅ Saved: outputs\\SUBCAT_hypnotica_Benzodiazepine/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SUBCAT_Amfetaminen\n",
      " ✅ Saved: outputs\\SUBCAT_Amfetaminen/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SUBCAT_Paracetamol_mono\n",
      " ✅ Saved: outputs\\SUBCAT_Paracetamol_mono/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SUBCAT_Anti_epileptica_stemmingsstabilisatoren\n",
      " ✅ Saved: outputs\\SUBCAT_Anti_epileptica_stemmingsstabilisatoren/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SUBCAT_Opioden\n",
      " ✅ Saved: outputs\\SUBCAT_Opioden/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SUBCAT_Z_drugs\n",
      " ✅ Saved: outputs\\SUBCAT_Z_drugs/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SUBCAT_NSAIDs\n",
      " ✅ Saved: outputs\\SUBCAT_NSAIDs/pooled_vif.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from collections import defaultdict\n",
    "\n",
    "# ✅ VIF computation function\n",
    "def compute_vif(X):\n",
    "    X = sm.add_constant(X, has_constant='add')\n",
    "    vif_df = pd.DataFrame()\n",
    "    vif_df[\"variable\"] = X.columns\n",
    "    vif_df[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "    return vif_df\n",
    "\n",
    "# ✅ Process each group\n",
    "for group in medication_groups:\n",
    "    print(f\"\\n🔍 Processing VIF for {group}\")\n",
    "\n",
    "    if group not in final_covariates_map:\n",
    "        print(f\" ⚠️ No covariates found for {group}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    covariates = final_covariates_map[group]\n",
    "    vif_list = []\n",
    "\n",
    "    for i, df_imp in enumerate(imputed_dfs):\n",
    "        try:\n",
    "            X = df_imp[covariates].copy()\n",
    "            vif_df = compute_vif(X)\n",
    "            vif_df[\"imputation\"] = i + 1\n",
    "            vif_list.append(vif_df)\n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ Failed on imputation {i+1} for {group}: {e}\")\n",
    "\n",
    "    if vif_list:\n",
    "        all_vif = pd.concat(vif_list)\n",
    "        pooled_vif = all_vif.groupby(\"variable\")[\"VIF\"].mean().reset_index()\n",
    "        pooled_vif = pooled_vif.sort_values(by=\"VIF\", ascending=False)\n",
    "\n",
    "        output_folder = os.path.join(\"outputs\", group)\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        pooled_vif.to_csv(os.path.join(output_folder, \"pooled_vif.csv\"), index=False)\n",
    "\n",
    "        print(f\" ✅ Saved: {output_folder}/pooled_vif.csv\")\n",
    "    else:\n",
    "        print(f\" ⚠️ Skipped {group}: No valid imputations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "ca4774b3-375f-4f4f-af16-075947427200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Running PS estimation for SUBCAT_Antipsychotica_atypisch\n",
      "   Imp 1: AUC = 0.998, ROC saved.\n",
      "   Imp 2: AUC = 0.998, ROC saved.\n",
      "   Imp 3: AUC = 0.998, ROC saved.\n",
      "   Imp 4: AUC = 0.998, ROC saved.\n",
      "   Imp 5: AUC = 0.998, ROC saved.\n",
      " Composite PS + AUC saved for SUBCAT_Antipsychotica_atypisch\n",
      " Running PS estimation for SUBCAT_TCA\n",
      "   Imp 1: AUC = 0.717, ROC saved.\n",
      "   Imp 2: AUC = 0.716, ROC saved.\n",
      "   Imp 3: AUC = 0.717, ROC saved.\n",
      "   Imp 4: AUC = 0.713, ROC saved.\n",
      "   Imp 5: AUC = 0.713, ROC saved.\n",
      " Composite PS + AUC saved for SUBCAT_TCA\n",
      " Running PS estimation for SUBCAT_SSRI\n",
      "   Imp 1: AUC = 0.769, ROC saved.\n",
      "   Imp 2: AUC = 0.770, ROC saved.\n",
      "   Imp 3: AUC = 0.768, ROC saved.\n",
      "   Imp 4: AUC = 0.770, ROC saved.\n",
      "   Imp 5: AUC = 0.767, ROC saved.\n",
      " Composite PS + AUC saved for SUBCAT_SSRI\n",
      " Running PS estimation for SUBCAT_SNRI\n",
      "   Imp 1: AUC = 0.654, ROC saved.\n",
      "   Imp 2: AUC = 0.621, ROC saved.\n",
      "   Imp 3: AUC = 0.636, ROC saved.\n",
      "   Imp 4: AUC = 0.612, ROC saved.\n",
      "   Imp 5: AUC = 0.634, ROC saved.\n",
      " Composite PS + AUC saved for SUBCAT_SNRI\n",
      " Running PS estimation for SUBCAT_Tetracyclische_antidepressiva\n",
      "   Imp 1: AUC = 0.681, ROC saved.\n",
      "   Imp 2: AUC = 0.698, ROC saved.\n",
      "   Imp 3: AUC = 0.682, ROC saved.\n",
      "   Imp 4: AUC = 0.688, ROC saved.\n",
      "   Imp 5: AUC = 0.699, ROC saved.\n",
      " Composite PS + AUC saved for SUBCAT_Tetracyclische_antidepressiva\n",
      " Running PS estimation for SUBCAT_Antidepressiva_overige\n",
      "   Imp 1: AUC = 0.561, ROC saved.\n",
      "   Imp 2: AUC = 0.646, ROC saved.\n",
      "   Imp 3: AUC = 0.629, ROC saved.\n",
      "   Imp 4: AUC = 0.601, ROC saved.\n",
      "   Imp 5: AUC = 0.632, ROC saved.\n",
      " Composite PS + AUC saved for SUBCAT_Antidepressiva_overige\n",
      " Running PS estimation for SUBCAT_Systemische_antihistaminica\n",
      "   Imp 1: AUC = 0.681, ROC saved.\n",
      "   Imp 2: AUC = 0.682, ROC saved.\n",
      "   Imp 3: AUC = 0.668, ROC saved.\n",
      "   Imp 4: AUC = 0.677, ROC saved.\n",
      "   Imp 5: AUC = 0.681, ROC saved.\n",
      " Composite PS + AUC saved for SUBCAT_Systemische_antihistaminica\n",
      " Running PS estimation for SUBCAT_anxiolytica_Benzodiazepine\n",
      "   Imp 1: AUC = 0.783, ROC saved.\n",
      "   Imp 2: AUC = 0.782, ROC saved.\n",
      "   Imp 3: AUC = 0.784, ROC saved.\n",
      "   Imp 4: AUC = 0.783, ROC saved.\n",
      "   Imp 5: AUC = 0.778, ROC saved.\n",
      " Composite PS + AUC saved for SUBCAT_anxiolytica_Benzodiazepine\n",
      " Running PS estimation for SUBCAT_hypnotica_Benzodiazepine\n",
      "   Imp 1: AUC = 0.711, ROC saved.\n",
      "   Imp 2: AUC = 0.714, ROC saved.\n",
      "   Imp 3: AUC = 0.741, ROC saved.\n",
      "   Imp 4: AUC = 0.740, ROC saved.\n",
      "   Imp 5: AUC = 0.727, ROC saved.\n",
      " Composite PS + AUC saved for SUBCAT_hypnotica_Benzodiazepine\n",
      " Running PS estimation for SUBCAT_Amfetaminen\n",
      "   Imp 1: AUC = 0.616, ROC saved.\n",
      "   Imp 2: AUC = 0.619, ROC saved.\n",
      "   Imp 3: AUC = 0.592, ROC saved.\n",
      "   Imp 4: AUC = 0.620, ROC saved.\n",
      "   Imp 5: AUC = 0.626, ROC saved.\n",
      " Composite PS + AUC saved for SUBCAT_Amfetaminen\n",
      " Running PS estimation for SUBCAT_Paracetamol_mono\n",
      "   Imp 1: AUC = 0.735, ROC saved.\n",
      "   Imp 2: AUC = 0.744, ROC saved.\n",
      "   Imp 3: AUC = 0.737, ROC saved.\n",
      "   Imp 4: AUC = 0.748, ROC saved.\n",
      "   Imp 5: AUC = 0.752, ROC saved.\n",
      " Composite PS + AUC saved for SUBCAT_Paracetamol_mono\n",
      " Running PS estimation for SUBCAT_Anti_epileptica_stemmingsstabilisatoren\n",
      "   Imp 1: AUC = 0.767, ROC saved.\n",
      "   Imp 2: AUC = 0.783, ROC saved.\n",
      "   Imp 3: AUC = 0.777, ROC saved.\n",
      "   Imp 4: AUC = 0.781, ROC saved.\n",
      "   Imp 5: AUC = 0.784, ROC saved.\n",
      " Composite PS + AUC saved for SUBCAT_Anti_epileptica_stemmingsstabilisatoren\n",
      " Running PS estimation for SUBCAT_Opioden\n",
      "   Imp 1: AUC = 0.788, ROC saved.\n",
      "   Imp 2: AUC = 0.787, ROC saved.\n",
      "   Imp 3: AUC = 0.788, ROC saved.\n",
      "   Imp 4: AUC = 0.789, ROC saved.\n",
      "   Imp 5: AUC = 0.777, ROC saved.\n",
      " Composite PS + AUC saved for SUBCAT_Opioden\n",
      " Running PS estimation for SUBCAT_Z_drugs\n",
      "   Imp 1: AUC = 0.639, ROC saved.\n",
      "   Imp 2: AUC = 0.659, ROC saved.\n",
      "   Imp 3: AUC = 0.649, ROC saved.\n",
      "   Imp 4: AUC = 0.645, ROC saved.\n",
      "   Imp 5: AUC = 0.645, ROC saved.\n",
      " Composite PS + AUC saved for SUBCAT_Z_drugs\n",
      " Running PS estimation for SUBCAT_NSAIDs\n",
      "   Imp 1: AUC = 0.748, ROC saved.\n",
      "   Imp 2: AUC = 0.738, ROC saved.\n",
      "   Imp 3: AUC = 0.717, ROC saved.\n",
      "   Imp 4: AUC = 0.767, ROC saved.\n",
      "   Imp 5: AUC = 0.757, ROC saved.\n",
      " Composite PS + AUC saved for SUBCAT_NSAIDs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ---------- PS Estimation Function ----------\n",
    "def run_logistic_ps_modeling(imputed_dfs, medication_groups, final_covariates_map):\n",
    "    for group in medication_groups:\n",
    "        print(f\" Running PS estimation for {group}\")\n",
    "\n",
    "        if group not in final_covariates_map:\n",
    "            print(f\" No covariates found for {group}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        output_folder = os.path.join(\"outputs\", group)\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "        covariates = final_covariates_map[group]\n",
    "        ps_matrix = pd.DataFrame()\n",
    "        auc_list = []\n",
    "\n",
    "        for i, df_imp in enumerate(imputed_dfs):\n",
    "            if group not in df_imp.columns:\n",
    "                print(f\" {group} not found in imputed dataset {i+1}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            X = df_imp[covariates].copy()\n",
    "            T = df_imp[group]\n",
    "\n",
    "            # Drop missing treatment rows\n",
    "            valid_idx = T.dropna().index\n",
    "            X = X.loc[valid_idx]\n",
    "            T = T.loc[valid_idx]\n",
    "\n",
    "            # Train-test split for ROC\n",
    "            X_train, X_test, T_train, T_test = train_test_split(\n",
    "                X, T, stratify=T, test_size=0.3, random_state=42\n",
    "            )\n",
    "\n",
    "            try:\n",
    "                model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "                model.fit(X_train, T_train)\n",
    "\n",
    "                ps_scores = model.predict_proba(X)[:, 1]\n",
    "                ps_matrix[f\"ps_imp{i+1}\"] = pd.Series(ps_scores, index=valid_idx)\n",
    "\n",
    "                # ROC & AUC\n",
    "                auc = roc_auc_score(T_test, model.predict_proba(X_test)[:, 1])\n",
    "                auc_list.append(auc)\n",
    "\n",
    "                fpr, tpr, _ = roc_curve(T_test, model.predict_proba(X_test)[:, 1])\n",
    "                plt.figure()\n",
    "                plt.plot(fpr, tpr, label=f\"AUC = {auc:.3f}\")\n",
    "                plt.plot([0, 1], [0, 1], 'k--')\n",
    "                plt.xlabel(\"False Positive Rate\")\n",
    "                plt.ylabel(\"True Positive Rate\")\n",
    "                plt.title(f\"ROC Curve - {group} (Imp {i+1})\")\n",
    "                plt.legend()\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(os.path.join(output_folder, f\"roc_curve_imp{i+1}.png\"))\n",
    "                plt.close()\n",
    "                print(f\"   Imp {i+1}: AUC = {auc:.3f}, ROC saved.\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"   Error in {group} (imp {i+1}): {e}\")\n",
    "\n",
    "        # Save AUCs and Composite PS\n",
    "        if not ps_matrix.empty:\n",
    "            # Fill NaN rows (from dropped subjects in some imputations) with mean\n",
    "            ps_matrix[\"composite_ps\"] = ps_matrix.mean(axis=1)\n",
    "            ps_matrix.to_excel(os.path.join(output_folder, \"propensity_scores.xlsx\"))\n",
    "\n",
    "            auc_df = pd.DataFrame({\n",
    "                \"imputation\": [f\"imp{i+1}\" for i in range(len(auc_list))],\n",
    "                \"AUC\": auc_list\n",
    "            })\n",
    "            auc_df.loc[len(auc_df.index)] = [\"mean\", np.mean(auc_list) if auc_list else np.nan]\n",
    "            auc_df.to_excel(os.path.join(output_folder, \"auc_scores.xlsx\"), index=False)\n",
    "\n",
    "            print(f\" Composite PS + AUC saved for {group}\")\n",
    "        else:\n",
    "            print(f\" No valid PS scores generated for {group}\")\n",
    "\n",
    "# ---------- Run ----------\n",
    "run_logistic_ps_modeling(imputed_dfs, medication_groups, final_covariates_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "38f7f379-7ca4-4f21-8cdc-767c8814a4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Computing feature importance for SUBCAT_Antipsychotica_atypisch\n",
      " Saved feature importance plot and CSV for SUBCAT_Antipsychotica_atypisch\n",
      "\n",
      " Computing feature importance for SUBCAT_TCA\n",
      " Saved feature importance plot and CSV for SUBCAT_TCA\n",
      "\n",
      " Computing feature importance for SUBCAT_SSRI\n",
      " Saved feature importance plot and CSV for SUBCAT_SSRI\n",
      "\n",
      " Computing feature importance for SUBCAT_SNRI\n",
      " Saved feature importance plot and CSV for SUBCAT_SNRI\n",
      "\n",
      " Computing feature importance for SUBCAT_Tetracyclische_antidepressiva\n",
      " Saved feature importance plot and CSV for SUBCAT_Tetracyclische_antidepressiva\n",
      "\n",
      " Computing feature importance for SUBCAT_Antidepressiva_overige\n",
      " Saved feature importance plot and CSV for SUBCAT_Antidepressiva_overige\n",
      "\n",
      " Computing feature importance for SUBCAT_Systemische_antihistaminica\n",
      " Saved feature importance plot and CSV for SUBCAT_Systemische_antihistaminica\n",
      "\n",
      " Computing feature importance for SUBCAT_anxiolytica_Benzodiazepine\n",
      " Saved feature importance plot and CSV for SUBCAT_anxiolytica_Benzodiazepine\n",
      "\n",
      " Computing feature importance for SUBCAT_hypnotica_Benzodiazepine\n",
      " Saved feature importance plot and CSV for SUBCAT_hypnotica_Benzodiazepine\n",
      "\n",
      " Computing feature importance for SUBCAT_Amfetaminen\n",
      " Saved feature importance plot and CSV for SUBCAT_Amfetaminen\n",
      "\n",
      " Computing feature importance for SUBCAT_Paracetamol_mono\n",
      " Saved feature importance plot and CSV for SUBCAT_Paracetamol_mono\n",
      "\n",
      " Computing feature importance for SUBCAT_Anti_epileptica_stemmingsstabilisatoren\n",
      " Saved feature importance plot and CSV for SUBCAT_Anti_epileptica_stemmingsstabilisatoren\n",
      "\n",
      " Computing feature importance for SUBCAT_Opioden\n",
      " Saved feature importance plot and CSV for SUBCAT_Opioden\n",
      "\n",
      " Computing feature importance for SUBCAT_Z_drugs\n",
      " Saved feature importance plot and CSV for SUBCAT_Z_drugs\n",
      "\n",
      " Computing feature importance for SUBCAT_NSAIDs\n",
      " Saved feature importance plot and CSV for SUBCAT_NSAIDs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def compute_feature_importance(imputed_dfs, medication_groups, final_covariates_map):\n",
    "    for group in medication_groups:\n",
    "        print(f\"\\n Computing feature importance for {group}\")\n",
    "\n",
    "        if group not in final_covariates_map:\n",
    "            print(f\" No covariates found for {group}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        covariates = final_covariates_map[group]\n",
    "        output_folder = os.path.join(\"outputs\", group)\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "        importance_df_list = []\n",
    "\n",
    "        for i, df_imp in enumerate(imputed_dfs):\n",
    "            if group not in df_imp.columns:\n",
    "                print(f\" {group} not in imputed dataset {i+1}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            X = df_imp[covariates].copy()\n",
    "            T = df_imp[group]\n",
    "\n",
    "            # Drop NaNs in treatment\n",
    "            valid_idx = T.dropna().index\n",
    "            X = X.loc[valid_idx]\n",
    "            T = T.loc[valid_idx]\n",
    "\n",
    "            try:\n",
    "                model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "                model.fit(X, T)\n",
    "\n",
    "                # Get feature importance (absolute coefficients)\n",
    "                importances = np.abs(model.coef_[0])\n",
    "                importance_dict = dict(zip(X.columns, importances))\n",
    "                df_feat = pd.DataFrame.from_dict(importance_dict, orient='index', columns=[f\"imp{i+1}\"])\n",
    "                df_feat.index.name = 'feature'\n",
    "                importance_df_list.append(df_feat)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"   Error during modeling: {e}\")\n",
    "\n",
    "        if importance_df_list:\n",
    "            # Combine and average\n",
    "            all_feat = pd.concat(importance_df_list, axis=1).fillna(0)\n",
    "            all_feat[\"mean_importance\"] = all_feat.mean(axis=1)\n",
    "\n",
    "            # Filter top 30 non-zero\n",
    "            non_zero = all_feat[all_feat[\"mean_importance\"] > 0]\n",
    "            top30 = non_zero.sort_values(by=\"mean_importance\", ascending=False).head(30)\n",
    "\n",
    "            # Save to CSV\n",
    "            top30.to_csv(os.path.join(output_folder, \"feature_importance.csv\"))\n",
    "\n",
    "            # Plot\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            plt.barh(top30.index[::-1], top30[\"mean_importance\"][::-1])  # plot top → bottom\n",
    "            plt.xlabel(\"Mean Gain Importance\")\n",
    "            plt.title(f\"Top 30 Feature Importance - {group}\")\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(output_folder, \"feature_importance_top30.png\"))\n",
    "            plt.close()\n",
    "\n",
    "            print(f\" Saved feature importance plot and CSV for {group}\")\n",
    "        else:\n",
    "            print(f\" No valid models for {group}\")\n",
    "\n",
    "#  Run\n",
    "compute_feature_importance(imputed_dfs, medication_groups, final_covariates_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "61c1cc1f-9ec7-402b-a19a-534d28c833ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SUBCAT_Antipsychotica_atypisch\n",
      "✅ Saved IPTW weights for SUBCAT_Antipsychotica_atypisch\n",
      "    ℹ️ Retained 183/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Antipsychotica_atypisch/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 185/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Antipsychotica_atypisch/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 189/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Antipsychotica_atypisch/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 188/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Antipsychotica_atypisch/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 187/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Antipsychotica_atypisch/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SUBCAT_TCA\n",
      "✅ Saved IPTW weights for SUBCAT_TCA\n",
      "    ℹ️ Retained 387/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_TCA/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 392/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_TCA/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 385/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_TCA/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 395/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_TCA/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 401/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_TCA/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SUBCAT_SSRI\n",
      "✅ Saved IPTW weights for SUBCAT_SSRI\n",
      "    ℹ️ Retained 2526/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_SSRI/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 2512/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_SSRI/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 2493/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_SSRI/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 2513/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_SSRI/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 2503/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_SSRI/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SUBCAT_SNRI\n",
      "✅ Saved IPTW weights for SUBCAT_SNRI\n",
      "    ℹ️ Retained 377/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_SNRI/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 394/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_SNRI/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 392/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_SNRI/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 370/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_SNRI/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 390/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_SNRI/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SUBCAT_Tetracyclische_antidepressiva\n",
      "✅ Saved IPTW weights for SUBCAT_Tetracyclische_antidepressiva\n",
      "    ℹ️ Retained 409/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Tetracyclische_antidepressiva/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 419/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Tetracyclische_antidepressiva/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 406/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Tetracyclische_antidepressiva/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 417/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Tetracyclische_antidepressiva/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 410/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Tetracyclische_antidepressiva/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SUBCAT_Antidepressiva_overige\n",
      "✅ Saved IPTW weights for SUBCAT_Antidepressiva_overige\n",
      "    ℹ️ Retained 86/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Antidepressiva_overige/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 67/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Antidepressiva_overige/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 77/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Antidepressiva_overige/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 93/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Antidepressiva_overige/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 73/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Antidepressiva_overige/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SUBCAT_Systemische_antihistaminica\n",
      "✅ Saved IPTW weights for SUBCAT_Systemische_antihistaminica\n",
      "    ℹ️ Retained 154/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Systemische_antihistaminica/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 154/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Systemische_antihistaminica/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 152/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Systemische_antihistaminica/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 155/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Systemische_antihistaminica/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 150/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Systemische_antihistaminica/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SUBCAT_anxiolytica_Benzodiazepine\n",
      "✅ Saved IPTW weights for SUBCAT_anxiolytica_Benzodiazepine\n",
      "    ℹ️ Retained 1748/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_anxiolytica_Benzodiazepine/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 1748/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_anxiolytica_Benzodiazepine/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 1748/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_anxiolytica_Benzodiazepine/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 1754/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_anxiolytica_Benzodiazepine/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 1748/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_anxiolytica_Benzodiazepine/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SUBCAT_hypnotica_Benzodiazepine\n",
      "✅ Saved IPTW weights for SUBCAT_hypnotica_Benzodiazepine\n",
      "    ℹ️ Retained 760/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_hypnotica_Benzodiazepine/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 773/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_hypnotica_Benzodiazepine/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 759/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_hypnotica_Benzodiazepine/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 773/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_hypnotica_Benzodiazepine/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 772/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_hypnotica_Benzodiazepine/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SUBCAT_Amfetaminen\n",
      "✅ Saved IPTW weights for SUBCAT_Amfetaminen\n",
      "    ℹ️ Retained 60/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Amfetaminen/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 57/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Amfetaminen/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 59/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Amfetaminen/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 87/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Amfetaminen/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 62/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Amfetaminen/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SUBCAT_Paracetamol_mono\n",
      "✅ Saved IPTW weights for SUBCAT_Paracetamol_mono\n",
      "    ℹ️ Retained 110/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Paracetamol_mono/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 99/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Paracetamol_mono/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 98/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Paracetamol_mono/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 100/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Paracetamol_mono/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 106/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Paracetamol_mono/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SUBCAT_Anti_epileptica_stemmingsstabilisatoren\n",
      "✅ Saved IPTW weights for SUBCAT_Anti_epileptica_stemmingsstabilisatoren\n",
      "    ℹ️ Retained 241/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Anti_epileptica_stemmingsstabilisatoren/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 240/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Anti_epileptica_stemmingsstabilisatoren/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 241/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Anti_epileptica_stemmingsstabilisatoren/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 243/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Anti_epileptica_stemmingsstabilisatoren/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 240/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Anti_epileptica_stemmingsstabilisatoren/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SUBCAT_Opioden\n",
      "✅ Saved IPTW weights for SUBCAT_Opioden\n",
      "    ℹ️ Retained 231/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Opioden/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 231/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Opioden/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 230/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Opioden/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 232/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Opioden/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 233/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Opioden/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SUBCAT_Z_drugs\n",
      "✅ Saved IPTW weights for SUBCAT_Z_drugs\n",
      "    ℹ️ Retained 208/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Z_drugs/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 210/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Z_drugs/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 215/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Z_drugs/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 212/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Z_drugs/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 210/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_Z_drugs/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SUBCAT_NSAIDs\n",
      "✅ Saved IPTW weights for SUBCAT_NSAIDs\n",
      "    ℹ️ Retained 127/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_NSAIDs/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 138/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_NSAIDs/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 139/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_NSAIDs/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 131/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_NSAIDs/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 129/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SUBCAT_NSAIDs/trimmed_data_imp5.*\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_trimmed_clipped_iptw(ps_df, treatment, lower=0.05, upper=0.95, clip_max=10):\n",
    "    weights = []\n",
    "    keep_mask = (ps_df > lower) & (ps_df < upper)\n",
    "\n",
    "    for i in range(ps_df.shape[1]):\n",
    "        ps = ps_df.iloc[:, i].clip(lower=1e-6, upper=1 - 1e-6)  # avoid div by zero\n",
    "        mask = keep_mask.iloc[:, i]\n",
    "        w = pd.Series(np.nan, index=ps.index)\n",
    "\n",
    "        w[mask & (treatment == 1)] = 1 / ps[mask & (treatment == 1)]\n",
    "        w[mask & (treatment == 0)] = 1 / (1 - ps[mask & (treatment == 0)])\n",
    "        w = w.clip(upper=clip_max)\n",
    "        weights.append(w)\n",
    "\n",
    "    return pd.concat(weights, axis=1)\n",
    "\n",
    "\n",
    "def apply_rubins_rule_to_iptw(iptw_matrix):\n",
    "    \"\"\"\n",
    "    Given an IPTW matrix (n rows × M imputations), return Rubin’s rule pooled mean, SD, SE.\n",
    "    \"\"\"\n",
    "    M = iptw_matrix.shape[1]\n",
    "    q_bar = iptw_matrix.mean(axis=1)\n",
    "    u_bar = iptw_matrix.var(axis=1, ddof=1)\n",
    "    B = iptw_matrix.apply(lambda x: x.mean(), axis=1).var(ddof=1)\n",
    "    total_var = u_bar + (1 + 1/M) * B\n",
    "    total_se = np.sqrt(total_var)\n",
    "    return q_bar, u_bar.pow(0.5), total_se\n",
    "\n",
    "\n",
    "def run_trim_clip_save_all(imputed_dfs, medication_groups, final_covariates_map):\n",
    "    for group in medication_groups:\n",
    "        print(f\"\\n🔍 Processing IPTW + trimming + clipping for {group}\")\n",
    "        output_folder = os.path.join(\"outputs\", group)\n",
    "        ps_path = os.path.join(output_folder, \"propensity_scores.xlsx\")\n",
    "\n",
    "        if not os.path.exists(ps_path):\n",
    "            print(f\"⚠️ Missing PS file: {ps_path}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            ps_all = pd.read_excel(ps_path, index_col=0)\n",
    "            ps_cols = [col for col in ps_all.columns if col.startswith(\"ps_imp\")]\n",
    "            composite_index = ps_all.index\n",
    "\n",
    "            # Get treatment from one imputed dataset\n",
    "            T_full = None\n",
    "            for df in imputed_dfs:\n",
    "                if group in df.columns:\n",
    "                    T_full = df.loc[composite_index, group]\n",
    "                    break\n",
    "\n",
    "            if T_full is None:\n",
    "                print(f\"❌ Treatment column {group} not found in any imputed dataset.\")\n",
    "                continue\n",
    "\n",
    "            # Compute IPTW matrix (shape: n × M)\n",
    "            iptw_matrix = compute_trimmed_clipped_iptw(ps_all[ps_cols], T_full)\n",
    "            iptw_matrix.columns = [f\"iptw_imp{i+1}\" for i in range(iptw_matrix.shape[1])]\n",
    "\n",
    "            # Apply Rubin’s Rule for mean, SD, SE\n",
    "            iptw_matrix[\"iptw_mean\"], iptw_matrix[\"iptw_sd\"], iptw_matrix[\"iptw_se\"] = apply_rubins_rule_to_iptw(\n",
    "                iptw_matrix[[f\"iptw_imp{i+1}\" for i in range(iptw_matrix.shape[1])]]\n",
    "            )\n",
    "\n",
    "            # Save IPTW matrix separately\n",
    "            iptw_matrix.to_excel(os.path.join(output_folder, \"iptw_weights.xlsx\"))\n",
    "            print(f\"✅ Saved IPTW weights for {group}\")\n",
    "\n",
    "            # Save trimmed & clipped imputed datasets with IPTW\n",
    "            for i in range(5):\n",
    "                df = imputed_dfs[i].copy()\n",
    "                if group not in df.columns:\n",
    "                    continue\n",
    "\n",
    "                trimmed_idx = iptw_matrix.index.intersection(df.index)\n",
    "                needed_cols = final_covariates_map[group] + [group, \"caps5_change_baseline\"]\n",
    "\n",
    "                # Select only necessary columns\n",
    "                df_trimmed = df.loc[trimmed_idx, needed_cols].copy()\n",
    "                df_trimmed[\"iptw\"] = iptw_matrix[f\"iptw_imp{i+1}\"].loc[trimmed_idx]\n",
    "\n",
    "                # ✅ DROP rows with missing IPTW values\n",
    "                before = len(df_trimmed)\n",
    "                df_trimmed = df_trimmed.dropna(subset=[\"iptw\"])\n",
    "                after = len(df_trimmed)\n",
    "                print(f\"    ℹ️ Retained {after}/{before} rows after IPTW NaN drop.\")\n",
    "\n",
    "                # Save to .pkl\n",
    "                df_trimmed.to_pickle(os.path.join(output_folder, f\"trimmed_data_imp{i+1}.pkl\"))\n",
    "                print(f\"  💾 Saved trimmed dataset: {output_folder}/trimmed_data_imp{i+1}.*\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error in {group}: {e}\")\n",
    "\n",
    "\n",
    "run_trim_clip_save_all(imputed_dfs, medication_groups, final_covariates_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "2e57891b-20aa-401e-b95e-019da87c3dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Plotting PS overlap for SUBCAT_Antipsychotica_atypisch\n",
      "✅ Saved unweighted and weighted PS plots for SUBCAT_Antipsychotica_atypisch\n",
      "\n",
      "📊 Plotting PS overlap for SUBCAT_TCA\n",
      "✅ Saved unweighted and weighted PS plots for SUBCAT_TCA\n",
      "\n",
      "📊 Plotting PS overlap for SUBCAT_SSRI\n",
      "✅ Saved unweighted and weighted PS plots for SUBCAT_SSRI\n",
      "\n",
      "📊 Plotting PS overlap for SUBCAT_SNRI\n",
      "✅ Saved unweighted and weighted PS plots for SUBCAT_SNRI\n",
      "\n",
      "📊 Plotting PS overlap for SUBCAT_Tetracyclische_antidepressiva\n",
      "✅ Saved unweighted and weighted PS plots for SUBCAT_Tetracyclische_antidepressiva\n",
      "\n",
      "📊 Plotting PS overlap for SUBCAT_Antidepressiva_overige\n",
      "✅ Saved unweighted and weighted PS plots for SUBCAT_Antidepressiva_overige\n",
      "\n",
      "📊 Plotting PS overlap for SUBCAT_Systemische_antihistaminica\n",
      "✅ Saved unweighted and weighted PS plots for SUBCAT_Systemische_antihistaminica\n",
      "\n",
      "📊 Plotting PS overlap for SUBCAT_anxiolytica_Benzodiazepine\n",
      "✅ Saved unweighted and weighted PS plots for SUBCAT_anxiolytica_Benzodiazepine\n",
      "\n",
      "📊 Plotting PS overlap for SUBCAT_hypnotica_Benzodiazepine\n",
      "✅ Saved unweighted and weighted PS plots for SUBCAT_hypnotica_Benzodiazepine\n",
      "\n",
      "📊 Plotting PS overlap for SUBCAT_Amfetaminen\n",
      "✅ Saved unweighted and weighted PS plots for SUBCAT_Amfetaminen\n",
      "\n",
      "📊 Plotting PS overlap for SUBCAT_Paracetamol_mono\n",
      "✅ Saved unweighted and weighted PS plots for SUBCAT_Paracetamol_mono\n",
      "\n",
      "📊 Plotting PS overlap for SUBCAT_Anti_epileptica_stemmingsstabilisatoren\n",
      "✅ Saved unweighted and weighted PS plots for SUBCAT_Anti_epileptica_stemmingsstabilisatoren\n",
      "\n",
      "📊 Plotting PS overlap for SUBCAT_Opioden\n",
      "✅ Saved unweighted and weighted PS plots for SUBCAT_Opioden\n",
      "\n",
      "📊 Plotting PS overlap for SUBCAT_Z_drugs\n",
      "✅ Saved unweighted and weighted PS plots for SUBCAT_Z_drugs\n",
      "\n",
      "📊 Plotting PS overlap for SUBCAT_NSAIDs\n",
      "✅ Saved unweighted and weighted PS plots for SUBCAT_NSAIDs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_ps_overlap_all_groups(medication_groups):\n",
    "    for group in medication_groups:\n",
    "        print(f\"\\n📊 Plotting PS overlap for {group}\")\n",
    "\n",
    "        folder = os.path.join(\"outputs\", group)\n",
    "        ps_file = os.path.join(folder, \"propensity_scores.xlsx\")\n",
    "        iptw_file = os.path.join(folder, \"iptw_weights.xlsx\")\n",
    "        trimmed_file = os.path.join(folder, \"trimmed_data_imp1.pkl\")\n",
    "\n",
    "        if not all(os.path.exists(f) for f in [ps_file, iptw_file, trimmed_file]):\n",
    "            print(f\"⚠️ Missing required files for {group}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            ps_df = pd.read_excel(ps_file, index_col=0)\n",
    "            iptw_df = pd.read_excel(iptw_file, index_col=0)\n",
    "            trimmed_df = pd.read_pickle(trimmed_file)\n",
    "\n",
    "            # Extract\n",
    "            ps = ps_df[\"composite_ps\"].reindex(trimmed_df.index)\n",
    "            w = iptw_df[\"iptw_mean\"].reindex(trimmed_df.index)\n",
    "            T = trimmed_df[group]\n",
    "\n",
    "            # Masks to remove NaNs\n",
    "            treated_mask = (T == 1) & ps.notna() & w.notna()\n",
    "            control_mask = (T == 0) & ps.notna() & w.notna()\n",
    "\n",
    "            treated = ps[treated_mask]\n",
    "            treated_w = w[treated_mask]\n",
    "\n",
    "            control = ps[control_mask]\n",
    "            control_w = w[control_mask]\n",
    "\n",
    "            # === Unweighted Plot ===\n",
    "            plt.figure(figsize=(8, 5))\n",
    "            plt.hist([treated, control], bins=25, label=[\"Treated\", \"Control\"], alpha=0.6)\n",
    "            plt.title(f\"Unweighted PS Overlap - {group}\")\n",
    "            plt.xlabel(\"Composite Propensity Score\")\n",
    "            plt.ylabel(\"Count\")\n",
    "            plt.legend()\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(folder, \"ps_overlap_unweighted.png\"))\n",
    "            plt.close()\n",
    "\n",
    "            # === Weighted Plot ===\n",
    "            plt.figure(figsize=(8, 5))\n",
    "            plt.hist([treated, control], bins=25, weights=[treated_w, control_w], label=[\"Treated\", \"Control\"], alpha=0.6)\n",
    "            plt.title(f\"Weighted PS Overlap - {group}\")\n",
    "            plt.xlabel(\"Composite Propensity Score\")\n",
    "            plt.ylabel(\"Weighted Count\")\n",
    "            plt.legend()\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(folder, \"ps_overlap_weighted.png\"))\n",
    "            plt.close()\n",
    "\n",
    "            print(f\"✅ Saved unweighted and weighted PS plots for {group}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error processing {group}: {e}\")\n",
    "\n",
    "# 🔁 Run\n",
    "plot_ps_overlap_all_groups(medication_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "1ff6b954-c0fd-4644-b88b-4d5e3073188a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ✅ Saved: outputs\\SUBCAT_Antipsychotica_atypisch\\four_panel_overlap_SUBCAT_Antipsychotica_atypisch.png\n",
      " ✅ Saved: outputs\\SUBCAT_TCA\\four_panel_overlap_SUBCAT_TCA.png\n",
      " ✅ Saved: outputs\\SUBCAT_SSRI\\four_panel_overlap_SUBCAT_SSRI.png\n",
      " ✅ Saved: outputs\\SUBCAT_SNRI\\four_panel_overlap_SUBCAT_SNRI.png\n",
      " ✅ Saved: outputs\\SUBCAT_Tetracyclische_antidepressiva\\four_panel_overlap_SUBCAT_Tetracyclische_antidepressiva.png\n",
      " ✅ Saved: outputs\\SUBCAT_Antidepressiva_overige\\four_panel_overlap_SUBCAT_Antidepressiva_overige.png\n",
      " ✅ Saved: outputs\\SUBCAT_Systemische_antihistaminica\\four_panel_overlap_SUBCAT_Systemische_antihistaminica.png\n",
      " ✅ Saved: outputs\\SUBCAT_anxiolytica_Benzodiazepine\\four_panel_overlap_SUBCAT_anxiolytica_Benzodiazepine.png\n",
      " ✅ Saved: outputs\\SUBCAT_hypnotica_Benzodiazepine\\four_panel_overlap_SUBCAT_hypnotica_Benzodiazepine.png\n",
      " ✅ Saved: outputs\\SUBCAT_Amfetaminen\\four_panel_overlap_SUBCAT_Amfetaminen.png\n",
      " ✅ Saved: outputs\\SUBCAT_Paracetamol_mono\\four_panel_overlap_SUBCAT_Paracetamol_mono.png\n",
      " ✅ Saved: outputs\\SUBCAT_Anti_epileptica_stemmingsstabilisatoren\\four_panel_overlap_SUBCAT_Anti_epileptica_stemmingsstabilisatoren.png\n",
      " ✅ Saved: outputs\\SUBCAT_Opioden\\four_panel_overlap_SUBCAT_Opioden.png\n",
      " ✅ Saved: outputs\\SUBCAT_Z_drugs\\four_panel_overlap_SUBCAT_Z_drugs.png\n",
      " ✅ Saved: outputs\\SUBCAT_NSAIDs\\four_panel_overlap_SUBCAT_NSAIDs.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set up base output folder\n",
    "output_base = \"outputs\"\n",
    "ps_file = \"propensity_scores.xlsx\"\n",
    "iptw_file = \"iptw_weights.xlsx\"\n",
    "trimmed_data_file = \"trimmed_data_imp1.pkl\"\n",
    "\n",
    "# Collect all treatment group folders\n",
    "groups = [g for g in medication_groups if os.path.isdir(os.path.join(output_base, g))]\n",
    "\n",
    "\n",
    "# Generate 4-panel overlap plots\n",
    "for group in groups:\n",
    "    group_path = os.path.join(output_base, group)\n",
    "    try:\n",
    "        # Load trimmed treatment info\n",
    "        trimmed_df = pd.read_pickle(os.path.join(group_path, trimmed_data_file))\n",
    "        index = trimmed_df.index\n",
    "\n",
    "        # Fix: case-insensitive match for treatment variable\n",
    "        possible_cols = [col for col in trimmed_df.columns if col.upper() == group.upper()]\n",
    "        if not possible_cols:\n",
    "            print(f\" Treatment variable {group} not found in {group}, skipping.\")\n",
    "            continue\n",
    "        treatment_var = possible_cols[0]\n",
    "        T = trimmed_df[treatment_var]\n",
    "\n",
    "        # Load composite PS (aligned to trimmed_df index)\n",
    "        ps_df = pd.read_excel(os.path.join(group_path, ps_file), index_col=0)\n",
    "        if 'composite_ps' not in ps_df.columns:\n",
    "            print(f\" Composite column missing in {ps_file}, skipping {group}.\")\n",
    "            continue\n",
    "        ps = ps_df.loc[index, 'composite_ps']\n",
    "\n",
    "        # Load IPTW weights (aligned to trimmed_df index)\n",
    "        weights_df = pd.read_excel(os.path.join(group_path, iptw_file), index_col=0)\n",
    "        if 'iptw_mean' not in weights_df.columns:\n",
    "            print(f\" IPTW weight column missing in {iptw_file}, skipping {group}.\")\n",
    "            continue\n",
    "        weights = weights_df.loc[index, 'iptw_mean']\n",
    "\n",
    "        # Prepare 4 datasets\n",
    "        raw_treated = ps[T == 1]\n",
    "        raw_control = ps[T == 0]\n",
    "        weighted_treated = (ps[T == 1], weights[T == 1])\n",
    "        weighted_control = (ps[T == 0], weights[T == 0])\n",
    "\n",
    "        # Create plot\n",
    "        fig, axs = plt.subplots(2, 2, figsize=(12, 8))\n",
    "        fig.suptitle(f\"Propensity Score Distribution - {group}\", fontsize=14)\n",
    "\n",
    "        axs[0, 0].hist(raw_treated, bins=20, alpha=0.7, color='blue')\n",
    "        axs[0, 0].set_title(\"Raw Treated\")\n",
    "\n",
    "        axs[0, 1].hist(raw_control, bins=20, alpha=0.7, color='green')\n",
    "        axs[0, 1].set_title(\"Raw Control\")\n",
    "\n",
    "        axs[1, 0].hist(weighted_treated[0], bins=20, weights=weighted_treated[1], alpha=0.7, color='blue')\n",
    "        axs[1, 0].set_title(\"Weighted Treated\")\n",
    "\n",
    "        axs[1, 1].hist(weighted_control[0], bins=20, weights=weighted_control[1], alpha=0.7, color='green')\n",
    "        axs[1, 1].set_title(\"Weighted Control\")\n",
    "\n",
    "        for ax in axs.flat:\n",
    "            ax.set_xlim(0, 1)\n",
    "            ax.set_xlabel(\"Propensity Score\")\n",
    "            ax.set_ylabel(\"Count\")\n",
    "\n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "\n",
    "        # Save figure\n",
    "        plot_path = os.path.join(group_path, f\"four_panel_overlap_{group}.png\")\n",
    "        plt.savefig(plot_path)\n",
    "        plt.close()\n",
    "        print(f\" ✅ Saved: {plot_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\" ❌ Error in {group}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "69b56397-7cf3-4956-94f0-b657d5eab983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ATT calculation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "3e629fc1-6c45-4ea9-b8a0-b6491f004f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weighted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "2580922c-2fd5-49b1-8083-ee1ddbfa0cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Running OLS for SUBCAT_Antipsychotica_atypisch\n",
      "✅ SUBCAT_Antipsychotica_atypisch | Seed 1: ATT = -2.2716, SE = 7.1258, p = 0.76584\n",
      "✅ SUBCAT_Antipsychotica_atypisch | Seed 2: ATT = -3.1746, SE = 5.0999, p = 0.56736\n",
      "✅ SUBCAT_Antipsychotica_atypisch | Seed 3: ATT = -3.2868, SE = 6.3732, p = 0.63324\n",
      "✅ SUBCAT_Antipsychotica_atypisch | Seed 4: ATT = -1.1870, SE = 8.8228, p = 0.89948\n",
      "✅ SUBCAT_Antipsychotica_atypisch | Seed 5: ATT = -1.6513, SE = 4.8367, p = 0.74997\n",
      "✅ SUBCAT_Antipsychotica_atypisch | Seed 6: ATT = -0.0522, SE = 5.9896, p = 0.99346\n",
      "✅ SUBCAT_Antipsychotica_atypisch | Seed 7: ATT = 1.1671, SE = 7.8934, p = 0.88961\n",
      "✅ SUBCAT_Antipsychotica_atypisch | Seed 8: ATT = -5.1265, SE = 6.1668, p = 0.45254\n",
      "✅ SUBCAT_Antipsychotica_atypisch | Seed 9: ATT = 0.3893, SE = 4.8967, p = 0.94044\n",
      "✅ SUBCAT_Antipsychotica_atypisch | Seed 10: ATT = -3.2036, SE = 7.1742, p = 0.67831\n",
      "📊 Diagnostic plots saved for SUBCAT_Antipsychotica_atypisch\n",
      "🏆 Best result for SUBCAT_Antipsychotica_atypisch → Seed 5 | SE = 4.8367\n",
      "\n",
      "🚀 Running OLS for SUBCAT_TCA\n",
      "✅ SUBCAT_TCA | Seed 1: ATT = 3.1494, SE = 3.5376, p = 0.42362\n",
      "✅ SUBCAT_TCA | Seed 2: ATT = 3.9006, SE = 3.0718, p = 0.27300\n",
      "✅ SUBCAT_TCA | Seed 3: ATT = 2.4119, SE = 3.6551, p = 0.54540\n",
      "✅ SUBCAT_TCA | Seed 4: ATT = 3.0393, SE = 3.6565, p = 0.45259\n",
      "✅ SUBCAT_TCA | Seed 5: ATT = 4.9404, SE = 4.0017, p = 0.28455\n",
      "✅ SUBCAT_TCA | Seed 6: ATT = 5.1357, SE = 2.8726, p = 0.14832\n",
      "✅ SUBCAT_TCA | Seed 7: ATT = 2.4870, SE = 3.3430, p = 0.49824\n",
      "✅ SUBCAT_TCA | Seed 8: ATT = 2.5741, SE = 4.0323, p = 0.55796\n",
      "✅ SUBCAT_TCA | Seed 9: ATT = 4.8225, SE = 4.0660, p = 0.30124\n",
      "✅ SUBCAT_TCA | Seed 10: ATT = 5.5655, SE = 3.7028, p = 0.20725\n",
      "📊 Diagnostic plots saved for SUBCAT_TCA\n",
      "🏆 Best result for SUBCAT_TCA → Seed 6 | SE = 2.8726\n",
      "\n",
      "🚀 Running OLS for SUBCAT_SSRI\n",
      "✅ SUBCAT_SSRI | Seed 1: ATT = -0.2947, SE = 1.4557, p = 0.84946\n",
      "✅ SUBCAT_SSRI | Seed 2: ATT = -0.9005, SE = 1.0364, p = 0.43396\n",
      "✅ SUBCAT_SSRI | Seed 3: ATT = -0.6645, SE = 1.2062, p = 0.61102\n",
      "✅ SUBCAT_SSRI | Seed 4: ATT = -0.8358, SE = 0.7968, p = 0.35340\n",
      "✅ SUBCAT_SSRI | Seed 5: ATT = -0.8953, SE = 0.9802, p = 0.41270\n",
      "✅ SUBCAT_SSRI | Seed 6: ATT = -0.3726, SE = 0.7735, p = 0.65516\n",
      "✅ SUBCAT_SSRI | Seed 7: ATT = -0.1703, SE = 1.0110, p = 0.87439\n",
      "✅ SUBCAT_SSRI | Seed 8: ATT = -0.2298, SE = 0.8488, p = 0.79998\n",
      "✅ SUBCAT_SSRI | Seed 9: ATT = 0.0029, SE = 1.0465, p = 0.99790\n",
      "✅ SUBCAT_SSRI | Seed 10: ATT = -0.5503, SE = 1.2029, p = 0.67106\n",
      "📊 Diagnostic plots saved for SUBCAT_SSRI\n",
      "🏆 Best result for SUBCAT_SSRI → Seed 6 | SE = 0.7735\n",
      "\n",
      "🚀 Running OLS for SUBCAT_SNRI\n",
      "✅ SUBCAT_SNRI | Seed 1: ATT = 3.5705, SE = 4.1131, p = 0.43434\n",
      "✅ SUBCAT_SNRI | Seed 2: ATT = 6.0262, SE = 2.5691, p = 0.07889\n",
      "✅ SUBCAT_SNRI | Seed 3: ATT = 4.1610, SE = 4.1420, p = 0.37194\n",
      "✅ SUBCAT_SNRI | Seed 4: ATT = 3.5050, SE = 4.2681, p = 0.45765\n",
      "✅ SUBCAT_SNRI | Seed 5: ATT = 5.5518, SE = 3.9036, p = 0.22802\n",
      "✅ SUBCAT_SNRI | Seed 6: ATT = 5.9646, SE = 3.0803, p = 0.12489\n",
      "✅ SUBCAT_SNRI | Seed 7: ATT = 3.8839, SE = 4.4995, p = 0.43672\n",
      "✅ SUBCAT_SNRI | Seed 8: ATT = 4.4335, SE = 5.4604, p = 0.46238\n",
      "✅ SUBCAT_SNRI | Seed 9: ATT = 3.5807, SE = 3.8532, p = 0.40535\n",
      "✅ SUBCAT_SNRI | Seed 10: ATT = 3.8440, SE = 4.2303, p = 0.41491\n",
      "📊 Diagnostic plots saved for SUBCAT_SNRI\n",
      "🏆 Best result for SUBCAT_SNRI → Seed 2 | SE = 2.5691\n",
      "\n",
      "🚀 Running OLS for SUBCAT_Tetracyclische_antidepressiva\n",
      "✅ SUBCAT_Tetracyclische_antidepressiva | Seed 1: ATT = 6.9180, SE = 3.8928, p = 0.15019\n",
      "✅ SUBCAT_Tetracyclische_antidepressiva | Seed 2: ATT = 4.3887, SE = 2.8790, p = 0.20209\n",
      "✅ SUBCAT_Tetracyclische_antidepressiva | Seed 3: ATT = 4.1892, SE = 2.8107, p = 0.21036\n",
      "✅ SUBCAT_Tetracyclische_antidepressiva | Seed 4: ATT = 8.0667, SE = 3.7243, p = 0.09625\n",
      "✅ SUBCAT_Tetracyclische_antidepressiva | Seed 5: ATT = 6.3377, SE = 3.8143, p = 0.17194\n",
      "✅ SUBCAT_Tetracyclische_antidepressiva | Seed 6: ATT = 4.5574, SE = 3.2788, p = 0.23690\n",
      "✅ SUBCAT_Tetracyclische_antidepressiva | Seed 7: ATT = 4.8109, SE = 4.4817, p = 0.34351\n",
      "✅ SUBCAT_Tetracyclische_antidepressiva | Seed 8: ATT = 4.6645, SE = 3.1718, p = 0.21534\n",
      "✅ SUBCAT_Tetracyclische_antidepressiva | Seed 9: ATT = 4.6274, SE = 2.4839, p = 0.13594\n",
      "✅ SUBCAT_Tetracyclische_antidepressiva | Seed 10: ATT = 6.1023, SE = 4.1983, p = 0.21975\n",
      "📊 Diagnostic plots saved for SUBCAT_Tetracyclische_antidepressiva\n",
      "🏆 Best result for SUBCAT_Tetracyclische_antidepressiva → Seed 9 | SE = 2.4839\n",
      "\n",
      "🚀 Running OLS for SUBCAT_Antidepressiva_overige\n",
      "✅ SUBCAT_Antidepressiva_overige | Seed 1: ATT = 9.1526, SE = 6.6929, p = 0.24327\n",
      "✅ SUBCAT_Antidepressiva_overige | Seed 2: ATT = 1.2106, SE = 8.3845, p = 0.89218\n",
      "✅ SUBCAT_Antidepressiva_overige | Seed 3: ATT = 11.7248, SE = 14.5061, p = 0.46426\n",
      "✅ SUBCAT_Antidepressiva_overige | Seed 4: ATT = 9.5748, SE = 12.3129, p = 0.48022\n",
      "✅ SUBCAT_Antidepressiva_overige | Seed 5: ATT = 13.5947, SE = 12.5638, p = 0.34010\n",
      "✅ SUBCAT_Antidepressiva_overige | Seed 6: ATT = 10.7605, SE = 9.7988, p = 0.33380\n",
      "✅ SUBCAT_Antidepressiva_overige | Seed 7: ATT = 6.5177, SE = 9.7541, p = 0.54058\n",
      "✅ SUBCAT_Antidepressiva_overige | Seed 8: ATT = 10.4978, SE = 9.6072, p = 0.33592\n",
      "✅ SUBCAT_Antidepressiva_overige | Seed 9: ATT = 2.4292, SE = 11.8268, p = 0.84729\n",
      "✅ SUBCAT_Antidepressiva_overige | Seed 10: ATT = 7.9512, SE = 9.1784, p = 0.43520\n",
      "📊 Diagnostic plots saved for SUBCAT_Antidepressiva_overige\n",
      "🏆 Best result for SUBCAT_Antidepressiva_overige → Seed 1 | SE = 6.6929\n",
      "\n",
      "🚀 Running OLS for SUBCAT_Systemische_antihistaminica\n",
      "✅ SUBCAT_Systemische_antihistaminica | Seed 1: ATT = 4.3101, SE = 4.5236, p = 0.39464\n",
      "✅ SUBCAT_Systemische_antihistaminica | Seed 2: ATT = 3.9731, SE = 3.6765, p = 0.34066\n",
      "✅ SUBCAT_Systemische_antihistaminica | Seed 3: ATT = 7.9089, SE = 4.8430, p = 0.17780\n",
      "✅ SUBCAT_Systemische_antihistaminica | Seed 4: ATT = 9.8883, SE = 4.2782, p = 0.08191\n",
      "✅ SUBCAT_Systemische_antihistaminica | Seed 5: ATT = 4.2591, SE = 6.4156, p = 0.54308\n",
      "✅ SUBCAT_Systemische_antihistaminica | Seed 6: ATT = 7.0666, SE = 6.9782, p = 0.36850\n",
      "✅ SUBCAT_Systemische_antihistaminica | Seed 7: ATT = 5.2280, SE = 4.5131, p = 0.31115\n",
      "✅ SUBCAT_Systemische_antihistaminica | Seed 8: ATT = 9.0331, SE = 5.0683, p = 0.14929\n",
      "✅ SUBCAT_Systemische_antihistaminica | Seed 9: ATT = 6.4804, SE = 6.5276, p = 0.37702\n",
      "✅ SUBCAT_Systemische_antihistaminica | Seed 10: ATT = 6.8974, SE = 4.1278, p = 0.17005\n",
      "📊 Diagnostic plots saved for SUBCAT_Systemische_antihistaminica\n",
      "🏆 Best result for SUBCAT_Systemische_antihistaminica → Seed 2 | SE = 3.6765\n",
      "\n",
      "🚀 Running OLS for SUBCAT_anxiolytica_Benzodiazepine\n",
      "✅ SUBCAT_anxiolytica_Benzodiazepine | Seed 1: ATT = 1.2919, SE = 1.6237, p = 0.47081\n",
      "✅ SUBCAT_anxiolytica_Benzodiazepine | Seed 2: ATT = 0.6791, SE = 1.1835, p = 0.59680\n",
      "✅ SUBCAT_anxiolytica_Benzodiazepine | Seed 3: ATT = 0.3856, SE = 1.7039, p = 0.83208\n",
      "✅ SUBCAT_anxiolytica_Benzodiazepine | Seed 4: ATT = 0.8551, SE = 1.0258, p = 0.45142\n",
      "✅ SUBCAT_anxiolytica_Benzodiazepine | Seed 5: ATT = 1.1942, SE = 1.3174, p = 0.41598\n",
      "✅ SUBCAT_anxiolytica_Benzodiazepine | Seed 6: ATT = 1.6841, SE = 1.5246, p = 0.33131\n",
      "✅ SUBCAT_anxiolytica_Benzodiazepine | Seed 7: ATT = 0.8469, SE = 1.6945, p = 0.64347\n",
      "✅ SUBCAT_anxiolytica_Benzodiazepine | Seed 8: ATT = 0.4546, SE = 1.1857, p = 0.72094\n",
      "✅ SUBCAT_anxiolytica_Benzodiazepine | Seed 9: ATT = 0.6249, SE = 1.2290, p = 0.63788\n",
      "✅ SUBCAT_anxiolytica_Benzodiazepine | Seed 10: ATT = 0.8127, SE = 1.1328, p = 0.51280\n",
      "📊 Diagnostic plots saved for SUBCAT_anxiolytica_Benzodiazepine\n",
      "🏆 Best result for SUBCAT_anxiolytica_Benzodiazepine → Seed 4 | SE = 1.0258\n",
      "\n",
      "🚀 Running OLS for SUBCAT_hypnotica_Benzodiazepine\n",
      "✅ SUBCAT_hypnotica_Benzodiazepine | Seed 1: ATT = -0.3818, SE = 1.9967, p = 0.85768\n",
      "✅ SUBCAT_hypnotica_Benzodiazepine | Seed 2: ATT = -0.2156, SE = 2.5864, p = 0.93758\n",
      "✅ SUBCAT_hypnotica_Benzodiazepine | Seed 3: ATT = 1.0157, SE = 2.9714, p = 0.74969\n",
      "✅ SUBCAT_hypnotica_Benzodiazepine | Seed 4: ATT = -0.6285, SE = 2.4390, p = 0.80936\n",
      "✅ SUBCAT_hypnotica_Benzodiazepine | Seed 5: ATT = -1.0986, SE = 2.5673, p = 0.69074\n",
      "✅ SUBCAT_hypnotica_Benzodiazepine | Seed 6: ATT = 0.6628, SE = 2.5038, p = 0.80430\n",
      "✅ SUBCAT_hypnotica_Benzodiazepine | Seed 7: ATT = 0.1270, SE = 2.8331, p = 0.96640\n",
      "✅ SUBCAT_hypnotica_Benzodiazepine | Seed 8: ATT = 0.0457, SE = 2.7367, p = 0.98749\n",
      "✅ SUBCAT_hypnotica_Benzodiazepine | Seed 9: ATT = 0.6978, SE = 3.2913, p = 0.84247\n",
      "✅ SUBCAT_hypnotica_Benzodiazepine | Seed 10: ATT = 0.3493, SE = 3.3810, p = 0.92268\n",
      "📊 Diagnostic plots saved for SUBCAT_hypnotica_Benzodiazepine\n",
      "🏆 Best result for SUBCAT_hypnotica_Benzodiazepine → Seed 1 | SE = 1.9967\n",
      "\n",
      "🚀 Running OLS for SUBCAT_Amfetaminen\n",
      "✅ SUBCAT_Amfetaminen | Seed 1: ATT = 4.7398, SE = 12.8867, p = 0.73165\n",
      "✅ SUBCAT_Amfetaminen | Seed 2: ATT = 5.0397, SE = 9.2567, p = 0.61507\n",
      "✅ SUBCAT_Amfetaminen | Seed 3: ATT = 7.1846, SE = 4.7428, p = 0.20439\n",
      "✅ SUBCAT_Amfetaminen | Seed 4: ATT = -4.4134, SE = 14.4245, p = 0.77490\n",
      "✅ SUBCAT_Amfetaminen | Seed 5: ATT = -4.3009, SE = 11.6962, p = 0.73172\n",
      "✅ SUBCAT_Amfetaminen | Seed 6: ATT = -0.9758, SE = 7.8814, p = 0.90744\n",
      "✅ SUBCAT_Amfetaminen | Seed 7: ATT = -3.7897, SE = 24.0512, p = 0.88243\n",
      "✅ SUBCAT_Amfetaminen | Seed 8: ATT = 3.1204, SE = 6.8249, p = 0.67125\n",
      "✅ SUBCAT_Amfetaminen | Seed 9: ATT = -0.8252, SE = 10.2184, p = 0.93952\n",
      "✅ SUBCAT_Amfetaminen | Seed 10: ATT = -1.9017, SE = 14.9000, p = 0.90460\n",
      "📊 Diagnostic plots saved for SUBCAT_Amfetaminen\n",
      "🏆 Best result for SUBCAT_Amfetaminen → Seed 3 | SE = 4.7428\n",
      "\n",
      "🚀 Running OLS for SUBCAT_Paracetamol_mono\n",
      "✅ SUBCAT_Paracetamol_mono | Seed 1: ATT = 2.9156, SE = 11.6018, p = 0.81396\n",
      "✅ SUBCAT_Paracetamol_mono | Seed 2: ATT = 9.3936, SE = 10.1495, p = 0.40708\n",
      "✅ SUBCAT_Paracetamol_mono | Seed 3: ATT = 5.2962, SE = 11.4557, p = 0.66788\n",
      "✅ SUBCAT_Paracetamol_mono | Seed 4: ATT = 10.2770, SE = 10.6850, p = 0.39061\n",
      "✅ SUBCAT_Paracetamol_mono | Seed 5: ATT = 1.4535, SE = 10.4121, p = 0.89572\n",
      "✅ SUBCAT_Paracetamol_mono | Seed 6: ATT = -2.2843, SE = 12.6554, p = 0.86553\n",
      "✅ SUBCAT_Paracetamol_mono | Seed 7: ATT = -0.9634, SE = 5.8716, p = 0.87763\n",
      "✅ SUBCAT_Paracetamol_mono | Seed 8: ATT = 8.8461, SE = 14.9161, p = 0.58505\n",
      "✅ SUBCAT_Paracetamol_mono | Seed 9: ATT = 6.1999, SE = 5.5280, p = 0.32484\n",
      "✅ SUBCAT_Paracetamol_mono | Seed 10: ATT = 7.3336, SE = 12.3353, p = 0.58416\n",
      "📊 Diagnostic plots saved for SUBCAT_Paracetamol_mono\n",
      "🏆 Best result for SUBCAT_Paracetamol_mono → Seed 9 | SE = 5.5280\n",
      "\n",
      "🚀 Running OLS for SUBCAT_Anti_epileptica_stemmingsstabilisatoren\n",
      "✅ SUBCAT_Anti_epileptica_stemmingsstabilisatoren | Seed 1: ATT = 9.6708, SE = 3.7045, p = 0.05939\n",
      "✅ SUBCAT_Anti_epileptica_stemmingsstabilisatoren | Seed 2: ATT = 8.1325, SE = 3.2230, p = 0.06513\n",
      "✅ SUBCAT_Anti_epileptica_stemmingsstabilisatoren | Seed 3: ATT = 8.5645, SE = 5.7114, p = 0.20811\n",
      "✅ SUBCAT_Anti_epileptica_stemmingsstabilisatoren | Seed 4: ATT = 8.9345, SE = 6.0253, p = 0.21226\n",
      "✅ SUBCAT_Anti_epileptica_stemmingsstabilisatoren | Seed 5: ATT = 9.3182, SE = 6.2617, p = 0.21094\n",
      "✅ SUBCAT_Anti_epileptica_stemmingsstabilisatoren | Seed 6: ATT = 8.4425, SE = 5.4160, p = 0.19405\n",
      "✅ SUBCAT_Anti_epileptica_stemmingsstabilisatoren | Seed 7: ATT = 12.1103, SE = 8.6894, p = 0.23586\n",
      "✅ SUBCAT_Anti_epileptica_stemmingsstabilisatoren | Seed 8: ATT = 9.1248, SE = 8.5726, p = 0.34713\n",
      "✅ SUBCAT_Anti_epileptica_stemmingsstabilisatoren | Seed 9: ATT = 7.9425, SE = 8.6475, p = 0.41034\n",
      "✅ SUBCAT_Anti_epileptica_stemmingsstabilisatoren | Seed 10: ATT = 12.0269, SE = 3.8691, p = 0.03592\n",
      "📊 Diagnostic plots saved for SUBCAT_Anti_epileptica_stemmingsstabilisatoren\n",
      "🏆 Best result for SUBCAT_Anti_epileptica_stemmingsstabilisatoren → Seed 2 | SE = 3.2230\n",
      "\n",
      "🚀 Running OLS for SUBCAT_Opioden\n",
      "✅ SUBCAT_Opioden | Seed 1: ATT = 0.0849, SE = 6.9953, p = 0.99089\n",
      "✅ SUBCAT_Opioden | Seed 2: ATT = -0.3443, SE = 5.5783, p = 0.95374\n",
      "✅ SUBCAT_Opioden | Seed 3: ATT = -2.1501, SE = 5.6914, p = 0.72478\n",
      "✅ SUBCAT_Opioden | Seed 4: ATT = -1.3219, SE = 5.0212, p = 0.80535\n",
      "✅ SUBCAT_Opioden | Seed 5: ATT = -2.3189, SE = 5.2592, p = 0.68205\n",
      "✅ SUBCAT_Opioden | Seed 6: ATT = -2.8233, SE = 3.9296, p = 0.51220\n",
      "✅ SUBCAT_Opioden | Seed 7: ATT = -2.5104, SE = 5.0557, p = 0.64555\n",
      "✅ SUBCAT_Opioden | Seed 8: ATT = -4.7592, SE = 3.5811, p = 0.25459\n",
      "✅ SUBCAT_Opioden | Seed 9: ATT = -2.3809, SE = 4.9162, p = 0.65350\n",
      "✅ SUBCAT_Opioden | Seed 10: ATT = 2.3357, SE = 4.9425, p = 0.66114\n",
      "📊 Diagnostic plots saved for SUBCAT_Opioden\n",
      "🏆 Best result for SUBCAT_Opioden → Seed 8 | SE = 3.5811\n",
      "\n",
      "🚀 Running OLS for SUBCAT_Z_drugs\n",
      "✅ SUBCAT_Z_drugs | Seed 1: ATT = 12.5377, SE = 4.6117, p = 0.05306\n",
      "✅ SUBCAT_Z_drugs | Seed 2: ATT = 13.0552, SE = 5.7957, p = 0.08740\n",
      "✅ SUBCAT_Z_drugs | Seed 3: ATT = 8.5675, SE = 5.3241, p = 0.18286\n",
      "✅ SUBCAT_Z_drugs | Seed 4: ATT = 13.9728, SE = 5.0175, p = 0.04957\n",
      "✅ SUBCAT_Z_drugs | Seed 5: ATT = 11.1974, SE = 5.3233, p = 0.10325\n",
      "✅ SUBCAT_Z_drugs | Seed 6: ATT = 10.9362, SE = 3.6806, p = 0.04109\n",
      "✅ SUBCAT_Z_drugs | Seed 7: ATT = 8.7653, SE = 3.5058, p = 0.06675\n",
      "✅ SUBCAT_Z_drugs | Seed 8: ATT = 10.9447, SE = 5.8368, p = 0.13404\n",
      "✅ SUBCAT_Z_drugs | Seed 9: ATT = 11.5570, SE = 4.0836, p = 0.04734\n",
      "✅ SUBCAT_Z_drugs | Seed 10: ATT = 15.2423, SE = 4.4240, p = 0.02616\n",
      "📊 Diagnostic plots saved for SUBCAT_Z_drugs\n",
      "🏆 Best result for SUBCAT_Z_drugs → Seed 7 | SE = 3.5058\n",
      "\n",
      "🚀 Running OLS for SUBCAT_NSAIDs\n",
      "✅ SUBCAT_NSAIDs | Seed 1: ATT = 3.5478, SE = 7.6752, p = 0.66793\n",
      "✅ SUBCAT_NSAIDs | Seed 2: ATT = -1.4150, SE = 7.2747, p = 0.85526\n",
      "✅ SUBCAT_NSAIDs | Seed 3: ATT = -9.6453, SE = 7.8294, p = 0.28544\n",
      "✅ SUBCAT_NSAIDs | Seed 4: ATT = -3.0747, SE = 9.3299, p = 0.75827\n",
      "✅ SUBCAT_NSAIDs | Seed 5: ATT = -3.6434, SE = 10.3055, p = 0.74153\n",
      "✅ SUBCAT_NSAIDs | Seed 6: ATT = -1.8107, SE = 9.1219, p = 0.85234\n",
      "✅ SUBCAT_NSAIDs | Seed 7: ATT = -1.3110, SE = 8.3416, p = 0.88273\n",
      "✅ SUBCAT_NSAIDs | Seed 8: ATT = -9.9619, SE = 7.1343, p = 0.23511\n",
      "✅ SUBCAT_NSAIDs | Seed 9: ATT = 5.9558, SE = 7.2480, p = 0.45739\n",
      "✅ SUBCAT_NSAIDs | Seed 10: ATT = 2.1345, SE = 12.5931, p = 0.87363\n",
      "📊 Diagnostic plots saved for SUBCAT_NSAIDs\n",
      "🏆 Best result for SUBCAT_NSAIDs → Seed 8 | SE = 7.1343\n",
      "\n",
      "🎯 All summary files saved.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import t, probplot\n",
    "import xgboost as xgb\n",
    "\n",
    "# -----------------------------\n",
    "# Configuration\n",
    "# -----------------------------\n",
    "seeds = list(range(1, 11))\n",
    "imputations = 5\n",
    "output_folder = \"outputs\"\n",
    "\n",
    "# -----------------------------\n",
    "# Diagnostic Plotting Function\n",
    "# -----------------------------\n",
    "def create_diagnostic_plots(residuals_data, fitted_data, group_name):\n",
    "    \"\"\"Create 4 diagnostic plots for model validation\"\"\"\n",
    "    plots_dir = os.path.join(output_folder, \"plots\")\n",
    "    os.makedirs(plots_dir, exist_ok=True)\n",
    "    \n",
    "    # Flatten the collected data\n",
    "    all_residuals = np.concatenate(residuals_data)\n",
    "    all_fitted = np.concatenate(fitted_data)\n",
    "    \n",
    "    # Create figure with 2x2 subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    fig.suptitle(f'Diagnostic Plots - {group_name}', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. Residuals vs Fitted\n",
    "    axes[0,0].scatter(all_fitted, all_residuals, alpha=0.6, s=20)\n",
    "    axes[0,0].axhline(y=0, color='red', linestyle='--', alpha=0.8)\n",
    "    axes[0,0].set_xlabel('Fitted Values')\n",
    "    axes[0,0].set_ylabel('Residuals')\n",
    "    axes[0,0].set_title('Residuals vs Fitted')\n",
    "    axes[0,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. QQ Plot\n",
    "    probplot(all_residuals, dist=\"norm\", plot=axes[0,1])\n",
    "    axes[0,1].set_title('Q-Q Plot (Normal)')\n",
    "    axes[0,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Residual Histogram\n",
    "    axes[1,0].hist(all_residuals, bins=30, density=True, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    axes[1,0].set_xlabel('Residuals')\n",
    "    axes[1,0].set_ylabel('Density')\n",
    "    axes[1,0].set_title('Residual Distribution')\n",
    "    axes[1,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Scale-Location Plot\n",
    "    sqrt_abs_residuals = np.sqrt(np.abs(all_residuals))\n",
    "    axes[1,1].scatter(all_fitted, sqrt_abs_residuals, alpha=0.6, s=20)\n",
    "    axes[1,1].set_xlabel('Fitted Values')\n",
    "    axes[1,1].set_ylabel('√|Residuals|')\n",
    "    axes[1,1].set_title('Scale-Location Plot')\n",
    "    axes[1,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save plot\n",
    "    plot_filename = os.path.join(plots_dir, f'{group_name}.png')\n",
    "    plt.savefig(plot_filename, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"📊 Diagnostic plots saved for {group_name}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Rubin's Rule\n",
    "# -----------------------------\n",
    "def rubins_pool(estimates, ses):\n",
    "    m = len(estimates)\n",
    "    q_bar = np.mean(estimates)\n",
    "    u_bar = np.mean(np.square(ses))\n",
    "    b_m = np.var(estimates, ddof=1)\n",
    "    total_var = u_bar + ((1 + 1/m) * b_m)\n",
    "    total_se = np.sqrt(total_var)\n",
    "    ci_lower = q_bar - 1.96 * total_se\n",
    "    ci_upper = q_bar + 1.96 * total_se\n",
    "    p_value = 2 * (1 - t.cdf(np.abs(q_bar / total_se), df=m-1))\n",
    "    rounded_p = round(p_value, 5)\n",
    "    formatted_p = \"< 0.00001\" if rounded_p <= 0.00001 else f\"{rounded_p:.5f}\"\n",
    "    return q_bar, total_se, ci_lower, ci_upper, formatted_p\n",
    "\n",
    "# -----------------------------\n",
    "# SMD + Variance Ratio\n",
    "# -----------------------------\n",
    "def calculate_smd_vr(X, T, weights):\n",
    "    treated = X[T == 1]\n",
    "    control = X[T == 0]\n",
    "    w_treated = weights[T == 1]\n",
    "    w_control = weights[T == 0]\n",
    "    smd, vr = [], []\n",
    "    for col in X.columns:\n",
    "        try:\n",
    "            m1, m0 = np.average(treated[col], weights=w_treated), np.average(control[col], weights=w_control)\n",
    "            s1 = np.sqrt(np.average((treated[col] - m1) ** 2, weights=w_treated))\n",
    "            s0 = np.sqrt(np.average((control[col] - m0) ** 2, weights=w_control))\n",
    "            pooled_sd = np.sqrt((s1 ** 2 + s0 ** 2) / 2)\n",
    "            smd.append((m1 - m0) / pooled_sd if pooled_sd > 0 else 0)\n",
    "            vr.append(s1**2 / s0**2 if s0**2 > 0 else 0)\n",
    "        except Exception:\n",
    "            smd.append(np.nan)\n",
    "            vr.append(np.nan)\n",
    "    return np.nanmean(smd), np.nanmean(vr)\n",
    "\n",
    "# -----------------------------\n",
    "# OLS Main Loop\n",
    "# -----------------------------\n",
    "def run_dml_with_trimmed_data(final_covariates_map):\n",
    "    att_results = []\n",
    "    balance_results = []\n",
    "\n",
    "    for group, covariates in final_covariates_map.items():\n",
    "        print(f\"\\n🚀 Running OLS for {group}\")\n",
    "        group_dir = os.path.join(output_folder, group)\n",
    "        os.makedirs(group_dir, exist_ok=True)\n",
    "\n",
    "        best_result = None\n",
    "        best_se = float(\"inf\")\n",
    "        \n",
    "        # Initialize lists to collect residuals and fitted values for diagnostic plots\n",
    "        group_residuals = []\n",
    "        group_fitted = []\n",
    "\n",
    "        for seed in seeds:\n",
    "            # Set random seed for this iteration\n",
    "            np.random.seed(seed)\n",
    "            \n",
    "            att_list, se_list, r2_list, rmse_list, smd_list, vr_list = [], [], [], [], [], []\n",
    "\n",
    "            for imp in range(1, imputations + 1):\n",
    "                file_path = os.path.join(group_dir, f\"trimmed_data_imp{imp}.pkl\")\n",
    "                if not os.path.exists(file_path):\n",
    "                    continue\n",
    "\n",
    "                df = pd.read_pickle(file_path)\n",
    "                if group not in df.columns or \"iptw\" not in df.columns:\n",
    "                    continue\n",
    "\n",
    "                # Add bootstrap sampling with seed-based randomization\n",
    "                n_samples = len(df)\n",
    "                bootstrap_idx = np.random.choice(n_samples, size=n_samples, replace=True)\n",
    "                df_bootstrap = df.iloc[bootstrap_idx].reset_index(drop=True)\n",
    "\n",
    "                X = df_bootstrap[covariates].copy()\n",
    "                T = df_bootstrap[group]\n",
    "                Y = df_bootstrap[\"caps5_change_baseline\"]\n",
    "                W = df_bootstrap[\"iptw\"]\n",
    "\n",
    "                try:\n",
    "                    # Create design matrix with treatment variable and covariates\n",
    "                    X_ols = pd.concat([T, X], axis=1)\n",
    "                    X_ols = sm.add_constant(X_ols)\n",
    "                    \n",
    "                    # Fit weighted OLS with robust standard errors\n",
    "                    ols_model = sm.WLS(Y, X_ols, weights=W).fit(cov_type='HC1')\n",
    "                    \n",
    "                    # Extract treatment effect (coefficient of treatment variable)\n",
    "                    att = ols_model.params[group]  # Treatment coefficient\n",
    "                    se = ols_model.bse[group]  # Robust standard error for treatment\n",
    "                    \n",
    "                    att_list.append(att)\n",
    "                    se_list.append(se)\n",
    "\n",
    "                    # Calculate model fit statistics\n",
    "                    Y_pred = ols_model.fittedvalues\n",
    "                    residuals = ols_model.resid\n",
    "                    rmse = mean_squared_error(Y, Y_pred, squared=False)\n",
    "                    r2 = ols_model.rsquared\n",
    "                    r2_list.append(r2)\n",
    "                    rmse_list.append(rmse)\n",
    "                    \n",
    "                    # Collect residuals and fitted values for diagnostic plots\n",
    "                    group_residuals.append(residuals.values)\n",
    "                    group_fitted.append(Y_pred.values)\n",
    "\n",
    "                    smd, vr = calculate_smd_vr(X, T, W)\n",
    "                    smd_list.append(smd)\n",
    "                    vr_list.append(vr)\n",
    "                except Exception as e:\n",
    "                    print(f\"⚠️ Error in {group}, seed {seed}, imp {imp}: {e}\")\n",
    "\n",
    "            if att_list:\n",
    "                att, se, ci_l, ci_u, p_val = rubins_pool(att_list, se_list)\n",
    "                avg_r2 = np.mean(r2_list)\n",
    "                avg_rmse = np.mean(rmse_list)\n",
    "                avg_smd = np.mean(smd_list)\n",
    "                avg_vr = np.mean(vr_list)\n",
    "\n",
    "                balance_results.append({\n",
    "                    \"group\": group, \"seed\": seed, \"smd\": avg_smd, \"vr\": avg_vr\n",
    "                })\n",
    "\n",
    "                if se < best_se:\n",
    "                    best_se = se\n",
    "                    best_result = {\n",
    "                        \"group\": group, \"seed\": seed, \"att\": att, \"se\": se,\n",
    "                        \"ci_lower\": ci_l, \"ci_upper\": ci_u, \"p_value\": p_val,\n",
    "                        \"r2\": avg_r2, \"rmse\": avg_rmse\n",
    "                    }\n",
    "\n",
    "                print(f\"✅ {group} | Seed {seed}: ATT = {att:.4f}, SE = {se:.4f}, p = {p_val}\")\n",
    "            else:\n",
    "                print(f\"⚠️ No valid results for {group} | Seed {seed}\")\n",
    "\n",
    "        # Create diagnostic plots for this group\n",
    "        if group_residuals and group_fitted:\n",
    "            create_diagnostic_plots(group_residuals, group_fitted, group)\n",
    "\n",
    "        if best_result:\n",
    "            att_results.append(best_result)\n",
    "            print(f\"🏆 Best result for {group} → Seed {best_result['seed']} | SE = {best_result['se']:.4f}\")\n",
    "\n",
    "    # Save final output\n",
    "    pd.DataFrame(att_results).to_excel(\"ols_summary_subcats.xlsx\", index=False)\n",
    "    pd.DataFrame(balance_results).to_excel(\"smd_vr_summary_subcats.xlsx\", index=False)\n",
    "    print(\"\\n🎯 All summary files saved.\")\n",
    "\n",
    "run_dml_with_trimmed_data(final_covariates_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "77b5527d-29d9-44b7-8752-8a6b09a1f2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unweighted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "7516480b-1b75-46c0-ba11-ddb32e50c668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Running OLS for SUBCAT_Antipsychotica_atypisch\n",
      "✅ SUBCAT_Antipsychotica_atypisch | Seed 1: ATT = -0.0374, SE = 8.1953, p = 0.99658\n",
      "✅ SUBCAT_Antipsychotica_atypisch | Seed 2: ATT = 0.0678, SE = 7.0955, p = 0.99284\n",
      "✅ SUBCAT_Antipsychotica_atypisch | Seed 3: ATT = -1.3636, SE = 7.3444, p = 0.86174\n",
      "✅ SUBCAT_Antipsychotica_atypisch | Seed 4: ATT = 0.6255, SE = 10.5174, p = 0.95543\n",
      "✅ SUBCAT_Antipsychotica_atypisch | Seed 5: ATT = 0.3015, SE = 6.2969, p = 0.96411\n",
      "✅ SUBCAT_Antipsychotica_atypisch | Seed 6: ATT = 3.0491, SE = 7.6157, p = 0.70934\n",
      "✅ SUBCAT_Antipsychotica_atypisch | Seed 7: ATT = 4.8450, SE = 8.5345, p = 0.60059\n",
      "✅ SUBCAT_Antipsychotica_atypisch | Seed 8: ATT = -3.4059, SE = 8.3208, p = 0.70327\n",
      "✅ SUBCAT_Antipsychotica_atypisch | Seed 9: ATT = 3.7405, SE = 6.9034, p = 0.61670\n",
      "✅ SUBCAT_Antipsychotica_atypisch | Seed 10: ATT = -0.7554, SE = 10.1639, p = 0.94433\n",
      "📊 Diagnostic plots saved for SUBCAT_Antipsychotica_atypisch\n",
      "🏆 Best result for SUBCAT_Antipsychotica_atypisch → Seed 5 | SE = 6.2969\n",
      "\n",
      "🚀 Running OLS for SUBCAT_TCA\n",
      "✅ SUBCAT_TCA | Seed 1: ATT = 3.8290, SE = 3.8979, p = 0.38155\n",
      "✅ SUBCAT_TCA | Seed 2: ATT = 3.6143, SE = 3.2360, p = 0.32660\n",
      "✅ SUBCAT_TCA | Seed 3: ATT = 1.8528, SE = 3.7999, p = 0.65135\n",
      "✅ SUBCAT_TCA | Seed 4: ATT = 2.8772, SE = 3.7464, p = 0.48531\n",
      "✅ SUBCAT_TCA | Seed 5: ATT = 5.5370, SE = 4.8451, p = 0.31688\n",
      "✅ SUBCAT_TCA | Seed 6: ATT = 5.7017, SE = 3.1529, p = 0.14482\n",
      "✅ SUBCAT_TCA | Seed 7: ATT = 2.1365, SE = 3.5967, p = 0.58447\n",
      "✅ SUBCAT_TCA | Seed 8: ATT = 3.0918, SE = 4.0854, p = 0.49131\n",
      "✅ SUBCAT_TCA | Seed 9: ATT = 5.0538, SE = 4.4190, p = 0.31656\n",
      "✅ SUBCAT_TCA | Seed 10: ATT = 5.0093, SE = 3.7725, p = 0.25494\n",
      "📊 Diagnostic plots saved for SUBCAT_TCA\n",
      "🏆 Best result for SUBCAT_TCA → Seed 6 | SE = 3.1529\n",
      "\n",
      "🚀 Running OLS for SUBCAT_SSRI\n",
      "✅ SUBCAT_SSRI | Seed 1: ATT = -0.4442, SE = 1.4815, p = 0.77925\n",
      "✅ SUBCAT_SSRI | Seed 2: ATT = -1.0641, SE = 1.2035, p = 0.42653\n",
      "✅ SUBCAT_SSRI | Seed 3: ATT = -0.9062, SE = 1.2372, p = 0.50452\n",
      "✅ SUBCAT_SSRI | Seed 4: ATT = -0.9468, SE = 0.8745, p = 0.33985\n",
      "✅ SUBCAT_SSRI | Seed 5: ATT = -1.1398, SE = 0.9725, p = 0.30624\n",
      "✅ SUBCAT_SSRI | Seed 6: ATT = -0.6221, SE = 0.8915, p = 0.52375\n",
      "✅ SUBCAT_SSRI | Seed 7: ATT = -0.2696, SE = 0.9956, p = 0.79993\n",
      "✅ SUBCAT_SSRI | Seed 8: ATT = -0.5998, SE = 0.8886, p = 0.53671\n",
      "✅ SUBCAT_SSRI | Seed 9: ATT = 0.0432, SE = 1.0017, p = 0.96768\n",
      "✅ SUBCAT_SSRI | Seed 10: ATT = -0.8227, SE = 1.1231, p = 0.50445\n",
      "📊 Diagnostic plots saved for SUBCAT_SSRI\n",
      "🏆 Best result for SUBCAT_SSRI → Seed 4 | SE = 0.8745\n",
      "\n",
      "🚀 Running OLS for SUBCAT_SNRI\n",
      "✅ SUBCAT_SNRI | Seed 1: ATT = 3.6044, SE = 3.4895, p = 0.36000\n",
      "✅ SUBCAT_SNRI | Seed 2: ATT = 5.5741, SE = 2.7358, p = 0.11127\n",
      "✅ SUBCAT_SNRI | Seed 3: ATT = 3.9432, SE = 3.4251, p = 0.31376\n",
      "✅ SUBCAT_SNRI | Seed 4: ATT = 3.9164, SE = 4.7980, p = 0.46017\n",
      "✅ SUBCAT_SNRI | Seed 5: ATT = 5.7465, SE = 5.3565, p = 0.34377\n",
      "✅ SUBCAT_SNRI | Seed 6: ATT = 5.6761, SE = 3.7747, p = 0.20709\n",
      "✅ SUBCAT_SNRI | Seed 7: ATT = 4.1889, SE = 5.1039, p = 0.45790\n",
      "✅ SUBCAT_SNRI | Seed 8: ATT = 4.8217, SE = 5.0950, p = 0.39756\n",
      "✅ SUBCAT_SNRI | Seed 9: ATT = 3.6293, SE = 3.7042, p = 0.38267\n",
      "✅ SUBCAT_SNRI | Seed 10: ATT = 3.9736, SE = 5.3368, p = 0.49790\n",
      "📊 Diagnostic plots saved for SUBCAT_SNRI\n",
      "🏆 Best result for SUBCAT_SNRI → Seed 2 | SE = 2.7358\n",
      "\n",
      "🚀 Running OLS for SUBCAT_Tetracyclische_antidepressiva\n",
      "✅ SUBCAT_Tetracyclische_antidepressiva | Seed 1: ATT = 6.5121, SE = 3.9412, p = 0.17381\n",
      "✅ SUBCAT_Tetracyclische_antidepressiva | Seed 2: ATT = 4.7696, SE = 3.1218, p = 0.20127\n",
      "✅ SUBCAT_Tetracyclische_antidepressiva | Seed 3: ATT = 4.3972, SE = 3.1845, p = 0.23948\n",
      "✅ SUBCAT_Tetracyclische_antidepressiva | Seed 4: ATT = 7.8938, SE = 3.9882, p = 0.11889\n",
      "✅ SUBCAT_Tetracyclische_antidepressiva | Seed 5: ATT = 5.7658, SE = 4.3955, p = 0.25982\n",
      "✅ SUBCAT_Tetracyclische_antidepressiva | Seed 6: ATT = 4.7582, SE = 3.3984, p = 0.23407\n",
      "✅ SUBCAT_Tetracyclische_antidepressiva | Seed 7: ATT = 5.1094, SE = 4.0580, p = 0.27646\n",
      "✅ SUBCAT_Tetracyclische_antidepressiva | Seed 8: ATT = 4.8028, SE = 3.3776, p = 0.22810\n",
      "✅ SUBCAT_Tetracyclische_antidepressiva | Seed 9: ATT = 5.5011, SE = 3.5802, p = 0.19921\n",
      "✅ SUBCAT_Tetracyclische_antidepressiva | Seed 10: ATT = 6.0853, SE = 3.9683, p = 0.19994\n",
      "📊 Diagnostic plots saved for SUBCAT_Tetracyclische_antidepressiva\n",
      "🏆 Best result for SUBCAT_Tetracyclische_antidepressiva → Seed 2 | SE = 3.1218\n",
      "\n",
      "🚀 Running OLS for SUBCAT_Antidepressiva_overige\n",
      "✅ SUBCAT_Antidepressiva_overige | Seed 1: ATT = 9.0494, SE = 7.4970, p = 0.29390\n",
      "✅ SUBCAT_Antidepressiva_overige | Seed 2: ATT = 0.6556, SE = 8.8554, p = 0.94454\n",
      "✅ SUBCAT_Antidepressiva_overige | Seed 3: ATT = 11.4645, SE = 14.8413, p = 0.48294\n",
      "✅ SUBCAT_Antidepressiva_overige | Seed 4: ATT = 10.4065, SE = 15.1419, p = 0.52969\n",
      "✅ SUBCAT_Antidepressiva_overige | Seed 5: ATT = 12.9605, SE = 12.9235, p = 0.37267\n",
      "✅ SUBCAT_Antidepressiva_overige | Seed 6: ATT = 9.8715, SE = 8.7797, p = 0.32377\n",
      "✅ SUBCAT_Antidepressiva_overige | Seed 7: ATT = 6.1761, SE = 9.7895, p = 0.56236\n",
      "✅ SUBCAT_Antidepressiva_overige | Seed 8: ATT = 8.4328, SE = 8.6810, p = 0.38635\n",
      "✅ SUBCAT_Antidepressiva_overige | Seed 9: ATT = 0.5585, SE = 11.9323, p = 0.96491\n",
      "✅ SUBCAT_Antidepressiva_overige | Seed 10: ATT = 7.1198, SE = 9.4736, p = 0.49413\n",
      "📊 Diagnostic plots saved for SUBCAT_Antidepressiva_overige\n",
      "🏆 Best result for SUBCAT_Antidepressiva_overige → Seed 1 | SE = 7.4970\n",
      "\n",
      "🚀 Running OLS for SUBCAT_Systemische_antihistaminica\n",
      "✅ SUBCAT_Systemische_antihistaminica | Seed 1: ATT = 4.4678, SE = 4.8536, p = 0.40939\n",
      "✅ SUBCAT_Systemische_antihistaminica | Seed 2: ATT = 5.7883, SE = 4.4838, p = 0.26628\n",
      "✅ SUBCAT_Systemische_antihistaminica | Seed 3: ATT = 9.5862, SE = 4.8442, p = 0.11895\n",
      "✅ SUBCAT_Systemische_antihistaminica | Seed 4: ATT = 11.3715, SE = 4.8892, p = 0.08062\n",
      "✅ SUBCAT_Systemische_antihistaminica | Seed 5: ATT = 4.2755, SE = 5.7054, p = 0.49529\n",
      "✅ SUBCAT_Systemische_antihistaminica | Seed 6: ATT = 7.4256, SE = 6.7943, p = 0.33583\n",
      "✅ SUBCAT_Systemische_antihistaminica | Seed 7: ATT = 8.1938, SE = 4.6324, p = 0.15165\n",
      "✅ SUBCAT_Systemische_antihistaminica | Seed 8: ATT = 9.9674, SE = 6.7620, p = 0.21448\n",
      "✅ SUBCAT_Systemische_antihistaminica | Seed 9: ATT = 7.4562, SE = 5.9914, p = 0.28126\n",
      "✅ SUBCAT_Systemische_antihistaminica | Seed 10: ATT = 7.1639, SE = 5.1927, p = 0.23981\n",
      "📊 Diagnostic plots saved for SUBCAT_Systemische_antihistaminica\n",
      "🏆 Best result for SUBCAT_Systemische_antihistaminica → Seed 2 | SE = 4.4838\n",
      "\n",
      "🚀 Running OLS for SUBCAT_anxiolytica_Benzodiazepine\n",
      "✅ SUBCAT_anxiolytica_Benzodiazepine | Seed 1: ATT = 1.4458, SE = 1.7573, p = 0.45687\n",
      "✅ SUBCAT_anxiolytica_Benzodiazepine | Seed 2: ATT = 1.0436, SE = 1.2837, p = 0.46185\n",
      "✅ SUBCAT_anxiolytica_Benzodiazepine | Seed 3: ATT = 0.4266, SE = 1.6269, p = 0.80609\n",
      "✅ SUBCAT_anxiolytica_Benzodiazepine | Seed 4: ATT = 1.0329, SE = 1.0478, p = 0.38004\n",
      "✅ SUBCAT_anxiolytica_Benzodiazepine | Seed 5: ATT = 1.2826, SE = 1.5035, p = 0.44169\n",
      "✅ SUBCAT_anxiolytica_Benzodiazepine | Seed 6: ATT = 1.7666, SE = 1.7282, p = 0.36447\n",
      "✅ SUBCAT_anxiolytica_Benzodiazepine | Seed 7: ATT = 1.2792, SE = 2.0413, p = 0.56486\n",
      "✅ SUBCAT_anxiolytica_Benzodiazepine | Seed 8: ATT = 0.4133, SE = 1.3639, p = 0.77696\n",
      "✅ SUBCAT_anxiolytica_Benzodiazepine | Seed 9: ATT = 0.7071, SE = 1.4257, p = 0.64595\n",
      "✅ SUBCAT_anxiolytica_Benzodiazepine | Seed 10: ATT = 0.9735, SE = 1.0348, p = 0.40011\n",
      "📊 Diagnostic plots saved for SUBCAT_anxiolytica_Benzodiazepine\n",
      "🏆 Best result for SUBCAT_anxiolytica_Benzodiazepine → Seed 10 | SE = 1.0348\n",
      "\n",
      "🚀 Running OLS for SUBCAT_hypnotica_Benzodiazepine\n",
      "✅ SUBCAT_hypnotica_Benzodiazepine | Seed 1: ATT = -0.4689, SE = 2.3439, p = 0.85120\n",
      "✅ SUBCAT_hypnotica_Benzodiazepine | Seed 2: ATT = -0.1242, SE = 2.6738, p = 0.96518\n",
      "✅ SUBCAT_hypnotica_Benzodiazepine | Seed 3: ATT = 0.6683, SE = 2.9665, p = 0.83280\n",
      "✅ SUBCAT_hypnotica_Benzodiazepine | Seed 4: ATT = -1.3190, SE = 2.0920, p = 0.56260\n",
      "✅ SUBCAT_hypnotica_Benzodiazepine | Seed 5: ATT = -1.1758, SE = 2.2465, p = 0.62836\n",
      "✅ SUBCAT_hypnotica_Benzodiazepine | Seed 6: ATT = 0.5622, SE = 2.9177, p = 0.85659\n",
      "✅ SUBCAT_hypnotica_Benzodiazepine | Seed 7: ATT = -0.1168, SE = 2.6235, p = 0.96663\n",
      "✅ SUBCAT_hypnotica_Benzodiazepine | Seed 8: ATT = -0.2708, SE = 2.6139, p = 0.92248\n",
      "✅ SUBCAT_hypnotica_Benzodiazepine | Seed 9: ATT = 0.1628, SE = 3.0627, p = 0.96016\n",
      "✅ SUBCAT_hypnotica_Benzodiazepine | Seed 10: ATT = -0.1970, SE = 3.3058, p = 0.95535\n",
      "📊 Diagnostic plots saved for SUBCAT_hypnotica_Benzodiazepine\n",
      "🏆 Best result for SUBCAT_hypnotica_Benzodiazepine → Seed 4 | SE = 2.0920\n",
      "\n",
      "🚀 Running OLS for SUBCAT_Amfetaminen\n",
      "✅ SUBCAT_Amfetaminen | Seed 1: ATT = 6.7900, SE = 13.5882, p = 0.64353\n",
      "✅ SUBCAT_Amfetaminen | Seed 2: ATT = 8.0151, SE = 9.0479, p = 0.42574\n",
      "✅ SUBCAT_Amfetaminen | Seed 3: ATT = 7.4347, SE = 9.0579, p = 0.45786\n",
      "✅ SUBCAT_Amfetaminen | Seed 4: ATT = -6.6639, SE = 15.9638, p = 0.69779\n",
      "✅ SUBCAT_Amfetaminen | Seed 5: ATT = -6.1166, SE = 12.0698, p = 0.63898\n",
      "✅ SUBCAT_Amfetaminen | Seed 6: ATT = -0.9064, SE = 10.7591, p = 0.93691\n",
      "✅ SUBCAT_Amfetaminen | Seed 7: ATT = -2.9375, SE = 24.7121, p = 0.91111\n",
      "✅ SUBCAT_Amfetaminen | Seed 8: ATT = 3.9972, SE = 8.8214, p = 0.67395\n",
      "✅ SUBCAT_Amfetaminen | Seed 9: ATT = -1.1730, SE = 11.1036, p = 0.92095\n",
      "✅ SUBCAT_Amfetaminen | Seed 10: ATT = -2.7156, SE = 15.7527, p = 0.87150\n",
      "📊 Diagnostic plots saved for SUBCAT_Amfetaminen\n",
      "🏆 Best result for SUBCAT_Amfetaminen → Seed 8 | SE = 8.8214\n",
      "\n",
      "🚀 Running OLS for SUBCAT_Paracetamol_mono\n",
      "✅ SUBCAT_Paracetamol_mono | Seed 1: ATT = 3.3031, SE = 10.7251, p = 0.77347\n",
      "✅ SUBCAT_Paracetamol_mono | Seed 2: ATT = 7.1394, SE = 12.3792, p = 0.59503\n",
      "✅ SUBCAT_Paracetamol_mono | Seed 3: ATT = 3.9347, SE = 13.0459, p = 0.77798\n",
      "✅ SUBCAT_Paracetamol_mono | Seed 4: ATT = 10.2203, SE = 10.6814, p = 0.39284\n",
      "✅ SUBCAT_Paracetamol_mono | Seed 5: ATT = 1.3818, SE = 11.2910, p = 0.90850\n",
      "✅ SUBCAT_Paracetamol_mono | Seed 6: ATT = -4.0169, SE = 13.1772, p = 0.77569\n",
      "✅ SUBCAT_Paracetamol_mono | Seed 7: ATT = -2.6395, SE = 9.1492, p = 0.78730\n",
      "✅ SUBCAT_Paracetamol_mono | Seed 8: ATT = 7.3758, SE = 19.2391, p = 0.72095\n",
      "✅ SUBCAT_Paracetamol_mono | Seed 9: ATT = 6.9756, SE = 8.3850, p = 0.45224\n",
      "✅ SUBCAT_Paracetamol_mono | Seed 10: ATT = 7.0032, SE = 12.2869, p = 0.59918\n",
      "📊 Diagnostic plots saved for SUBCAT_Paracetamol_mono\n",
      "🏆 Best result for SUBCAT_Paracetamol_mono → Seed 9 | SE = 8.3850\n",
      "\n",
      "🚀 Running OLS for SUBCAT_Anti_epileptica_stemmingsstabilisatoren\n",
      "✅ SUBCAT_Anti_epileptica_stemmingsstabilisatoren | Seed 1: ATT = 7.6039, SE = 4.4024, p = 0.15920\n",
      "✅ SUBCAT_Anti_epileptica_stemmingsstabilisatoren | Seed 2: ATT = 7.9868, SE = 3.8166, p = 0.10452\n",
      "✅ SUBCAT_Anti_epileptica_stemmingsstabilisatoren | Seed 3: ATT = 7.8009, SE = 4.7949, p = 0.17909\n",
      "✅ SUBCAT_Anti_epileptica_stemmingsstabilisatoren | Seed 4: ATT = 8.0952, SE = 6.1548, p = 0.25875\n",
      "✅ SUBCAT_Anti_epileptica_stemmingsstabilisatoren | Seed 5: ATT = 7.8881, SE = 5.2881, p = 0.21006\n",
      "✅ SUBCAT_Anti_epileptica_stemmingsstabilisatoren | Seed 6: ATT = 7.5652, SE = 5.6098, p = 0.24877\n",
      "✅ SUBCAT_Anti_epileptica_stemmingsstabilisatoren | Seed 7: ATT = 9.7581, SE = 8.9936, p = 0.33894\n",
      "✅ SUBCAT_Anti_epileptica_stemmingsstabilisatoren | Seed 8: ATT = 7.8955, SE = 9.3784, p = 0.44724\n",
      "✅ SUBCAT_Anti_epileptica_stemmingsstabilisatoren | Seed 9: ATT = 5.8963, SE = 7.0395, p = 0.44938\n",
      "✅ SUBCAT_Anti_epileptica_stemmingsstabilisatoren | Seed 10: ATT = 9.7091, SE = 3.8871, p = 0.06693\n",
      "📊 Diagnostic plots saved for SUBCAT_Anti_epileptica_stemmingsstabilisatoren\n",
      "🏆 Best result for SUBCAT_Anti_epileptica_stemmingsstabilisatoren → Seed 2 | SE = 3.8166\n",
      "\n",
      "🚀 Running OLS for SUBCAT_Opioden\n",
      "✅ SUBCAT_Opioden | Seed 1: ATT = 1.1661, SE = 6.4414, p = 0.86515\n",
      "✅ SUBCAT_Opioden | Seed 2: ATT = -0.1321, SE = 6.9247, p = 0.98569\n",
      "✅ SUBCAT_Opioden | Seed 3: ATT = -1.6233, SE = 5.7499, p = 0.79171\n",
      "✅ SUBCAT_Opioden | Seed 4: ATT = -1.4490, SE = 5.5293, p = 0.80622\n",
      "✅ SUBCAT_Opioden | Seed 5: ATT = -2.5312, SE = 5.3921, p = 0.66322\n",
      "✅ SUBCAT_Opioden | Seed 6: ATT = -2.2651, SE = 5.0981, p = 0.67980\n",
      "✅ SUBCAT_Opioden | Seed 7: ATT = -2.6959, SE = 5.2764, p = 0.63631\n",
      "✅ SUBCAT_Opioden | Seed 8: ATT = -4.8766, SE = 5.0516, p = 0.38904\n",
      "✅ SUBCAT_Opioden | Seed 9: ATT = -1.5261, SE = 5.6760, p = 0.80133\n",
      "✅ SUBCAT_Opioden | Seed 10: ATT = 1.9728, SE = 5.7942, p = 0.75063\n",
      "📊 Diagnostic plots saved for SUBCAT_Opioden\n",
      "🏆 Best result for SUBCAT_Opioden → Seed 8 | SE = 5.0516\n",
      "\n",
      "🚀 Running OLS for SUBCAT_Z_drugs\n",
      "✅ SUBCAT_Z_drugs | Seed 1: ATT = 12.0955, SE = 5.0010, p = 0.07287\n",
      "✅ SUBCAT_Z_drugs | Seed 2: ATT = 11.8018, SE = 5.4476, p = 0.09619\n",
      "✅ SUBCAT_Z_drugs | Seed 3: ATT = 9.3867, SE = 6.1566, p = 0.20203\n",
      "✅ SUBCAT_Z_drugs | Seed 4: ATT = 15.3194, SE = 4.2236, p = 0.02222\n",
      "✅ SUBCAT_Z_drugs | Seed 5: ATT = 11.9978, SE = 5.0929, p = 0.07802\n",
      "✅ SUBCAT_Z_drugs | Seed 6: ATT = 10.3334, SE = 6.2779, p = 0.17511\n",
      "✅ SUBCAT_Z_drugs | Seed 7: ATT = 9.1757, SE = 4.5978, p = 0.11669\n",
      "✅ SUBCAT_Z_drugs | Seed 8: ATT = 10.8570, SE = 6.4279, p = 0.16648\n",
      "✅ SUBCAT_Z_drugs | Seed 9: ATT = 10.7536, SE = 5.5213, p = 0.12329\n",
      "✅ SUBCAT_Z_drugs | Seed 10: ATT = 15.0622, SE = 5.1895, p = 0.04401\n",
      "📊 Diagnostic plots saved for SUBCAT_Z_drugs\n",
      "🏆 Best result for SUBCAT_Z_drugs → Seed 4 | SE = 4.2236\n",
      "\n",
      "🚀 Running OLS for SUBCAT_NSAIDs\n",
      "✅ SUBCAT_NSAIDs | Seed 1: ATT = 1.6641, SE = 6.7529, p = 0.81748\n",
      "✅ SUBCAT_NSAIDs | Seed 2: ATT = -1.2595, SE = 6.3954, p = 0.85348\n",
      "✅ SUBCAT_NSAIDs | Seed 3: ATT = -7.2042, SE = 8.8945, p = 0.46339\n",
      "✅ SUBCAT_NSAIDs | Seed 4: ATT = -4.0358, SE = 7.7102, p = 0.62833\n",
      "✅ SUBCAT_NSAIDs | Seed 5: ATT = -4.5058, SE = 9.7396, p = 0.66768\n",
      "✅ SUBCAT_NSAIDs | Seed 6: ATT = -2.4095, SE = 9.1816, p = 0.80595\n",
      "✅ SUBCAT_NSAIDs | Seed 7: ATT = -2.9312, SE = 9.7011, p = 0.77759\n",
      "✅ SUBCAT_NSAIDs | Seed 8: ATT = -7.8472, SE = 8.8114, p = 0.42348\n",
      "✅ SUBCAT_NSAIDs | Seed 9: ATT = 2.9630, SE = 8.2901, p = 0.73884\n",
      "✅ SUBCAT_NSAIDs | Seed 10: ATT = 0.5975, SE = 13.6375, p = 0.96715\n",
      "📊 Diagnostic plots saved for SUBCAT_NSAIDs\n",
      "🏆 Best result for SUBCAT_NSAIDs → Seed 2 | SE = 6.3954\n",
      "\n",
      "🎯 All summary files saved.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import t, probplot\n",
    "import xgboost as xgb\n",
    "\n",
    "# -----------------------------\n",
    "# Configuration\n",
    "# -----------------------------\n",
    "seeds = list(range(1, 11))\n",
    "imputations = 5\n",
    "output_folder = \"outputs\"\n",
    "\n",
    "# -----------------------------\n",
    "# Diagnostic Plotting Function\n",
    "# -----------------------------\n",
    "def create_diagnostic_plots(residuals_data, fitted_data, group_name):\n",
    "    \"\"\"Create 4 diagnostic plots for model validation\"\"\"\n",
    "    plots_dir = os.path.join(output_folder, \"plots\")\n",
    "    os.makedirs(plots_dir, exist_ok=True)\n",
    "    \n",
    "    # Flatten the collected data\n",
    "    all_residuals = np.concatenate(residuals_data)\n",
    "    all_fitted = np.concatenate(fitted_data)\n",
    "    \n",
    "    # Create figure with 2x2 subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    fig.suptitle(f'Diagnostic Plots - {group_name}', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. Residuals vs Fitted\n",
    "    axes[0,0].scatter(all_fitted, all_residuals, alpha=0.6, s=20)\n",
    "    axes[0,0].axhline(y=0, color='red', linestyle='--', alpha=0.8)\n",
    "    axes[0,0].set_xlabel('Fitted Values')\n",
    "    axes[0,0].set_ylabel('Residuals')\n",
    "    axes[0,0].set_title('Residuals vs Fitted')\n",
    "    axes[0,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. QQ Plot\n",
    "    probplot(all_residuals, dist=\"norm\", plot=axes[0,1])\n",
    "    axes[0,1].set_title('Q-Q Plot (Normal)')\n",
    "    axes[0,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Residual Histogram\n",
    "    axes[1,0].hist(all_residuals, bins=30, density=True, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    axes[1,0].set_xlabel('Residuals')\n",
    "    axes[1,0].set_ylabel('Density')\n",
    "    axes[1,0].set_title('Residual Distribution')\n",
    "    axes[1,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Scale-Location Plot\n",
    "    sqrt_abs_residuals = np.sqrt(np.abs(all_residuals))\n",
    "    axes[1,1].scatter(all_fitted, sqrt_abs_residuals, alpha=0.6, s=20)\n",
    "    axes[1,1].set_xlabel('Fitted Values')\n",
    "    axes[1,1].set_ylabel('√|Residuals|')\n",
    "    axes[1,1].set_title('Scale-Location Plot')\n",
    "    axes[1,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save plot\n",
    "    plot_filename = os.path.join(plots_dir, f'{group_name}_unweighted.png')\n",
    "    plt.savefig(plot_filename, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"📊 Diagnostic plots saved for {group_name}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Rubin's Rule\n",
    "# -----------------------------\n",
    "def rubins_pool(estimates, ses):\n",
    "    m = len(estimates)\n",
    "    q_bar = np.mean(estimates)\n",
    "    u_bar = np.mean(np.square(ses))\n",
    "    b_m = np.var(estimates, ddof=1)\n",
    "    total_var = u_bar + ((1 + 1/m) * b_m)\n",
    "    total_se = np.sqrt(total_var)\n",
    "    ci_lower = q_bar - 1.96 * total_se\n",
    "    ci_upper = q_bar + 1.96 * total_se\n",
    "    p_value = 2 * (1 - t.cdf(np.abs(q_bar / total_se), df=m-1))\n",
    "    rounded_p = round(p_value, 5)\n",
    "    formatted_p = \"< 0.00001\" if rounded_p <= 0.00001 else f\"{rounded_p:.5f}\"\n",
    "    return q_bar, total_se, ci_lower, ci_upper, formatted_p\n",
    "\n",
    "# -----------------------------\n",
    "# SMD + Variance Ratio\n",
    "# -----------------------------\n",
    "def calculate_smd_vr(X, T):\n",
    "    treated = X[T == 1]\n",
    "    control = X[T == 0]\n",
    "    smd, vr = [], []\n",
    "    for col in X.columns:\n",
    "        try:\n",
    "            m1, m0 = treated[col].mean(), control[col].mean()\n",
    "            s1 = treated[col].std()\n",
    "            s0 = control[col].std()\n",
    "            pooled_sd = np.sqrt((s1 ** 2 + s0 ** 2) / 2)\n",
    "            smd.append((m1 - m0) / pooled_sd if pooled_sd > 0 else 0)\n",
    "            vr.append(s1**2 / s0**2 if s0**2 > 0 else 0)\n",
    "        except Exception:\n",
    "            smd.append(np.nan)\n",
    "            vr.append(np.nan)\n",
    "    return np.nanmean(smd), np.nanmean(vr)\n",
    "\n",
    "# -----------------------------\n",
    "# OLS Main Loop\n",
    "# -----------------------------\n",
    "def run_dml_with_trimmed_data(final_covariates_map):\n",
    "    att_results = []\n",
    "    balance_results = []\n",
    "\n",
    "    for group, covariates in final_covariates_map.items():\n",
    "        print(f\"\\n🚀 Running OLS for {group}\")\n",
    "        group_dir = os.path.join(output_folder, group)\n",
    "        os.makedirs(group_dir, exist_ok=True)\n",
    "\n",
    "        best_result = None\n",
    "        best_se = float(\"inf\")\n",
    "        \n",
    "        # Initialize lists to collect residuals and fitted values for diagnostic plots\n",
    "        group_residuals = []\n",
    "        group_fitted = []\n",
    "\n",
    "        for seed in seeds:\n",
    "            # Set random seed for this iteration\n",
    "            np.random.seed(seed)\n",
    "            \n",
    "            att_list, se_list, r2_list, rmse_list, smd_list, vr_list = [], [], [], [], [], []\n",
    "\n",
    "            for imp in range(1, imputations + 1):\n",
    "                file_path = os.path.join(group_dir, f\"trimmed_data_imp{imp}.pkl\")\n",
    "                if not os.path.exists(file_path):\n",
    "                    continue\n",
    "\n",
    "                df = pd.read_pickle(file_path)\n",
    "                if group not in df.columns or \"iptw\" not in df.columns:\n",
    "                    continue\n",
    "\n",
    "                # Add bootstrap sampling with seed-based randomization\n",
    "                n_samples = len(df)\n",
    "                bootstrap_idx = np.random.choice(n_samples, size=n_samples, replace=True)\n",
    "                df_bootstrap = df.iloc[bootstrap_idx].reset_index(drop=True)\n",
    "\n",
    "                X = df_bootstrap[covariates].copy()\n",
    "                T = df_bootstrap[group]\n",
    "                Y = df_bootstrap[\"caps5_change_baseline\"]\n",
    "                #W = df_bootstrap[\"iptw\"]\n",
    "\n",
    "                try:\n",
    "                    # Create design matrix with treatment variable and covariates\n",
    "                    X_ols = pd.concat([T, X], axis=1)\n",
    "                    X_ols = sm.add_constant(X_ols)\n",
    "                    \n",
    "                    # Fit OLS with robust standard errors (unweighted)\n",
    "                    ols_model = sm.OLS(Y, X_ols).fit(cov_type='HC1')\n",
    "                    \n",
    "                    # Extract treatment effect (coefficient of treatment variable)\n",
    "                    att = ols_model.params[group]  # Treatment coefficient\n",
    "                    se = ols_model.bse[group]  # Robust standard error for treatment\n",
    "                    \n",
    "                    att_list.append(att)\n",
    "                    se_list.append(se)\n",
    "\n",
    "                    # Calculate model fit statistics\n",
    "                    Y_pred = ols_model.fittedvalues\n",
    "                    residuals = ols_model.resid\n",
    "                    rmse = mean_squared_error(Y, Y_pred, squared=False)\n",
    "                    r2 = ols_model.rsquared\n",
    "                    r2_list.append(r2)\n",
    "                    rmse_list.append(rmse)\n",
    "                    \n",
    "                    # Collect residuals and fitted values for diagnostic plots\n",
    "                    group_residuals.append(residuals.values)\n",
    "                    group_fitted.append(Y_pred.values)\n",
    "\n",
    "                    smd, vr = calculate_smd_vr(X, T)\n",
    "                    smd_list.append(smd)\n",
    "                    vr_list.append(vr)\n",
    "                except Exception as e:\n",
    "                    print(f\"⚠️ Error in {group}, seed {seed}, imp {imp}: {e}\")\n",
    "\n",
    "            if att_list:\n",
    "                att, se, ci_l, ci_u, p_val = rubins_pool(att_list, se_list)\n",
    "                avg_r2 = np.mean(r2_list)\n",
    "                avg_rmse = np.mean(rmse_list)\n",
    "                avg_smd = np.mean(smd_list)\n",
    "                avg_vr = np.mean(vr_list)\n",
    "\n",
    "                balance_results.append({\n",
    "                    \"group\": group, \"seed\": seed, \"smd\": avg_smd, \"vr\": avg_vr\n",
    "                })\n",
    "\n",
    "                if se < best_se:\n",
    "                    best_se = se\n",
    "                    best_result = {\n",
    "                        \"group\": group, \"seed\": seed, \"att\": att, \"se\": se,\n",
    "                        \"ci_lower\": ci_l, \"ci_upper\": ci_u, \"p_value\": p_val,\n",
    "                        \"r2\": avg_r2, \"rmse\": avg_rmse\n",
    "                    }\n",
    "\n",
    "                print(f\"✅ {group} | Seed {seed}: ATT = {att:.4f}, SE = {se:.4f}, p = {p_val}\")\n",
    "            else:\n",
    "                print(f\"⚠️ No valid results for {group} | Seed {seed}\")\n",
    "\n",
    "        # Create diagnostic plots for this group\n",
    "        if group_residuals and group_fitted:\n",
    "            create_diagnostic_plots(group_residuals, group_fitted, group)\n",
    "\n",
    "        if best_result:\n",
    "            att_results.append(best_result)\n",
    "            print(f\"🏆 Best result for {group} → Seed {best_result['seed']} | SE = {best_result['se']:.4f}\")\n",
    "\n",
    "    # Save final output\n",
    "    pd.DataFrame(att_results).to_excel(\"ols_rubin_summary_subcats_unweighted.xlsx\", index=False)\n",
    "    pd.DataFrame(balance_results).to_excel(\"smd_vr_summary_subcats_unweighted.xlsx\", index=False)\n",
    "    print(\"\\n🎯 All summary files saved.\")\n",
    "\n",
    "run_dml_with_trimmed_data(final_covariates_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "9e3e1778-8b6a-4db4-915c-c8fc1a7d4992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Final_ATT_Summary_SubCat saved\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import sem, ttest_ind\n",
    "\n",
    "# ----------------------------------\n",
    "# File paths\n",
    "# ----------------------------------\n",
    "output_base = \"outputs\"\n",
    "att_file = \"ols_summary_subcats.xlsx\"\n",
    "trimmed_file = \"trimmed_data_imp1.pkl\"\n",
    "auc_file = \"auc_scores.xlsx\"  \n",
    "\n",
    "# ----------------------------------\n",
    "# Load ATT Summary\n",
    "# ----------------------------------\n",
    "if os.path.exists(att_file):\n",
    "    att_df = pd.read_excel(att_file)\n",
    "else:\n",
    "    raise FileNotFoundError(\"❌ ATT summary file not found: ols_summary_subcats.xlsx\")\n",
    "\n",
    "summary_rows = []\n",
    "\n",
    "# ----------------------------------\n",
    "# Loop over medication groups\n",
    "# ----------------------------------\n",
    "groups = [g for g in medication_groups if os.path.isdir(os.path.join(output_base, g))]\n",
    "\n",
    "for med in groups:\n",
    "    try:\n",
    "        group_path = os.path.join(output_base, med)\n",
    "\n",
    "        # Load trimmed data\n",
    "        df = pd.read_pickle(os.path.join(group_path, trimmed_file))\n",
    "\n",
    "        # Detect treatment column\n",
    "        treatment_cols = [col for col in df.columns if col.upper() == med.upper()]\n",
    "        if not treatment_cols:\n",
    "            print(f\"⚠️ Treatment column {med} not found in trimmed data. Skipping.\")\n",
    "            continue\n",
    "        treatment_var = treatment_cols[0]\n",
    "\n",
    "        # Extract treatment and outcome\n",
    "        T = df[treatment_var]\n",
    "        Y = df[\"caps5_change_baseline\"]\n",
    "\n",
    "        # Treated and control stats\n",
    "        treated = Y[T == 1]\n",
    "        control = Y[T == 0]\n",
    "\n",
    "        mean_treat = treated.mean()\n",
    "        se_treat = sem(treated) if len(treated) > 1 else np.nan\n",
    "\n",
    "        mean_ctrl = control.mean()\n",
    "        se_ctrl = sem(control) if len(control) > 1 else np.nan\n",
    "\n",
    "        # Cohen's d (unadjusted)\n",
    "        pooled_sd = np.sqrt(((treated.std() ** 2) + (control.std() ** 2)) / 2)\n",
    "        cohen_d = (mean_treat - mean_ctrl) / pooled_sd if pooled_sd > 0 else np.nan\n",
    "\n",
    "        # E-value (unadjusted)\n",
    "        delta = mean_treat - mean_ctrl\n",
    "        E = delta / abs(mean_ctrl) * 100 if mean_ctrl != 0 else np.nan\n",
    "\n",
    "        # Unadjusted p-value\n",
    "        try:\n",
    "            t_stat, p_val = ttest_ind(treated, control, equal_var=False, nan_policy=\"omit\")\n",
    "            rounded_p = round(p_val, 5)\n",
    "            formatted_p = \"< 0.00001\" if rounded_p < 0.00001 else rounded_p\n",
    "        except Exception:\n",
    "            formatted_p = np.nan\n",
    "\n",
    "        # AUC from new auc_scores.xlsx file\n",
    "        auc_val = np.nan\n",
    "        auc_path = os.path.join(group_path, auc_file)\n",
    "        if os.path.exists(auc_path):\n",
    "            auc_df = pd.read_excel(auc_path)\n",
    "            if \"AUC\" in auc_df.columns:\n",
    "                auc_val = auc_df[\"AUC\"].dropna().mean()\n",
    "\n",
    "        # Adjusted stats from Rubin summary\n",
    "        att_row = att_df[att_df[\"group\"].str.strip().str.upper() == med.strip().upper()]\n",
    "        if not att_row.empty:\n",
    "            att = att_row.iloc[0][\"att\"]\n",
    "            att_se = att_row.iloc[0][\"se\"]\n",
    "            att_p_val = att_row.iloc[0][\"p_value\"]\n",
    "            r2 = att_row.iloc[0][\"r2\"]\n",
    "            rmse = att_row.iloc[0][\"rmse\"]\n",
    "\n",
    "            try:\n",
    "                rounded_att_p = round(float(att_p_val), 5)\n",
    "                formatted_att_p = \"< 0.00001\" if rounded_att_p < 0.00001 else rounded_att_p\n",
    "            except:\n",
    "                formatted_att_p = att_p_val\n",
    "        else:\n",
    "            att, att_se, formatted_att_p, r2, rmse = np.nan, np.nan, np.nan, np.nan, np.nan\n",
    "\n",
    "        # Append full row\n",
    "        summary_rows.append({\n",
    "            'Medication Group': med,\n",
    "            'Mean Treated': mean_treat,\n",
    "            'SE Treated': se_treat,\n",
    "            'Mean Control': mean_ctrl,\n",
    "            'SE Control': se_ctrl,\n",
    "            'Cohen d': cohen_d,\n",
    "            'E (Unadjusted)': E,\n",
    "            'n Treated': len(treated),\n",
    "            'n Control': len(control),\n",
    "            #'Unadjusted p-value': formatted_p,\n",
    "            'ATT Estimate': att,\n",
    "            'ATT SE (Robust)': att_se,\n",
    "            'ATT p-value': formatted_att_p,\n",
    "            'R²': r2,\n",
    "            'RMSE': rmse,\n",
    "            'AUC': auc_val\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error in {med}: {e}\")\n",
    "\n",
    "# ----------------------------------\n",
    "# Save final summary\n",
    "# ----------------------------------\n",
    "summary_df = pd.DataFrame(summary_rows)\n",
    "summary_df = summary_df.sort_values(\"Medication Group\")\n",
    "summary_df.to_excel(\"Final_ATT_Summary_SubCat.xlsx\", index=False)\n",
    "print(\"✅ Final_ATT_Summary_SubCat saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "89c085a6-dd36-4cfd-9501-5a4dc75e036a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ols_att_barplot_subcat saved\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "# ✅ Load the final summary table\n",
    "final_df = pd.read_excel(\"Final_ATT_Summary_SubCat.xlsx\")\n",
    "\n",
    "# ✅ Parse DML p-values (handle \"< 0.00001\")\n",
    "def parse_pval(p):\n",
    "    try:\n",
    "        if isinstance(p, str) and \"<\" in p:\n",
    "            return 0.000001\n",
    "        return float(p)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "final_df['ATT p-value'] = final_df['ATT p-value'].apply(parse_pval)\n",
    "\n",
    "# ✅ Plot settings\n",
    "width = 0.35\n",
    "\n",
    "# ✅ Plotting function for a single medication group\n",
    "def plot_single_group(row):\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    bars1 = ax.bar(-width/2, row['Mean Control'], width, \n",
    "                   yerr=row['SE Control'], label='Control', hatch='//', color='gray', capsize=5)\n",
    "    bars2 = ax.bar(+width/2, row['Mean Treated'], width, \n",
    "                   yerr=row['SE Treated'], label='Treated', color='steelblue', capsize=5)\n",
    "\n",
    "    label = (\n",
    "        f\"ATT = {row['ATT Estimate']:.2f}\\n\"\n",
    "        f\"d = {row['Cohen d']:.2f}, p = {row['ATT p-value']:.3f}\\n\"\n",
    "        f\"nT = {row['n Treated']}, nC = {row['n Control']}\\n\"\n",
    "        f\"E = {row['E (Unadjusted)']:.1f}%\"\n",
    "    )\n",
    "    max_y = max(row['Mean Control'], row['Mean Treated']) + 1.5\n",
    "    ax.text(0, max_y, label, ha='center', va='bottom', fontsize=9, color='#FFD700')\n",
    "\n",
    "    ax.axhline(0, color='black', linewidth=0.8)\n",
    "    ax.set_xticks([-width/2, +width/2])\n",
    "    ax.set_xticklabels(['Control', 'Treated'])\n",
    "    ax.set_title(f\"Group: {row['Medication Group']}\", fontsize=12, weight='bold')\n",
    "    ax.set_ylabel(\"CAPS5 Change Score\")\n",
    "    ax.set_ylim(bottom=0, top=max_y + 2)\n",
    "    ax.legend()\n",
    "    fig.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# ✅ Generate and save all plots into a multi-page PDF\n",
    "with PdfPages(\"ols_att_barplot_subcat.pdf\") as pdf:\n",
    "    for idx, row in final_df.iterrows():\n",
    "        fig = plot_single_group(row)\n",
    "        pdf.savefig(fig, dpi=300, bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "print(\"✅ ols_att_barplot_subcat saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "8088e735-50ea-4250-913d-d259ae773864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Love plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "f84dd49c-2e5e-4323-926a-03c6450de68c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Processing SUBCAT_Amfetaminen...\n",
      "📊 Exported numeric summary to: outputs\\SUBCAT_Amfetaminen\\covariate_balance_table_SUBCAT_Amfetaminen.xlsx\n",
      "✅ Saved love plot: outputs\\SUBCAT_Amfetaminen\\love_plot_SUBCAT_Amfetaminen.pdf\n",
      "📏 Max weighted SMD for SUBCAT_Amfetaminen: 0.705\n",
      "\n",
      "🔍 Processing SUBCAT_Antidepressiva_Overige...\n",
      "📊 Exported numeric summary to: outputs\\SUBCAT_Antidepressiva_Overige\\covariate_balance_table_SUBCAT_Antidepressiva_Overige.xlsx\n",
      "✅ Saved love plot: outputs\\SUBCAT_Antidepressiva_Overige\\love_plot_SUBCAT_Antidepressiva_Overige.pdf\n",
      "📏 Max weighted SMD for SUBCAT_Antidepressiva_Overige: 0.949\n",
      "\n",
      "🔍 Processing SUBCAT_Antipsychotica_Atypisch...\n",
      "📊 Exported numeric summary to: outputs\\SUBCAT_Antipsychotica_Atypisch\\covariate_balance_table_SUBCAT_Antipsychotica_Atypisch.xlsx\n",
      "✅ Saved love plot: outputs\\SUBCAT_Antipsychotica_Atypisch\\love_plot_SUBCAT_Antipsychotica_Atypisch.pdf\n",
      "📏 Max weighted SMD for SUBCAT_Antipsychotica_Atypisch: 0.679\n",
      "\n",
      "🔍 Processing SUBCAT_Anti_Epileptica_Stemmingsstabilisatoren...\n",
      "📊 Exported numeric summary to: outputs\\SUBCAT_Anti_Epileptica_Stemmingsstabilisatoren\\covariate_balance_table_SUBCAT_Anti_Epileptica_Stemmingsstabilisatoren.xlsx\n",
      "✅ Saved love plot: outputs\\SUBCAT_Anti_Epileptica_Stemmingsstabilisatoren\\love_plot_SUBCAT_Anti_Epileptica_Stemmingsstabilisatoren.pdf\n",
      "📏 Max weighted SMD for SUBCAT_Anti_Epileptica_Stemmingsstabilisatoren: 0.232\n",
      "\n",
      "🔍 Processing SUBCAT_Anxiolytica_Benzodiazepine...\n",
      "📊 Exported numeric summary to: outputs\\SUBCAT_Anxiolytica_Benzodiazepine\\covariate_balance_table_SUBCAT_Anxiolytica_Benzodiazepine.xlsx\n",
      "✅ Saved love plot: outputs\\SUBCAT_Anxiolytica_Benzodiazepine\\love_plot_SUBCAT_Anxiolytica_Benzodiazepine.pdf\n",
      "📏 Max weighted SMD for SUBCAT_Anxiolytica_Benzodiazepine: 0.197\n",
      "\n",
      "🔍 Processing SUBCAT_Hypnotica_Benzodiazepine...\n",
      "📊 Exported numeric summary to: outputs\\SUBCAT_Hypnotica_Benzodiazepine\\covariate_balance_table_SUBCAT_Hypnotica_Benzodiazepine.xlsx\n",
      "✅ Saved love plot: outputs\\SUBCAT_Hypnotica_Benzodiazepine\\love_plot_SUBCAT_Hypnotica_Benzodiazepine.pdf\n",
      "📏 Max weighted SMD for SUBCAT_Hypnotica_Benzodiazepine: 0.166\n",
      "\n",
      "🔍 Processing SUBCAT_Nsaids...\n",
      "📊 Exported numeric summary to: outputs\\SUBCAT_Nsaids\\covariate_balance_table_SUBCAT_Nsaids.xlsx\n",
      "✅ Saved love plot: outputs\\SUBCAT_Nsaids\\love_plot_SUBCAT_Nsaids.pdf\n",
      "📏 Max weighted SMD for SUBCAT_Nsaids: 0.520\n",
      "\n",
      "🔍 Processing SUBCAT_Opioden...\n",
      "📊 Exported numeric summary to: outputs\\SUBCAT_Opioden\\covariate_balance_table_SUBCAT_Opioden.xlsx\n",
      "✅ Saved love plot: outputs\\SUBCAT_Opioden\\love_plot_SUBCAT_Opioden.pdf\n",
      "📏 Max weighted SMD for SUBCAT_Opioden: 0.484\n",
      "\n",
      "🔍 Processing SUBCAT_Paracetamol_Mono...\n",
      "📊 Exported numeric summary to: outputs\\SUBCAT_Paracetamol_Mono\\covariate_balance_table_SUBCAT_Paracetamol_Mono.xlsx\n",
      "✅ Saved love plot: outputs\\SUBCAT_Paracetamol_Mono\\love_plot_SUBCAT_Paracetamol_Mono.pdf\n",
      "📏 Max weighted SMD for SUBCAT_Paracetamol_Mono: 0.664\n",
      "\n",
      "🔍 Processing SUBCAT_Snri...\n",
      "📊 Exported numeric summary to: outputs\\SUBCAT_Snri\\covariate_balance_table_SUBCAT_Snri.xlsx\n",
      "✅ Saved love plot: outputs\\SUBCAT_Snri\\love_plot_SUBCAT_Snri.pdf\n",
      "📏 Max weighted SMD for SUBCAT_Snri: 0.323\n",
      "\n",
      "🔍 Processing SUBCAT_Ssri...\n",
      "📊 Exported numeric summary to: outputs\\SUBCAT_Ssri\\covariate_balance_table_SUBCAT_Ssri.xlsx\n",
      "✅ Saved love plot: outputs\\SUBCAT_Ssri\\love_plot_SUBCAT_Ssri.pdf\n",
      "📏 Max weighted SMD for SUBCAT_Ssri: 0.240\n",
      "\n",
      "🔍 Processing SUBCAT_Systemische_Antihistaminica...\n",
      "📊 Exported numeric summary to: outputs\\SUBCAT_Systemische_Antihistaminica\\covariate_balance_table_SUBCAT_Systemische_Antihistaminica.xlsx\n",
      "✅ Saved love plot: outputs\\SUBCAT_Systemische_Antihistaminica\\love_plot_SUBCAT_Systemische_Antihistaminica.pdf\n",
      "📏 Max weighted SMD for SUBCAT_Systemische_Antihistaminica: 0.465\n",
      "\n",
      "🔍 Processing SUBCAT_Tca...\n",
      "📊 Exported numeric summary to: outputs\\SUBCAT_Tca\\covariate_balance_table_SUBCAT_Tca.xlsx\n",
      "✅ Saved love plot: outputs\\SUBCAT_Tca\\love_plot_SUBCAT_Tca.pdf\n",
      "📏 Max weighted SMD for SUBCAT_Tca: 0.307\n",
      "\n",
      "🔍 Processing SUBCAT_Tetracyclische_Antidepressiva...\n",
      "📊 Exported numeric summary to: outputs\\SUBCAT_Tetracyclische_Antidepressiva\\covariate_balance_table_SUBCAT_Tetracyclische_Antidepressiva.xlsx\n",
      "✅ Saved love plot: outputs\\SUBCAT_Tetracyclische_Antidepressiva\\love_plot_SUBCAT_Tetracyclische_Antidepressiva.pdf\n",
      "📏 Max weighted SMD for SUBCAT_Tetracyclische_Antidepressiva: 0.314\n",
      "\n",
      "🔍 Processing SUBCAT_Z_Drugs...\n",
      "📊 Exported numeric summary to: outputs\\SUBCAT_Z_Drugs\\covariate_balance_table_SUBCAT_Z_Drugs.xlsx\n",
      "✅ Saved love plot: outputs\\SUBCAT_Z_Drugs\\love_plot_SUBCAT_Z_Drugs.pdf\n",
      "📏 Max weighted SMD for SUBCAT_Z_Drugs: 0.367\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "# ----------------------------------------\n",
    "# Functions to calculate balance\n",
    "# ----------------------------------------\n",
    "def calculate_smd(x1, x2, w1=None, w2=None):\n",
    "    def weighted_mean(x, w): return np.average(x, weights=w)\n",
    "    def weighted_var(x, w):\n",
    "        m = np.average(x, weights=w)\n",
    "        return np.average((x - m) ** 2, weights=w)\n",
    "    \n",
    "    m1 = weighted_mean(x1, w1) if w1 is not None else np.mean(x1)\n",
    "    m2 = weighted_mean(x2, w2) if w2 is not None else np.mean(x2)\n",
    "    v1 = weighted_var(x1, w1) if w1 is not None else np.var(x1, ddof=1)\n",
    "    v2 = weighted_var(x2, w2) if w2 is not None else np.var(x2, ddof=1)\n",
    "    \n",
    "    pooled_sd = np.sqrt((v1 + v2) / 2)\n",
    "    return np.abs(m1 - m2) / pooled_sd if pooled_sd > 0 else 0\n",
    "\n",
    "def variance_ratio(x1, x2, w1=None, w2=None):\n",
    "    def weighted_var(x, w):\n",
    "        m = np.average(x, weights=w)\n",
    "        return np.average((x - m) ** 2, weights=w)\n",
    "    \n",
    "    v1 = weighted_var(x1, w1) if w1 is not None else np.var(x1, ddof=1)\n",
    "    v2 = weighted_var(x2, w2) if w2 is not None else np.var(x2, ddof=1)\n",
    "    \n",
    "    return max(v1 / v2, v2 / v1) if v1 > 0 and v2 > 0 else 1\n",
    "\n",
    "# ----------------------------------------\n",
    "# Setup\n",
    "# ----------------------------------------\n",
    "output_base = \"outputs\"\n",
    "groups = [g for g in os.listdir(output_base) if os.path.isdir(os.path.join(output_base, g))]\n",
    "\n",
    "# Create a case-insensitive mapping\n",
    "final_covariates_map_lower = {k.lower(): v for k, v in final_covariates_map.items()}\n",
    "\n",
    "# ----------------------------------------\n",
    "# Main Loop\n",
    "# ----------------------------------------\n",
    "for group in groups:\n",
    "    if group.lower() not in final_covariates_map_lower:\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n🔍 Processing {group}...\")\n",
    "\n",
    "    try:\n",
    "        group_path = os.path.join(output_base, group)\n",
    "        covariates = final_covariates_map_lower[group.lower()]\n",
    "        \n",
    "        column_name = None\n",
    "        for col in pd.read_pickle(os.path.join(group_path, \"trimmed_data_imp1.pkl\")).columns:\n",
    "            if col.lower() == group.lower():\n",
    "                column_name = col\n",
    "                break\n",
    "        if column_name is None:\n",
    "            print(f\"⚠️ Column not found for {group}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        smd_unw_all, smd_w_all = [], []\n",
    "        vr_unw_all, vr_w_all = [], []\n",
    "\n",
    "        for i in range(1, 6):\n",
    "            df_path = os.path.join(group_path, f\"trimmed_data_imp{i}.pkl\")\n",
    "            iptw_path = os.path.join(group_path, \"iptw_weights.xlsx\")\n",
    "\n",
    "            if not os.path.exists(df_path) or not os.path.exists(iptw_path):\n",
    "                print(f\"⚠️ Missing data for {group} imp{i}, skipping.\")\n",
    "                continue\n",
    "\n",
    "            df = pd.read_pickle(df_path)\n",
    "            iptw_df = pd.read_excel(iptw_path, index_col=0)\n",
    "            T = df[column_name]\n",
    "            W = iptw_df.loc[df.index, \"iptw_mean\"]\n",
    "\n",
    "            smd_unw_i, smd_w_i, vr_unw_i, vr_w_i = [], [], [], []\n",
    "\n",
    "            for cov in covariates:\n",
    "                x1, x0 = df.loc[T == 1, cov], df.loc[T == 0, cov]\n",
    "                w1, w0 = W[T == 1], W[T == 0]\n",
    "\n",
    "                su = calculate_smd(x1, x0)\n",
    "                sw = calculate_smd(x1, x0, w1, w0)\n",
    "\n",
    "                vu = variance_ratio(x1, x0) if cov in ['treatmentdurationdays', 'CAPS5score_baseline', 'age'] else np.nan\n",
    "                vw = variance_ratio(x1, x0, w1, w0) if cov in ['treatmentdurationdays', 'CAPS5score_baseline', 'age'] else np.nan\n",
    "\n",
    "                smd_unw_i.append(su)\n",
    "                smd_w_i.append(sw)\n",
    "                vr_unw_i.append(vu)\n",
    "                vr_w_i.append(vw)\n",
    "\n",
    "            smd_unw_all.append(smd_unw_i)\n",
    "            smd_w_all.append(smd_w_i)\n",
    "            vr_unw_all.append(vr_unw_i)\n",
    "            vr_w_all.append(vr_w_i)\n",
    "\n",
    "        smd_unw = np.mean(smd_unw_all, axis=0)\n",
    "        smd_w = np.mean(smd_w_all, axis=0)\n",
    "        vr_unw = np.nanmean(vr_unw_all, axis=0)\n",
    "        vr_w = np.nanmean(vr_w_all, axis=0)\n",
    "\n",
    "        severity = []\n",
    "        for sw in smd_w:\n",
    "            if sw <= 0.1:\n",
    "                severity.append(\"Good\")\n",
    "            elif sw <= 0.2:\n",
    "                severity.append(\"Moderate\")\n",
    "            else:\n",
    "                severity.append(\"Poor\")\n",
    "\n",
    "        covariate_names = covariates\n",
    "        numeric_df = pd.DataFrame({\n",
    "            \"Covariate\": covariate_names,\n",
    "            \"SMD_Unweighted\": smd_unw,\n",
    "            \"SMD_Weighted\": smd_w,\n",
    "            \"Imbalance_Severity\": severity,\n",
    "            \"VR_Unweighted\": vr_unw,\n",
    "            \"VR_Weighted\": vr_w\n",
    "        })\n",
    "\n",
    "        numeric_path = os.path.join(group_path, f\"covariate_balance_table_{group}.xlsx\")\n",
    "        numeric_df.to_excel(numeric_path, index=False)\n",
    "        print(f\"📊 Exported numeric summary to: {numeric_path}\")\n",
    "\n",
    "        # -------------------------\n",
    "        # Plot\n",
    "        # -------------------------\n",
    "        labels = covariates\n",
    "        y_pos = np.arange(len(labels))\n",
    "\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(18, len(labels) * 0.45))\n",
    "\n",
    "        axes[0].scatter(smd_unw, y_pos, color='red', label=\"Unweighted\")\n",
    "        axes[0].scatter(smd_w, y_pos, color='blue', label=\"Weighted\")\n",
    "        axes[0].axvline(0.1, color='gray', linestyle='--', label=\"Threshold 0.1\")\n",
    "        axes[0].axvline(0.2, color='black', linestyle='--', label=\"Threshold 0.2\")\n",
    "        axes[0].set_xlim(0, max(max(smd_unw), max(smd_w), 0.25) + 0.05)\n",
    "        axes[0].set_yticks(y_pos)\n",
    "        axes[0].set_yticklabels(labels)\n",
    "        axes[0].invert_yaxis()\n",
    "        axes[0].set_title(\"Standardized Mean Differences (SMD)\")\n",
    "        axes[0].legend(loc=\"upper right\")\n",
    "        axes[0].grid(True)\n",
    "\n",
    "        vr_mask = [cov in ['treatmentdurationdays', 'CAPS5score_baseline', 'age'] for cov in covariates]\n",
    "        filtered_y = [i for i, b in enumerate(vr_mask) if b]\n",
    "        filtered_labels = [labels[i] for i in filtered_y]\n",
    "        filtered_vr_unw = [vr_unw[i] for i in filtered_y]\n",
    "        filtered_vr_w = [vr_w[i] for i in filtered_y]\n",
    "\n",
    "        axes[1].scatter(filtered_vr_unw, filtered_y, color='blue', marker='o', label=\"Unweighted\")\n",
    "        axes[1].scatter(filtered_vr_w, filtered_y, color='red', marker='x', label=\"Weighted\")\n",
    "        axes[1].axvline(2, color='gray', linestyle='--')\n",
    "        axes[1].axvline(0.5, color='gray', linestyle='--')\n",
    "        axes[1].set_xlim(0, max(filtered_vr_unw + filtered_vr_w + [2.5]) + 0.5)\n",
    "        axes[1].set_yticks(filtered_y)\n",
    "        axes[1].set_yticklabels(filtered_labels)\n",
    "        axes[1].invert_yaxis()\n",
    "        axes[1].set_title(\"Variance Ratio (VR)\")\n",
    "        axes[1].legend()\n",
    "        axes[1].grid(True)\n",
    "\n",
    "        fig.suptitle(f\"Covariate Balance for {group.replace('CAT_', '')}\", fontsize=14, weight='bold')\n",
    "        fig.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "        plot_path = os.path.join(group_path, f\"love_plot_{group}.pdf\")\n",
    "        fig.savefig(plot_path, dpi=300)\n",
    "        plt.close()\n",
    "        print(f\"✅ Saved love plot: {plot_path}\")\n",
    "        print(f\"📏 Max weighted SMD for {group}: {np.max(smd_w):.3f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error in {group}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "633fd988-7a59-468d-895b-e92529e96f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "e954a5bc-a137-481e-a44f-92ed766c8abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Creating Heatmap for SUBCAT_Antipsychotica_atypisch ==========\n",
      "✅ Heatmap saved: outputs\\SUBCAT_Antipsychotica_atypisch\\heatmap_smd_SUBCAT_Antipsychotica_atypisch.png\n",
      "\n",
      "========== Creating Heatmap for SUBCAT_TCA ==========\n",
      "✅ Heatmap saved: outputs\\SUBCAT_TCA\\heatmap_smd_SUBCAT_TCA.png\n",
      "\n",
      "========== Creating Heatmap for SUBCAT_SSRI ==========\n",
      "✅ Heatmap saved: outputs\\SUBCAT_SSRI\\heatmap_smd_SUBCAT_SSRI.png\n",
      "\n",
      "========== Creating Heatmap for SUBCAT_SNRI ==========\n",
      "✅ Heatmap saved: outputs\\SUBCAT_SNRI\\heatmap_smd_SUBCAT_SNRI.png\n",
      "\n",
      "========== Creating Heatmap for SUBCAT_Tetracyclische_antidepressiva ==========\n",
      "✅ Heatmap saved: outputs\\SUBCAT_Tetracyclische_antidepressiva\\heatmap_smd_SUBCAT_Tetracyclische_antidepressiva.png\n",
      "\n",
      "========== Creating Heatmap for SUBCAT_Antidepressiva_overige ==========\n",
      "✅ Heatmap saved: outputs\\SUBCAT_Antidepressiva_overige\\heatmap_smd_SUBCAT_Antidepressiva_overige.png\n",
      "\n",
      "========== Creating Heatmap for SUBCAT_Systemische_antihistaminica ==========\n",
      "✅ Heatmap saved: outputs\\SUBCAT_Systemische_antihistaminica\\heatmap_smd_SUBCAT_Systemische_antihistaminica.png\n",
      "\n",
      "========== Creating Heatmap for SUBCAT_anxiolytica_Benzodiazepine ==========\n",
      "✅ Heatmap saved: outputs\\SUBCAT_anxiolytica_Benzodiazepine\\heatmap_smd_SUBCAT_anxiolytica_Benzodiazepine.png\n",
      "\n",
      "========== Creating Heatmap for SUBCAT_hypnotica_Benzodiazepine ==========\n",
      "✅ Heatmap saved: outputs\\SUBCAT_hypnotica_Benzodiazepine\\heatmap_smd_SUBCAT_hypnotica_Benzodiazepine.png\n",
      "\n",
      "========== Creating Heatmap for SUBCAT_Amfetaminen ==========\n",
      "✅ Heatmap saved: outputs\\SUBCAT_Amfetaminen\\heatmap_smd_SUBCAT_Amfetaminen.png\n",
      "\n",
      "========== Creating Heatmap for SUBCAT_Paracetamol_mono ==========\n",
      "✅ Heatmap saved: outputs\\SUBCAT_Paracetamol_mono\\heatmap_smd_SUBCAT_Paracetamol_mono.png\n",
      "\n",
      "========== Creating Heatmap for SUBCAT_Anti_epileptica_stemmingsstabilisatoren ==========\n",
      "✅ Heatmap saved: outputs\\SUBCAT_Anti_epileptica_stemmingsstabilisatoren\\heatmap_smd_SUBCAT_Anti_epileptica_stemmingsstabilisatoren.png\n",
      "\n",
      "========== Creating Heatmap for SUBCAT_Opioden ==========\n",
      "✅ Heatmap saved: outputs\\SUBCAT_Opioden\\heatmap_smd_SUBCAT_Opioden.png\n",
      "\n",
      "========== Creating Heatmap for SUBCAT_Z_drugs ==========\n",
      "✅ Heatmap saved: outputs\\SUBCAT_Z_drugs\\heatmap_smd_SUBCAT_Z_drugs.png\n",
      "\n",
      "========== Creating Heatmap for SUBCAT_NSAIDs ==========\n",
      "✅ Heatmap saved: outputs\\SUBCAT_NSAIDs\\heatmap_smd_SUBCAT_NSAIDs.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "#-----------------------------\n",
    "# Generate heatmaps\n",
    "# -------------------------------\n",
    "for treatment_var in medication_groups:\n",
    "    print(f\"\\n========== Creating Heatmap for {treatment_var} ==========\")\n",
    "\n",
    "    try:\n",
    "        output_folder = os.path.join('outputs', treatment_var)\n",
    "        balance_path = os.path.join(output_folder, f'covariate_balance_table_{treatment_var}.xlsx')\n",
    "\n",
    "        if not os.path.exists(balance_path):\n",
    "            print(f\"❌ Balance file not found: {balance_path}\")\n",
    "            continue\n",
    "\n",
    "        balance_df = pd.read_excel(balance_path)\n",
    "\n",
    "        # ✅ Use finalized covariates + 'Propensity Score'\n",
    "        covariates = final_covariates_map[treatment_var] + ['Propensity Score']\n",
    "        balance_df = balance_df[balance_df['Covariate'].isin(covariates)]\n",
    "\n",
    "        # ✅ Check for CAPS5score_baseline\n",
    "        highlight_caps = 'CAPS5score_baseline' in balance_df['Covariate'].values\n",
    "\n",
    "        # ✅ Format for heatmap\n",
    "        heatmap_df = balance_df[['Covariate', 'SMD_Unweighted', 'SMD_Weighted']].copy()\n",
    "        heatmap_df.columns = ['Covariate', 'Unweighted', 'Weighted']\n",
    "        heatmap_df = heatmap_df.set_index('Covariate')\n",
    "        heatmap_df = heatmap_df.sort_values(by='Unweighted', ascending=False)\n",
    "\n",
    "        # ✅ Plot\n",
    "        plt.figure(figsize=(12, max(10, len(heatmap_df) * 0.35)))\n",
    "        ax = sns.heatmap(\n",
    "            heatmap_df,\n",
    "            cmap=\"coolwarm\",\n",
    "            annot=True,\n",
    "            fmt=\".2f\",\n",
    "            linewidths=0.6,\n",
    "            linecolor='gray',\n",
    "            cbar_kws={\"label\": \"Standardized Mean Difference\"}\n",
    "        )\n",
    "\n",
    "        plt.title(f\"Covariate Balance Heatmap (Rubin IPTW)\\n{treatment_var}\", fontsize=15, weight='bold')\n",
    "        plt.xlabel(\"Condition\")\n",
    "        plt.ylabel(\"Covariate\")\n",
    "\n",
    "        # ✅ Bold CAPS5score_baseline if present\n",
    "        if highlight_caps:\n",
    "            ylabels = [label.get_text() for label in ax.get_yticklabels()]\n",
    "            ax.set_yticklabels([\n",
    "                f\"{label} ←\" if label == 'CAPS5score_baseline' else label for label in ylabels\n",
    "            ])\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # ✅ Save image\n",
    "        save_path = os.path.join(output_folder, f'heatmap_smd_{treatment_var}.png')\n",
    "        plt.savefig(save_path, dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "        print(f\"✅ Heatmap saved: {save_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error processing {treatment_var}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03725ea3-1967-48cf-a8ae-acabff5ac054",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "feef0543-716d-47ca-a887-00fcb78c5521",
   "metadata": {},
   "source": [
    "### SubSubCat Analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "384b36ab-32ce-40e7-a2ad-4ea810f87841",
   "metadata": {},
   "outputs": [],
   "source": [
    "covariates_SubSubCat_Oxazepam = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antidepressiva', 'CAT_Antipsychotica',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "covariates_SubSubCat_Diazepam = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antidepressiva', 'CAT_Antipsychotica',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "\n",
    "covariates_SubSubCat_Paracetamol = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antidepressiva',\n",
    "    'CAT_Antipsychotica',\n",
    "    'CAT_Benzodiazepine',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "covariates_SubSubCat_Lorazepam = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antidepressiva', 'CAT_Antipsychotica',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "covariates_SubSubCat_Mirtazapine = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antipsychotica',\n",
    "    'CAT_Benzodiazepine',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "covariates_SubSubCat_Escitalopram = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antipsychotica',\n",
    "    'CAT_Benzodiazepine',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "\n",
    "covariates_SubSubCat_Sertraline = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antipsychotica',\n",
    "    'CAT_Benzodiazepine',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "covariates_SubSubCat_Temazepam = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antidepressiva', 'CAT_Antipsychotica',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "covariates_SubSubCat_Citalopram = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antipsychotica',\n",
    "    'CAT_Benzodiazepine',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "covariates_SubSubCat_Quetiapine = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antidepressiva',\n",
    "    'CAT_Benzodiazepine',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "covariates_SubSubCat_Amitriptyline = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antipsychotica',\n",
    "    'CAT_Benzodiazepine',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "\n",
    "covariates_SubSubCat_Venlafaxine = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antipsychotica',\n",
    "    'CAT_Benzodiazepine',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "covariates_SubSubCat_Fluoxetine = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antipsychotica',\n",
    "    'CAT_Benzodiazepine',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "covariates_SubSubCat_Topiramaat = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antidepressiva',\n",
    "    'CAT_Antipsychotica',\n",
    "    'CAT_Benzodiazepine',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "covariates_SubSubCat_Zopiclon = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antidepressiva',\n",
    "    'CAT_Antipsychotica',\n",
    "    'CAT_Benzodiazepine',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "covariates_SubSubCat_Bupropion = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antipsychotica',\n",
    "    'CAT_Benzodiazepine',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "covariates_SubSubCat_Methylfenidaat = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antidepressiva',\n",
    "    'CAT_Antipsychotica',\n",
    "    'CAT_Benzodiazepine',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD',\n",
    "    'DIAGNOSIS_SEXUAL_TRAUMA', 'DIAGNOSIS_SUICIDALITY',\n",
    "    'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n",
    "covariates_SubSubCat_Olanzapine = [\n",
    "    'treatmentdurationdays', 'CAPS5score_baseline',\n",
    "    'CAT_Antidepressiva',\n",
    "    'CAT_Benzodiazepine',\n",
    "    'DIAGNOSIS_CHILDHOOD_TRAUMA', 'DIAGNOSIS_CPTSD', 'DIAGNOSIS_SEXUAL_TRAUMA',\n",
    "    'DIAGNOSIS_SUICIDALITY', 'age',\n",
    "    'DIAGNOSIS_ANXIETY_OCD',\n",
    "    'DIAGNOSIS_PSYCHOTIC',\n",
    "    'DIAGNOSIS_EATING_DISORDER',\n",
    "    'DIAGNOSIS_SUBSTANCE_DISORDER', 'SDV_SEXE_1', 'SDV_SEXE_2', 'SDV_SEXE_3', \"EB_TRAUMA_FOCUSED_THERAPY\",\n",
    "    \"Bipolar_and_Mood_disorder\", \"ethnicity_Dutch\", \"ethnicity_other\"\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "7be2d6fd-69da-43e9-b686-89d57f72036d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groups found: ['SubSubCat_Oxazepam', 'SubSubCat_Diazepam', 'SubSubCat_Paracetamol', 'SubSubCat_Lorazepam', 'SubSubCat_Mirtazapine', 'SubSubCat_Escitalopram', 'SubSubCat_Sertraline', 'SubSubCat_Temazepam', 'SubSubCat_Citalopram', 'SubSubCat_Quetiapine', 'SubSubCat_Amitriptyline', 'SubSubCat_Venlafaxine', 'SubSubCat_Fluoxetine', 'SubSubCat_Topiramaat', 'SubSubCat_Zopiclon', 'SubSubCat_Bupropion', 'SubSubCat_Methylfenidaat', 'SubSubCat_Olanzapine']\n",
      "['SubSubCat_Oxazepam', 'SubSubCat_Diazepam', 'SubSubCat_Paracetamol', 'SubSubCat_Lorazepam', 'SubSubCat_Mirtazapine', 'SubSubCat_Escitalopram', 'SubSubCat_Sertraline', 'SubSubCat_Temazepam', 'SubSubCat_Citalopram', 'SubSubCat_Quetiapine', 'SubSubCat_Amitriptyline', 'SubSubCat_Venlafaxine', 'SubSubCat_Fluoxetine', 'SubSubCat_Topiramaat', 'SubSubCat_Zopiclon', 'SubSubCat_Bupropion', 'SubSubCat_Methylfenidaat', 'SubSubCat_Olanzapine']\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# This finds all variables that start with covariates_SUbSubCAT_ or covariates_SubSubcat_\n",
    "final_covariates_map = defaultdict(list)\n",
    "final_covariates_map.update({\n",
    "    var.replace(\"covariates_\", \"\"): val\n",
    "    for var, val in globals().items()\n",
    "    if var.lower().startswith(\"covariates_subsubcat_\") and isinstance(val, list)\n",
    "})\n",
    "\n",
    "# Show detected group names\n",
    "print(\"Groups found:\", list(final_covariates_map.keys()))\n",
    "medication_groups = list(final_covariates_map.keys())\n",
    "print(medication_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "8407653a-734f-44e5-bc41-aeea94992c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Starting analysis for all SUBSUBCAT groups\n",
      "\n",
      " Processing SUBSUBCAT_Oxazepam...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBSUBCAT_Oxazepam\n",
      "\n",
      " Processing SUBSUBCAT_Diazepam...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBSUBCAT_Diazepam\n",
      "\n",
      " Processing SUBSUBCAT_Paracetamol...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBSUBCAT_Paracetamol\n",
      "\n",
      " Processing SUBSUBCAT_Lorazepam...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBSUBCAT_Lorazepam\n",
      "\n",
      " Processing SUBSUBCAT_Mirtazapine...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBSUBCAT_Mirtazapine\n",
      "\n",
      " Processing SUBSUBCAT_Escitalopram...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBSUBCAT_Escitalopram\n",
      "\n",
      " Processing SUBSUBCAT_Sertraline...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBSUBCAT_Sertraline\n",
      "\n",
      " Processing SUBSUBCAT_Temazepam...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBSUBCAT_Temazepam\n",
      "\n",
      " Processing SUBSUBCAT_Citalopram...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBSUBCAT_Citalopram\n",
      "\n",
      " Processing SUBSUBCAT_Quetiapine...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBSUBCAT_Quetiapine\n",
      "\n",
      " Processing SUBSUBCAT_Amitriptyline...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBSUBCAT_Amitriptyline\n",
      "\n",
      " Processing SUBSUBCAT_Venlafaxine...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBSUBCAT_Venlafaxine\n",
      "\n",
      " Processing SUBSUBCAT_Fluoxetine...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBSUBCAT_Fluoxetine\n",
      "\n",
      " Processing SUBSUBCAT_Topiramaat...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBSUBCAT_Topiramaat\n",
      "\n",
      " Processing SUBSUBCAT_Zopiclon...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBSUBCAT_Zopiclon\n",
      "\n",
      " Processing SUBSUBCAT_Bupropion...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBSUBCAT_Bupropion\n",
      "\n",
      " Processing SUBSUBCAT_Methylfenidaat...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBSUBCAT_Methylfenidaat\n",
      "\n",
      " Processing SUBSUBCAT_Olanzapine...\n",
      "  → Using imputation 1\n",
      "  → Using imputation 2\n",
      "  → Using imputation 3\n",
      "  → Using imputation 4\n",
      "  → Using imputation 5\n",
      " Done: SUBSUBCAT_Olanzapine\n",
      "\n",
      " All SUBSUBCAT group analyses complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def run_all_SUBSUBCAT_group_models(imputed_dfs):\n",
    "    \"\"\"\n",
    "    Runs downstream analysis for each SUBSUBCAT medisubsubcation group using imputed datasets.\n",
    "\n",
    "    Parameters:\n",
    "    - imputed_dfs: list of 5 imputed DataFrames (from df_imputed_final_imp1.pkl ... imp5.pkl)\n",
    "    \n",
    "    Notes:\n",
    "    - Covariate lists must be defined as global variables: covariates_subsubcat_<group>\n",
    "    - Outputs are saved in: outputs/SUBSUBCAT_<GROUP>/\n",
    "    \"\"\"\n",
    "\n",
    "    print(\" Starting analysis for all SUBSUBCAT groups\")\n",
    "\n",
    "    for var_name in globals():\n",
    "        if var_name.lower().startswith(\"covariates_subsubcat_\") and isinstance(globals()[var_name], list):\n",
    "            group_name = var_name.replace(\"covariates_\", \"\")\n",
    "            group_name = group_name.replace(\"_\", \" \").title().replace(\" \", \"_\")  # e.g., subsubcat_z_drugs → Subsubcat_Z_Drugs\n",
    "            group_name = group_name.replace(\"Subsubcat_\", \"SUBSUBCAT_\")  # force prefix to uppercase\n",
    "\n",
    "            covariates = globals()[var_name]\n",
    "            output_dir = f\"outputs/{group_name}\"\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "            print(f\"\\n Processing {group_name}...\")\n",
    "\n",
    "            for k, df_imp in enumerate(imputed_dfs):\n",
    "                print(f\"  → Using imputation {k+1}\")\n",
    "\n",
    "                # Define X and Y\n",
    "                X = df_imp[covariates]\n",
    "                Y = df_imp[\"caps5_change_baseline\"]\n",
    "\n",
    "                # === Save X and Y as placeholder (replace with modeling later)\n",
    "                X.to_csv(f\"{output_dir}/X_imp{k+1}.csv\", index=False)\n",
    "                Y.to_frame(name=\"Y\").to_csv(f\"{output_dir}/Y_imp{k+1}.csv\", index=False)\n",
    "\n",
    "            print(f\" Done: {group_name}\")\n",
    "\n",
    "    print(\"\\n All SUBSUBCAT group analyses complete.\")\n",
    "\n",
    "# ========= STEP 4: Execute ========= #\n",
    "run_all_SUBSUBCAT_group_models(imputed_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "a3f192e5-b4a6-42ed-98ee-0183e20212b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " SubSubCat_Oxazepam\n",
      "  Imp 1: Treated = 206, Control = 3435, Missing = 0\n",
      "  Imp 2: Treated = 206, Control = 3435, Missing = 0\n",
      "  Imp 3: Treated = 206, Control = 3435, Missing = 0\n",
      "  Imp 4: Treated = 206, Control = 3435, Missing = 0\n",
      "  Imp 5: Treated = 206, Control = 3435, Missing = 0\n",
      "\n",
      " SubSubCat_Diazepam\n",
      "  Imp 1: Treated = 42, Control = 3599, Missing = 0\n",
      "  Imp 2: Treated = 42, Control = 3599, Missing = 0\n",
      "  Imp 3: Treated = 42, Control = 3599, Missing = 0\n",
      "  Imp 4: Treated = 42, Control = 3599, Missing = 0\n",
      "  Imp 5: Treated = 42, Control = 3599, Missing = 0\n",
      "\n",
      " SubSubCat_Paracetamol\n",
      "  Imp 1: Treated = 43, Control = 3598, Missing = 0\n",
      "  Imp 2: Treated = 43, Control = 3598, Missing = 0\n",
      "  Imp 3: Treated = 43, Control = 3598, Missing = 0\n",
      "  Imp 4: Treated = 43, Control = 3598, Missing = 0\n",
      "  Imp 5: Treated = 43, Control = 3598, Missing = 0\n",
      "\n",
      " SubSubCat_Lorazepam\n",
      "  Imp 1: Treated = 67, Control = 3574, Missing = 0\n",
      "  Imp 2: Treated = 67, Control = 3574, Missing = 0\n",
      "  Imp 3: Treated = 67, Control = 3574, Missing = 0\n",
      "  Imp 4: Treated = 67, Control = 3574, Missing = 0\n",
      "  Imp 5: Treated = 67, Control = 3574, Missing = 0\n",
      "\n",
      " SubSubCat_Mirtazapine\n",
      "  Imp 1: Treated = 87, Control = 3554, Missing = 0\n",
      "  Imp 2: Treated = 87, Control = 3554, Missing = 0\n",
      "  Imp 3: Treated = 87, Control = 3554, Missing = 0\n",
      "  Imp 4: Treated = 87, Control = 3554, Missing = 0\n",
      "  Imp 5: Treated = 87, Control = 3554, Missing = 0\n",
      "\n",
      " SubSubCat_Escitalopram\n",
      "  Imp 1: Treated = 69, Control = 3572, Missing = 0\n",
      "  Imp 2: Treated = 69, Control = 3572, Missing = 0\n",
      "  Imp 3: Treated = 69, Control = 3572, Missing = 0\n",
      "  Imp 4: Treated = 69, Control = 3572, Missing = 0\n",
      "  Imp 5: Treated = 69, Control = 3572, Missing = 0\n",
      "\n",
      " SubSubCat_Sertraline\n",
      "  Imp 1: Treated = 102, Control = 3539, Missing = 0\n",
      "  Imp 2: Treated = 102, Control = 3539, Missing = 0\n",
      "  Imp 3: Treated = 102, Control = 3539, Missing = 0\n",
      "  Imp 4: Treated = 102, Control = 3539, Missing = 0\n",
      "  Imp 5: Treated = 102, Control = 3539, Missing = 0\n",
      "\n",
      " SubSubCat_Temazepam\n",
      "  Imp 1: Treated = 93, Control = 3548, Missing = 0\n",
      "  Imp 2: Treated = 93, Control = 3548, Missing = 0\n",
      "  Imp 3: Treated = 93, Control = 3548, Missing = 0\n",
      "  Imp 4: Treated = 93, Control = 3548, Missing = 0\n",
      "  Imp 5: Treated = 93, Control = 3548, Missing = 0\n",
      "\n",
      " SubSubCat_Citalopram\n",
      "  Imp 1: Treated = 125, Control = 3516, Missing = 0\n",
      "  Imp 2: Treated = 125, Control = 3516, Missing = 0\n",
      "  Imp 3: Treated = 125, Control = 3516, Missing = 0\n",
      "  Imp 4: Treated = 125, Control = 3516, Missing = 0\n",
      "  Imp 5: Treated = 125, Control = 3516, Missing = 0\n",
      "\n",
      " SubSubCat_Quetiapine\n",
      "  Imp 1: Treated = 203, Control = 3438, Missing = 0\n",
      "  Imp 2: Treated = 203, Control = 3438, Missing = 0\n",
      "  Imp 3: Treated = 203, Control = 3438, Missing = 0\n",
      "  Imp 4: Treated = 203, Control = 3438, Missing = 0\n",
      "  Imp 5: Treated = 203, Control = 3438, Missing = 0\n",
      "\n",
      " SubSubCat_Amitriptyline\n",
      "  Imp 1: Treated = 52, Control = 3589, Missing = 0\n",
      "  Imp 2: Treated = 52, Control = 3589, Missing = 0\n",
      "  Imp 3: Treated = 52, Control = 3589, Missing = 0\n",
      "  Imp 4: Treated = 52, Control = 3589, Missing = 0\n",
      "  Imp 5: Treated = 52, Control = 3589, Missing = 0\n",
      "\n",
      " SubSubCat_Venlafaxine\n",
      "  Imp 1: Treated = 59, Control = 3582, Missing = 0\n",
      "  Imp 2: Treated = 59, Control = 3582, Missing = 0\n",
      "  Imp 3: Treated = 59, Control = 3582, Missing = 0\n",
      "  Imp 4: Treated = 59, Control = 3582, Missing = 0\n",
      "  Imp 5: Treated = 59, Control = 3582, Missing = 0\n",
      "\n",
      " SubSubCat_Fluoxetine\n",
      "  Imp 1: Treated = 71, Control = 3570, Missing = 0\n",
      "  Imp 2: Treated = 71, Control = 3570, Missing = 0\n",
      "  Imp 3: Treated = 71, Control = 3570, Missing = 0\n",
      "  Imp 4: Treated = 71, Control = 3570, Missing = 0\n",
      "  Imp 5: Treated = 71, Control = 3570, Missing = 0\n",
      "\n",
      " SubSubCat_Topiramaat\n",
      "  Imp 1: Treated = 41, Control = 3600, Missing = 0\n",
      "  Imp 2: Treated = 41, Control = 3600, Missing = 0\n",
      "  Imp 3: Treated = 41, Control = 3600, Missing = 0\n",
      "  Imp 4: Treated = 41, Control = 3600, Missing = 0\n",
      "  Imp 5: Treated = 41, Control = 3600, Missing = 0\n",
      "\n",
      " SubSubCat_Zopiclon\n",
      "  Imp 1: Treated = 32, Control = 3609, Missing = 0\n",
      "  Imp 2: Treated = 32, Control = 3609, Missing = 0\n",
      "  Imp 3: Treated = 32, Control = 3609, Missing = 0\n",
      "  Imp 4: Treated = 32, Control = 3609, Missing = 0\n",
      "  Imp 5: Treated = 32, Control = 3609, Missing = 0\n",
      "\n",
      " SubSubCat_Bupropion\n",
      "  Imp 1: Treated = 34, Control = 3607, Missing = 0\n",
      "  Imp 2: Treated = 34, Control = 3607, Missing = 0\n",
      "  Imp 3: Treated = 34, Control = 3607, Missing = 0\n",
      "  Imp 4: Treated = 34, Control = 3607, Missing = 0\n",
      "  Imp 5: Treated = 34, Control = 3607, Missing = 0\n",
      "\n",
      " SubSubCat_Methylfenidaat\n",
      "  Imp 1: Treated = 38, Control = 3603, Missing = 0\n",
      "  Imp 2: Treated = 38, Control = 3603, Missing = 0\n",
      "  Imp 3: Treated = 38, Control = 3603, Missing = 0\n",
      "  Imp 4: Treated = 38, Control = 3603, Missing = 0\n",
      "  Imp 5: Treated = 38, Control = 3603, Missing = 0\n",
      "\n",
      " SubSubCat_Olanzapine\n",
      "  Imp 1: Treated = 33, Control = 3608, Missing = 0\n",
      "  Imp 2: Treated = 33, Control = 3608, Missing = 0\n",
      "  Imp 3: Treated = 33, Control = 3608, Missing = 0\n",
      "  Imp 4: Treated = 33, Control = 3608, Missing = 0\n",
      "  Imp 5: Treated = 33, Control = 3608, Missing = 0\n"
     ]
    }
   ],
   "source": [
    "for treatment_var in medication_groups:\n",
    "    print(f\"\\n {treatment_var}\")\n",
    "    \n",
    "    for i, df in enumerate(imputed_dfs):\n",
    "        if treatment_var not in df.columns:\n",
    "            print(f\"  Imp {i+1}:  Not found in columns.\")\n",
    "            continue\n",
    "\n",
    "        treated = (df[treatment_var] == 1).sum()\n",
    "        control = (df[treatment_var] == 0).sum()\n",
    "        missing = df[treatment_var].isna().sum()\n",
    "\n",
    "        print(f\"  Imp {i+1}: Treated = {treated}, Control = {control}, Missing = {missing}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "1735200e-f051-4982-b69a-62345955e88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Processing VIF for SubSubCat_Oxazepam\n",
      " ✅ Saved: outputs\\SubSubCat_Oxazepam/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SubSubCat_Diazepam\n",
      " ✅ Saved: outputs\\SubSubCat_Diazepam/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SubSubCat_Paracetamol\n",
      " ✅ Saved: outputs\\SubSubCat_Paracetamol/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SubSubCat_Lorazepam\n",
      " ✅ Saved: outputs\\SubSubCat_Lorazepam/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SubSubCat_Mirtazapine\n",
      " ✅ Saved: outputs\\SubSubCat_Mirtazapine/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SubSubCat_Escitalopram\n",
      " ✅ Saved: outputs\\SubSubCat_Escitalopram/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SubSubCat_Sertraline\n",
      " ✅ Saved: outputs\\SubSubCat_Sertraline/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SubSubCat_Temazepam\n",
      " ✅ Saved: outputs\\SubSubCat_Temazepam/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SubSubCat_Citalopram\n",
      " ✅ Saved: outputs\\SubSubCat_Citalopram/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SubSubCat_Quetiapine\n",
      " ✅ Saved: outputs\\SubSubCat_Quetiapine/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SubSubCat_Amitriptyline\n",
      " ✅ Saved: outputs\\SubSubCat_Amitriptyline/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SubSubCat_Venlafaxine\n",
      " ✅ Saved: outputs\\SubSubCat_Venlafaxine/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SubSubCat_Fluoxetine\n",
      " ✅ Saved: outputs\\SubSubCat_Fluoxetine/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SubSubCat_Topiramaat\n",
      " ✅ Saved: outputs\\SubSubCat_Topiramaat/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SubSubCat_Zopiclon\n",
      " ✅ Saved: outputs\\SubSubCat_Zopiclon/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SubSubCat_Bupropion\n",
      " ✅ Saved: outputs\\SubSubCat_Bupropion/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SubSubCat_Methylfenidaat\n",
      " ✅ Saved: outputs\\SubSubCat_Methylfenidaat/pooled_vif.csv\n",
      "\n",
      "🔍 Processing VIF for SubSubCat_Olanzapine\n",
      " ✅ Saved: outputs\\SubSubCat_Olanzapine/pooled_vif.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from collections import defaultdict\n",
    "\n",
    "# ✅ VIF computation function\n",
    "def compute_vif(X):\n",
    "    X = sm.add_constant(X, has_constant='add')\n",
    "    vif_df = pd.DataFrame()\n",
    "    vif_df[\"variable\"] = X.columns\n",
    "    vif_df[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "    return vif_df\n",
    "\n",
    "# ✅ Process each group\n",
    "for group in medication_groups:\n",
    "    print(f\"\\n🔍 Processing VIF for {group}\")\n",
    "\n",
    "    if group not in final_covariates_map:\n",
    "        print(f\" ⚠️ No covariates found for {group}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    covariates = final_covariates_map[group]\n",
    "    vif_list = []\n",
    "\n",
    "    for i, df_imp in enumerate(imputed_dfs):\n",
    "        try:\n",
    "            X = df_imp[covariates].copy()\n",
    "            vif_df = compute_vif(X)\n",
    "            vif_df[\"imputation\"] = i + 1\n",
    "            vif_list.append(vif_df)\n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ Failed on imputation {i+1} for {group}: {e}\")\n",
    "\n",
    "    if vif_list:\n",
    "        all_vif = pd.concat(vif_list)\n",
    "        pooled_vif = all_vif.groupby(\"variable\")[\"VIF\"].mean().reset_index()\n",
    "        pooled_vif = pooled_vif.sort_values(by=\"VIF\", ascending=False)\n",
    "\n",
    "        output_folder = os.path.join(\"outputs\", group)\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        pooled_vif.to_csv(os.path.join(output_folder, \"pooled_vif.csv\"), index=False)\n",
    "\n",
    "        print(f\" ✅ Saved: {output_folder}/pooled_vif.csv\")\n",
    "    else:\n",
    "        print(f\" ⚠️ Skipped {group}: No valid imputations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "528186ed-26e4-4988-83b8-14883f9d0c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Running PS estimation for SubSubCat_Oxazepam\n",
      "   Imp 1: AUC = 0.750, ROC saved.\n",
      "   Imp 2: AUC = 0.749, ROC saved.\n",
      "   Imp 3: AUC = 0.747, ROC saved.\n",
      "   Imp 4: AUC = 0.753, ROC saved.\n",
      "   Imp 5: AUC = 0.753, ROC saved.\n",
      " Composite PS + AUC saved for SubSubCat_Oxazepam\n",
      " Running PS estimation for SubSubCat_Diazepam\n",
      "   Imp 1: AUC = 0.755, ROC saved.\n",
      "   Imp 2: AUC = 0.746, ROC saved.\n",
      "   Imp 3: AUC = 0.762, ROC saved.\n",
      "   Imp 4: AUC = 0.765, ROC saved.\n",
      "   Imp 5: AUC = 0.747, ROC saved.\n",
      " Composite PS + AUC saved for SubSubCat_Diazepam\n",
      " Running PS estimation for SubSubCat_Paracetamol\n",
      "   Imp 1: AUC = 0.743, ROC saved.\n",
      "   Imp 2: AUC = 0.761, ROC saved.\n",
      "   Imp 3: AUC = 0.747, ROC saved.\n",
      "   Imp 4: AUC = 0.759, ROC saved.\n",
      "   Imp 5: AUC = 0.758, ROC saved.\n",
      " Composite PS + AUC saved for SubSubCat_Paracetamol\n",
      " Running PS estimation for SubSubCat_Lorazepam\n",
      "   Imp 1: AUC = 0.815, ROC saved.\n",
      "   Imp 2: AUC = 0.817, ROC saved.\n",
      "   Imp 3: AUC = 0.838, ROC saved.\n",
      "   Imp 4: AUC = 0.794, ROC saved.\n",
      "   Imp 5: AUC = 0.802, ROC saved.\n",
      " Composite PS + AUC saved for SubSubCat_Lorazepam\n",
      " Running PS estimation for SubSubCat_Mirtazapine\n",
      "   Imp 1: AUC = 0.736, ROC saved.\n",
      "   Imp 2: AUC = 0.738, ROC saved.\n",
      "   Imp 3: AUC = 0.728, ROC saved.\n",
      "   Imp 4: AUC = 0.735, ROC saved.\n",
      "   Imp 5: AUC = 0.740, ROC saved.\n",
      " Composite PS + AUC saved for SubSubCat_Mirtazapine\n",
      " Running PS estimation for SubSubCat_Escitalopram\n",
      "   Imp 1: AUC = 0.553, ROC saved.\n",
      "   Imp 2: AUC = 0.552, ROC saved.\n",
      "   Imp 3: AUC = 0.553, ROC saved.\n",
      "   Imp 4: AUC = 0.558, ROC saved.\n",
      "   Imp 5: AUC = 0.564, ROC saved.\n",
      " Composite PS + AUC saved for SubSubCat_Escitalopram\n",
      " Running PS estimation for SubSubCat_Sertraline\n",
      "   Imp 1: AUC = 0.780, ROC saved.\n",
      "   Imp 2: AUC = 0.781, ROC saved.\n",
      "   Imp 3: AUC = 0.781, ROC saved.\n",
      "   Imp 4: AUC = 0.782, ROC saved.\n",
      "   Imp 5: AUC = 0.783, ROC saved.\n",
      " Composite PS + AUC saved for SubSubCat_Sertraline\n",
      " Running PS estimation for SubSubCat_Temazepam\n",
      "   Imp 1: AUC = 0.606, ROC saved.\n",
      "   Imp 2: AUC = 0.606, ROC saved.\n",
      "   Imp 3: AUC = 0.604, ROC saved.\n",
      "   Imp 4: AUC = 0.606, ROC saved.\n",
      "   Imp 5: AUC = 0.604, ROC saved.\n",
      " Composite PS + AUC saved for SubSubCat_Temazepam\n",
      " Running PS estimation for SubSubCat_Citalopram\n",
      "   Imp 1: AUC = 0.715, ROC saved.\n",
      "   Imp 2: AUC = 0.726, ROC saved.\n",
      "   Imp 3: AUC = 0.723, ROC saved.\n",
      "   Imp 4: AUC = 0.687, ROC saved.\n",
      "   Imp 5: AUC = 0.724, ROC saved.\n",
      " Composite PS + AUC saved for SubSubCat_Citalopram\n",
      " Running PS estimation for SubSubCat_Quetiapine\n",
      "   Imp 1: AUC = 0.825, ROC saved.\n",
      "   Imp 2: AUC = 0.824, ROC saved.\n",
      "   Imp 3: AUC = 0.826, ROC saved.\n",
      "   Imp 4: AUC = 0.826, ROC saved.\n",
      "   Imp 5: AUC = 0.822, ROC saved.\n",
      " Composite PS + AUC saved for SubSubCat_Quetiapine\n",
      " Running PS estimation for SubSubCat_Amitriptyline\n",
      "   Imp 1: AUC = 0.678, ROC saved.\n",
      "   Imp 2: AUC = 0.679, ROC saved.\n",
      "   Imp 3: AUC = 0.686, ROC saved.\n",
      "   Imp 4: AUC = 0.652, ROC saved.\n",
      "   Imp 5: AUC = 0.687, ROC saved.\n",
      " Composite PS + AUC saved for SubSubCat_Amitriptyline\n",
      " Running PS estimation for SubSubCat_Venlafaxine\n",
      "   Imp 1: AUC = 0.760, ROC saved.\n",
      "   Imp 2: AUC = 0.744, ROC saved.\n",
      "   Imp 3: AUC = 0.739, ROC saved.\n",
      "   Imp 4: AUC = 0.711, ROC saved.\n",
      "   Imp 5: AUC = 0.760, ROC saved.\n",
      " Composite PS + AUC saved for SubSubCat_Venlafaxine\n",
      " Running PS estimation for SubSubCat_Fluoxetine\n",
      "   Imp 1: AUC = 0.726, ROC saved.\n",
      "   Imp 2: AUC = 0.723, ROC saved.\n",
      "   Imp 3: AUC = 0.728, ROC saved.\n",
      "   Imp 4: AUC = 0.724, ROC saved.\n",
      "   Imp 5: AUC = 0.718, ROC saved.\n",
      " Composite PS + AUC saved for SubSubCat_Fluoxetine\n",
      " Running PS estimation for SubSubCat_Topiramaat\n",
      "   Imp 1: AUC = 0.908, ROC saved.\n",
      "   Imp 2: AUC = 0.913, ROC saved.\n",
      "   Imp 3: AUC = 0.901, ROC saved.\n",
      "   Imp 4: AUC = 0.909, ROC saved.\n",
      "   Imp 5: AUC = 0.912, ROC saved.\n",
      " Composite PS + AUC saved for SubSubCat_Topiramaat\n",
      " Running PS estimation for SubSubCat_Zopiclon\n",
      "   Imp 1: AUC = 0.569, ROC saved.\n",
      "   Imp 2: AUC = 0.548, ROC saved.\n",
      "   Imp 3: AUC = 0.568, ROC saved.\n",
      "   Imp 4: AUC = 0.554, ROC saved.\n",
      "   Imp 5: AUC = 0.550, ROC saved.\n",
      " Composite PS + AUC saved for SubSubCat_Zopiclon\n",
      " Running PS estimation for SubSubCat_Bupropion\n",
      "   Imp 1: AUC = 0.563, ROC saved.\n",
      "   Imp 2: AUC = 0.563, ROC saved.\n",
      "   Imp 3: AUC = 0.567, ROC saved.\n",
      "   Imp 4: AUC = 0.584, ROC saved.\n",
      "   Imp 5: AUC = 0.572, ROC saved.\n",
      " Composite PS + AUC saved for SubSubCat_Bupropion\n",
      " Running PS estimation for SubSubCat_Methylfenidaat\n",
      "   Imp 1: AUC = 0.708, ROC saved.\n",
      "   Imp 2: AUC = 0.702, ROC saved.\n",
      "   Imp 3: AUC = 0.676, ROC saved.\n",
      "   Imp 4: AUC = 0.730, ROC saved.\n",
      "   Imp 5: AUC = 0.706, ROC saved.\n",
      " Composite PS + AUC saved for SubSubCat_Methylfenidaat\n",
      " Running PS estimation for SubSubCat_Olanzapine\n",
      "   Imp 1: AUC = 0.708, ROC saved.\n",
      "   Imp 2: AUC = 0.704, ROC saved.\n",
      "   Imp 3: AUC = 0.709, ROC saved.\n",
      "   Imp 4: AUC = 0.726, ROC saved.\n",
      "   Imp 5: AUC = 0.698, ROC saved.\n",
      " Composite PS + AUC saved for SubSubCat_Olanzapine\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ---------- PS Estimation Function ----------\n",
    "def run_logistic_ps_modeling(imputed_dfs, medication_groups, final_covariates_map):\n",
    "    for group in medication_groups:\n",
    "        print(f\" Running PS estimation for {group}\")\n",
    "\n",
    "        if group not in final_covariates_map:\n",
    "            print(f\" No covariates found for {group}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        output_folder = os.path.join(\"outputs\", group)\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "        covariates = final_covariates_map[group]\n",
    "        ps_matrix = pd.DataFrame()\n",
    "        auc_list = []\n",
    "\n",
    "        for i, df_imp in enumerate(imputed_dfs):\n",
    "            if group not in df_imp.columns:\n",
    "                print(f\" {group} not found in imputed dataset {i+1}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            X = df_imp[covariates].copy()\n",
    "            T = df_imp[group]\n",
    "\n",
    "            # Drop missing treatment rows\n",
    "            valid_idx = T.dropna().index\n",
    "            X = X.loc[valid_idx]\n",
    "            T = T.loc[valid_idx]\n",
    "\n",
    "            # Train-test split for ROC\n",
    "            X_train, X_test, T_train, T_test = train_test_split(\n",
    "                X, T, stratify=T, test_size=0.3, random_state=42\n",
    "            )\n",
    "\n",
    "            try:\n",
    "                model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "                model.fit(X_train, T_train)\n",
    "\n",
    "                ps_scores = model.predict_proba(X)[:, 1]\n",
    "                ps_matrix[f\"ps_imp{i+1}\"] = pd.Series(ps_scores, index=valid_idx)\n",
    "\n",
    "                # ROC & AUC\n",
    "                auc = roc_auc_score(T_test, model.predict_proba(X_test)[:, 1])\n",
    "                auc_list.append(auc)\n",
    "\n",
    "                fpr, tpr, _ = roc_curve(T_test, model.predict_proba(X_test)[:, 1])\n",
    "                plt.figure()\n",
    "                plt.plot(fpr, tpr, label=f\"AUC = {auc:.3f}\")\n",
    "                plt.plot([0, 1], [0, 1], 'k--')\n",
    "                plt.xlabel(\"False Positive Rate\")\n",
    "                plt.ylabel(\"True Positive Rate\")\n",
    "                plt.title(f\"ROC Curve - {group} (Imp {i+1})\")\n",
    "                plt.legend()\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(os.path.join(output_folder, f\"roc_curve_imp{i+1}.png\"))\n",
    "                plt.close()\n",
    "                print(f\"   Imp {i+1}: AUC = {auc:.3f}, ROC saved.\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"   Error in {group} (imp {i+1}): {e}\")\n",
    "\n",
    "        # Save AUCs and Composite PS\n",
    "        if not ps_matrix.empty:\n",
    "            # Fill NaN rows (from dropped subjects in some imputations) with mean\n",
    "            ps_matrix[\"composite_ps\"] = ps_matrix.mean(axis=1)\n",
    "            ps_matrix.to_excel(os.path.join(output_folder, \"propensity_scores.xlsx\"))\n",
    "\n",
    "            auc_df = pd.DataFrame({\n",
    "                \"imputation\": [f\"imp{i+1}\" for i in range(len(auc_list))],\n",
    "                \"AUC\": auc_list\n",
    "            })\n",
    "            auc_df.loc[len(auc_df.index)] = [\"mean\", np.mean(auc_list) if auc_list else np.nan]\n",
    "            auc_df.to_excel(os.path.join(output_folder, \"auc_scores.xlsx\"), index=False)\n",
    "\n",
    "            print(f\" Composite PS + AUC saved for {group}\")\n",
    "        else:\n",
    "            print(f\" No valid PS scores generated for {group}\")\n",
    "\n",
    "# ---------- Run ----------\n",
    "run_logistic_ps_modeling(imputed_dfs, medication_groups, final_covariates_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "b29752b0-b189-4d0c-92bf-17cbcf7a96d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Computing feature importance for SubSubCat_Oxazepam\n",
      " Saved feature importance plot and CSV for SubSubCat_Oxazepam\n",
      "\n",
      " Computing feature importance for SubSubCat_Diazepam\n",
      " Saved feature importance plot and CSV for SubSubCat_Diazepam\n",
      "\n",
      " Computing feature importance for SubSubCat_Paracetamol\n",
      " Saved feature importance plot and CSV for SubSubCat_Paracetamol\n",
      "\n",
      " Computing feature importance for SubSubCat_Lorazepam\n",
      " Saved feature importance plot and CSV for SubSubCat_Lorazepam\n",
      "\n",
      " Computing feature importance for SubSubCat_Mirtazapine\n",
      " Saved feature importance plot and CSV for SubSubCat_Mirtazapine\n",
      "\n",
      " Computing feature importance for SubSubCat_Escitalopram\n",
      " Saved feature importance plot and CSV for SubSubCat_Escitalopram\n",
      "\n",
      " Computing feature importance for SubSubCat_Sertraline\n",
      " Saved feature importance plot and CSV for SubSubCat_Sertraline\n",
      "\n",
      " Computing feature importance for SubSubCat_Temazepam\n",
      " Saved feature importance plot and CSV for SubSubCat_Temazepam\n",
      "\n",
      " Computing feature importance for SubSubCat_Citalopram\n",
      " Saved feature importance plot and CSV for SubSubCat_Citalopram\n",
      "\n",
      " Computing feature importance for SubSubCat_Quetiapine\n",
      " Saved feature importance plot and CSV for SubSubCat_Quetiapine\n",
      "\n",
      " Computing feature importance for SubSubCat_Amitriptyline\n",
      " Saved feature importance plot and CSV for SubSubCat_Amitriptyline\n",
      "\n",
      " Computing feature importance for SubSubCat_Venlafaxine\n",
      " Saved feature importance plot and CSV for SubSubCat_Venlafaxine\n",
      "\n",
      " Computing feature importance for SubSubCat_Fluoxetine\n",
      " Saved feature importance plot and CSV for SubSubCat_Fluoxetine\n",
      "\n",
      " Computing feature importance for SubSubCat_Topiramaat\n",
      " Saved feature importance plot and CSV for SubSubCat_Topiramaat\n",
      "\n",
      " Computing feature importance for SubSubCat_Zopiclon\n",
      " Saved feature importance plot and CSV for SubSubCat_Zopiclon\n",
      "\n",
      " Computing feature importance for SubSubCat_Bupropion\n",
      " Saved feature importance plot and CSV for SubSubCat_Bupropion\n",
      "\n",
      " Computing feature importance for SubSubCat_Methylfenidaat\n",
      " Saved feature importance plot and CSV for SubSubCat_Methylfenidaat\n",
      "\n",
      " Computing feature importance for SubSubCat_Olanzapine\n",
      " Saved feature importance plot and CSV for SubSubCat_Olanzapine\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def compute_feature_importance(imputed_dfs, medication_groups, final_covariates_map):\n",
    "    for group in medication_groups:\n",
    "        print(f\"\\n Computing feature importance for {group}\")\n",
    "\n",
    "        if group not in final_covariates_map:\n",
    "            print(f\" No covariates found for {group}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        covariates = final_covariates_map[group]\n",
    "        output_folder = os.path.join(\"outputs\", group)\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "        importance_df_list = []\n",
    "\n",
    "        for i, df_imp in enumerate(imputed_dfs):\n",
    "            if group not in df_imp.columns:\n",
    "                print(f\" {group} not in imputed dataset {i+1}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            X = df_imp[covariates].copy()\n",
    "            T = df_imp[group]\n",
    "\n",
    "            # Drop NaNs in treatment\n",
    "            valid_idx = T.dropna().index\n",
    "            X = X.loc[valid_idx]\n",
    "            T = T.loc[valid_idx]\n",
    "\n",
    "            try:\n",
    "                model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "                model.fit(X, T)\n",
    "\n",
    "                # Get feature importance (absolute coefficients)\n",
    "                importances = np.abs(model.coef_[0])\n",
    "                importance_dict = dict(zip(X.columns, importances))\n",
    "                df_feat = pd.DataFrame.from_dict(importance_dict, orient='index', columns=[f\"imp{i+1}\"])\n",
    "                df_feat.index.name = 'feature'\n",
    "                importance_df_list.append(df_feat)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"   Error during modeling: {e}\")\n",
    "\n",
    "        if importance_df_list:\n",
    "            # Combine and average\n",
    "            all_feat = pd.concat(importance_df_list, axis=1).fillna(0)\n",
    "            all_feat[\"mean_importance\"] = all_feat.mean(axis=1)\n",
    "\n",
    "            # Filter top 30 non-zero\n",
    "            non_zero = all_feat[all_feat[\"mean_importance\"] > 0]\n",
    "            top30 = non_zero.sort_values(by=\"mean_importance\", ascending=False).head(30)\n",
    "\n",
    "            # Save to CSV\n",
    "            top30.to_csv(os.path.join(output_folder, \"feature_importance.csv\"))\n",
    "\n",
    "            # Plot\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            plt.barh(top30.index[::-1], top30[\"mean_importance\"][::-1])  # plot top → bottom\n",
    "            plt.xlabel(\"Mean Gain Importance\")\n",
    "            plt.title(f\"Top 30 Feature Importance - {group}\")\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(output_folder, \"feature_importance_top30.png\"))\n",
    "            plt.close()\n",
    "\n",
    "            print(f\" Saved feature importance plot and CSV for {group}\")\n",
    "        else:\n",
    "            print(f\" No valid models for {group}\")\n",
    "\n",
    "#  Run\n",
    "compute_feature_importance(imputed_dfs, medication_groups, final_covariates_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "aec84d68-8957-4d30-b509-c6fe2224a9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SubSubCat_Oxazepam\n",
      "✅ Saved IPTW weights for SubSubCat_Oxazepam\n",
      "    ℹ️ Retained 1251/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Oxazepam/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 1249/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Oxazepam/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 1251/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Oxazepam/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 1265/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Oxazepam/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 1260/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Oxazepam/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SubSubCat_Diazepam\n",
      "✅ Saved IPTW weights for SubSubCat_Diazepam\n",
      "    ℹ️ Retained 90/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Diazepam/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 95/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Diazepam/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 88/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Diazepam/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 94/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Diazepam/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 101/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Diazepam/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SubSubCat_Paracetamol\n",
      "✅ Saved IPTW weights for SubSubCat_Paracetamol\n",
      "    ℹ️ Retained 131/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Paracetamol/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 115/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Paracetamol/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 120/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Paracetamol/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 116/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Paracetamol/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 114/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Paracetamol/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SubSubCat_Lorazepam\n",
      "✅ Saved IPTW weights for SubSubCat_Lorazepam\n",
      "    ℹ️ Retained 284/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Lorazepam/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 282/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Lorazepam/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 284/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Lorazepam/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 289/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Lorazepam/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 279/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Lorazepam/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SubSubCat_Mirtazapine\n",
      "✅ Saved IPTW weights for SubSubCat_Mirtazapine\n",
      "    ℹ️ Retained 391/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Mirtazapine/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 395/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Mirtazapine/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 388/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Mirtazapine/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 397/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Mirtazapine/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 399/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Mirtazapine/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SubSubCat_Escitalopram\n",
      "✅ Saved IPTW weights for SubSubCat_Escitalopram\n",
      "    ℹ️ Retained 219/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Escitalopram/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 223/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Escitalopram/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 222/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Escitalopram/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 221/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Escitalopram/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 218/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Escitalopram/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SubSubCat_Sertraline\n",
      "✅ Saved IPTW weights for SubSubCat_Sertraline\n",
      "    ℹ️ Retained 490/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Sertraline/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 500/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Sertraline/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 499/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Sertraline/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 483/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Sertraline/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 502/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Sertraline/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SubSubCat_Temazepam\n",
      "✅ Saved IPTW weights for SubSubCat_Temazepam\n",
      "    ℹ️ Retained 398/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Temazepam/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 396/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Temazepam/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 398/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Temazepam/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 396/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Temazepam/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 399/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Temazepam/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SubSubCat_Citalopram\n",
      "✅ Saved IPTW weights for SubSubCat_Citalopram\n",
      "    ℹ️ Retained 666/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Citalopram/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 675/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Citalopram/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 686/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Citalopram/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 680/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Citalopram/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 678/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Citalopram/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SubSubCat_Quetiapine\n",
      "✅ Saved IPTW weights for SubSubCat_Quetiapine\n",
      "    ℹ️ Retained 1023/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Quetiapine/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 1031/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Quetiapine/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 1010/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Quetiapine/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 1020/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Quetiapine/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 1022/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Quetiapine/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SubSubCat_Amitriptyline\n",
      "✅ Saved IPTW weights for SubSubCat_Amitriptyline\n",
      "    ℹ️ Retained 86/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Amitriptyline/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 82/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Amitriptyline/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 80/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Amitriptyline/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 70/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Amitriptyline/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 73/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Amitriptyline/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SubSubCat_Venlafaxine\n",
      "✅ Saved IPTW weights for SubSubCat_Venlafaxine\n",
      "    ℹ️ Retained 208/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Venlafaxine/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 201/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Venlafaxine/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 224/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Venlafaxine/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 219/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Venlafaxine/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 217/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Venlafaxine/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SubSubCat_Fluoxetine\n",
      "✅ Saved IPTW weights for SubSubCat_Fluoxetine\n",
      "    ℹ️ Retained 287/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Fluoxetine/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 275/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Fluoxetine/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 264/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Fluoxetine/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 270/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Fluoxetine/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 268/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Fluoxetine/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SubSubCat_Topiramaat\n",
      "✅ Saved IPTW weights for SubSubCat_Topiramaat\n",
      "    ℹ️ Retained 168/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Topiramaat/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 169/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Topiramaat/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 160/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Topiramaat/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 168/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Topiramaat/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 169/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Topiramaat/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SubSubCat_Zopiclon\n",
      "✅ Saved IPTW weights for SubSubCat_Zopiclon\n",
      "    ℹ️ Retained 127/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Zopiclon/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 114/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Zopiclon/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 127/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Zopiclon/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 137/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Zopiclon/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 121/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Zopiclon/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SubSubCat_Bupropion\n",
      "✅ Saved IPTW weights for SubSubCat_Bupropion\n",
      "    ℹ️ Retained 53/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Bupropion/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 51/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Bupropion/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 52/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Bupropion/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 68/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Bupropion/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 55/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Bupropion/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SubSubCat_Methylfenidaat\n",
      "✅ Saved IPTW weights for SubSubCat_Methylfenidaat\n",
      "    ℹ️ Retained 71/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Methylfenidaat/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 66/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Methylfenidaat/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 71/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Methylfenidaat/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 67/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Methylfenidaat/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 69/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Methylfenidaat/trimmed_data_imp5.*\n",
      "\n",
      "🔍 Processing IPTW + trimming + clipping for SubSubCat_Olanzapine\n",
      "✅ Saved IPTW weights for SubSubCat_Olanzapine\n",
      "    ℹ️ Retained 111/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Olanzapine/trimmed_data_imp1.*\n",
      "    ℹ️ Retained 102/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Olanzapine/trimmed_data_imp2.*\n",
      "    ℹ️ Retained 107/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Olanzapine/trimmed_data_imp3.*\n",
      "    ℹ️ Retained 99/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Olanzapine/trimmed_data_imp4.*\n",
      "    ℹ️ Retained 107/3641 rows after IPTW NaN drop.\n",
      "  💾 Saved trimmed dataset: outputs\\SubSubCat_Olanzapine/trimmed_data_imp5.*\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_trimmed_clipped_iptw(ps_df, treatment, lower=0.05, upper=0.95, clip_max=10):\n",
    "    weights = []\n",
    "    keep_mask = (ps_df > lower) & (ps_df < upper)\n",
    "\n",
    "    for i in range(ps_df.shape[1]):\n",
    "        ps = ps_df.iloc[:, i].clip(lower=1e-6, upper=1 - 1e-6)  # avoid div by zero\n",
    "        mask = keep_mask.iloc[:, i]\n",
    "        w = pd.Series(np.nan, index=ps.index)\n",
    "\n",
    "        w[mask & (treatment == 1)] = 1 / ps[mask & (treatment == 1)]\n",
    "        w[mask & (treatment == 0)] = 1 / (1 - ps[mask & (treatment == 0)])\n",
    "        w = w.clip(upper=clip_max)\n",
    "        weights.append(w)\n",
    "\n",
    "    return pd.concat(weights, axis=1)\n",
    "\n",
    "\n",
    "def apply_rubins_rule_to_iptw(iptw_matrix):\n",
    "    \"\"\"\n",
    "    Given an IPTW matrix (n rows × M imputations), return Rubin’s rule pooled mean, SD, SE.\n",
    "    \"\"\"\n",
    "    M = iptw_matrix.shape[1]\n",
    "    q_bar = iptw_matrix.mean(axis=1)\n",
    "    u_bar = iptw_matrix.var(axis=1, ddof=1)\n",
    "    B = iptw_matrix.apply(lambda x: x.mean(), axis=1).var(ddof=1)\n",
    "    total_var = u_bar + (1 + 1/M) * B\n",
    "    total_se = np.sqrt(total_var)\n",
    "    return q_bar, u_bar.pow(0.5), total_se\n",
    "\n",
    "\n",
    "def run_trim_clip_save_all(imputed_dfs, medication_groups, final_covariates_map):\n",
    "    for group in medication_groups:\n",
    "        print(f\"\\n🔍 Processing IPTW + trimming + clipping for {group}\")\n",
    "        output_folder = os.path.join(\"outputs\", group)\n",
    "        ps_path = os.path.join(output_folder, \"propensity_scores.xlsx\")\n",
    "\n",
    "        if not os.path.exists(ps_path):\n",
    "            print(f\"⚠️ Missing PS file: {ps_path}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            ps_all = pd.read_excel(ps_path, index_col=0)\n",
    "            ps_cols = [col for col in ps_all.columns if col.startswith(\"ps_imp\")]\n",
    "            composite_index = ps_all.index\n",
    "\n",
    "            # Get treatment from one imputed dataset\n",
    "            T_full = None\n",
    "            for df in imputed_dfs:\n",
    "                if group in df.columns:\n",
    "                    T_full = df.loc[composite_index, group]\n",
    "                    break\n",
    "\n",
    "            if T_full is None:\n",
    "                print(f\"❌ Treatment column {group} not found in any imputed dataset.\")\n",
    "                continue\n",
    "\n",
    "            # Compute IPTW matrix (shape: n × M)\n",
    "            iptw_matrix = compute_trimmed_clipped_iptw(ps_all[ps_cols], T_full)\n",
    "            iptw_matrix.columns = [f\"iptw_imp{i+1}\" for i in range(iptw_matrix.shape[1])]\n",
    "\n",
    "            # Apply Rubin’s Rule for mean, SD, SE\n",
    "            iptw_matrix[\"iptw_mean\"], iptw_matrix[\"iptw_sd\"], iptw_matrix[\"iptw_se\"] = apply_rubins_rule_to_iptw(\n",
    "                iptw_matrix[[f\"iptw_imp{i+1}\" for i in range(iptw_matrix.shape[1])]]\n",
    "            )\n",
    "\n",
    "            # Save IPTW matrix separately\n",
    "            iptw_matrix.to_excel(os.path.join(output_folder, \"iptw_weights.xlsx\"))\n",
    "            print(f\"✅ Saved IPTW weights for {group}\")\n",
    "\n",
    "            # Save trimmed & clipped imputed datasets with IPTW\n",
    "            for i in range(5):\n",
    "                df = imputed_dfs[i].copy()\n",
    "                if group not in df.columns:\n",
    "                    continue\n",
    "\n",
    "                trimmed_idx = iptw_matrix.index.intersection(df.index)\n",
    "                needed_cols = final_covariates_map[group] + [group, \"caps5_change_baseline\"]\n",
    "\n",
    "                # Select only necessary columns\n",
    "                df_trimmed = df.loc[trimmed_idx, needed_cols].copy()\n",
    "                df_trimmed[\"iptw\"] = iptw_matrix[f\"iptw_imp{i+1}\"].loc[trimmed_idx]\n",
    "\n",
    "                # ✅ DROP rows with missing IPTW values\n",
    "                before = len(df_trimmed)\n",
    "                df_trimmed = df_trimmed.dropna(subset=[\"iptw\"])\n",
    "                after = len(df_trimmed)\n",
    "                print(f\"    ℹ️ Retained {after}/{before} rows after IPTW NaN drop.\")\n",
    "\n",
    "                # Save to .pkl\n",
    "                df_trimmed.to_pickle(os.path.join(output_folder, f\"trimmed_data_imp{i+1}.pkl\"))\n",
    "                print(f\"  💾 Saved trimmed dataset: {output_folder}/trimmed_data_imp{i+1}.*\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error in {group}: {e}\")\n",
    "\n",
    "\n",
    "run_trim_clip_save_all(imputed_dfs, medication_groups, final_covariates_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "0fc51d56-a7dc-4735-b9a7-9f1645bd811f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Plotting PS overlap for SubSubCat_Oxazepam\n",
      "✅ Saved unweighted and weighted PS plots for SubSubCat_Oxazepam\n",
      "\n",
      "📊 Plotting PS overlap for SubSubCat_Diazepam\n",
      "✅ Saved unweighted and weighted PS plots for SubSubCat_Diazepam\n",
      "\n",
      "📊 Plotting PS overlap for SubSubCat_Paracetamol\n",
      "✅ Saved unweighted and weighted PS plots for SubSubCat_Paracetamol\n",
      "\n",
      "📊 Plotting PS overlap for SubSubCat_Lorazepam\n",
      "✅ Saved unweighted and weighted PS plots for SubSubCat_Lorazepam\n",
      "\n",
      "📊 Plotting PS overlap for SubSubCat_Mirtazapine\n",
      "✅ Saved unweighted and weighted PS plots for SubSubCat_Mirtazapine\n",
      "\n",
      "📊 Plotting PS overlap for SubSubCat_Escitalopram\n",
      "✅ Saved unweighted and weighted PS plots for SubSubCat_Escitalopram\n",
      "\n",
      "📊 Plotting PS overlap for SubSubCat_Sertraline\n",
      "✅ Saved unweighted and weighted PS plots for SubSubCat_Sertraline\n",
      "\n",
      "📊 Plotting PS overlap for SubSubCat_Temazepam\n",
      "✅ Saved unweighted and weighted PS plots for SubSubCat_Temazepam\n",
      "\n",
      "📊 Plotting PS overlap for SubSubCat_Citalopram\n",
      "✅ Saved unweighted and weighted PS plots for SubSubCat_Citalopram\n",
      "\n",
      "📊 Plotting PS overlap for SubSubCat_Quetiapine\n",
      "✅ Saved unweighted and weighted PS plots for SubSubCat_Quetiapine\n",
      "\n",
      "📊 Plotting PS overlap for SubSubCat_Amitriptyline\n",
      "✅ Saved unweighted and weighted PS plots for SubSubCat_Amitriptyline\n",
      "\n",
      "📊 Plotting PS overlap for SubSubCat_Venlafaxine\n",
      "✅ Saved unweighted and weighted PS plots for SubSubCat_Venlafaxine\n",
      "\n",
      "📊 Plotting PS overlap for SubSubCat_Fluoxetine\n",
      "✅ Saved unweighted and weighted PS plots for SubSubCat_Fluoxetine\n",
      "\n",
      "📊 Plotting PS overlap for SubSubCat_Topiramaat\n",
      "✅ Saved unweighted and weighted PS plots for SubSubCat_Topiramaat\n",
      "\n",
      "📊 Plotting PS overlap for SubSubCat_Zopiclon\n",
      "✅ Saved unweighted and weighted PS plots for SubSubCat_Zopiclon\n",
      "\n",
      "📊 Plotting PS overlap for SubSubCat_Bupropion\n",
      "✅ Saved unweighted and weighted PS plots for SubSubCat_Bupropion\n",
      "\n",
      "📊 Plotting PS overlap for SubSubCat_Methylfenidaat\n",
      "✅ Saved unweighted and weighted PS plots for SubSubCat_Methylfenidaat\n",
      "\n",
      "📊 Plotting PS overlap for SubSubCat_Olanzapine\n",
      "✅ Saved unweighted and weighted PS plots for SubSubCat_Olanzapine\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_ps_overlap_all_groups(medication_groups):\n",
    "    for group in medication_groups:\n",
    "        print(f\"\\n📊 Plotting PS overlap for {group}\")\n",
    "\n",
    "        folder = os.path.join(\"outputs\", group)\n",
    "        ps_file = os.path.join(folder, \"propensity_scores.xlsx\")\n",
    "        iptw_file = os.path.join(folder, \"iptw_weights.xlsx\")\n",
    "        trimmed_file = os.path.join(folder, \"trimmed_data_imp1.pkl\")\n",
    "\n",
    "        if not all(os.path.exists(f) for f in [ps_file, iptw_file, trimmed_file]):\n",
    "            print(f\"⚠️ Missing required files for {group}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            ps_df = pd.read_excel(ps_file, index_col=0)\n",
    "            iptw_df = pd.read_excel(iptw_file, index_col=0)\n",
    "            trimmed_df = pd.read_pickle(trimmed_file)\n",
    "\n",
    "            # Extract\n",
    "            ps = ps_df[\"composite_ps\"].reindex(trimmed_df.index)\n",
    "            w = iptw_df[\"iptw_mean\"].reindex(trimmed_df.index)\n",
    "            T = trimmed_df[group]\n",
    "\n",
    "            # Masks to remove NaNs\n",
    "            treated_mask = (T == 1) & ps.notna() & w.notna()\n",
    "            control_mask = (T == 0) & ps.notna() & w.notna()\n",
    "\n",
    "            treated = ps[treated_mask]\n",
    "            treated_w = w[treated_mask]\n",
    "\n",
    "            control = ps[control_mask]\n",
    "            control_w = w[control_mask]\n",
    "\n",
    "            # === Unweighted Plot ===\n",
    "            plt.figure(figsize=(8, 5))\n",
    "            plt.hist([treated, control], bins=25, label=[\"Treated\", \"Control\"], alpha=0.6)\n",
    "            plt.title(f\"Unweighted PS Overlap - {group}\")\n",
    "            plt.xlabel(\"Composite Propensity Score\")\n",
    "            plt.ylabel(\"Count\")\n",
    "            plt.legend()\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(folder, \"ps_overlap_unweighted.png\"))\n",
    "            plt.close()\n",
    "\n",
    "            # === Weighted Plot ===\n",
    "            plt.figure(figsize=(8, 5))\n",
    "            plt.hist([treated, control], bins=25, weights=[treated_w, control_w], label=[\"Treated\", \"Control\"], alpha=0.6)\n",
    "            plt.title(f\"Weighted PS Overlap - {group}\")\n",
    "            plt.xlabel(\"Composite Propensity Score\")\n",
    "            plt.ylabel(\"Weighted Count\")\n",
    "            plt.legend()\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(folder, \"ps_overlap_weighted.png\"))\n",
    "            plt.close()\n",
    "\n",
    "            print(f\"✅ Saved unweighted and weighted PS plots for {group}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error processing {group}: {e}\")\n",
    "\n",
    "# 🔁 Run\n",
    "plot_ps_overlap_all_groups(medication_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "9b3cfb7d-89a3-4646-a30c-59dfd41f5c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ✅ Saved: outputs\\SubSubCat_Oxazepam\\four_panel_overlap_SubSubCat_Oxazepam.png\n",
      " ✅ Saved: outputs\\SubSubCat_Diazepam\\four_panel_overlap_SubSubCat_Diazepam.png\n",
      " ✅ Saved: outputs\\SubSubCat_Paracetamol\\four_panel_overlap_SubSubCat_Paracetamol.png\n",
      " ✅ Saved: outputs\\SubSubCat_Lorazepam\\four_panel_overlap_SubSubCat_Lorazepam.png\n",
      " ✅ Saved: outputs\\SubSubCat_Mirtazapine\\four_panel_overlap_SubSubCat_Mirtazapine.png\n",
      " ✅ Saved: outputs\\SubSubCat_Escitalopram\\four_panel_overlap_SubSubCat_Escitalopram.png\n",
      " ✅ Saved: outputs\\SubSubCat_Sertraline\\four_panel_overlap_SubSubCat_Sertraline.png\n",
      " ✅ Saved: outputs\\SubSubCat_Temazepam\\four_panel_overlap_SubSubCat_Temazepam.png\n",
      " ✅ Saved: outputs\\SubSubCat_Citalopram\\four_panel_overlap_SubSubCat_Citalopram.png\n",
      " ✅ Saved: outputs\\SubSubCat_Quetiapine\\four_panel_overlap_SubSubCat_Quetiapine.png\n",
      " ✅ Saved: outputs\\SubSubCat_Amitriptyline\\four_panel_overlap_SubSubCat_Amitriptyline.png\n",
      " ✅ Saved: outputs\\SubSubCat_Venlafaxine\\four_panel_overlap_SubSubCat_Venlafaxine.png\n",
      " ✅ Saved: outputs\\SubSubCat_Fluoxetine\\four_panel_overlap_SubSubCat_Fluoxetine.png\n",
      " ✅ Saved: outputs\\SubSubCat_Topiramaat\\four_panel_overlap_SubSubCat_Topiramaat.png\n",
      " ✅ Saved: outputs\\SubSubCat_Zopiclon\\four_panel_overlap_SubSubCat_Zopiclon.png\n",
      " ✅ Saved: outputs\\SubSubCat_Bupropion\\four_panel_overlap_SubSubCat_Bupropion.png\n",
      " ✅ Saved: outputs\\SubSubCat_Methylfenidaat\\four_panel_overlap_SubSubCat_Methylfenidaat.png\n",
      " ✅ Saved: outputs\\SubSubCat_Olanzapine\\four_panel_overlap_SubSubCat_Olanzapine.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set up base output folder\n",
    "output_base = \"outputs\"\n",
    "ps_file = \"propensity_scores.xlsx\"\n",
    "iptw_file = \"iptw_weights.xlsx\"\n",
    "trimmed_data_file = \"trimmed_data_imp1.pkl\"\n",
    "\n",
    "# Collect all treatment group folders\n",
    "groups = [g for g in medication_groups if os.path.isdir(os.path.join(output_base, g))]\n",
    "\n",
    "# Generate 4-panel overlap plots\n",
    "for group in groups:\n",
    "    group_path = os.path.join(output_base, group)\n",
    "    try:\n",
    "        # Load trimmed treatment info\n",
    "        trimmed_df = pd.read_pickle(os.path.join(group_path, trimmed_data_file))\n",
    "        index = trimmed_df.index\n",
    "\n",
    "        # Fix: case-insensitive match for treatment variable\n",
    "        possible_cols = [col for col in trimmed_df.columns if col.upper() == group.upper()]\n",
    "        if not possible_cols:\n",
    "            print(f\" Treatment variable {group} not found in {group}, skipping.\")\n",
    "            continue\n",
    "        treatment_var = possible_cols[0]\n",
    "        T = trimmed_df[treatment_var]\n",
    "\n",
    "        # Load composite PS (aligned to trimmed_df index)\n",
    "        ps_df = pd.read_excel(os.path.join(group_path, ps_file), index_col=0)\n",
    "        if 'composite_ps' not in ps_df.columns:\n",
    "            print(f\" Composite column missing in {ps_file}, skipping {group}.\")\n",
    "            continue\n",
    "        ps = ps_df.loc[index, 'composite_ps']\n",
    "\n",
    "        # Load IPTW weights (aligned to trimmed_df index)\n",
    "        weights_df = pd.read_excel(os.path.join(group_path, iptw_file), index_col=0)\n",
    "        if 'iptw_mean' not in weights_df.columns:\n",
    "            print(f\" IPTW weight column missing in {iptw_file}, skipping {group}.\")\n",
    "            continue\n",
    "        weights = weights_df.loc[index, 'iptw_mean']\n",
    "\n",
    "        # Prepare 4 datasets\n",
    "        raw_treated = ps[T == 1]\n",
    "        raw_control = ps[T == 0]\n",
    "        weighted_treated = (ps[T == 1], weights[T == 1])\n",
    "        weighted_control = (ps[T == 0], weights[T == 0])\n",
    "\n",
    "        # Create plot\n",
    "        fig, axs = plt.subplots(2, 2, figsize=(12, 8))\n",
    "        fig.suptitle(f\"Propensity Score Distribution - {group}\", fontsize=14)\n",
    "\n",
    "        axs[0, 0].hist(raw_treated, bins=20, alpha=0.7, color='blue')\n",
    "        axs[0, 0].set_title(\"Raw Treated\")\n",
    "\n",
    "        axs[0, 1].hist(raw_control, bins=20, alpha=0.7, color='green')\n",
    "        axs[0, 1].set_title(\"Raw Control\")\n",
    "\n",
    "        axs[1, 0].hist(weighted_treated[0], bins=20, weights=weighted_treated[1], alpha=0.7, color='blue')\n",
    "        axs[1, 0].set_title(\"Weighted Treated\")\n",
    "\n",
    "        axs[1, 1].hist(weighted_control[0], bins=20, weights=weighted_control[1], alpha=0.7, color='green')\n",
    "        axs[1, 1].set_title(\"Weighted Control\")\n",
    "\n",
    "        for ax in axs.flat:\n",
    "            ax.set_xlim(0, 1)\n",
    "            ax.set_xlabel(\"Propensity Score\")\n",
    "            ax.set_ylabel(\"Count\")\n",
    "\n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "\n",
    "        # Save figure\n",
    "        plot_path = os.path.join(group_path, f\"four_panel_overlap_{group}.png\")\n",
    "        plt.savefig(plot_path)\n",
    "        plt.close()\n",
    "        print(f\" ✅ Saved: {plot_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\" ❌ Error in {group}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "859bca6c-231a-474e-a286-a502ad718a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ATT calculation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "f6a37efb-712b-4a73-aaa2-b62ca84f289c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weighted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "4214a077-9e99-4d3e-b9c6-12cf0486f5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Running OLS for SubSubCat_Oxazepam\n",
      "✅ SubSubCat_Oxazepam | Seed 1: ATT = 0.5705, SE = 1.8107, p = 0.76845\n",
      "✅ SubSubCat_Oxazepam | Seed 2: ATT = 0.7490, SE = 1.7494, p = 0.69060\n",
      "✅ SubSubCat_Oxazepam | Seed 3: ATT = 1.6505, SE = 1.4800, p = 0.32722\n",
      "✅ SubSubCat_Oxazepam | Seed 4: ATT = 1.2022, SE = 2.0133, p = 0.58259\n",
      "✅ SubSubCat_Oxazepam | Seed 5: ATT = 0.8220, SE = 2.1818, p = 0.72549\n",
      "✅ SubSubCat_Oxazepam | Seed 6: ATT = 0.5920, SE = 1.3018, p = 0.67286\n",
      "✅ SubSubCat_Oxazepam | Seed 7: ATT = 1.2967, SE = 1.8697, p = 0.52616\n",
      "✅ SubSubCat_Oxazepam | Seed 8: ATT = 1.2093, SE = 1.7328, p = 0.52370\n",
      "✅ SubSubCat_Oxazepam | Seed 9: ATT = 0.8009, SE = 1.9111, p = 0.69669\n",
      "✅ SubSubCat_Oxazepam | Seed 10: ATT = -0.3863, SE = 1.4669, p = 0.80530\n",
      "📊 Diagnostic plots saved for SubSubCat_Oxazepam\n",
      "🏆 Best result for SubSubCat_Oxazepam → Seed 6 | SE = 1.3018\n",
      "\n",
      "🚀 Running OLS for SubSubCat_Diazepam\n",
      "✅ SubSubCat_Diazepam | Seed 1: ATT = -6.1380, SE = 7.3974, p = 0.45332\n",
      "✅ SubSubCat_Diazepam | Seed 2: ATT = 0.9681, SE = 8.2068, p = 0.91179\n",
      "✅ SubSubCat_Diazepam | Seed 3: ATT = -4.3587, SE = 8.1900, p = 0.62278\n",
      "✅ SubSubCat_Diazepam | Seed 4: ATT = -2.5692, SE = 8.1805, p = 0.76917\n",
      "✅ SubSubCat_Diazepam | Seed 5: ATT = -2.5094, SE = 8.8732, p = 0.79135\n",
      "✅ SubSubCat_Diazepam | Seed 6: ATT = -5.7700, SE = 7.5991, p = 0.48995\n",
      "✅ SubSubCat_Diazepam | Seed 7: ATT = 3.5049, SE = 12.5775, p = 0.79432\n",
      "✅ SubSubCat_Diazepam | Seed 8: ATT = 1.9492, SE = 6.0938, p = 0.76508\n",
      "✅ SubSubCat_Diazepam | Seed 9: ATT = -9.8212, SE = 8.4282, p = 0.30866\n",
      "✅ SubSubCat_Diazepam | Seed 10: ATT = -7.3670, SE = 7.9282, p = 0.40537\n",
      "📊 Diagnostic plots saved for SubSubCat_Diazepam\n",
      "🏆 Best result for SubSubCat_Diazepam → Seed 8 | SE = 6.0938\n",
      "\n",
      "🚀 Running OLS for SubSubCat_Paracetamol\n",
      "✅ SubSubCat_Paracetamol | Seed 1: ATT = 4.3479, SE = 6.6863, p = 0.55098\n",
      "✅ SubSubCat_Paracetamol | Seed 2: ATT = 3.4811, SE = 7.6491, p = 0.67265\n",
      "✅ SubSubCat_Paracetamol | Seed 3: ATT = 7.0887, SE = 5.7274, p = 0.28352\n",
      "✅ SubSubCat_Paracetamol | Seed 4: ATT = 7.8227, SE = 7.9350, p = 0.38002\n",
      "✅ SubSubCat_Paracetamol | Seed 5: ATT = -0.4082, SE = 8.5642, p = 0.96427\n",
      "✅ SubSubCat_Paracetamol | Seed 6: ATT = 6.2839, SE = 6.3933, p = 0.38131\n",
      "✅ SubSubCat_Paracetamol | Seed 7: ATT = 7.0241, SE = 9.3139, p = 0.49272\n",
      "✅ SubSubCat_Paracetamol | Seed 8: ATT = 9.8257, SE = 8.4484, p = 0.30947\n",
      "✅ SubSubCat_Paracetamol | Seed 9: ATT = 8.0598, SE = 8.0673, p = 0.37430\n",
      "✅ SubSubCat_Paracetamol | Seed 10: ATT = 2.1051, SE = 5.4026, p = 0.71666\n",
      "📊 Diagnostic plots saved for SubSubCat_Paracetamol\n",
      "🏆 Best result for SubSubCat_Paracetamol → Seed 10 | SE = 5.4026\n",
      "\n",
      "🚀 Running OLS for SubSubCat_Lorazepam\n",
      "✅ SubSubCat_Lorazepam | Seed 1: ATT = 2.3966, SE = 4.2419, p = 0.60227\n",
      "✅ SubSubCat_Lorazepam | Seed 2: ATT = -0.2551, SE = 3.4701, p = 0.94492\n",
      "✅ SubSubCat_Lorazepam | Seed 3: ATT = 3.2795, SE = 3.7647, p = 0.43285\n",
      "✅ SubSubCat_Lorazepam | Seed 4: ATT = 2.1366, SE = 3.4397, p = 0.56814\n",
      "✅ SubSubCat_Lorazepam | Seed 5: ATT = 2.5855, SE = 4.4971, p = 0.59613\n",
      "✅ SubSubCat_Lorazepam | Seed 6: ATT = 2.4847, SE = 4.8994, p = 0.63874\n",
      "✅ SubSubCat_Lorazepam | Seed 7: ATT = 3.1741, SE = 4.1209, p = 0.48413\n",
      "✅ SubSubCat_Lorazepam | Seed 8: ATT = 2.4791, SE = 4.4064, p = 0.60373\n",
      "✅ SubSubCat_Lorazepam | Seed 9: ATT = 2.7829, SE = 3.8606, p = 0.51088\n",
      "✅ SubSubCat_Lorazepam | Seed 10: ATT = 1.8781, SE = 5.3657, p = 0.74398\n",
      "📊 Diagnostic plots saved for SubSubCat_Lorazepam\n",
      "🏆 Best result for SubSubCat_Lorazepam → Seed 4 | SE = 3.4397\n",
      "\n",
      "🚀 Running OLS for SubSubCat_Mirtazapine\n",
      "✅ SubSubCat_Mirtazapine | Seed 1: ATT = 5.1510, SE = 2.7075, p = 0.12986\n",
      "✅ SubSubCat_Mirtazapine | Seed 2: ATT = 4.9517, SE = 3.0263, p = 0.17713\n",
      "✅ SubSubCat_Mirtazapine | Seed 3: ATT = 5.5364, SE = 3.1248, p = 0.15113\n",
      "✅ SubSubCat_Mirtazapine | Seed 4: ATT = 5.7170, SE = 4.2858, p = 0.25311\n",
      "✅ SubSubCat_Mirtazapine | Seed 5: ATT = 7.6247, SE = 2.3852, p = 0.03301\n",
      "✅ SubSubCat_Mirtazapine | Seed 6: ATT = 5.6583, SE = 2.9773, p = 0.13017\n",
      "✅ SubSubCat_Mirtazapine | Seed 7: ATT = 4.3473, SE = 4.0152, p = 0.33984\n",
      "✅ SubSubCat_Mirtazapine | Seed 8: ATT = 6.1535, SE = 3.2703, p = 0.13303\n",
      "✅ SubSubCat_Mirtazapine | Seed 9: ATT = 4.1287, SE = 2.9237, p = 0.23076\n",
      "✅ SubSubCat_Mirtazapine | Seed 10: ATT = 5.0135, SE = 3.4511, p = 0.21996\n",
      "📊 Diagnostic plots saved for SubSubCat_Mirtazapine\n",
      "🏆 Best result for SubSubCat_Mirtazapine → Seed 5 | SE = 2.3852\n",
      "\n",
      "🚀 Running OLS for SubSubCat_Escitalopram\n",
      "✅ SubSubCat_Escitalopram | Seed 1: ATT = 2.0006, SE = 5.1085, p = 0.71531\n",
      "✅ SubSubCat_Escitalopram | Seed 2: ATT = -2.1152, SE = 6.1816, p = 0.74944\n",
      "✅ SubSubCat_Escitalopram | Seed 3: ATT = 2.9470, SE = 9.0683, p = 0.76148\n",
      "✅ SubSubCat_Escitalopram | Seed 4: ATT = 1.2518, SE = 6.0206, p = 0.84545\n",
      "✅ SubSubCat_Escitalopram | Seed 5: ATT = -0.8450, SE = 4.1666, p = 0.84919\n",
      "✅ SubSubCat_Escitalopram | Seed 6: ATT = -5.6372, SE = 5.0772, p = 0.32912\n",
      "✅ SubSubCat_Escitalopram | Seed 7: ATT = 1.6135, SE = 8.2699, p = 0.85482\n",
      "✅ SubSubCat_Escitalopram | Seed 8: ATT = 0.2543, SE = 4.9470, p = 0.96147\n",
      "✅ SubSubCat_Escitalopram | Seed 9: ATT = 2.1222, SE = 6.7297, p = 0.76826\n",
      "✅ SubSubCat_Escitalopram | Seed 10: ATT = -0.4981, SE = 5.7597, p = 0.93524\n",
      "📊 Diagnostic plots saved for SubSubCat_Escitalopram\n",
      "🏆 Best result for SubSubCat_Escitalopram → Seed 5 | SE = 4.1666\n",
      "\n",
      "🚀 Running OLS for SubSubCat_Sertraline\n",
      "✅ SubSubCat_Sertraline | Seed 1: ATT = 2.1943, SE = 2.7749, p = 0.47333\n",
      "✅ SubSubCat_Sertraline | Seed 2: ATT = 2.7300, SE = 2.4941, p = 0.33520\n",
      "✅ SubSubCat_Sertraline | Seed 3: ATT = 1.4738, SE = 2.3564, p = 0.56561\n",
      "✅ SubSubCat_Sertraline | Seed 4: ATT = 0.9172, SE = 2.0530, p = 0.67816\n",
      "✅ SubSubCat_Sertraline | Seed 5: ATT = 1.3151, SE = 3.6143, p = 0.73438\n",
      "✅ SubSubCat_Sertraline | Seed 6: ATT = 2.0012, SE = 2.4636, p = 0.46219\n",
      "✅ SubSubCat_Sertraline | Seed 7: ATT = 2.0722, SE = 2.5869, p = 0.46800\n",
      "✅ SubSubCat_Sertraline | Seed 8: ATT = 1.8514, SE = 2.4216, p = 0.48716\n",
      "✅ SubSubCat_Sertraline | Seed 9: ATT = 1.9080, SE = 2.8059, p = 0.53382\n",
      "✅ SubSubCat_Sertraline | Seed 10: ATT = 1.7975, SE = 3.3008, p = 0.61498\n",
      "📊 Diagnostic plots saved for SubSubCat_Sertraline\n",
      "🏆 Best result for SubSubCat_Sertraline → Seed 4 | SE = 2.0530\n",
      "\n",
      "🚀 Running OLS for SubSubCat_Temazepam\n",
      "✅ SubSubCat_Temazepam | Seed 1: ATT = 2.1404, SE = 3.3895, p = 0.56202\n",
      "✅ SubSubCat_Temazepam | Seed 2: ATT = 0.8039, SE = 6.1645, p = 0.90253\n",
      "✅ SubSubCat_Temazepam | Seed 3: ATT = 2.5048, SE = 2.9737, p = 0.44702\n",
      "✅ SubSubCat_Temazepam | Seed 4: ATT = 2.8596, SE = 3.8447, p = 0.49833\n",
      "✅ SubSubCat_Temazepam | Seed 5: ATT = 0.6666, SE = 3.5214, p = 0.85908\n",
      "✅ SubSubCat_Temazepam | Seed 6: ATT = 2.9586, SE = 5.0104, p = 0.58661\n",
      "✅ SubSubCat_Temazepam | Seed 7: ATT = 1.5688, SE = 3.5180, p = 0.67872\n",
      "✅ SubSubCat_Temazepam | Seed 8: ATT = -0.3590, SE = 3.6388, p = 0.92616\n",
      "✅ SubSubCat_Temazepam | Seed 9: ATT = -0.0663, SE = 4.5517, p = 0.98908\n",
      "✅ SubSubCat_Temazepam | Seed 10: ATT = 1.3157, SE = 5.4979, p = 0.82263\n",
      "📊 Diagnostic plots saved for SubSubCat_Temazepam\n",
      "🏆 Best result for SubSubCat_Temazepam → Seed 3 | SE = 2.9737\n",
      "\n",
      "🚀 Running OLS for SubSubCat_Citalopram\n",
      "✅ SubSubCat_Citalopram | Seed 1: ATT = -4.9014, SE = 2.8854, p = 0.16461\n",
      "✅ SubSubCat_Citalopram | Seed 2: ATT = -5.6934, SE = 4.1169, p = 0.23887\n",
      "✅ SubSubCat_Citalopram | Seed 3: ATT = -5.3239, SE = 2.8093, p = 0.13098\n",
      "✅ SubSubCat_Citalopram | Seed 4: ATT = -6.0628, SE = 3.1417, p = 0.12585\n",
      "✅ SubSubCat_Citalopram | Seed 5: ATT = -6.6588, SE = 2.3803, p = 0.04893\n",
      "✅ SubSubCat_Citalopram | Seed 6: ATT = -6.2465, SE = 3.0361, p = 0.10877\n",
      "✅ SubSubCat_Citalopram | Seed 7: ATT = -4.4764, SE = 3.0917, p = 0.22121\n",
      "✅ SubSubCat_Citalopram | Seed 8: ATT = -5.2916, SE = 3.7714, p = 0.23325\n",
      "✅ SubSubCat_Citalopram | Seed 9: ATT = -6.1751, SE = 2.2440, p = 0.05128\n",
      "✅ SubSubCat_Citalopram | Seed 10: ATT = -5.4228, SE = 3.0485, p = 0.14988\n",
      "📊 Diagnostic plots saved for SubSubCat_Citalopram\n",
      "🏆 Best result for SubSubCat_Citalopram → Seed 9 | SE = 2.2440\n",
      "\n",
      "🚀 Running OLS for SubSubCat_Quetiapine\n",
      "✅ SubSubCat_Quetiapine | Seed 1: ATT = 1.6633, SE = 2.0325, p = 0.45912\n",
      "✅ SubSubCat_Quetiapine | Seed 2: ATT = 2.6943, SE = 3.2174, p = 0.44947\n",
      "✅ SubSubCat_Quetiapine | Seed 3: ATT = 2.8620, SE = 1.7735, p = 0.18187\n",
      "✅ SubSubCat_Quetiapine | Seed 4: ATT = 2.4702, SE = 1.9903, p = 0.28238\n",
      "✅ SubSubCat_Quetiapine | Seed 5: ATT = 1.6341, SE = 1.8924, p = 0.43655\n",
      "✅ SubSubCat_Quetiapine | Seed 6: ATT = 2.2101, SE = 2.3446, p = 0.39923\n",
      "✅ SubSubCat_Quetiapine | Seed 7: ATT = 3.6096, SE = 2.6248, p = 0.24107\n",
      "✅ SubSubCat_Quetiapine | Seed 8: ATT = 2.5999, SE = 2.1560, p = 0.29430\n",
      "✅ SubSubCat_Quetiapine | Seed 9: ATT = 2.1167, SE = 2.5932, p = 0.46018\n",
      "✅ SubSubCat_Quetiapine | Seed 10: ATT = 1.9602, SE = 1.5887, p = 0.28480\n",
      "📊 Diagnostic plots saved for SubSubCat_Quetiapine\n",
      "🏆 Best result for SubSubCat_Quetiapine → Seed 10 | SE = 1.5887\n",
      "\n",
      "🚀 Running OLS for SubSubCat_Amitriptyline\n",
      "✅ SubSubCat_Amitriptyline | Seed 1: ATT = 8.9202, SE = 14.5075, p = 0.57190\n",
      "✅ SubSubCat_Amitriptyline | Seed 2: ATT = 13.6574, SE = 10.3958, p = 0.25921\n",
      "✅ SubSubCat_Amitriptyline | Seed 3: ATT = 4.9053, SE = 9.1230, p = 0.61931\n",
      "✅ SubSubCat_Amitriptyline | Seed 4: ATT = 6.9302, SE = 13.4728, p = 0.63410\n",
      "✅ SubSubCat_Amitriptyline | Seed 5: ATT = 8.0432, SE = 9.2966, p = 0.43575\n",
      "✅ SubSubCat_Amitriptyline | Seed 6: ATT = 8.0343, SE = 19.1134, p = 0.69583\n",
      "✅ SubSubCat_Amitriptyline | Seed 7: ATT = 16.8473, SE = 9.0377, p = 0.13575\n",
      "✅ SubSubCat_Amitriptyline | Seed 8: ATT = 11.2124, SE = 14.8612, p = 0.49255\n",
      "✅ SubSubCat_Amitriptyline | Seed 9: ATT = 21.7959, SE = 12.9526, p = 0.16771\n",
      "✅ SubSubCat_Amitriptyline | Seed 10: ATT = 10.2286, SE = 11.8773, p = 0.43770\n",
      "📊 Diagnostic plots saved for SubSubCat_Amitriptyline\n",
      "🏆 Best result for SubSubCat_Amitriptyline → Seed 7 | SE = 9.0377\n",
      "\n",
      "🚀 Running OLS for SubSubCat_Venlafaxine\n",
      "✅ SubSubCat_Venlafaxine | Seed 1: ATT = 1.1061, SE = 5.2774, p = 0.84424\n",
      "✅ SubSubCat_Venlafaxine | Seed 2: ATT = -4.0363, SE = 7.1882, p = 0.60442\n",
      "✅ SubSubCat_Venlafaxine | Seed 3: ATT = 1.6356, SE = 8.1763, p = 0.85120\n",
      "✅ SubSubCat_Venlafaxine | Seed 4: ATT = 2.0992, SE = 7.3097, p = 0.78823\n",
      "✅ SubSubCat_Venlafaxine | Seed 5: ATT = -1.0891, SE = 3.6995, p = 0.78310\n",
      "✅ SubSubCat_Venlafaxine | Seed 6: ATT = 2.0199, SE = 6.2257, p = 0.76186\n",
      "✅ SubSubCat_Venlafaxine | Seed 7: ATT = 0.9724, SE = 5.1240, p = 0.85873\n",
      "✅ SubSubCat_Venlafaxine | Seed 8: ATT = 5.1916, SE = 9.3818, p = 0.60948\n",
      "✅ SubSubCat_Venlafaxine | Seed 9: ATT = 0.5753, SE = 6.1339, p = 0.92979\n",
      "✅ SubSubCat_Venlafaxine | Seed 10: ATT = -2.2502, SE = 6.8010, p = 0.75736\n",
      "📊 Diagnostic plots saved for SubSubCat_Venlafaxine\n",
      "🏆 Best result for SubSubCat_Venlafaxine → Seed 5 | SE = 3.6995\n",
      "\n",
      "🚀 Running OLS for SubSubCat_Fluoxetine\n",
      "✅ SubSubCat_Fluoxetine | Seed 1: ATT = 8.0300, SE = 4.8536, p = 0.17338\n",
      "✅ SubSubCat_Fluoxetine | Seed 2: ATT = 7.0745, SE = 5.5404, p = 0.27073\n",
      "✅ SubSubCat_Fluoxetine | Seed 3: ATT = 11.3230, SE = 3.7723, p = 0.03988\n",
      "✅ SubSubCat_Fluoxetine | Seed 4: ATT = 10.4765, SE = 3.9700, p = 0.05765\n",
      "✅ SubSubCat_Fluoxetine | Seed 5: ATT = 7.8891, SE = 4.9089, p = 0.18331\n",
      "✅ SubSubCat_Fluoxetine | Seed 6: ATT = 9.8655, SE = 5.4607, p = 0.14511\n",
      "✅ SubSubCat_Fluoxetine | Seed 7: ATT = 12.5184, SE = 2.9439, p = 0.01313\n",
      "✅ SubSubCat_Fluoxetine | Seed 8: ATT = 8.5876, SE = 5.9673, p = 0.22352\n",
      "✅ SubSubCat_Fluoxetine | Seed 9: ATT = 8.7987, SE = 7.6117, p = 0.31205\n",
      "✅ SubSubCat_Fluoxetine | Seed 10: ATT = 11.1391, SE = 4.8424, p = 0.08291\n",
      "📊 Diagnostic plots saved for SubSubCat_Fluoxetine\n",
      "🏆 Best result for SubSubCat_Fluoxetine → Seed 7 | SE = 2.9439\n",
      "\n",
      "🚀 Running OLS for SubSubCat_Topiramaat\n",
      "✅ SubSubCat_Topiramaat | Seed 1: ATT = 13.3015, SE = 4.8106, p = 0.05059\n",
      "✅ SubSubCat_Topiramaat | Seed 2: ATT = 9.8857, SE = 5.1641, p = 0.12810\n",
      "✅ SubSubCat_Topiramaat | Seed 3: ATT = 6.6949, SE = 8.3684, p = 0.46852\n",
      "✅ SubSubCat_Topiramaat | Seed 4: ATT = 11.4972, SE = 8.9600, p = 0.26873\n",
      "✅ SubSubCat_Topiramaat | Seed 5: ATT = 9.6108, SE = 5.5170, p = 0.15647\n",
      "✅ SubSubCat_Topiramaat | Seed 6: ATT = 15.2198, SE = 4.2888, p = 0.02383\n",
      "✅ SubSubCat_Topiramaat | Seed 7: ATT = 10.2344, SE = 12.1861, p = 0.44826\n",
      "✅ SubSubCat_Topiramaat | Seed 8: ATT = 9.3541, SE = 9.3720, p = 0.37472\n",
      "✅ SubSubCat_Topiramaat | Seed 9: ATT = 15.7421, SE = 6.3339, p = 0.06782\n",
      "✅ SubSubCat_Topiramaat | Seed 10: ATT = 13.0960, SE = 7.1642, p = 0.14156\n",
      "📊 Diagnostic plots saved for SubSubCat_Topiramaat\n",
      "🏆 Best result for SubSubCat_Topiramaat → Seed 6 | SE = 4.2888\n",
      "\n",
      "🚀 Running OLS for SubSubCat_Zopiclon\n",
      "✅ SubSubCat_Zopiclon | Seed 1: ATT = -3.4034, SE = 7.6118, p = 0.67793\n",
      "✅ SubSubCat_Zopiclon | Seed 2: ATT = -8.1172, SE = 4.5400, p = 0.14831\n",
      "✅ SubSubCat_Zopiclon | Seed 3: ATT = -5.4354, SE = 5.0071, p = 0.33873\n",
      "✅ SubSubCat_Zopiclon | Seed 4: ATT = -3.8715, SE = 6.8900, p = 0.60417\n",
      "✅ SubSubCat_Zopiclon | Seed 5: ATT = -5.2040, SE = 5.6908, p = 0.41221\n",
      "✅ SubSubCat_Zopiclon | Seed 6: ATT = -5.6876, SE = 5.7538, p = 0.37887\n",
      "✅ SubSubCat_Zopiclon | Seed 7: ATT = -7.5110, SE = 4.6776, p = 0.18360\n",
      "✅ SubSubCat_Zopiclon | Seed 8: ATT = -6.6062, SE = 5.5988, p = 0.30340\n",
      "✅ SubSubCat_Zopiclon | Seed 9: ATT = -8.5229, SE = 5.3016, p = 0.18320\n",
      "✅ SubSubCat_Zopiclon | Seed 10: ATT = -4.7696, SE = 6.7115, p = 0.51654\n",
      "📊 Diagnostic plots saved for SubSubCat_Zopiclon\n",
      "🏆 Best result for SubSubCat_Zopiclon → Seed 2 | SE = 4.5400\n",
      "\n",
      "🚀 Running OLS for SubSubCat_Bupropion\n",
      "✅ SubSubCat_Bupropion | Seed 1: ATT = 0.0000, SE = 0.0000, p = 0.65904\n",
      "✅ SubSubCat_Bupropion | Seed 2: ATT = 1.9031, SE = 5.0409, p = 0.72496\n",
      "✅ SubSubCat_Bupropion | Seed 3: ATT = 2.9147, SE = 7.6319, p = 0.72195\n",
      "✅ SubSubCat_Bupropion | Seed 4: ATT = -0.0000, SE = 0.0000, p = 0.56767\n",
      "✅ SubSubCat_Bupropion | Seed 5: ATT = 2.6508, SE = 8.6528, p = 0.77462\n",
      "✅ SubSubCat_Bupropion | Seed 6: ATT = 3.3167, SE = 9.3741, p = 0.74134\n",
      "✅ SubSubCat_Bupropion | Seed 7: ATT = 1.7679, SE = 5.5052, p = 0.76420\n",
      "✅ SubSubCat_Bupropion | Seed 8: ATT = 3.3089, SE = 8.5873, p = 0.71961\n",
      "✅ SubSubCat_Bupropion | Seed 9: ATT = 1.8492, SE = 5.7064, p = 0.76213\n",
      "✅ SubSubCat_Bupropion | Seed 10: ATT = 2.7567, SE = 7.7068, p = 0.73865\n",
      "📊 Diagnostic plots saved for SubSubCat_Bupropion\n",
      "🏆 Best result for SubSubCat_Bupropion → Seed 4 | SE = 0.0000\n",
      "\n",
      "🚀 Running OLS for SubSubCat_Methylfenidaat\n",
      "✅ SubSubCat_Methylfenidaat | Seed 1: ATT = 1.2736, SE = 8.2715, p = 0.88509\n",
      "✅ SubSubCat_Methylfenidaat | Seed 2: ATT = 7.2626, SE = 8.1641, p = 0.42396\n",
      "✅ SubSubCat_Methylfenidaat | Seed 3: ATT = -2.0394, SE = 14.3236, p = 0.89366\n",
      "✅ SubSubCat_Methylfenidaat | Seed 4: ATT = 1.7182, SE = 11.0235, p = 0.88369\n",
      "✅ SubSubCat_Methylfenidaat | Seed 5: ATT = 3.9980, SE = 13.4847, p = 0.78161\n",
      "✅ SubSubCat_Methylfenidaat | Seed 6: ATT = 5.1151, SE = 11.8197, p = 0.68750\n",
      "✅ SubSubCat_Methylfenidaat | Seed 7: ATT = 8.1028, SE = 9.0984, p = 0.42348\n",
      "✅ SubSubCat_Methylfenidaat | Seed 8: ATT = 5.4834, SE = 8.6443, p = 0.56033\n",
      "✅ SubSubCat_Methylfenidaat | Seed 9: ATT = 16.4400, SE = 17.3895, p = 0.39799\n",
      "✅ SubSubCat_Methylfenidaat | Seed 10: ATT = 6.3121, SE = 9.3665, p = 0.53731\n",
      "📊 Diagnostic plots saved for SubSubCat_Methylfenidaat\n",
      "🏆 Best result for SubSubCat_Methylfenidaat → Seed 2 | SE = 8.1641\n",
      "\n",
      "🚀 Running OLS for SubSubCat_Olanzapine\n",
      "✅ SubSubCat_Olanzapine | Seed 1: ATT = -3.6463, SE = 6.9867, p = 0.62931\n",
      "✅ SubSubCat_Olanzapine | Seed 2: ATT = 3.5398, SE = 12.4672, p = 0.79056\n",
      "✅ SubSubCat_Olanzapine | Seed 3: ATT = 2.6412, SE = 5.5253, p = 0.65758\n",
      "✅ SubSubCat_Olanzapine | Seed 4: ATT = 0.7456, SE = 6.2530, p = 0.91084\n",
      "✅ SubSubCat_Olanzapine | Seed 5: ATT = 1.8099, SE = 12.9763, p = 0.89582\n",
      "✅ SubSubCat_Olanzapine | Seed 6: ATT = 1.0811, SE = 6.7064, p = 0.87975\n",
      "✅ SubSubCat_Olanzapine | Seed 7: ATT = 1.4871, SE = 9.4101, p = 0.88209\n",
      "✅ SubSubCat_Olanzapine | Seed 8: ATT = -2.5111, SE = 7.4246, p = 0.75221\n",
      "✅ SubSubCat_Olanzapine | Seed 9: ATT = -0.1586, SE = 8.5845, p = 0.98614\n",
      "✅ SubSubCat_Olanzapine | Seed 10: ATT = 0.3364, SE = 5.1421, p = 0.95098\n",
      "📊 Diagnostic plots saved for SubSubCat_Olanzapine\n",
      "🏆 Best result for SubSubCat_Olanzapine → Seed 10 | SE = 5.1421\n",
      "\n",
      "🎯 All summary files saved.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import t, probplot\n",
    "import xgboost as xgb\n",
    "\n",
    "# -----------------------------\n",
    "# Configuration\n",
    "# -----------------------------\n",
    "seeds = list(range(1, 11))\n",
    "imputations = 5\n",
    "output_folder = \"outputs\"\n",
    "\n",
    "# -----------------------------\n",
    "# Diagnostic Plotting Function\n",
    "# -----------------------------\n",
    "def create_diagnostic_plots(residuals_data, fitted_data, group_name):\n",
    "    \"\"\"Create 4 diagnostic plots for model validation\"\"\"\n",
    "    plots_dir = os.path.join(output_folder, \"plots\")\n",
    "    os.makedirs(plots_dir, exist_ok=True)\n",
    "    \n",
    "    # Flatten the collected data\n",
    "    all_residuals = np.concatenate(residuals_data)\n",
    "    all_fitted = np.concatenate(fitted_data)\n",
    "    \n",
    "    # Create figure with 2x2 subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    fig.suptitle(f'Diagnostic Plots - {group_name}', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. Residuals vs Fitted\n",
    "    axes[0,0].scatter(all_fitted, all_residuals, alpha=0.6, s=20)\n",
    "    axes[0,0].axhline(y=0, color='red', linestyle='--', alpha=0.8)\n",
    "    axes[0,0].set_xlabel('Fitted Values')\n",
    "    axes[0,0].set_ylabel('Residuals')\n",
    "    axes[0,0].set_title('Residuals vs Fitted')\n",
    "    axes[0,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. QQ Plot\n",
    "    probplot(all_residuals, dist=\"norm\", plot=axes[0,1])\n",
    "    axes[0,1].set_title('Q-Q Plot (Normal)')\n",
    "    axes[0,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Residual Histogram\n",
    "    axes[1,0].hist(all_residuals, bins=30, density=True, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    axes[1,0].set_xlabel('Residuals')\n",
    "    axes[1,0].set_ylabel('Density')\n",
    "    axes[1,0].set_title('Residual Distribution')\n",
    "    axes[1,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Scale-Location Plot\n",
    "    sqrt_abs_residuals = np.sqrt(np.abs(all_residuals))\n",
    "    axes[1,1].scatter(all_fitted, sqrt_abs_residuals, alpha=0.6, s=20)\n",
    "    axes[1,1].set_xlabel('Fitted Values')\n",
    "    axes[1,1].set_ylabel('√|Residuals|')\n",
    "    axes[1,1].set_title('Scale-Location Plot')\n",
    "    axes[1,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save plot\n",
    "    plot_filename = os.path.join(plots_dir, f'{group_name}.png')\n",
    "    plt.savefig(plot_filename, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"📊 Diagnostic plots saved for {group_name}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Rubin's Rule\n",
    "# -----------------------------\n",
    "def rubins_pool(estimates, ses):\n",
    "    m = len(estimates)\n",
    "    q_bar = np.mean(estimates)\n",
    "    u_bar = np.mean(np.square(ses))\n",
    "    b_m = np.var(estimates, ddof=1)\n",
    "    total_var = u_bar + ((1 + 1/m) * b_m)\n",
    "    total_se = np.sqrt(total_var)\n",
    "    ci_lower = q_bar - 1.96 * total_se\n",
    "    ci_upper = q_bar + 1.96 * total_se\n",
    "    p_value = 2 * (1 - t.cdf(np.abs(q_bar / total_se), df=m-1))\n",
    "    rounded_p = round(p_value, 5)\n",
    "    formatted_p = \"< 0.00001\" if rounded_p <= 0.00001 else f\"{rounded_p:.5f}\"\n",
    "    return q_bar, total_se, ci_lower, ci_upper, formatted_p\n",
    "\n",
    "# -----------------------------\n",
    "# SMD + Variance Ratio\n",
    "# -----------------------------\n",
    "def calculate_smd_vr(X, T, weights):\n",
    "    treated = X[T == 1]\n",
    "    control = X[T == 0]\n",
    "    w_treated = weights[T == 1]\n",
    "    w_control = weights[T == 0]\n",
    "    smd, vr = [], []\n",
    "    for col in X.columns:\n",
    "        try:\n",
    "            m1, m0 = np.average(treated[col], weights=w_treated), np.average(control[col], weights=w_control)\n",
    "            s1 = np.sqrt(np.average((treated[col] - m1) ** 2, weights=w_treated))\n",
    "            s0 = np.sqrt(np.average((control[col] - m0) ** 2, weights=w_control))\n",
    "            pooled_sd = np.sqrt((s1 ** 2 + s0 ** 2) / 2)\n",
    "            smd.append((m1 - m0) / pooled_sd if pooled_sd > 0 else 0)\n",
    "            vr.append(s1**2 / s0**2 if s0**2 > 0 else 0)\n",
    "        except Exception:\n",
    "            smd.append(np.nan)\n",
    "            vr.append(np.nan)\n",
    "    return np.nanmean(smd), np.nanmean(vr)\n",
    "\n",
    "# -----------------------------\n",
    "# OLS Main Loop\n",
    "# -----------------------------\n",
    "def run_dml_with_trimmed_data(final_covariates_map):\n",
    "    att_results = []\n",
    "    balance_results = []\n",
    "\n",
    "    for group, covariates in final_covariates_map.items():\n",
    "        print(f\"\\n🚀 Running OLS for {group}\")\n",
    "        group_dir = os.path.join(output_folder, group)\n",
    "        os.makedirs(group_dir, exist_ok=True)\n",
    "\n",
    "        best_result = None\n",
    "        best_se = float(\"inf\")\n",
    "        \n",
    "        # Initialize lists to collect residuals and fitted values for diagnostic plots\n",
    "        group_residuals = []\n",
    "        group_fitted = []\n",
    "\n",
    "        for seed in seeds:\n",
    "            # Set random seed for this iteration\n",
    "            np.random.seed(seed)\n",
    "            \n",
    "            att_list, se_list, r2_list, rmse_list, smd_list, vr_list = [], [], [], [], [], []\n",
    "\n",
    "            for imp in range(1, imputations + 1):\n",
    "                file_path = os.path.join(group_dir, f\"trimmed_data_imp{imp}.pkl\")\n",
    "                if not os.path.exists(file_path):\n",
    "                    continue\n",
    "\n",
    "                df = pd.read_pickle(file_path)\n",
    "                if group not in df.columns or \"iptw\" not in df.columns:\n",
    "                    continue\n",
    "\n",
    "                # Add bootstrap sampling with seed-based randomization\n",
    "                n_samples = len(df)\n",
    "                bootstrap_idx = np.random.choice(n_samples, size=n_samples, replace=True)\n",
    "                df_bootstrap = df.iloc[bootstrap_idx].reset_index(drop=True)\n",
    "\n",
    "                X = df_bootstrap[covariates].copy()\n",
    "                T = df_bootstrap[group]\n",
    "                Y = df_bootstrap[\"caps5_change_baseline\"]\n",
    "                W = df_bootstrap[\"iptw\"]\n",
    "\n",
    "                try:\n",
    "                    # Create design matrix with treatment variable and covariates\n",
    "                    X_ols = pd.concat([T, X], axis=1)\n",
    "                    X_ols = sm.add_constant(X_ols)\n",
    "                    \n",
    "                    # Fit weighted OLS with robust standard errors\n",
    "                    ols_model = sm.WLS(Y, X_ols, weights=W).fit(cov_type='HC1')\n",
    "                    \n",
    "                    # Extract treatment effect (coefficient of treatment variable)\n",
    "                    att = ols_model.params[group]  # Treatment coefficient\n",
    "                    se = ols_model.bse[group]  # Robust standard error for treatment\n",
    "                    \n",
    "                    att_list.append(att)\n",
    "                    se_list.append(se)\n",
    "\n",
    "                    # Calculate model fit statistics\n",
    "                    Y_pred = ols_model.fittedvalues\n",
    "                    residuals = ols_model.resid\n",
    "                    rmse = mean_squared_error(Y, Y_pred, squared=False)\n",
    "                    r2 = ols_model.rsquared\n",
    "                    r2_list.append(r2)\n",
    "                    rmse_list.append(rmse)\n",
    "                    \n",
    "                    # Collect residuals and fitted values for diagnostic plots\n",
    "                    group_residuals.append(residuals.values)\n",
    "                    group_fitted.append(Y_pred.values)\n",
    "\n",
    "                    smd, vr = calculate_smd_vr(X, T, W)\n",
    "                    smd_list.append(smd)\n",
    "                    vr_list.append(vr)\n",
    "                except Exception as e:\n",
    "                    print(f\"⚠️ Error in {group}, seed {seed}, imp {imp}: {e}\")\n",
    "\n",
    "            if att_list:\n",
    "                att, se, ci_l, ci_u, p_val = rubins_pool(att_list, se_list)\n",
    "                avg_r2 = np.mean(r2_list)\n",
    "                avg_rmse = np.mean(rmse_list)\n",
    "                avg_smd = np.mean(smd_list)\n",
    "                avg_vr = np.mean(vr_list)\n",
    "\n",
    "                balance_results.append({\n",
    "                    \"group\": group, \"seed\": seed, \"smd\": avg_smd, \"vr\": avg_vr\n",
    "                })\n",
    "\n",
    "                if se < best_se:\n",
    "                    best_se = se\n",
    "                    best_result = {\n",
    "                        \"group\": group, \"seed\": seed, \"att\": att, \"se\": se,\n",
    "                        \"ci_lower\": ci_l, \"ci_upper\": ci_u, \"p_value\": p_val,\n",
    "                        \"r2\": avg_r2, \"rmse\": avg_rmse\n",
    "                    }\n",
    "\n",
    "                print(f\"✅ {group} | Seed {seed}: ATT = {att:.4f}, SE = {se:.4f}, p = {p_val}\")\n",
    "            else:\n",
    "                print(f\"⚠️ No valid results for {group} | Seed {seed}\")\n",
    "\n",
    "        # Create diagnostic plots for this group\n",
    "        if group_residuals and group_fitted:\n",
    "            create_diagnostic_plots(group_residuals, group_fitted, group)\n",
    "\n",
    "        if best_result:\n",
    "            att_results.append(best_result)\n",
    "            print(f\"🏆 Best result for {group} → Seed {best_result['seed']} | SE = {best_result['se']:.4f}\")\n",
    "\n",
    "    # Save final output\n",
    "    pd.DataFrame(att_results).to_excel(\"ols_rubin_summary_subsubcats.xlsx\", index=False)\n",
    "    pd.DataFrame(balance_results).to_excel(\"smd_vr_summary_subsubcats.xlsx\", index=False)\n",
    "    print(\"\\n🎯 All summary files saved.\")\n",
    "\n",
    "run_dml_with_trimmed_data(final_covariates_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "33707ec9-ca5a-413e-95df-a57b83ae905d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unweighted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "52d64785-d493-4aa1-8042-f15bddc87406",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Running OLS for SubSubCat_Oxazepam\n",
      "✅ SubSubCat_Oxazepam | Seed 1: ATT = 0.7187, SE = 1.5172, p = 0.66043\n",
      "✅ SubSubCat_Oxazepam | Seed 2: ATT = 0.9364, SE = 1.5441, p = 0.57694\n",
      "✅ SubSubCat_Oxazepam | Seed 3: ATT = 1.6006, SE = 1.6439, p = 0.38537\n",
      "✅ SubSubCat_Oxazepam | Seed 4: ATT = 1.5106, SE = 2.1499, p = 0.52103\n",
      "✅ SubSubCat_Oxazepam | Seed 5: ATT = 0.9480, SE = 2.2452, p = 0.69456\n",
      "✅ SubSubCat_Oxazepam | Seed 6: ATT = 0.9398, SE = 1.4529, p = 0.55299\n",
      "✅ SubSubCat_Oxazepam | Seed 7: ATT = 1.7766, SE = 1.9929, p = 0.42304\n",
      "✅ SubSubCat_Oxazepam | Seed 8: ATT = 1.4453, SE = 1.9797, p = 0.50582\n",
      "✅ SubSubCat_Oxazepam | Seed 9: ATT = 0.8379, SE = 1.6719, p = 0.64258\n",
      "✅ SubSubCat_Oxazepam | Seed 10: ATT = -0.3180, SE = 1.4388, p = 0.83588\n",
      "📊 Diagnostic plots saved for SubSubCat_Oxazepam\n",
      "🏆 Best result for SubSubCat_Oxazepam → Seed 10 | SE = 1.4388\n",
      "\n",
      "🚀 Running OLS for SubSubCat_Diazepam\n",
      "✅ SubSubCat_Diazepam | Seed 1: ATT = -5.6622, SE = 5.4012, p = 0.35365\n",
      "✅ SubSubCat_Diazepam | Seed 2: ATT = -0.7836, SE = 9.6544, p = 0.93921\n",
      "✅ SubSubCat_Diazepam | Seed 3: ATT = -5.6317, SE = 7.8372, p = 0.51213\n",
      "✅ SubSubCat_Diazepam | Seed 4: ATT = -5.6376, SE = 8.7739, p = 0.55550\n",
      "✅ SubSubCat_Diazepam | Seed 5: ATT = -2.5936, SE = 8.9595, p = 0.78660\n",
      "✅ SubSubCat_Diazepam | Seed 6: ATT = -7.3513, SE = 8.4688, p = 0.43434\n",
      "✅ SubSubCat_Diazepam | Seed 7: ATT = 2.4403, SE = 10.9925, p = 0.83519\n",
      "✅ SubSubCat_Diazepam | Seed 8: ATT = 1.5821, SE = 6.7495, p = 0.82618\n",
      "✅ SubSubCat_Diazepam | Seed 9: ATT = -8.6176, SE = 8.0247, p = 0.34334\n",
      "✅ SubSubCat_Diazepam | Seed 10: ATT = -6.2541, SE = 8.4219, p = 0.49897\n",
      "📊 Diagnostic plots saved for SubSubCat_Diazepam\n",
      "🏆 Best result for SubSubCat_Diazepam → Seed 1 | SE = 5.4012\n",
      "\n",
      "🚀 Running OLS for SubSubCat_Paracetamol\n",
      "✅ SubSubCat_Paracetamol | Seed 1: ATT = 5.6750, SE = 6.7420, p = 0.44732\n",
      "✅ SubSubCat_Paracetamol | Seed 2: ATT = 6.6908, SE = 8.4590, p = 0.47322\n",
      "✅ SubSubCat_Paracetamol | Seed 3: ATT = 8.1838, SE = 7.0645, p = 0.31114\n",
      "✅ SubSubCat_Paracetamol | Seed 4: ATT = 9.2914, SE = 8.8216, p = 0.35164\n",
      "✅ SubSubCat_Paracetamol | Seed 5: ATT = 4.4102, SE = 11.0407, p = 0.70997\n",
      "✅ SubSubCat_Paracetamol | Seed 6: ATT = 7.1450, SE = 7.3321, p = 0.38500\n",
      "✅ SubSubCat_Paracetamol | Seed 7: ATT = 7.8703, SE = 10.7523, p = 0.50476\n",
      "✅ SubSubCat_Paracetamol | Seed 8: ATT = 10.6276, SE = 10.6481, p = 0.37473\n",
      "✅ SubSubCat_Paracetamol | Seed 9: ATT = 8.5652, SE = 8.7697, p = 0.38403\n",
      "✅ SubSubCat_Paracetamol | Seed 10: ATT = 4.3597, SE = 7.6587, p = 0.59963\n",
      "📊 Diagnostic plots saved for SubSubCat_Paracetamol\n",
      "🏆 Best result for SubSubCat_Paracetamol → Seed 1 | SE = 6.7420\n",
      "\n",
      "🚀 Running OLS for SubSubCat_Lorazepam\n",
      "✅ SubSubCat_Lorazepam | Seed 1: ATT = 2.2418, SE = 4.9580, p = 0.67459\n",
      "✅ SubSubCat_Lorazepam | Seed 2: ATT = -0.6019, SE = 3.2605, p = 0.86252\n",
      "✅ SubSubCat_Lorazepam | Seed 3: ATT = 3.6950, SE = 5.1205, p = 0.51046\n",
      "✅ SubSubCat_Lorazepam | Seed 4: ATT = 2.6744, SE = 3.9839, p = 0.53881\n",
      "✅ SubSubCat_Lorazepam | Seed 5: ATT = 2.1189, SE = 4.9227, p = 0.68905\n",
      "✅ SubSubCat_Lorazepam | Seed 6: ATT = 1.6942, SE = 5.4474, p = 0.77132\n",
      "✅ SubSubCat_Lorazepam | Seed 7: ATT = 3.1173, SE = 4.2647, p = 0.50531\n",
      "✅ SubSubCat_Lorazepam | Seed 8: ATT = 2.1054, SE = 3.9459, p = 0.62191\n",
      "✅ SubSubCat_Lorazepam | Seed 9: ATT = 2.3992, SE = 3.6368, p = 0.54549\n",
      "✅ SubSubCat_Lorazepam | Seed 10: ATT = 2.2980, SE = 6.0759, p = 0.72449\n",
      "📊 Diagnostic plots saved for SubSubCat_Lorazepam\n",
      "🏆 Best result for SubSubCat_Lorazepam → Seed 2 | SE = 3.2605\n",
      "\n",
      "🚀 Running OLS for SubSubCat_Mirtazapine\n",
      "✅ SubSubCat_Mirtazapine | Seed 1: ATT = 5.6273, SE = 2.6996, p = 0.10549\n",
      "✅ SubSubCat_Mirtazapine | Seed 2: ATT = 5.6228, SE = 3.6015, p = 0.19349\n",
      "✅ SubSubCat_Mirtazapine | Seed 3: ATT = 5.2933, SE = 3.3187, p = 0.18594\n",
      "✅ SubSubCat_Mirtazapine | Seed 4: ATT = 6.2623, SE = 3.9698, p = 0.18982\n",
      "✅ SubSubCat_Mirtazapine | Seed 5: ATT = 7.5136, SE = 2.9204, p = 0.06179\n",
      "✅ SubSubCat_Mirtazapine | Seed 6: ATT = 5.7026, SE = 2.9237, p = 0.12288\n",
      "✅ SubSubCat_Mirtazapine | Seed 7: ATT = 5.2939, SE = 3.8093, p = 0.23696\n",
      "✅ SubSubCat_Mirtazapine | Seed 8: ATT = 6.5266, SE = 3.8255, p = 0.16319\n",
      "✅ SubSubCat_Mirtazapine | Seed 9: ATT = 5.4262, SE = 3.2831, p = 0.17372\n",
      "✅ SubSubCat_Mirtazapine | Seed 10: ATT = 5.3874, SE = 4.3037, p = 0.27885\n",
      "📊 Diagnostic plots saved for SubSubCat_Mirtazapine\n",
      "🏆 Best result for SubSubCat_Mirtazapine → Seed 1 | SE = 2.6996\n",
      "\n",
      "🚀 Running OLS for SubSubCat_Escitalopram\n",
      "✅ SubSubCat_Escitalopram | Seed 1: ATT = 1.3626, SE = 6.6100, p = 0.84675\n",
      "✅ SubSubCat_Escitalopram | Seed 2: ATT = -2.7086, SE = 5.9659, p = 0.67336\n",
      "✅ SubSubCat_Escitalopram | Seed 3: ATT = 2.6039, SE = 9.1622, p = 0.79036\n",
      "✅ SubSubCat_Escitalopram | Seed 4: ATT = -0.9371, SE = 6.8215, p = 0.89737\n",
      "✅ SubSubCat_Escitalopram | Seed 5: ATT = -1.4247, SE = 5.9793, p = 0.82337\n",
      "✅ SubSubCat_Escitalopram | Seed 6: ATT = -5.8344, SE = 6.5242, p = 0.42173\n",
      "✅ SubSubCat_Escitalopram | Seed 7: ATT = 0.5671, SE = 8.3219, p = 0.94894\n",
      "✅ SubSubCat_Escitalopram | Seed 8: ATT = -0.8498, SE = 5.2165, p = 0.87848\n",
      "✅ SubSubCat_Escitalopram | Seed 9: ATT = 0.0799, SE = 7.7937, p = 0.99231\n",
      "✅ SubSubCat_Escitalopram | Seed 10: ATT = -1.0531, SE = 6.1295, p = 0.87193\n",
      "📊 Diagnostic plots saved for SubSubCat_Escitalopram\n",
      "🏆 Best result for SubSubCat_Escitalopram → Seed 8 | SE = 5.2165\n",
      "\n",
      "🚀 Running OLS for SubSubCat_Sertraline\n",
      "✅ SubSubCat_Sertraline | Seed 1: ATT = 2.5554, SE = 2.8860, p = 0.42594\n",
      "✅ SubSubCat_Sertraline | Seed 2: ATT = 2.7575, SE = 3.1607, p = 0.43221\n",
      "✅ SubSubCat_Sertraline | Seed 3: ATT = 0.7885, SE = 2.1416, p = 0.73141\n",
      "✅ SubSubCat_Sertraline | Seed 4: ATT = 0.3651, SE = 2.3071, p = 0.88194\n",
      "✅ SubSubCat_Sertraline | Seed 5: ATT = 0.6895, SE = 3.7874, p = 0.86440\n",
      "✅ SubSubCat_Sertraline | Seed 6: ATT = 1.5273, SE = 2.6146, p = 0.59048\n",
      "✅ SubSubCat_Sertraline | Seed 7: ATT = 1.3328, SE = 2.9679, p = 0.67664\n",
      "✅ SubSubCat_Sertraline | Seed 8: ATT = 1.3411, SE = 2.8546, p = 0.66296\n",
      "✅ SubSubCat_Sertraline | Seed 9: ATT = 1.8309, SE = 3.2201, p = 0.60004\n",
      "✅ SubSubCat_Sertraline | Seed 10: ATT = 2.3640, SE = 3.2004, p = 0.50111\n",
      "📊 Diagnostic plots saved for SubSubCat_Sertraline\n",
      "🏆 Best result for SubSubCat_Sertraline → Seed 3 | SE = 2.1416\n",
      "\n",
      "🚀 Running OLS for SubSubCat_Temazepam\n",
      "✅ SubSubCat_Temazepam | Seed 1: ATT = 2.0496, SE = 3.2240, p = 0.55950\n",
      "✅ SubSubCat_Temazepam | Seed 2: ATT = 0.7698, SE = 6.3993, p = 0.91005\n",
      "✅ SubSubCat_Temazepam | Seed 3: ATT = 2.7725, SE = 3.1839, p = 0.43302\n",
      "✅ SubSubCat_Temazepam | Seed 4: ATT = 2.3003, SE = 3.9286, p = 0.58963\n",
      "✅ SubSubCat_Temazepam | Seed 5: ATT = 0.1424, SE = 3.9233, p = 0.97278\n",
      "✅ SubSubCat_Temazepam | Seed 6: ATT = 2.7917, SE = 5.3564, p = 0.62976\n",
      "✅ SubSubCat_Temazepam | Seed 7: ATT = 1.2793, SE = 3.5462, p = 0.73653\n",
      "✅ SubSubCat_Temazepam | Seed 8: ATT = -0.3347, SE = 3.5303, p = 0.92904\n",
      "✅ SubSubCat_Temazepam | Seed 9: ATT = -0.3023, SE = 4.5186, p = 0.94987\n",
      "✅ SubSubCat_Temazepam | Seed 10: ATT = 1.5304, SE = 5.3840, p = 0.79033\n",
      "📊 Diagnostic plots saved for SubSubCat_Temazepam\n",
      "🏆 Best result for SubSubCat_Temazepam → Seed 3 | SE = 3.1839\n",
      "\n",
      "🚀 Running OLS for SubSubCat_Citalopram\n",
      "✅ SubSubCat_Citalopram | Seed 1: ATT = -4.6982, SE = 3.4850, p = 0.24890\n",
      "✅ SubSubCat_Citalopram | Seed 2: ATT = -5.6106, SE = 4.5588, p = 0.28585\n",
      "✅ SubSubCat_Citalopram | Seed 3: ATT = -5.1144, SE = 3.4332, p = 0.21055\n",
      "✅ SubSubCat_Citalopram | Seed 4: ATT = -6.4234, SE = 3.1794, p = 0.11345\n",
      "✅ SubSubCat_Citalopram | Seed 5: ATT = -6.1142, SE = 2.8352, p = 0.09727\n",
      "✅ SubSubCat_Citalopram | Seed 6: ATT = -6.2808, SE = 3.4674, p = 0.14432\n",
      "✅ SubSubCat_Citalopram | Seed 7: ATT = -3.8690, SE = 3.3895, p = 0.31737\n",
      "✅ SubSubCat_Citalopram | Seed 8: ATT = -4.8892, SE = 3.6717, p = 0.25382\n",
      "✅ SubSubCat_Citalopram | Seed 9: ATT = -5.0837, SE = 2.4680, p = 0.10848\n",
      "✅ SubSubCat_Citalopram | Seed 10: ATT = -4.7327, SE = 3.4350, p = 0.24033\n",
      "📊 Diagnostic plots saved for SubSubCat_Citalopram\n",
      "🏆 Best result for SubSubCat_Citalopram → Seed 9 | SE = 2.4680\n",
      "\n",
      "🚀 Running OLS for SubSubCat_Quetiapine\n",
      "✅ SubSubCat_Quetiapine | Seed 1: ATT = 1.6904, SE = 1.7761, p = 0.39512\n",
      "✅ SubSubCat_Quetiapine | Seed 2: ATT = 2.3149, SE = 2.9305, p = 0.47377\n",
      "✅ SubSubCat_Quetiapine | Seed 3: ATT = 2.2541, SE = 1.7689, p = 0.27156\n",
      "✅ SubSubCat_Quetiapine | Seed 4: ATT = 2.7038, SE = 2.2318, p = 0.29239\n",
      "✅ SubSubCat_Quetiapine | Seed 5: ATT = 1.5479, SE = 2.2916, p = 0.53641\n",
      "✅ SubSubCat_Quetiapine | Seed 6: ATT = 1.9809, SE = 2.6817, p = 0.50110\n",
      "✅ SubSubCat_Quetiapine | Seed 7: ATT = 3.4291, SE = 2.5843, p = 0.25522\n",
      "✅ SubSubCat_Quetiapine | Seed 8: ATT = 2.6223, SE = 2.3029, p = 0.31841\n",
      "✅ SubSubCat_Quetiapine | Seed 9: ATT = 2.0119, SE = 2.4199, p = 0.45249\n",
      "✅ SubSubCat_Quetiapine | Seed 10: ATT = 1.7767, SE = 1.4068, p = 0.27522\n",
      "📊 Diagnostic plots saved for SubSubCat_Quetiapine\n",
      "🏆 Best result for SubSubCat_Quetiapine → Seed 10 | SE = 1.4068\n",
      "\n",
      "🚀 Running OLS for SubSubCat_Amitriptyline\n",
      "✅ SubSubCat_Amitriptyline | Seed 1: ATT = 11.7404, SE = 16.7821, p = 0.52274\n",
      "✅ SubSubCat_Amitriptyline | Seed 2: ATT = 15.6951, SE = 12.1067, p = 0.26457\n",
      "✅ SubSubCat_Amitriptyline | Seed 3: ATT = 5.6273, SE = 11.3403, p = 0.64577\n",
      "✅ SubSubCat_Amitriptyline | Seed 4: ATT = 7.6439, SE = 15.1075, p = 0.63949\n",
      "✅ SubSubCat_Amitriptyline | Seed 5: ATT = 8.4376, SE = 9.6965, p = 0.43332\n",
      "✅ SubSubCat_Amitriptyline | Seed 6: ATT = 7.7133, SE = 19.2415, p = 0.70901\n",
      "✅ SubSubCat_Amitriptyline | Seed 7: ATT = 17.1304, SE = 12.4555, p = 0.24103\n",
      "✅ SubSubCat_Amitriptyline | Seed 8: ATT = 15.6706, SE = 14.1349, p = 0.32975\n",
      "✅ SubSubCat_Amitriptyline | Seed 9: ATT = 20.9402, SE = 14.0677, p = 0.21084\n",
      "✅ SubSubCat_Amitriptyline | Seed 10: ATT = 10.5706, SE = 12.5536, p = 0.44717\n",
      "📊 Diagnostic plots saved for SubSubCat_Amitriptyline\n",
      "🏆 Best result for SubSubCat_Amitriptyline → Seed 5 | SE = 9.6965\n",
      "\n",
      "🚀 Running OLS for SubSubCat_Venlafaxine\n",
      "✅ SubSubCat_Venlafaxine | Seed 1: ATT = -0.0652, SE = 6.8886, p = 0.99290\n",
      "✅ SubSubCat_Venlafaxine | Seed 2: ATT = -6.1866, SE = 9.2762, p = 0.54131\n",
      "✅ SubSubCat_Venlafaxine | Seed 3: ATT = 0.8383, SE = 10.6266, p = 0.94091\n",
      "✅ SubSubCat_Venlafaxine | Seed 4: ATT = 1.2724, SE = 8.3634, p = 0.88644\n",
      "✅ SubSubCat_Venlafaxine | Seed 5: ATT = -1.8611, SE = 5.5204, p = 0.75296\n",
      "✅ SubSubCat_Venlafaxine | Seed 6: ATT = 0.0123, SE = 7.6212, p = 0.99879\n",
      "✅ SubSubCat_Venlafaxine | Seed 7: ATT = -0.2856, SE = 5.3304, p = 0.95984\n",
      "✅ SubSubCat_Venlafaxine | Seed 8: ATT = 4.7558, SE = 10.9343, p = 0.68604\n",
      "✅ SubSubCat_Venlafaxine | Seed 9: ATT = 0.3922, SE = 9.4837, p = 0.96899\n",
      "✅ SubSubCat_Venlafaxine | Seed 10: ATT = -3.6042, SE = 6.8094, p = 0.62461\n",
      "📊 Diagnostic plots saved for SubSubCat_Venlafaxine\n",
      "🏆 Best result for SubSubCat_Venlafaxine → Seed 7 | SE = 5.3304\n",
      "\n",
      "🚀 Running OLS for SubSubCat_Fluoxetine\n",
      "✅ SubSubCat_Fluoxetine | Seed 1: ATT = 8.3367, SE = 4.9752, p = 0.16912\n",
      "✅ SubSubCat_Fluoxetine | Seed 2: ATT = 7.0653, SE = 5.2782, p = 0.25172\n",
      "✅ SubSubCat_Fluoxetine | Seed 3: ATT = 9.6790, SE = 4.3898, p = 0.09215\n",
      "✅ SubSubCat_Fluoxetine | Seed 4: ATT = 9.3573, SE = 3.5893, p = 0.05961\n",
      "✅ SubSubCat_Fluoxetine | Seed 5: ATT = 7.6744, SE = 4.9976, p = 0.19943\n",
      "✅ SubSubCat_Fluoxetine | Seed 6: ATT = 8.2564, SE = 5.0144, p = 0.17500\n",
      "✅ SubSubCat_Fluoxetine | Seed 7: ATT = 12.3462, SE = 4.0496, p = 0.03808\n",
      "✅ SubSubCat_Fluoxetine | Seed 8: ATT = 8.4987, SE = 6.0682, p = 0.23396\n",
      "✅ SubSubCat_Fluoxetine | Seed 9: ATT = 7.4001, SE = 8.5954, p = 0.43782\n",
      "✅ SubSubCat_Fluoxetine | Seed 10: ATT = 10.1965, SE = 5.6039, p = 0.14295\n",
      "📊 Diagnostic plots saved for SubSubCat_Fluoxetine\n",
      "🏆 Best result for SubSubCat_Fluoxetine → Seed 4 | SE = 3.5893\n",
      "\n",
      "🚀 Running OLS for SubSubCat_Topiramaat\n",
      "✅ SubSubCat_Topiramaat | Seed 1: ATT = 12.6590, SE = 7.2918, p = 0.15756\n",
      "✅ SubSubCat_Topiramaat | Seed 2: ATT = 7.9133, SE = 5.7128, p = 0.23824\n",
      "✅ SubSubCat_Topiramaat | Seed 3: ATT = 6.0593, SE = 5.1618, p = 0.30557\n",
      "✅ SubSubCat_Topiramaat | Seed 4: ATT = 10.8172, SE = 7.8396, p = 0.23975\n",
      "✅ SubSubCat_Topiramaat | Seed 5: ATT = 8.5103, SE = 6.9414, p = 0.28743\n",
      "✅ SubSubCat_Topiramaat | Seed 6: ATT = 14.0764, SE = 5.6571, p = 0.06761\n",
      "✅ SubSubCat_Topiramaat | Seed 7: ATT = 7.9187, SE = 9.3296, p = 0.44382\n",
      "✅ SubSubCat_Topiramaat | Seed 8: ATT = 8.0656, SE = 8.0887, p = 0.37513\n",
      "✅ SubSubCat_Topiramaat | Seed 9: ATT = 12.7322, SE = 7.0997, p = 0.14738\n",
      "✅ SubSubCat_Topiramaat | Seed 10: ATT = 11.0649, SE = 7.6758, p = 0.22288\n",
      "📊 Diagnostic plots saved for SubSubCat_Topiramaat\n",
      "🏆 Best result for SubSubCat_Topiramaat → Seed 3 | SE = 5.1618\n",
      "\n",
      "🚀 Running OLS for SubSubCat_Zopiclon\n",
      "✅ SubSubCat_Zopiclon | Seed 1: ATT = -4.5978, SE = 9.3252, p = 0.64782\n",
      "✅ SubSubCat_Zopiclon | Seed 2: ATT = -9.0664, SE = 5.1847, p = 0.15525\n",
      "✅ SubSubCat_Zopiclon | Seed 3: ATT = -6.0705, SE = 6.3214, p = 0.39128\n",
      "✅ SubSubCat_Zopiclon | Seed 4: ATT = -4.2508, SE = 7.4912, p = 0.60074\n",
      "✅ SubSubCat_Zopiclon | Seed 5: ATT = -6.1300, SE = 6.1917, p = 0.37821\n",
      "✅ SubSubCat_Zopiclon | Seed 6: ATT = -6.8818, SE = 7.1915, p = 0.39279\n",
      "✅ SubSubCat_Zopiclon | Seed 7: ATT = -7.2118, SE = 5.5583, p = 0.26424\n",
      "✅ SubSubCat_Zopiclon | Seed 8: ATT = -6.5212, SE = 7.2382, p = 0.41856\n",
      "✅ SubSubCat_Zopiclon | Seed 9: ATT = -9.1053, SE = 5.5709, p = 0.17751\n",
      "✅ SubSubCat_Zopiclon | Seed 10: ATT = -5.9644, SE = 6.8506, p = 0.43308\n",
      "📊 Diagnostic plots saved for SubSubCat_Zopiclon\n",
      "🏆 Best result for SubSubCat_Zopiclon → Seed 2 | SE = 5.1847\n",
      "\n",
      "🚀 Running OLS for SubSubCat_Bupropion\n",
      "✅ SubSubCat_Bupropion | Seed 1: ATT = 0.0000, SE = 0.0000, p = 0.74100\n",
      "✅ SubSubCat_Bupropion | Seed 2: ATT = 1.6658, SE = 4.6406, p = 0.73776\n",
      "✅ SubSubCat_Bupropion | Seed 3: ATT = 2.8825, SE = 7.5473, p = 0.72194\n",
      "✅ SubSubCat_Bupropion | Seed 4: ATT = 0.0000, SE = 0.0000, p = 0.59583\n",
      "✅ SubSubCat_Bupropion | Seed 5: ATT = 2.6649, SE = 8.6822, p = 0.77421\n",
      "✅ SubSubCat_Bupropion | Seed 6: ATT = 3.3188, SE = 9.3804, p = 0.74135\n",
      "✅ SubSubCat_Bupropion | Seed 7: ATT = 1.6194, SE = 5.3799, p = 0.77840\n",
      "✅ SubSubCat_Bupropion | Seed 8: ATT = 3.2901, SE = 8.5426, p = 0.71974\n",
      "✅ SubSubCat_Bupropion | Seed 9: ATT = 2.0273, SE = 6.1831, p = 0.75945\n",
      "✅ SubSubCat_Bupropion | Seed 10: ATT = 2.5955, SE = 7.5069, p = 0.74695\n",
      "📊 Diagnostic plots saved for SubSubCat_Bupropion\n",
      "🏆 Best result for SubSubCat_Bupropion → Seed 4 | SE = 0.0000\n",
      "\n",
      "🚀 Running OLS for SubSubCat_Methylfenidaat\n",
      "✅ SubSubCat_Methylfenidaat | Seed 1: ATT = 0.5565, SE = 8.4860, p = 0.95086\n",
      "✅ SubSubCat_Methylfenidaat | Seed 2: ATT = 7.0260, SE = 8.5873, p = 0.45919\n",
      "✅ SubSubCat_Methylfenidaat | Seed 3: ATT = -1.7596, SE = 14.6986, p = 0.91049\n",
      "✅ SubSubCat_Methylfenidaat | Seed 4: ATT = 1.7681, SE = 11.4598, p = 0.88485\n",
      "✅ SubSubCat_Methylfenidaat | Seed 5: ATT = 3.9116, SE = 13.9259, p = 0.79273\n",
      "✅ SubSubCat_Methylfenidaat | Seed 6: ATT = 3.8593, SE = 11.6069, p = 0.75621\n",
      "✅ SubSubCat_Methylfenidaat | Seed 7: ATT = 8.5847, SE = 9.6469, p = 0.42381\n",
      "✅ SubSubCat_Methylfenidaat | Seed 8: ATT = 5.4399, SE = 10.5747, p = 0.63407\n",
      "✅ SubSubCat_Methylfenidaat | Seed 9: ATT = 16.0336, SE = 18.0344, p = 0.42421\n",
      "✅ SubSubCat_Methylfenidaat | Seed 10: ATT = 6.3929, SE = 10.5520, p = 0.57732\n",
      "📊 Diagnostic plots saved for SubSubCat_Methylfenidaat\n",
      "🏆 Best result for SubSubCat_Methylfenidaat → Seed 1 | SE = 8.4860\n",
      "\n",
      "🚀 Running OLS for SubSubCat_Olanzapine\n",
      "✅ SubSubCat_Olanzapine | Seed 1: ATT = -3.6856, SE = 7.3057, p = 0.64045\n",
      "✅ SubSubCat_Olanzapine | Seed 2: ATT = 4.9211, SE = 11.6277, p = 0.69390\n",
      "✅ SubSubCat_Olanzapine | Seed 3: ATT = 1.3447, SE = 5.9286, p = 0.83169\n",
      "✅ SubSubCat_Olanzapine | Seed 4: ATT = 0.0228, SE = 7.0031, p = 0.99755\n",
      "✅ SubSubCat_Olanzapine | Seed 5: ATT = 2.5935, SE = 9.9952, p = 0.80808\n",
      "✅ SubSubCat_Olanzapine | Seed 6: ATT = 1.2520, SE = 6.7536, p = 0.86195\n",
      "✅ SubSubCat_Olanzapine | Seed 7: ATT = 0.0785, SE = 9.4068, p = 0.99374\n",
      "✅ SubSubCat_Olanzapine | Seed 8: ATT = -4.4360, SE = 9.2460, p = 0.65644\n",
      "✅ SubSubCat_Olanzapine | Seed 9: ATT = -0.1102, SE = 9.6211, p = 0.99141\n",
      "✅ SubSubCat_Olanzapine | Seed 10: ATT = -0.1043, SE = 6.1361, p = 0.98726\n",
      "📊 Diagnostic plots saved for SubSubCat_Olanzapine\n",
      "🏆 Best result for SubSubCat_Olanzapine → Seed 3 | SE = 5.9286\n",
      "\n",
      "🎯 All summary files saved.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import t, probplot\n",
    "import xgboost as xgb\n",
    "\n",
    "# -----------------------------\n",
    "# Configuration\n",
    "# -----------------------------\n",
    "seeds = list(range(1, 11))\n",
    "imputations = 5\n",
    "output_folder = \"outputs\"\n",
    "\n",
    "# -----------------------------\n",
    "# Diagnostic Plotting Function\n",
    "# -----------------------------\n",
    "def create_diagnostic_plots(residuals_data, fitted_data, group_name):\n",
    "    \"\"\"Create 4 diagnostic plots for model validation\"\"\"\n",
    "    plots_dir = os.path.join(output_folder, \"plots\")\n",
    "    os.makedirs(plots_dir, exist_ok=True)\n",
    "    \n",
    "    # Flatten the collected data\n",
    "    all_residuals = np.concatenate(residuals_data)\n",
    "    all_fitted = np.concatenate(fitted_data)\n",
    "    \n",
    "    # Create figure with 2x2 subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    fig.suptitle(f'Diagnostic Plots - {group_name}', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. Residuals vs Fitted\n",
    "    axes[0,0].scatter(all_fitted, all_residuals, alpha=0.6, s=20)\n",
    "    axes[0,0].axhline(y=0, color='red', linestyle='--', alpha=0.8)\n",
    "    axes[0,0].set_xlabel('Fitted Values')\n",
    "    axes[0,0].set_ylabel('Residuals')\n",
    "    axes[0,0].set_title('Residuals vs Fitted')\n",
    "    axes[0,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. QQ Plot\n",
    "    probplot(all_residuals, dist=\"norm\", plot=axes[0,1])\n",
    "    axes[0,1].set_title('Q-Q Plot (Normal)')\n",
    "    axes[0,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Residual Histogram\n",
    "    axes[1,0].hist(all_residuals, bins=30, density=True, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    axes[1,0].set_xlabel('Residuals')\n",
    "    axes[1,0].set_ylabel('Density')\n",
    "    axes[1,0].set_title('Residual Distribution')\n",
    "    axes[1,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Scale-Location Plot\n",
    "    sqrt_abs_residuals = np.sqrt(np.abs(all_residuals))\n",
    "    axes[1,1].scatter(all_fitted, sqrt_abs_residuals, alpha=0.6, s=20)\n",
    "    axes[1,1].set_xlabel('Fitted Values')\n",
    "    axes[1,1].set_ylabel('√|Residuals|')\n",
    "    axes[1,1].set_title('Scale-Location Plot')\n",
    "    axes[1,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save plot\n",
    "    plot_filename = os.path.join(plots_dir, f'{group_name}_unweighted.png')\n",
    "    plt.savefig(plot_filename, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"📊 Diagnostic plots saved for {group_name}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Rubin's Rule\n",
    "# -----------------------------\n",
    "def rubins_pool(estimates, ses):\n",
    "    m = len(estimates)\n",
    "    q_bar = np.mean(estimates)\n",
    "    u_bar = np.mean(np.square(ses))\n",
    "    b_m = np.var(estimates, ddof=1)\n",
    "    total_var = u_bar + ((1 + 1/m) * b_m)\n",
    "    total_se = np.sqrt(total_var)\n",
    "    ci_lower = q_bar - 1.96 * total_se\n",
    "    ci_upper = q_bar + 1.96 * total_se\n",
    "    p_value = 2 * (1 - t.cdf(np.abs(q_bar / total_se), df=m-1))\n",
    "    rounded_p = round(p_value, 5)\n",
    "    formatted_p = \"< 0.00001\" if rounded_p <= 0.00001 else f\"{rounded_p:.5f}\"\n",
    "    return q_bar, total_se, ci_lower, ci_upper, formatted_p\n",
    "\n",
    "# -----------------------------\n",
    "# SMD + Variance Ratio\n",
    "# -----------------------------\n",
    "def calculate_smd_vr(X, T):\n",
    "    treated = X[T == 1]\n",
    "    control = X[T == 0]\n",
    "    smd, vr = [], []\n",
    "    for col in X.columns:\n",
    "        try:\n",
    "            m1, m0 = treated[col].mean(), control[col].mean()\n",
    "            s1 = treated[col].std()\n",
    "            s0 = control[col].std()\n",
    "            pooled_sd = np.sqrt((s1 ** 2 + s0 ** 2) / 2)\n",
    "            smd.append((m1 - m0) / pooled_sd if pooled_sd > 0 else 0)\n",
    "            vr.append(s1**2 / s0**2 if s0**2 > 0 else 0)\n",
    "        except Exception:\n",
    "            smd.append(np.nan)\n",
    "            vr.append(np.nan)\n",
    "    return np.nanmean(smd), np.nanmean(vr)\n",
    "\n",
    "# -----------------------------\n",
    "# OLS Main Loop\n",
    "# -----------------------------\n",
    "def run_dml_with_trimmed_data(final_covariates_map):\n",
    "    att_results = []\n",
    "    balance_results = []\n",
    "\n",
    "    for group, covariates in final_covariates_map.items():\n",
    "        print(f\"\\n🚀 Running OLS for {group}\")\n",
    "        group_dir = os.path.join(output_folder, group)\n",
    "        os.makedirs(group_dir, exist_ok=True)\n",
    "\n",
    "        best_result = None\n",
    "        best_se = float(\"inf\")\n",
    "        \n",
    "        # Initialize lists to collect residuals and fitted values for diagnostic plots\n",
    "        group_residuals = []\n",
    "        group_fitted = []\n",
    "\n",
    "        for seed in seeds:\n",
    "            # Set random seed for this iteration\n",
    "            np.random.seed(seed)\n",
    "            \n",
    "            att_list, se_list, r2_list, rmse_list, smd_list, vr_list = [], [], [], [], [], []\n",
    "\n",
    "            for imp in range(1, imputations + 1):\n",
    "                file_path = os.path.join(group_dir, f\"trimmed_data_imp{imp}.pkl\")\n",
    "                if not os.path.exists(file_path):\n",
    "                    continue\n",
    "\n",
    "                df = pd.read_pickle(file_path)\n",
    "                if group not in df.columns or \"iptw\" not in df.columns:\n",
    "                    continue\n",
    "\n",
    "                # Add bootstrap sampling with seed-based randomization\n",
    "                n_samples = len(df)\n",
    "                bootstrap_idx = np.random.choice(n_samples, size=n_samples, replace=True)\n",
    "                df_bootstrap = df.iloc[bootstrap_idx].reset_index(drop=True)\n",
    "\n",
    "                X = df_bootstrap[covariates].copy()\n",
    "                T = df_bootstrap[group]\n",
    "                Y = df_bootstrap[\"caps5_change_baseline\"]\n",
    "                #W = df_bootstrap[\"iptw\"]\n",
    "\n",
    "                try:\n",
    "                    # Create design matrix with treatment variable and covariates\n",
    "                    X_ols = pd.concat([T, X], axis=1)\n",
    "                    X_ols = sm.add_constant(X_ols)\n",
    "                    \n",
    "                    # Fit OLS with robust standard errors (unweighted)\n",
    "                    ols_model = sm.OLS(Y, X_ols).fit(cov_type='HC1')\n",
    "                    \n",
    "                    # Extract treatment effect (coefficient of treatment variable)\n",
    "                    att = ols_model.params[group]  # Treatment coefficient\n",
    "                    se = ols_model.bse[group]  # Robust standard error for treatment\n",
    "                    \n",
    "                    att_list.append(att)\n",
    "                    se_list.append(se)\n",
    "\n",
    "                    # Calculate model fit statistics\n",
    "                    Y_pred = ols_model.fittedvalues\n",
    "                    residuals = ols_model.resid\n",
    "                    rmse = mean_squared_error(Y, Y_pred, squared=False)\n",
    "                    r2 = ols_model.rsquared\n",
    "                    r2_list.append(r2)\n",
    "                    rmse_list.append(rmse)\n",
    "                    \n",
    "                    # Collect residuals and fitted values for diagnostic plots\n",
    "                    group_residuals.append(residuals.values)\n",
    "                    group_fitted.append(Y_pred.values)\n",
    "\n",
    "                    smd, vr = calculate_smd_vr(X, T)\n",
    "                    smd_list.append(smd)\n",
    "                    vr_list.append(vr)\n",
    "                except Exception as e:\n",
    "                    print(f\"⚠️ Error in {group}, seed {seed}, imp {imp}: {e}\")\n",
    "\n",
    "            if att_list:\n",
    "                att, se, ci_l, ci_u, p_val = rubins_pool(att_list, se_list)\n",
    "                avg_r2 = np.mean(r2_list)\n",
    "                avg_rmse = np.mean(rmse_list)\n",
    "                avg_smd = np.mean(smd_list)\n",
    "                avg_vr = np.mean(vr_list)\n",
    "\n",
    "                balance_results.append({\n",
    "                    \"group\": group, \"seed\": seed, \"smd\": avg_smd, \"vr\": avg_vr\n",
    "                })\n",
    "\n",
    "                if se < best_se:\n",
    "                    best_se = se\n",
    "                    best_result = {\n",
    "                        \"group\": group, \"seed\": seed, \"att\": att, \"se\": se,\n",
    "                        \"ci_lower\": ci_l, \"ci_upper\": ci_u, \"p_value\": p_val,\n",
    "                        \"r2\": avg_r2, \"rmse\": avg_rmse\n",
    "                    }\n",
    "\n",
    "                print(f\"✅ {group} | Seed {seed}: ATT = {att:.4f}, SE = {se:.4f}, p = {p_val}\")\n",
    "            else:\n",
    "                print(f\"⚠️ No valid results for {group} | Seed {seed}\")\n",
    "\n",
    "        # Create diagnostic plots for this group\n",
    "        if group_residuals and group_fitted:\n",
    "            create_diagnostic_plots(group_residuals, group_fitted, group)\n",
    "\n",
    "        if best_result:\n",
    "            att_results.append(best_result)\n",
    "            print(f\"🏆 Best result for {group} → Seed {best_result['seed']} | SE = {best_result['se']:.4f}\")\n",
    "\n",
    "    # Save final output\n",
    "    pd.DataFrame(att_results).to_excel(\"ols_rubin_summary_subsubcats_unweighted.xlsx\", index=False)\n",
    "    pd.DataFrame(balance_results).to_excel(\"smd_vr_summary_subsubcats_unweighted.xlsx\", index=False)\n",
    "    print(\"\\n🎯 All summary files saved.\")\n",
    "\n",
    "run_dml_with_trimmed_data(final_covariates_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "23e02efd-519d-4712-b990-4d017532db01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Final_ATT_Summary_SubSubCat saved\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import sem, ttest_ind\n",
    "\n",
    "# ----------------------------------\n",
    "# File paths\n",
    "# ----------------------------------\n",
    "output_base = \"outputs\"\n",
    "att_file = \"ols_rubin_summary_subsubcats.xlsx\"\n",
    "trimmed_file = \"trimmed_data_imp1.pkl\"\n",
    "auc_file = \"auc_scores.xlsx\"  # NEW\n",
    "\n",
    "# ----------------------------------\n",
    "# Load ATT Summary\n",
    "# ----------------------------------\n",
    "if os.path.exists(att_file):\n",
    "    att_df = pd.read_excel(att_file)\n",
    "else:\n",
    "    raise FileNotFoundError(\"❌ ATT summary file not found: ols_summary_subsubcats.xlsx\")\n",
    "\n",
    "summary_rows = []\n",
    "\n",
    "# ----------------------------------\n",
    "# Loop over medication groups\n",
    "# ----------------------------------\n",
    "groups = [g for g in medication_groups if os.path.isdir(os.path.join(output_base, g))]\n",
    "\n",
    "for med in groups:\n",
    "    try:\n",
    "        group_path = os.path.join(output_base, med)\n",
    "\n",
    "        # Load trimmed data\n",
    "        df = pd.read_pickle(os.path.join(group_path, trimmed_file))\n",
    "\n",
    "        # Detect treatment column\n",
    "        treatment_cols = [col for col in df.columns if col.upper() == med.upper()]\n",
    "        if not treatment_cols:\n",
    "            print(f\"⚠️ Treatment column {med} not found in trimmed data. Skipping.\")\n",
    "            continue\n",
    "        treatment_var = treatment_cols[0]\n",
    "\n",
    "        # Extract treatment and outcome\n",
    "        T = df[treatment_var]\n",
    "        Y = df[\"caps5_change_baseline\"]\n",
    "\n",
    "        # Treated and control stats\n",
    "        treated = Y[T == 1]\n",
    "        control = Y[T == 0]\n",
    "\n",
    "        mean_treat = treated.mean()\n",
    "        se_treat = sem(treated) if len(treated) > 1 else np.nan\n",
    "\n",
    "        mean_ctrl = control.mean()\n",
    "        se_ctrl = sem(control) if len(control) > 1 else np.nan\n",
    "\n",
    "        # Cohen's d (unadjusted)\n",
    "        pooled_sd = np.sqrt(((treated.std() ** 2) + (control.std() ** 2)) / 2)\n",
    "        cohen_d = (mean_treat - mean_ctrl) / pooled_sd if pooled_sd > 0 else np.nan\n",
    "\n",
    "        # E-value (unadjusted)\n",
    "        delta = mean_treat - mean_ctrl\n",
    "        E = delta / abs(mean_ctrl) * 100 if mean_ctrl != 0 else np.nan\n",
    "\n",
    "        # Unadjusted p-value\n",
    "        try:\n",
    "            t_stat, p_val = ttest_ind(treated, control, equal_var=False, nan_policy=\"omit\")\n",
    "            rounded_p = round(p_val, 5)\n",
    "            formatted_p = \"< 0.00001\" if rounded_p < 0.00001 else rounded_p\n",
    "        except Exception:\n",
    "            formatted_p = np.nan\n",
    "\n",
    "        # AUC from new auc_scores.xlsx file\n",
    "        auc_val = np.nan\n",
    "        auc_path = os.path.join(group_path, auc_file)\n",
    "        if os.path.exists(auc_path):\n",
    "            auc_df = pd.read_excel(auc_path)\n",
    "            if \"AUC\" in auc_df.columns:\n",
    "                auc_val = auc_df[\"AUC\"].dropna().mean()\n",
    "\n",
    "        # Adjusted stats from Rubin summary\n",
    "        att_row = att_df[att_df[\"group\"].str.strip().str.upper() == med.strip().upper()]\n",
    "        if not att_row.empty:\n",
    "            att = att_row.iloc[0][\"att\"]\n",
    "            att_se = att_row.iloc[0][\"se\"]\n",
    "            att_p_val = att_row.iloc[0][\"p_value\"]\n",
    "            r2 = att_row.iloc[0][\"r2\"]\n",
    "            rmse = att_row.iloc[0][\"rmse\"]\n",
    "\n",
    "            try:\n",
    "                rounded_att_p = round(float(att_p_val), 5)\n",
    "                formatted_att_p = \"< 0.00001\" if rounded_att_p < 0.00001 else rounded_att_p\n",
    "            except:\n",
    "                formatted_att_p = att_p_val\n",
    "        else:\n",
    "            att, att_se, formatted_att_p, r2, rmse = np.nan, np.nan, np.nan, np.nan, np.nan\n",
    "\n",
    "        # Append full row\n",
    "        summary_rows.append({\n",
    "            'Medication Group': med,\n",
    "            'Mean Treated': mean_treat,\n",
    "            'SE Treated': se_treat,\n",
    "            'Mean Control': mean_ctrl,\n",
    "            'SE Control': se_ctrl,\n",
    "            'Cohen d': cohen_d,\n",
    "            'E (Unadjusted)': E,\n",
    "            'n Treated': len(treated),\n",
    "            'n Control': len(control),\n",
    "            #'Unadjusted p-value': formatted_p,\n",
    "            'ATT Estimate': att,\n",
    "            'ATT SE (Robust)': att_se,\n",
    "            'ATT p-value': formatted_att_p,\n",
    "            'R²': r2,\n",
    "            'RMSE': rmse,\n",
    "            'AUC': auc_val\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error in {med}: {e}\")\n",
    "\n",
    "# ----------------------------------\n",
    "# Save final summary\n",
    "# ----------------------------------\n",
    "summary_df = pd.DataFrame(summary_rows)\n",
    "summary_df = summary_df.sort_values(\"Medication Group\")\n",
    "summary_df.to_excel(\"Final_ATT_Summary_SubSubCat.xlsx\", index=False)\n",
    "print(\"✅ Final_ATT_Summary_SubSubCat saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "fb3090fc-bcf4-4134-ba0e-4aebd0c93537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ols_att_barplot_subsubcat saved\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "# ✅ Load the final summary table\n",
    "final_df = pd.read_excel(\"Final_ATT_Summary_SubSubCat.xlsx\")\n",
    "\n",
    "# ✅ Parse DML p-values (handle \"< 0.00001\")\n",
    "def parse_pval(p):\n",
    "    try:\n",
    "        if isinstance(p, str) and \"<\" in p:\n",
    "            return 0.000001\n",
    "        return float(p)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "final_df['ATT p-value'] = final_df['ATT p-value'].apply(parse_pval)\n",
    "\n",
    "# ✅ Plot settings\n",
    "width = 0.35\n",
    "\n",
    "# ✅ Plotting function for a single medication group\n",
    "def plot_single_group(row):\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    bars1 = ax.bar(-width/2, row['Mean Control'], width, \n",
    "                   yerr=row['SE Control'], label='Control', hatch='//', color='gray', capsize=5)\n",
    "    bars2 = ax.bar(+width/2, row['Mean Treated'], width, \n",
    "                   yerr=row['SE Treated'], label='Treated', color='steelblue', capsize=5)\n",
    "\n",
    "    label = (\n",
    "        f\"ATT = {row['ATT Estimate']:.2f}\\n\"\n",
    "        f\"d = {row['Cohen d']:.2f}, p = {row['ATT p-value']:.3f}\\n\"\n",
    "        f\"nT = {row['n Treated']}, nC = {row['n Control']}\\n\"\n",
    "        f\"E = {row['E (Unadjusted)']:.1f}%\"\n",
    "    )\n",
    "    max_y = max(row['Mean Control'], row['Mean Treated']) + 1.5\n",
    "    ax.text(0, max_y, label, ha='center', va='bottom', fontsize=9, color='#FFD700')\n",
    "\n",
    "    ax.axhline(0, color='black', linewidth=0.8)\n",
    "    ax.set_xticks([-width/2, +width/2])\n",
    "    ax.set_xticklabels(['Control', 'Treated'])\n",
    "    ax.set_title(f\"Group: {row['Medication Group']}\", fontsize=12, weight='bold')\n",
    "    ax.set_ylabel(\"CAPS5 Change Score\")\n",
    "    ax.set_ylim(bottom=0, top=max_y + 2)\n",
    "    ax.legend()\n",
    "    fig.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# ✅ Generate and save all plots into a multi-page PDF\n",
    "with PdfPages(\"ols_att_barplot_subsubcat.pdf\") as pdf:\n",
    "    for idx, row in final_df.iterrows():\n",
    "        fig = plot_single_group(row)\n",
    "        pdf.savefig(fig, dpi=300, bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "print(\"✅ ols_att_barplot_subsubcat saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "1ca0cd05-2cb6-4516-b20d-55a74f23e2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Love plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "bf7bf994-5ff3-4c95-8be8-2903b37e2f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Processing SUBSUBCAT_Amitriptyline...\n",
      "📊 Exported numeric summary to: outputs\\SUBSUBCAT_Amitriptyline\\covariate_balance_table_SUBSUBCAT_Amitriptyline.xlsx\n",
      "✅ Saved love plot: outputs\\SUBSUBCAT_Amitriptyline\\love_plot_SUBSUBCAT_Amitriptyline.pdf\n",
      "📏 Max weighted SMD for SUBSUBCAT_Amitriptyline: 0.917\n",
      "\n",
      "🔍 Processing SUBSUBCAT_Bupropion...\n",
      "❌ Error in SUBSUBCAT_Bupropion: Weights sum to zero, can't be normalized\n",
      "\n",
      "🔍 Processing SUBSUBCAT_Citalopram...\n",
      "📊 Exported numeric summary to: outputs\\SUBSUBCAT_Citalopram\\covariate_balance_table_SUBSUBCAT_Citalopram.xlsx\n",
      "✅ Saved love plot: outputs\\SUBSUBCAT_Citalopram\\love_plot_SUBSUBCAT_Citalopram.pdf\n",
      "📏 Max weighted SMD for SUBSUBCAT_Citalopram: 0.133\n",
      "\n",
      "🔍 Processing SUBSUBCAT_Diazepam...\n",
      "📊 Exported numeric summary to: outputs\\SUBSUBCAT_Diazepam\\covariate_balance_table_SUBSUBCAT_Diazepam.xlsx\n",
      "✅ Saved love plot: outputs\\SUBSUBCAT_Diazepam\\love_plot_SUBSUBCAT_Diazepam.pdf\n",
      "📏 Max weighted SMD for SUBSUBCAT_Diazepam: 0.599\n",
      "\n",
      "🔍 Processing SUBSUBCAT_Escitalopram...\n",
      "📊 Exported numeric summary to: outputs\\SUBSUBCAT_Escitalopram\\covariate_balance_table_SUBSUBCAT_Escitalopram.xlsx\n",
      "✅ Saved love plot: outputs\\SUBSUBCAT_Escitalopram\\love_plot_SUBSUBCAT_Escitalopram.pdf\n",
      "📏 Max weighted SMD for SUBSUBCAT_Escitalopram: 0.423\n",
      "\n",
      "🔍 Processing SUBSUBCAT_Fluoxetine...\n",
      "📊 Exported numeric summary to: outputs\\SUBSUBCAT_Fluoxetine\\covariate_balance_table_SUBSUBCAT_Fluoxetine.xlsx\n",
      "✅ Saved love plot: outputs\\SUBSUBCAT_Fluoxetine\\love_plot_SUBSUBCAT_Fluoxetine.pdf\n",
      "📏 Max weighted SMD for SUBSUBCAT_Fluoxetine: 0.496\n",
      "\n",
      "🔍 Processing SUBSUBCAT_Lorazepam...\n",
      "📊 Exported numeric summary to: outputs\\SUBSUBCAT_Lorazepam\\covariate_balance_table_SUBSUBCAT_Lorazepam.xlsx\n",
      "✅ Saved love plot: outputs\\SUBSUBCAT_Lorazepam\\love_plot_SUBSUBCAT_Lorazepam.pdf\n",
      "📏 Max weighted SMD for SUBSUBCAT_Lorazepam: 0.270\n",
      "\n",
      "🔍 Processing SUBSUBCAT_Methylfenidaat...\n",
      "📊 Exported numeric summary to: outputs\\SUBSUBCAT_Methylfenidaat\\covariate_balance_table_SUBSUBCAT_Methylfenidaat.xlsx\n",
      "✅ Saved love plot: outputs\\SUBSUBCAT_Methylfenidaat\\love_plot_SUBSUBCAT_Methylfenidaat.pdf\n",
      "📏 Max weighted SMD for SUBSUBCAT_Methylfenidaat: 0.746\n",
      "\n",
      "🔍 Processing SUBSUBCAT_Mirtazapine...\n",
      "📊 Exported numeric summary to: outputs\\SUBSUBCAT_Mirtazapine\\covariate_balance_table_SUBSUBCAT_Mirtazapine.xlsx\n",
      "✅ Saved love plot: outputs\\SUBSUBCAT_Mirtazapine\\love_plot_SUBSUBCAT_Mirtazapine.pdf\n",
      "📏 Max weighted SMD for SUBSUBCAT_Mirtazapine: 0.218\n",
      "\n",
      "🔍 Processing SUBSUBCAT_Olanzapine...\n",
      "📊 Exported numeric summary to: outputs\\SUBSUBCAT_Olanzapine\\covariate_balance_table_SUBSUBCAT_Olanzapine.xlsx\n",
      "✅ Saved love plot: outputs\\SUBSUBCAT_Olanzapine\\love_plot_SUBSUBCAT_Olanzapine.pdf\n",
      "📏 Max weighted SMD for SUBSUBCAT_Olanzapine: 0.819\n",
      "\n",
      "🔍 Processing SUBSUBCAT_Oxazepam...\n",
      "📊 Exported numeric summary to: outputs\\SUBSUBCAT_Oxazepam\\covariate_balance_table_SUBSUBCAT_Oxazepam.xlsx\n",
      "✅ Saved love plot: outputs\\SUBSUBCAT_Oxazepam\\love_plot_SUBSUBCAT_Oxazepam.pdf\n",
      "📏 Max weighted SMD for SUBSUBCAT_Oxazepam: 0.204\n",
      "\n",
      "🔍 Processing SUBSUBCAT_Paracetamol...\n",
      "📊 Exported numeric summary to: outputs\\SUBSUBCAT_Paracetamol\\covariate_balance_table_SUBSUBCAT_Paracetamol.xlsx\n",
      "✅ Saved love plot: outputs\\SUBSUBCAT_Paracetamol\\love_plot_SUBSUBCAT_Paracetamol.pdf\n",
      "📏 Max weighted SMD for SUBSUBCAT_Paracetamol: 0.466\n",
      "\n",
      "🔍 Processing SUBSUBCAT_Quetiapine...\n",
      "📊 Exported numeric summary to: outputs\\SUBSUBCAT_Quetiapine\\covariate_balance_table_SUBSUBCAT_Quetiapine.xlsx\n",
      "✅ Saved love plot: outputs\\SUBSUBCAT_Quetiapine\\love_plot_SUBSUBCAT_Quetiapine.pdf\n",
      "📏 Max weighted SMD for SUBSUBCAT_Quetiapine: 0.201\n",
      "\n",
      "🔍 Processing SUBSUBCAT_Sertraline...\n",
      "📊 Exported numeric summary to: outputs\\SUBSUBCAT_Sertraline\\covariate_balance_table_SUBSUBCAT_Sertraline.xlsx\n",
      "✅ Saved love plot: outputs\\SUBSUBCAT_Sertraline\\love_plot_SUBSUBCAT_Sertraline.pdf\n",
      "📏 Max weighted SMD for SUBSUBCAT_Sertraline: 0.281\n",
      "\n",
      "🔍 Processing SUBSUBCAT_Temazepam...\n",
      "📊 Exported numeric summary to: outputs\\SUBSUBCAT_Temazepam\\covariate_balance_table_SUBSUBCAT_Temazepam.xlsx\n",
      "✅ Saved love plot: outputs\\SUBSUBCAT_Temazepam\\love_plot_SUBSUBCAT_Temazepam.pdf\n",
      "📏 Max weighted SMD for SUBSUBCAT_Temazepam: 0.291\n",
      "\n",
      "🔍 Processing SUBSUBCAT_Topiramaat...\n",
      "📊 Exported numeric summary to: outputs\\SUBSUBCAT_Topiramaat\\covariate_balance_table_SUBSUBCAT_Topiramaat.xlsx\n",
      "✅ Saved love plot: outputs\\SUBSUBCAT_Topiramaat\\love_plot_SUBSUBCAT_Topiramaat.pdf\n",
      "📏 Max weighted SMD for SUBSUBCAT_Topiramaat: 0.415\n",
      "\n",
      "🔍 Processing SUBSUBCAT_Venlafaxine...\n",
      "📊 Exported numeric summary to: outputs\\SUBSUBCAT_Venlafaxine\\covariate_balance_table_SUBSUBCAT_Venlafaxine.xlsx\n",
      "✅ Saved love plot: outputs\\SUBSUBCAT_Venlafaxine\\love_plot_SUBSUBCAT_Venlafaxine.pdf\n",
      "📏 Max weighted SMD for SUBSUBCAT_Venlafaxine: 0.631\n",
      "\n",
      "🔍 Processing SUBSUBCAT_Zopiclon...\n",
      "📊 Exported numeric summary to: outputs\\SUBSUBCAT_Zopiclon\\covariate_balance_table_SUBSUBCAT_Zopiclon.xlsx\n",
      "✅ Saved love plot: outputs\\SUBSUBCAT_Zopiclon\\love_plot_SUBSUBCAT_Zopiclon.pdf\n",
      "📏 Max weighted SMD for SUBSUBCAT_Zopiclon: 0.692\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "# ----------------------------------------\n",
    "# Functions to calculate balance\n",
    "# ----------------------------------------\n",
    "def calculate_smd(x1, x2, w1=None, w2=None):\n",
    "    def weighted_mean(x, w): return np.average(x, weights=w)\n",
    "    def weighted_var(x, w):\n",
    "        m = np.average(x, weights=w)\n",
    "        return np.average((x - m) ** 2, weights=w)\n",
    "    \n",
    "    m1 = weighted_mean(x1, w1) if w1 is not None else np.mean(x1)\n",
    "    m2 = weighted_mean(x2, w2) if w2 is not None else np.mean(x2)\n",
    "    v1 = weighted_var(x1, w1) if w1 is not None else np.var(x1, ddof=1)\n",
    "    v2 = weighted_var(x2, w2) if w2 is not None else np.var(x2, ddof=1)\n",
    "    \n",
    "    pooled_sd = np.sqrt((v1 + v2) / 2)\n",
    "    return np.abs(m1 - m2) / pooled_sd if pooled_sd > 0 else 0\n",
    "\n",
    "def variance_ratio(x1, x2, w1=None, w2=None):\n",
    "    def weighted_var(x, w):\n",
    "        m = np.average(x, weights=w)\n",
    "        return np.average((x - m) ** 2, weights=w)\n",
    "    \n",
    "    v1 = weighted_var(x1, w1) if w1 is not None else np.var(x1, ddof=1)\n",
    "    v2 = weighted_var(x2, w2) if w2 is not None else np.var(x2, ddof=1)\n",
    "    \n",
    "    return max(v1 / v2, v2 / v1) if v1 > 0 and v2 > 0 else 1\n",
    "\n",
    "# ----------------------------------------\n",
    "# Setup\n",
    "# ----------------------------------------\n",
    "output_base = \"outputs\"\n",
    "groups = [g for g in os.listdir(output_base) if os.path.isdir(os.path.join(output_base, g))]\n",
    "\n",
    "# Create a case-insensitive mapping\n",
    "final_covariates_map_lower = {k.lower(): v for k, v in final_covariates_map.items()}\n",
    "\n",
    "# ----------------------------------------\n",
    "# Main Loop\n",
    "# ----------------------------------------\n",
    "for group in groups:\n",
    "    if group.lower() not in final_covariates_map_lower:\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n🔍 Processing {group}...\")\n",
    "\n",
    "    try:\n",
    "        group_path = os.path.join(output_base, group)\n",
    "        covariates = final_covariates_map_lower[group.lower()]\n",
    "        \n",
    "        column_name = None\n",
    "        for col in pd.read_pickle(os.path.join(group_path, \"trimmed_data_imp1.pkl\")).columns:\n",
    "            if col.lower() == group.lower():\n",
    "                column_name = col\n",
    "                break\n",
    "        if column_name is None:\n",
    "            print(f\"⚠️ Column not found for {group}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        smd_unw_all, smd_w_all = [], []\n",
    "        vr_unw_all, vr_w_all = [], []\n",
    "\n",
    "        for i in range(1, 6):\n",
    "            df_path = os.path.join(group_path, f\"trimmed_data_imp{i}.pkl\")\n",
    "            iptw_path = os.path.join(group_path, \"iptw_weights.xlsx\")\n",
    "\n",
    "            if not os.path.exists(df_path) or not os.path.exists(iptw_path):\n",
    "                print(f\"⚠️ Missing data for {group} imp{i}, skipping.\")\n",
    "                continue\n",
    "\n",
    "            df = pd.read_pickle(df_path)\n",
    "            iptw_df = pd.read_excel(iptw_path, index_col=0)\n",
    "            T = df[column_name]\n",
    "            W = iptw_df.loc[df.index, \"iptw_mean\"]\n",
    "\n",
    "            smd_unw_i, smd_w_i, vr_unw_i, vr_w_i = [], [], [], []\n",
    "\n",
    "            for cov in covariates:\n",
    "                x1, x0 = df.loc[T == 1, cov], df.loc[T == 0, cov]\n",
    "                w1, w0 = W[T == 1], W[T == 0]\n",
    "\n",
    "                su = calculate_smd(x1, x0)\n",
    "                sw = calculate_smd(x1, x0, w1, w0)\n",
    "\n",
    "                vu = variance_ratio(x1, x0) if cov in ['treatmentdurationdays', 'CAPS5score_baseline', 'age'] else np.nan\n",
    "                vw = variance_ratio(x1, x0, w1, w0) if cov in ['treatmentdurationdays', 'CAPS5score_baseline', 'age'] else np.nan\n",
    "\n",
    "                smd_unw_i.append(su)\n",
    "                smd_w_i.append(sw)\n",
    "                vr_unw_i.append(vu)\n",
    "                vr_w_i.append(vw)\n",
    "\n",
    "            smd_unw_all.append(smd_unw_i)\n",
    "            smd_w_all.append(smd_w_i)\n",
    "            vr_unw_all.append(vr_unw_i)\n",
    "            vr_w_all.append(vr_w_i)\n",
    "\n",
    "        smd_unw = np.mean(smd_unw_all, axis=0)\n",
    "        smd_w = np.mean(smd_w_all, axis=0)\n",
    "        vr_unw = np.nanmean(vr_unw_all, axis=0)\n",
    "        vr_w = np.nanmean(vr_w_all, axis=0)\n",
    "\n",
    "        severity = []\n",
    "        for sw in smd_w:\n",
    "            if sw <= 0.1:\n",
    "                severity.append(\"Good\")\n",
    "            elif sw <= 0.2:\n",
    "                severity.append(\"Moderate\")\n",
    "            else:\n",
    "                severity.append(\"Poor\")\n",
    "\n",
    "        covariate_names = covariates\n",
    "        numeric_df = pd.DataFrame({\n",
    "            \"Covariate\": covariate_names,\n",
    "            \"SMD_Unweighted\": smd_unw,\n",
    "            \"SMD_Weighted\": smd_w,\n",
    "            \"Imbalance_Severity\": severity,\n",
    "            \"VR_Unweighted\": vr_unw,\n",
    "            \"VR_Weighted\": vr_w\n",
    "        })\n",
    "\n",
    "        numeric_path = os.path.join(group_path, f\"covariate_balance_table_{group}.xlsx\")\n",
    "        numeric_df.to_excel(numeric_path, index=False)\n",
    "        print(f\"📊 Exported numeric summary to: {numeric_path}\")\n",
    "\n",
    "        # -------------------------\n",
    "        # Plot\n",
    "        # -------------------------\n",
    "        labels = covariates\n",
    "        y_pos = np.arange(len(labels))\n",
    "\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(18, len(labels) * 0.45))\n",
    "\n",
    "        axes[0].scatter(smd_unw, y_pos, color='red', label=\"Unweighted\")\n",
    "        axes[0].scatter(smd_w, y_pos, color='blue', label=\"Weighted\")\n",
    "        axes[0].axvline(0.1, color='gray', linestyle='--', label=\"Threshold 0.1\")\n",
    "        axes[0].axvline(0.2, color='black', linestyle='--', label=\"Threshold 0.2\")\n",
    "        axes[0].set_xlim(0, max(max(smd_unw), max(smd_w), 0.25) + 0.05)\n",
    "        axes[0].set_yticks(y_pos)\n",
    "        axes[0].set_yticklabels(labels)\n",
    "        axes[0].invert_yaxis()\n",
    "        axes[0].set_title(\"Standardized Mean Differences (SMD)\")\n",
    "        axes[0].legend(loc=\"upper right\")\n",
    "        axes[0].grid(True)\n",
    "\n",
    "        vr_mask = [cov in ['treatmentdurationdays', 'CAPS5score_baseline', 'age'] for cov in covariates]\n",
    "        filtered_y = [i for i, b in enumerate(vr_mask) if b]\n",
    "        filtered_labels = [labels[i] for i in filtered_y]\n",
    "        filtered_vr_unw = [vr_unw[i] for i in filtered_y]\n",
    "        filtered_vr_w = [vr_w[i] for i in filtered_y]\n",
    "\n",
    "        axes[1].scatter(filtered_vr_unw, filtered_y, color='blue', marker='o', label=\"Unweighted\")\n",
    "        axes[1].scatter(filtered_vr_w, filtered_y, color='red', marker='x', label=\"Weighted\")\n",
    "        axes[1].axvline(2, color='gray', linestyle='--')\n",
    "        axes[1].axvline(0.5, color='gray', linestyle='--')\n",
    "        axes[1].set_xlim(0, max(filtered_vr_unw + filtered_vr_w + [2.5]) + 0.5)\n",
    "        axes[1].set_yticks(filtered_y)\n",
    "        axes[1].set_yticklabels(filtered_labels)\n",
    "        axes[1].invert_yaxis()\n",
    "        axes[1].set_title(\"Variance Ratio (VR)\")\n",
    "        axes[1].legend()\n",
    "        axes[1].grid(True)\n",
    "\n",
    "        fig.suptitle(f\"Covariate Balance for {group.replace('CAT_', '')}\", fontsize=14, weight='bold')\n",
    "        fig.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "        plot_path = os.path.join(group_path, f\"love_plot_{group}.pdf\")\n",
    "        fig.savefig(plot_path, dpi=300)\n",
    "        plt.close()\n",
    "        print(f\"✅ Saved love plot: {plot_path}\")\n",
    "        print(f\"📏 Max weighted SMD for {group}: {np.max(smd_w):.3f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error in {group}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "351cdcc2-c480-437b-a023-c81a95efbb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "1f2a0c4e-78d3-42d2-b3f4-7aa21c575faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Creating Heatmap for SubSubCat_Oxazepam ==========\n",
      "✅ Heatmap saved: outputs\\SubSubCat_Oxazepam\\heatmap_smd_SubSubCat_Oxazepam.png\n",
      "\n",
      "========== Creating Heatmap for SubSubCat_Diazepam ==========\n",
      "✅ Heatmap saved: outputs\\SubSubCat_Diazepam\\heatmap_smd_SubSubCat_Diazepam.png\n",
      "\n",
      "========== Creating Heatmap for SubSubCat_Paracetamol ==========\n",
      "✅ Heatmap saved: outputs\\SubSubCat_Paracetamol\\heatmap_smd_SubSubCat_Paracetamol.png\n",
      "\n",
      "========== Creating Heatmap for SubSubCat_Lorazepam ==========\n",
      "✅ Heatmap saved: outputs\\SubSubCat_Lorazepam\\heatmap_smd_SubSubCat_Lorazepam.png\n",
      "\n",
      "========== Creating Heatmap for SubSubCat_Mirtazapine ==========\n",
      "✅ Heatmap saved: outputs\\SubSubCat_Mirtazapine\\heatmap_smd_SubSubCat_Mirtazapine.png\n",
      "\n",
      "========== Creating Heatmap for SubSubCat_Escitalopram ==========\n",
      "✅ Heatmap saved: outputs\\SubSubCat_Escitalopram\\heatmap_smd_SubSubCat_Escitalopram.png\n",
      "\n",
      "========== Creating Heatmap for SubSubCat_Sertraline ==========\n",
      "✅ Heatmap saved: outputs\\SubSubCat_Sertraline\\heatmap_smd_SubSubCat_Sertraline.png\n",
      "\n",
      "========== Creating Heatmap for SubSubCat_Temazepam ==========\n",
      "✅ Heatmap saved: outputs\\SubSubCat_Temazepam\\heatmap_smd_SubSubCat_Temazepam.png\n",
      "\n",
      "========== Creating Heatmap for SubSubCat_Citalopram ==========\n",
      "✅ Heatmap saved: outputs\\SubSubCat_Citalopram\\heatmap_smd_SubSubCat_Citalopram.png\n",
      "\n",
      "========== Creating Heatmap for SubSubCat_Quetiapine ==========\n",
      "✅ Heatmap saved: outputs\\SubSubCat_Quetiapine\\heatmap_smd_SubSubCat_Quetiapine.png\n",
      "\n",
      "========== Creating Heatmap for SubSubCat_Amitriptyline ==========\n",
      "✅ Heatmap saved: outputs\\SubSubCat_Amitriptyline\\heatmap_smd_SubSubCat_Amitriptyline.png\n",
      "\n",
      "========== Creating Heatmap for SubSubCat_Venlafaxine ==========\n",
      "✅ Heatmap saved: outputs\\SubSubCat_Venlafaxine\\heatmap_smd_SubSubCat_Venlafaxine.png\n",
      "\n",
      "========== Creating Heatmap for SubSubCat_Fluoxetine ==========\n",
      "✅ Heatmap saved: outputs\\SubSubCat_Fluoxetine\\heatmap_smd_SubSubCat_Fluoxetine.png\n",
      "\n",
      "========== Creating Heatmap for SubSubCat_Topiramaat ==========\n",
      "✅ Heatmap saved: outputs\\SubSubCat_Topiramaat\\heatmap_smd_SubSubCat_Topiramaat.png\n",
      "\n",
      "========== Creating Heatmap for SubSubCat_Zopiclon ==========\n",
      "✅ Heatmap saved: outputs\\SubSubCat_Zopiclon\\heatmap_smd_SubSubCat_Zopiclon.png\n",
      "\n",
      "========== Creating Heatmap for SubSubCat_Bupropion ==========\n",
      "❌ Balance file not found: outputs\\SubSubCat_Bupropion\\covariate_balance_table_SubSubCat_Bupropion.xlsx\n",
      "\n",
      "========== Creating Heatmap for SubSubCat_Methylfenidaat ==========\n",
      "✅ Heatmap saved: outputs\\SubSubCat_Methylfenidaat\\heatmap_smd_SubSubCat_Methylfenidaat.png\n",
      "\n",
      "========== Creating Heatmap for SubSubCat_Olanzapine ==========\n",
      "✅ Heatmap saved: outputs\\SubSubCat_Olanzapine\\heatmap_smd_SubSubCat_Olanzapine.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "#-----------------------------\n",
    "# Generate heatmaps\n",
    "# -------------------------------\n",
    "for treatment_var in medication_groups:\n",
    "    print(f\"\\n========== Creating Heatmap for {treatment_var} ==========\")\n",
    "\n",
    "    try:\n",
    "        output_folder = os.path.join('outputs', treatment_var)\n",
    "        balance_path = os.path.join(output_folder, f'covariate_balance_table_{treatment_var}.xlsx')\n",
    "\n",
    "        if not os.path.exists(balance_path):\n",
    "            print(f\"❌ Balance file not found: {balance_path}\")\n",
    "            continue\n",
    "\n",
    "        balance_df = pd.read_excel(balance_path)\n",
    "\n",
    "        # ✅ Use finalized covariates + 'Propensity Score'\n",
    "        covariates = final_covariates_map[treatment_var] + ['Propensity Score']\n",
    "        balance_df = balance_df[balance_df['Covariate'].isin(covariates)]\n",
    "\n",
    "        # ✅ Check for CAPS5score_baseline\n",
    "        highlight_caps = 'CAPS5score_baseline' in balance_df['Covariate'].values\n",
    "\n",
    "        # ✅ Format for heatmap\n",
    "        heatmap_df = balance_df[['Covariate', 'SMD_Unweighted', 'SMD_Weighted']].copy()\n",
    "        heatmap_df.columns = ['Covariate', 'Unweighted', 'Weighted']\n",
    "        heatmap_df = heatmap_df.set_index('Covariate')\n",
    "        heatmap_df = heatmap_df.sort_values(by='Unweighted', ascending=False)\n",
    "\n",
    "        # ✅ Plot\n",
    "        plt.figure(figsize=(12, max(10, len(heatmap_df) * 0.35)))\n",
    "        ax = sns.heatmap(\n",
    "            heatmap_df,\n",
    "            cmap=\"coolwarm\",\n",
    "            annot=True,\n",
    "            fmt=\".2f\",\n",
    "            linewidths=0.6,\n",
    "            linecolor='gray',\n",
    "            cbar_kws={\"label\": \"Standardized Mean Difference\"}\n",
    "        )\n",
    "\n",
    "        plt.title(f\"Covariate Balance Heatmap (Rubin IPTW)\\n{treatment_var}\", fontsize=15, weight='bold')\n",
    "        plt.xlabel(\"Condition\")\n",
    "        plt.ylabel(\"Covariate\")\n",
    "\n",
    "        # ✅ Bold CAPS5score_baseline if present\n",
    "        if highlight_caps:\n",
    "            ylabels = [label.get_text() for label in ax.get_yticklabels()]\n",
    "            ax.set_yticklabels([\n",
    "                f\"{label} ←\" if label == 'CAPS5score_baseline' else label for label in ylabels\n",
    "            ])\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # ✅ Save image\n",
    "        save_path = os.path.join(output_folder, f'heatmap_smd_{treatment_var}.png')\n",
    "        plt.savefig(save_path, dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "        print(f\"✅ Heatmap saved: {save_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error processing {treatment_var}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91c1872-86ad-4dd6-9015-795fe70a59d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
